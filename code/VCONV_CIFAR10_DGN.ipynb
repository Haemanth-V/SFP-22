{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "60b216e5a90f4ee3b5651069ad98028a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77d5339b69cd414185724ea453e7e9c4",
              "IPY_MODEL_4480894d3f8241f9921ffafc9782201a",
              "IPY_MODEL_769f498fcfe74cee8318f9990bde4e98"
            ],
            "layout": "IPY_MODEL_0f00e7829ab34ef4aa8f3708fce8417e"
          }
        },
        "77d5339b69cd414185724ea453e7e9c4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7510440a55b54f5888d6232fede727d6",
            "placeholder": "​",
            "style": "IPY_MODEL_f81c788de72e475280f0c7be32624601",
            "value": ""
          }
        },
        "4480894d3f8241f9921ffafc9782201a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7748b2b3eb13465baedd02b633f59cdf",
            "max": 170498071,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_ac9182457a5c4e7aac1aa103c5058f5a",
            "value": 170498071
          }
        },
        "769f498fcfe74cee8318f9990bde4e98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_c5d50102e1ca4ffb86f78f80384f48d8",
            "placeholder": "​",
            "style": "IPY_MODEL_daab4de79c4e4a85b0df57b3fce5768b",
            "value": " 170499072/? [00:02&lt;00:00, 73605287.94it/s]"
          }
        },
        "0f00e7829ab34ef4aa8f3708fce8417e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7510440a55b54f5888d6232fede727d6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f81c788de72e475280f0c7be32624601": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7748b2b3eb13465baedd02b633f59cdf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ac9182457a5c4e7aac1aa103c5058f5a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "c5d50102e1ca4ffb86f78f80384f48d8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "daab4de79c4e4a85b0df57b3fce5768b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "yMbJIL709WuX"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4NZGI_gTE6c3"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import argparse\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import re\n",
        "import torch.optim as optim\n",
        "import torch.nn.init as initialization\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Constants"
      ],
      "metadata": {
        "id": "dBx2W6gEKbPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "img_width = 32"
      ],
      "metadata": {
        "id": "oQ_HxUi5Kbe4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "args={}\n",
        "kwargs={}\n",
        "\n",
        "args['image_size'] = img_width*img_width  #Number of features in the input image\n",
        "args['channels'] = 3  #Number of color channels for each image(3 usually for RGB)\n",
        "args['batch_size']=32  #Number of samples in each batch\n",
        "args['epochs']=80  #The number of Epochs is the number of times you go through the full dataset. \n",
        "args['lr']=1e-2  #Learning rate is how fast it will decend. \n",
        "\n",
        "args['cuda']=True  #Use GPU or not"
      ],
      "metadata": {
        "id": "6gE_jyoa9bSU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lossFn = nn.NLLLoss()\n",
        "eps, beta = 0.1, 4"
      ],
      "metadata": {
        "id": "lUnQFDGXYjMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load CIFAR10 Dataset"
      ],
      "metadata": {
        "id": "GX5GjvZaIMGl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "\n",
        "train_set = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=args['batch_size'],\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "validation_set = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "validation_loader = torch.utils.data.DataLoader(validation_set, batch_size=args['batch_size'],\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101,
          "referenced_widgets": [
            "60b216e5a90f4ee3b5651069ad98028a",
            "77d5339b69cd414185724ea453e7e9c4",
            "4480894d3f8241f9921ffafc9782201a",
            "769f498fcfe74cee8318f9990bde4e98",
            "0f00e7829ab34ef4aa8f3708fce8417e",
            "7510440a55b54f5888d6232fede727d6",
            "f81c788de72e475280f0c7be32624601",
            "7748b2b3eb13465baedd02b633f59cdf",
            "ac9182457a5c4e7aac1aa103c5058f5a",
            "c5d50102e1ca4ffb86f78f80384f48d8",
            "daab4de79c4e4a85b0df57b3fce5768b"
          ]
        },
        "id": "e-SvFrAWFUAu",
        "outputId": "aa0482a2-77be-47ce-e89b-0bd49521ba30"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "60b216e5a90f4ee3b5651069ad98028a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# functions to show an image\n",
        "\n",
        "def imshow(img):\n",
        "    img = img / 2 + 0.5     # denormalize\n",
        "    npimg = img.numpy()\n",
        "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# get some random training images\n",
        "dataiter = iter(train_loader)\n",
        "images, labels = dataiter.next()\n",
        "\n",
        "# show images\n",
        "imshow(torchvision.utils.make_grid(images))\n",
        "# print labels\n",
        "print(' '.join(f'{classes[labels[j]]:5s}' for j in range(args['batch_size'])))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 257
        },
        "id": "E3JdJ9iPJebX",
        "outputId": "de98679b-3e0a-441b-f50d-412bec4dd4b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ship  dog   bird  dog   dog   horse car   frog  dog   bird  bird  ship  bird  frog  plane car   frog  car   car   cat   cat   cat   bird  ship  deer  bird  horse deer  frog  car   frog  frog \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check if CUDA is available(CIFAR10 takes very long time to train)\n",
        "train_on_gpu = torch.cuda.is_available()\n",
        "\n",
        "if not train_on_gpu:\n",
        "  print('CUDA is not available.  Training on CPU ...')\n",
        "else:\n",
        "  print('CUDA is available!  Training on GPU ...')\n",
        "\n",
        "device = torch.device('cuda' if train_on_gpu else 'cpu')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l2nmfgi862xz",
        "outputId": "3ba59394-7a12-4db0-d8d0-8ffa69109ea3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CUDA is available!  Training on GPU ...\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, epoch, train_loader, lossFn, optimizer):\n",
        "\n",
        "  model.train()\n",
        "  running_loss = 0.0\n",
        "  samples = 0\n",
        "\n",
        "  for batch_idx, (inputs, labels) in enumerate(train_loader):\n",
        "     \n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    \n",
        "    samples += len(inputs)\n",
        "\n",
        "    # zero the parameter gradients\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    # forward pass\n",
        "    outputs = model(inputs)\n",
        "    \n",
        "    # Compute loss\n",
        "    loss = lossFn(outputs, labels)\n",
        "\n",
        "    # backpropagation\n",
        "    loss.backward()\n",
        "\n",
        "    # optimize parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    running_loss += loss.data\n",
        "\n",
        "  # print statistics\n",
        "  print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "            epoch, samples, len(train_loader.dataset),\n",
        "            100. * batch_idx / len(train_loader), running_loss/len(train_loader)))\n",
        "\n",
        "def validate(model, validation_loader, lossFn):\n",
        "  correct = 0\n",
        "  total = 0\n",
        "  validation_loss = 0\n",
        "  model.eval()\n",
        "\n",
        "  # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "  with torch.no_grad():\n",
        "    for inputs, labels in validation_loader:\n",
        "\n",
        "      inputs, labels = inputs.to(device), labels.to(device)\n",
        "\n",
        "      # calculate outputs by running images through the network\n",
        "      outputs = model(inputs)\n",
        "\n",
        "      # Calculate loss\n",
        "      validation_loss += lossFn(outputs, labels).data.item()\n",
        "\n",
        "      # the class with the highest energy is what we choose as prediction\n",
        "      _, predicted = torch.max(outputs.data, 1)\n",
        "      \n",
        "      total += labels.size(0)\n",
        "      correct += (predicted == labels).sum().item()  #find number of correct predictions\n",
        "\n",
        "  print('\\nValidation set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
        "        validation_loss/len(validation_loader), correct, len(validation_loader.dataset),\n",
        "        100. * correct / len(validation_loader.dataset)))"
      ],
      "metadata": {
        "id": "6YJNkZ3nJwQG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ReLU"
      ],
      "metadata": {
        "id": "jO8C8vMqFUg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv4Relu(nn.Module):\n",
        "\n",
        "  def __init__(self, image_size, channels):\n",
        "\n",
        "    super(Conv4Relu, self).__init__()\n",
        "\n",
        "    #Build a Vanilla ConvNet\n",
        "    self.C1 = nn.Conv2d(channels, 64, kernel_size = (3, 3), padding = 'same')\n",
        "    self.C2 = nn.Conv2d(64, 64, kernel_size = (3, 3), padding = 'same')\n",
        "    self.C3 = nn.Conv2d(64, 128, kernel_size = (3, 3), padding = 'same')\n",
        "    self.C4 = nn.Conv2d(128, 128, kernel_size = (3, 3), padding = 'same')\n",
        "\n",
        "    self.F = nn.Flatten()\n",
        "    self.D1 = nn.Linear(image_size*128, 256)\n",
        "    self.D2 = nn.Linear(256, 256)\n",
        "\n",
        "    #Output\n",
        "    self.outputs = nn.Linear(256, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    Z = F.relu(self.C1(x))\n",
        "    Z = F.relu(self.C2(Z))\n",
        "    Z = F.relu(self.C3(Z))\n",
        "    Z = F.relu(self.C4(Z))\n",
        "\n",
        "    Z = self.F(Z)\n",
        "\n",
        "    Z = F.relu(self.D1(Z))\n",
        "    Z = F.relu(self.D2(Z))\n",
        "\n",
        "    return F.log_softmax(self.outputs(Z))"
      ],
      "metadata": {
        "id": "x7LFMyPoFTEf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "relu_model = Conv4Relu(args['image_size'], args['channels'])\n",
        "relu_model.to(device)\n",
        "relu_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kun5T5umKYAF",
        "outputId": "d8d8914d-0876-41cf-fa61-87c85d11a903"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv4Relu(\n",
              "  (C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (outputs): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(relu_model.parameters(), lr=args['lr'])"
      ],
      "metadata": {
        "id": "QKtrELlXIK3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(1, args['epochs']+1):\n",
        "  train(relu_model, epoch, train_loader, lossFn, optimizer)\n",
        "  validate(relu_model, validation_loader, lossFn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_-F5e9rsXfPc",
        "outputId": "46dbd4f1-6a43-4835-ebde-2ffb62c5cd81"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:32: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [50000/50000 (100%)]\tLoss: 1.927200\n",
            "\n",
            "Validation set: Average loss: 1.6206, Accuracy: 4232/10000 (42%)\n",
            "\n",
            "Train Epoch: 2 [50000/50000 (100%)]\tLoss: 1.497743\n",
            "\n",
            "Validation set: Average loss: 1.4256, Accuracy: 4947/10000 (49%)\n",
            "\n",
            "Train Epoch: 3 [50000/50000 (100%)]\tLoss: 1.308422\n",
            "\n",
            "Validation set: Average loss: 1.3530, Accuracy: 5245/10000 (52%)\n",
            "\n",
            "Train Epoch: 4 [50000/50000 (100%)]\tLoss: 1.161742\n",
            "\n",
            "Validation set: Average loss: 1.1726, Accuracy: 5804/10000 (58%)\n",
            "\n",
            "Train Epoch: 5 [50000/50000 (100%)]\tLoss: 1.035623\n",
            "\n",
            "Validation set: Average loss: 1.1067, Accuracy: 6087/10000 (61%)\n",
            "\n",
            "Train Epoch: 6 [50000/50000 (100%)]\tLoss: 0.911908\n",
            "\n",
            "Validation set: Average loss: 1.0452, Accuracy: 6321/10000 (63%)\n",
            "\n",
            "Train Epoch: 7 [50000/50000 (100%)]\tLoss: 0.783226\n",
            "\n",
            "Validation set: Average loss: 1.2041, Accuracy: 6010/10000 (60%)\n",
            "\n",
            "Train Epoch: 8 [50000/50000 (100%)]\tLoss: 0.650782\n",
            "\n",
            "Validation set: Average loss: 1.0707, Accuracy: 6373/10000 (64%)\n",
            "\n",
            "Train Epoch: 9 [50000/50000 (100%)]\tLoss: 0.503696\n",
            "\n",
            "Validation set: Average loss: 1.1712, Accuracy: 6361/10000 (64%)\n",
            "\n",
            "Train Epoch: 10 [50000/50000 (100%)]\tLoss: 0.361205\n",
            "\n",
            "Validation set: Average loss: 1.2254, Accuracy: 6452/10000 (65%)\n",
            "\n",
            "Train Epoch: 11 [50000/50000 (100%)]\tLoss: 0.240725\n",
            "\n",
            "Validation set: Average loss: 1.4766, Accuracy: 6446/10000 (64%)\n",
            "\n",
            "Train Epoch: 12 [50000/50000 (100%)]\tLoss: 0.157578\n",
            "\n",
            "Validation set: Average loss: 1.6140, Accuracy: 6393/10000 (64%)\n",
            "\n",
            "Train Epoch: 13 [50000/50000 (100%)]\tLoss: 0.115950\n",
            "\n",
            "Validation set: Average loss: 1.7345, Accuracy: 6530/10000 (65%)\n",
            "\n",
            "Train Epoch: 14 [50000/50000 (100%)]\tLoss: 0.081626\n",
            "\n",
            "Validation set: Average loss: 1.8606, Accuracy: 6500/10000 (65%)\n",
            "\n",
            "Train Epoch: 15 [50000/50000 (100%)]\tLoss: 0.059529\n",
            "\n",
            "Validation set: Average loss: 1.9868, Accuracy: 6545/10000 (65%)\n",
            "\n",
            "Train Epoch: 16 [50000/50000 (100%)]\tLoss: 0.033024\n",
            "\n",
            "Validation set: Average loss: 2.2348, Accuracy: 6574/10000 (66%)\n",
            "\n",
            "Train Epoch: 17 [50000/50000 (100%)]\tLoss: 0.043045\n",
            "\n",
            "Validation set: Average loss: 2.1285, Accuracy: 6604/10000 (66%)\n",
            "\n",
            "Train Epoch: 18 [50000/50000 (100%)]\tLoss: 0.032514\n",
            "\n",
            "Validation set: Average loss: 2.1687, Accuracy: 6631/10000 (66%)\n",
            "\n",
            "Train Epoch: 19 [50000/50000 (100%)]\tLoss: 0.025693\n",
            "\n",
            "Validation set: Average loss: 2.4743, Accuracy: 6632/10000 (66%)\n",
            "\n",
            "Train Epoch: 20 [50000/50000 (100%)]\tLoss: 0.013043\n",
            "\n",
            "Validation set: Average loss: 2.5893, Accuracy: 6559/10000 (66%)\n",
            "\n",
            "Train Epoch: 21 [50000/50000 (100%)]\tLoss: 0.012062\n",
            "\n",
            "Validation set: Average loss: 2.4491, Accuracy: 6646/10000 (66%)\n",
            "\n",
            "Train Epoch: 22 [50000/50000 (100%)]\tLoss: 0.012040\n",
            "\n",
            "Validation set: Average loss: 2.6377, Accuracy: 6625/10000 (66%)\n",
            "\n",
            "Train Epoch: 23 [50000/50000 (100%)]\tLoss: 0.018400\n",
            "\n",
            "Validation set: Average loss: 2.5342, Accuracy: 6626/10000 (66%)\n",
            "\n",
            "Train Epoch: 24 [50000/50000 (100%)]\tLoss: 0.012813\n",
            "\n",
            "Validation set: Average loss: 2.6588, Accuracy: 6634/10000 (66%)\n",
            "\n",
            "Train Epoch: 25 [50000/50000 (100%)]\tLoss: 0.012170\n",
            "\n",
            "Validation set: Average loss: 2.5956, Accuracy: 6656/10000 (67%)\n",
            "\n",
            "Train Epoch: 26 [50000/50000 (100%)]\tLoss: 0.018737\n",
            "\n",
            "Validation set: Average loss: 2.6219, Accuracy: 6668/10000 (67%)\n",
            "\n",
            "Train Epoch: 27 [50000/50000 (100%)]\tLoss: 0.008358\n",
            "\n",
            "Validation set: Average loss: 2.7872, Accuracy: 6565/10000 (66%)\n",
            "\n",
            "Train Epoch: 28 [50000/50000 (100%)]\tLoss: 0.006871\n",
            "\n",
            "Validation set: Average loss: 2.7866, Accuracy: 6662/10000 (67%)\n",
            "\n",
            "Train Epoch: 29 [50000/50000 (100%)]\tLoss: 0.003742\n",
            "\n",
            "Validation set: Average loss: 2.8490, Accuracy: 6655/10000 (67%)\n",
            "\n",
            "Train Epoch: 30 [50000/50000 (100%)]\tLoss: 0.002582\n",
            "\n",
            "Validation set: Average loss: 2.9144, Accuracy: 6734/10000 (67%)\n",
            "\n",
            "Train Epoch: 31 [50000/50000 (100%)]\tLoss: 0.000755\n",
            "\n",
            "Validation set: Average loss: 3.0883, Accuracy: 6721/10000 (67%)\n",
            "\n",
            "Train Epoch: 32 [50000/50000 (100%)]\tLoss: 0.000121\n",
            "\n",
            "Validation set: Average loss: 3.0638, Accuracy: 6763/10000 (68%)\n",
            "\n",
            "Train Epoch: 33 [50000/50000 (100%)]\tLoss: 0.000063\n",
            "\n",
            "Validation set: Average loss: 3.1185, Accuracy: 6751/10000 (68%)\n",
            "\n",
            "Train Epoch: 34 [50000/50000 (100%)]\tLoss: 0.000047\n",
            "\n",
            "Validation set: Average loss: 3.1527, Accuracy: 6754/10000 (68%)\n",
            "\n",
            "Train Epoch: 35 [50000/50000 (100%)]\tLoss: 0.000040\n",
            "\n",
            "Validation set: Average loss: 3.1818, Accuracy: 6757/10000 (68%)\n",
            "\n",
            "Train Epoch: 36 [50000/50000 (100%)]\tLoss: 0.000035\n",
            "\n",
            "Validation set: Average loss: 3.2082, Accuracy: 6763/10000 (68%)\n",
            "\n",
            "Train Epoch: 37 [50000/50000 (100%)]\tLoss: 0.000031\n",
            "\n",
            "Validation set: Average loss: 3.2298, Accuracy: 6765/10000 (68%)\n",
            "\n",
            "Train Epoch: 38 [50000/50000 (100%)]\tLoss: 0.000028\n",
            "\n",
            "Validation set: Average loss: 3.2504, Accuracy: 6769/10000 (68%)\n",
            "\n",
            "Train Epoch: 39 [50000/50000 (100%)]\tLoss: 0.000026\n",
            "\n",
            "Validation set: Average loss: 3.2690, Accuracy: 6767/10000 (68%)\n",
            "\n",
            "Train Epoch: 40 [50000/50000 (100%)]\tLoss: 0.000024\n",
            "\n",
            "Validation set: Average loss: 3.2869, Accuracy: 6768/10000 (68%)\n",
            "\n",
            "Train Epoch: 41 [50000/50000 (100%)]\tLoss: 0.000022\n",
            "\n",
            "Validation set: Average loss: 3.3039, Accuracy: 6770/10000 (68%)\n",
            "\n",
            "Train Epoch: 42 [50000/50000 (100%)]\tLoss: 0.000021\n",
            "\n",
            "Validation set: Average loss: 3.3194, Accuracy: 6769/10000 (68%)\n",
            "\n",
            "Train Epoch: 43 [50000/50000 (100%)]\tLoss: 0.000020\n",
            "\n",
            "Validation set: Average loss: 3.3338, Accuracy: 6771/10000 (68%)\n",
            "\n",
            "Train Epoch: 44 [50000/50000 (100%)]\tLoss: 0.000019\n",
            "\n",
            "Validation set: Average loss: 3.3471, Accuracy: 6768/10000 (68%)\n",
            "\n",
            "Train Epoch: 45 [50000/50000 (100%)]\tLoss: 0.000018\n",
            "\n",
            "Validation set: Average loss: 3.3596, Accuracy: 6769/10000 (68%)\n",
            "\n",
            "Train Epoch: 46 [50000/50000 (100%)]\tLoss: 0.000017\n",
            "\n",
            "Validation set: Average loss: 3.3723, Accuracy: 6771/10000 (68%)\n",
            "\n",
            "Train Epoch: 47 [50000/50000 (100%)]\tLoss: 0.000016\n",
            "\n",
            "Validation set: Average loss: 3.3839, Accuracy: 6768/10000 (68%)\n",
            "\n",
            "Train Epoch: 48 [50000/50000 (100%)]\tLoss: 0.000015\n",
            "\n",
            "Validation set: Average loss: 3.3956, Accuracy: 6774/10000 (68%)\n",
            "\n",
            "Train Epoch: 49 [50000/50000 (100%)]\tLoss: 0.000015\n",
            "\n",
            "Validation set: Average loss: 3.4064, Accuracy: 6775/10000 (68%)\n",
            "\n",
            "Train Epoch: 50 [50000/50000 (100%)]\tLoss: 0.000014\n",
            "\n",
            "Validation set: Average loss: 3.4165, Accuracy: 6773/10000 (68%)\n",
            "\n",
            "Train Epoch: 51 [50000/50000 (100%)]\tLoss: 0.000013\n",
            "\n",
            "Validation set: Average loss: 3.4261, Accuracy: 6771/10000 (68%)\n",
            "\n",
            "Train Epoch: 52 [50000/50000 (100%)]\tLoss: 0.000013\n",
            "\n",
            "Validation set: Average loss: 3.4358, Accuracy: 6770/10000 (68%)\n",
            "\n",
            "Train Epoch: 53 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 3.4450, Accuracy: 6771/10000 (68%)\n",
            "\n",
            "Train Epoch: 54 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 3.4539, Accuracy: 6771/10000 (68%)\n",
            "\n",
            "Train Epoch: 55 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 3.4625, Accuracy: 6773/10000 (68%)\n",
            "\n",
            "Train Epoch: 56 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 3.4709, Accuracy: 6772/10000 (68%)\n",
            "\n",
            "Train Epoch: 57 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 3.4791, Accuracy: 6771/10000 (68%)\n",
            "\n",
            "Train Epoch: 58 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 3.4867, Accuracy: 6773/10000 (68%)\n",
            "\n",
            "Train Epoch: 59 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 3.4947, Accuracy: 6774/10000 (68%)\n",
            "\n",
            "Train Epoch: 60 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 3.5021, Accuracy: 6776/10000 (68%)\n",
            "\n",
            "Train Epoch: 61 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 3.5093, Accuracy: 6778/10000 (68%)\n",
            "\n",
            "Train Epoch: 62 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 3.5163, Accuracy: 6777/10000 (68%)\n",
            "\n",
            "Train Epoch: 63 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 3.5229, Accuracy: 6777/10000 (68%)\n",
            "\n",
            "Train Epoch: 64 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 3.5296, Accuracy: 6776/10000 (68%)\n",
            "\n",
            "Train Epoch: 65 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 3.5361, Accuracy: 6774/10000 (68%)\n",
            "\n",
            "Train Epoch: 66 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 3.5426, Accuracy: 6774/10000 (68%)\n",
            "\n",
            "Train Epoch: 67 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 3.5489, Accuracy: 6772/10000 (68%)\n",
            "\n",
            "Train Epoch: 68 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 3.5549, Accuracy: 6771/10000 (68%)\n",
            "\n",
            "Train Epoch: 69 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 3.5609, Accuracy: 6774/10000 (68%)\n",
            "\n",
            "Train Epoch: 70 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 3.5668, Accuracy: 6774/10000 (68%)\n",
            "\n",
            "Train Epoch: 71 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 3.5725, Accuracy: 6773/10000 (68%)\n",
            "\n",
            "Train Epoch: 72 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 3.5780, Accuracy: 6773/10000 (68%)\n",
            "\n",
            "Train Epoch: 73 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 3.5836, Accuracy: 6773/10000 (68%)\n",
            "\n",
            "Train Epoch: 74 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 3.5889, Accuracy: 6772/10000 (68%)\n",
            "\n",
            "Train Epoch: 75 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 3.5942, Accuracy: 6772/10000 (68%)\n",
            "\n",
            "Train Epoch: 76 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 3.5994, Accuracy: 6772/10000 (68%)\n",
            "\n",
            "Train Epoch: 77 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 3.6045, Accuracy: 6770/10000 (68%)\n",
            "\n",
            "Train Epoch: 78 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 3.6097, Accuracy: 6770/10000 (68%)\n",
            "\n",
            "Train Epoch: 79 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 3.6146, Accuracy: 6768/10000 (68%)\n",
            "\n",
            "Train Epoch: 80 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 3.6193, Accuracy: 6769/10000 (68%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DGN with ReLU activation for NPF"
      ],
      "metadata": {
        "id": "2Zvm0WzAdLU2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoupled learning with Soft ReLU activation"
      ],
      "metadata": {
        "id": "zY5cFU-PYDJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SoftGate(nn.Module):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(SoftGate, self).__init__()\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    super(SoftGate, self).build(input_shape)  \n",
        "\n",
        "  def forward(self, x):\n",
        "    activation = (1 + eps)*F.sigmoid(beta*x)\n",
        "    return activation\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    return input_shape"
      ],
      "metadata": {
        "id": "xU_VzpaZczZk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv4SoftGalu(nn.Module):\n",
        "\n",
        "  def __init__(self, image_size, channels):\n",
        "      \n",
        "    super(Conv4SoftGalu, self).__init__()\n",
        "\n",
        "    #NPF network\n",
        "    self.NPF_C1 = nn.Conv2d(channels, 64, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPF_C2 = nn.Conv2d(64, 64, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPF_C3 = nn.Conv2d(64, 128, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPF_C4 = nn.Conv2d(128, 128, kernel_size = (3, 3), padding = 'same')\n",
        "\n",
        "    self.NPF_F = nn.Flatten()\n",
        "    self.NPF_D1 = nn.Linear(image_size*128, 256)\n",
        "    self.NPF_D2 = nn.Linear(256, 256)\n",
        "\n",
        "    #NPV Network\n",
        "    self.NPV_C1 = nn.Conv2d(channels, 64, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPV_C2 = nn.Conv2d(64, 64, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPV_C3 = nn.Conv2d(64, 128, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPV_C4 = nn.Conv2d(128, 128, kernel_size = (3, 3),  padding = 'same')\n",
        "    self.NPV_F = nn.Flatten()\n",
        "    self.NPV_D1 = nn.Linear(image_size*128, 256)\n",
        "    self.NPV_D2 = nn.Linear(256, 256)\n",
        "    self.outputs = nn.Linear(256, 10)\n",
        "\n",
        "    \n",
        "  def forward(self, x):\n",
        "\n",
        "    # Calculate pre-activations(Qfi) and activations(Zfi) for NPF network\n",
        "    Qf1 = self.NPF_C1(x)  \n",
        "    Zf1 = F.relu(Qf1)\n",
        "    Qf2 = self.NPF_C2(Zf1)\n",
        "    Zf2 = F.relu(Qf2)\n",
        "    Qf3 = self.NPF_C3(Zf2)\n",
        "    Zf3 = F.relu(Qf3)\n",
        "    Qf4 = self.NPF_C4(Zf3)\n",
        "    Zf4 = F.relu(Qf4)\n",
        "\n",
        "    Zf4 = self.NPF_F(Zf4)\n",
        "    Qf5 = self.NPF_D1(Zf4)\n",
        "    Zf5 = F.relu(Qf5)\n",
        "    Qf6 = self.NPF_D2(Zf5)\n",
        "\n",
        "    # Gating values\n",
        "    G1 = SoftGate()(Qf1)\n",
        "    G2 = SoftGate()(Qf2)\n",
        "    G3 = SoftGate()(Qf3)\n",
        "    G4 = SoftGate()(Qf4)\n",
        "    G5 = SoftGate()(Qf5)\n",
        "    G6 = SoftGate()(Qf6)\n",
        "\n",
        "    # Calculate pre-activations(Qvi) and activations(Zvi) for NPV network\n",
        "    Qv1 = self.NPV_C1(x)\n",
        "    Zv1 = torch.mul(G1, Qv1)\n",
        "    Qv2 = self.NPV_C2(Zv1)\n",
        "    Zv2 = torch.mul(G2, Qv2)\n",
        "    Qv3 = self.NPV_C3(Zv2)\n",
        "    Zv3 = torch.mul(G3, Qv3)\n",
        "    Qv4 = self.NPV_C4(Zv3)\n",
        "    Zv4 = torch.mul(G4, Qv4)\n",
        "\n",
        "    Zv4 = self.NPV_F(Zv4)\n",
        "    Qv5 = self.NPV_D1(Zv4)\n",
        "    Zv5 = torch.mul(G5, Qv5)\n",
        "    Qv6 = self.NPV_D2(Zv5)\n",
        "    Zv6 = torch.mul(G6, Qv6)\n",
        "\n",
        "    return F.log_softmax(self.outputs(Zv6))"
      ],
      "metadata": {
        "id": "2UP6jfMYX7KA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoupled_soft_relu_model = Conv4SoftGalu(args['image_size'], args['channels'])\n",
        "decoupled_soft_relu_model.to(device)\n",
        "decoupled_soft_relu_model"
      ],
      "metadata": {
        "id": "fo4enldo5HXD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "878f4e76-ce07-4f09-8261-cf89b7c5ba73"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv4SoftGalu(\n",
              "  (NPF_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPF_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPF_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (NPV_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPV_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPV_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (outputs): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(decoupled_soft_relu_model.parameters(), lr=args['lr'])\n",
        "for epoch in range(1, args['epochs']+1):\n",
        "  train(decoupled_soft_relu_model, epoch, train_loader, lossFn, optimizer)\n",
        "  validate(decoupled_soft_relu_model, validation_loader, lossFn)"
      ],
      "metadata": {
        "id": "0hlWWNdUQgzk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ff62535c-3f53-4cdc-9246-c0b0be332dd2"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:69: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [50000/50000 (100%)]\tLoss: 2.151316\n",
            "\n",
            "Validation set: Average loss: 1.8115, Accuracy: 3666/10000 (37%)\n",
            "\n",
            "Train Epoch: 2 [50000/50000 (100%)]\tLoss: 1.610187\n",
            "\n",
            "Validation set: Average loss: 1.5020, Accuracy: 4694/10000 (47%)\n",
            "\n",
            "Train Epoch: 3 [50000/50000 (100%)]\tLoss: 1.405864\n",
            "\n",
            "Validation set: Average loss: 1.3950, Accuracy: 5042/10000 (50%)\n",
            "\n",
            "Train Epoch: 4 [50000/50000 (100%)]\tLoss: 1.273511\n",
            "\n",
            "Validation set: Average loss: 1.2656, Accuracy: 5499/10000 (55%)\n",
            "\n",
            "Train Epoch: 5 [50000/50000 (100%)]\tLoss: 1.155720\n",
            "\n",
            "Validation set: Average loss: 1.2037, Accuracy: 5801/10000 (58%)\n",
            "\n",
            "Train Epoch: 6 [50000/50000 (100%)]\tLoss: 1.041662\n",
            "\n",
            "Validation set: Average loss: 1.1218, Accuracy: 5988/10000 (60%)\n",
            "\n",
            "Train Epoch: 7 [50000/50000 (100%)]\tLoss: 0.922955\n",
            "\n",
            "Validation set: Average loss: 1.1044, Accuracy: 6101/10000 (61%)\n",
            "\n",
            "Train Epoch: 8 [50000/50000 (100%)]\tLoss: 0.785313\n",
            "\n",
            "Validation set: Average loss: 1.0849, Accuracy: 6371/10000 (64%)\n",
            "\n",
            "Train Epoch: 9 [50000/50000 (100%)]\tLoss: 0.633125\n",
            "\n",
            "Validation set: Average loss: 1.1487, Accuracy: 6286/10000 (63%)\n",
            "\n",
            "Train Epoch: 10 [50000/50000 (100%)]\tLoss: 0.471456\n",
            "\n",
            "Validation set: Average loss: 1.2223, Accuracy: 6380/10000 (64%)\n",
            "\n",
            "Train Epoch: 11 [50000/50000 (100%)]\tLoss: 0.336072\n",
            "\n",
            "Validation set: Average loss: 1.3616, Accuracy: 6326/10000 (63%)\n",
            "\n",
            "Train Epoch: 12 [50000/50000 (100%)]\tLoss: 0.239736\n",
            "\n",
            "Validation set: Average loss: 1.5207, Accuracy: 6311/10000 (63%)\n",
            "\n",
            "Train Epoch: 13 [50000/50000 (100%)]\tLoss: 0.174616\n",
            "\n",
            "Validation set: Average loss: 1.6487, Accuracy: 6246/10000 (62%)\n",
            "\n",
            "Train Epoch: 14 [50000/50000 (100%)]\tLoss: 0.134357\n",
            "\n",
            "Validation set: Average loss: 1.8052, Accuracy: 6230/10000 (62%)\n",
            "\n",
            "Train Epoch: 15 [50000/50000 (100%)]\tLoss: 0.108492\n",
            "\n",
            "Validation set: Average loss: 2.0694, Accuracy: 6209/10000 (62%)\n",
            "\n",
            "Train Epoch: 16 [50000/50000 (100%)]\tLoss: 0.079856\n",
            "\n",
            "Validation set: Average loss: 2.1525, Accuracy: 6324/10000 (63%)\n",
            "\n",
            "Train Epoch: 17 [50000/50000 (100%)]\tLoss: 0.063174\n",
            "\n",
            "Validation set: Average loss: 2.4286, Accuracy: 6223/10000 (62%)\n",
            "\n",
            "Train Epoch: 18 [50000/50000 (100%)]\tLoss: 0.062284\n",
            "\n",
            "Validation set: Average loss: 2.2378, Accuracy: 6273/10000 (63%)\n",
            "\n",
            "Train Epoch: 19 [50000/50000 (100%)]\tLoss: 0.052169\n",
            "\n",
            "Validation set: Average loss: 2.2540, Accuracy: 6350/10000 (64%)\n",
            "\n",
            "Train Epoch: 20 [50000/50000 (100%)]\tLoss: 0.042645\n",
            "\n",
            "Validation set: Average loss: 2.4945, Accuracy: 6296/10000 (63%)\n",
            "\n",
            "Train Epoch: 21 [50000/50000 (100%)]\tLoss: 0.052360\n",
            "\n",
            "Validation set: Average loss: 2.4596, Accuracy: 6329/10000 (63%)\n",
            "\n",
            "Train Epoch: 22 [50000/50000 (100%)]\tLoss: 0.028879\n",
            "\n",
            "Validation set: Average loss: 2.4558, Accuracy: 6344/10000 (63%)\n",
            "\n",
            "Train Epoch: 23 [50000/50000 (100%)]\tLoss: 0.021402\n",
            "\n",
            "Validation set: Average loss: 2.6899, Accuracy: 6362/10000 (64%)\n",
            "\n",
            "Train Epoch: 24 [50000/50000 (100%)]\tLoss: 0.018484\n",
            "\n",
            "Validation set: Average loss: 2.7528, Accuracy: 6304/10000 (63%)\n",
            "\n",
            "Train Epoch: 25 [50000/50000 (100%)]\tLoss: 0.027757\n",
            "\n",
            "Validation set: Average loss: 2.7445, Accuracy: 6359/10000 (64%)\n",
            "\n",
            "Train Epoch: 26 [50000/50000 (100%)]\tLoss: 0.034929\n",
            "\n",
            "Validation set: Average loss: 2.7054, Accuracy: 6312/10000 (63%)\n",
            "\n",
            "Train Epoch: 27 [50000/50000 (100%)]\tLoss: 0.035122\n",
            "\n",
            "Validation set: Average loss: 2.6974, Accuracy: 6357/10000 (64%)\n",
            "\n",
            "Train Epoch: 28 [50000/50000 (100%)]\tLoss: 0.021027\n",
            "\n",
            "Validation set: Average loss: 2.9562, Accuracy: 6311/10000 (63%)\n",
            "\n",
            "Train Epoch: 29 [50000/50000 (100%)]\tLoss: 0.017554\n",
            "\n",
            "Validation set: Average loss: 2.8575, Accuracy: 6356/10000 (64%)\n",
            "\n",
            "Train Epoch: 30 [50000/50000 (100%)]\tLoss: 0.015167\n",
            "\n",
            "Validation set: Average loss: 3.0406, Accuracy: 6401/10000 (64%)\n",
            "\n",
            "Train Epoch: 31 [50000/50000 (100%)]\tLoss: 0.012255\n",
            "\n",
            "Validation set: Average loss: 3.0171, Accuracy: 6325/10000 (63%)\n",
            "\n",
            "Train Epoch: 32 [50000/50000 (100%)]\tLoss: 0.015676\n",
            "\n",
            "Validation set: Average loss: 3.0382, Accuracy: 6381/10000 (64%)\n",
            "\n",
            "Train Epoch: 33 [50000/50000 (100%)]\tLoss: 0.024052\n",
            "\n",
            "Validation set: Average loss: 2.9100, Accuracy: 6325/10000 (63%)\n",
            "\n",
            "Train Epoch: 34 [50000/50000 (100%)]\tLoss: 0.021829\n",
            "\n",
            "Validation set: Average loss: 2.9464, Accuracy: 6359/10000 (64%)\n",
            "\n",
            "Train Epoch: 35 [50000/50000 (100%)]\tLoss: 0.019754\n",
            "\n",
            "Validation set: Average loss: 2.9450, Accuracy: 6277/10000 (63%)\n",
            "\n",
            "Train Epoch: 36 [50000/50000 (100%)]\tLoss: 0.021752\n",
            "\n",
            "Validation set: Average loss: 2.9146, Accuracy: 6303/10000 (63%)\n",
            "\n",
            "Train Epoch: 37 [50000/50000 (100%)]\tLoss: 0.011008\n",
            "\n",
            "Validation set: Average loss: 2.9950, Accuracy: 6388/10000 (64%)\n",
            "\n",
            "Train Epoch: 38 [50000/50000 (100%)]\tLoss: 0.004178\n",
            "\n",
            "Validation set: Average loss: 3.2170, Accuracy: 6443/10000 (64%)\n",
            "\n",
            "Train Epoch: 39 [50000/50000 (100%)]\tLoss: 0.001108\n",
            "\n",
            "Validation set: Average loss: 3.2835, Accuracy: 6442/10000 (64%)\n",
            "\n",
            "Train Epoch: 40 [50000/50000 (100%)]\tLoss: 0.000172\n",
            "\n",
            "Validation set: Average loss: 3.3602, Accuracy: 6465/10000 (65%)\n",
            "\n",
            "Train Epoch: 41 [50000/50000 (100%)]\tLoss: 0.000089\n",
            "\n",
            "Validation set: Average loss: 3.4049, Accuracy: 6467/10000 (65%)\n",
            "\n",
            "Train Epoch: 42 [50000/50000 (100%)]\tLoss: 0.000070\n",
            "\n",
            "Validation set: Average loss: 3.4397, Accuracy: 6472/10000 (65%)\n",
            "\n",
            "Train Epoch: 43 [50000/50000 (100%)]\tLoss: 0.000059\n",
            "\n",
            "Validation set: Average loss: 3.4686, Accuracy: 6475/10000 (65%)\n",
            "\n",
            "Train Epoch: 44 [50000/50000 (100%)]\tLoss: 0.000051\n",
            "\n",
            "Validation set: Average loss: 3.4948, Accuracy: 6482/10000 (65%)\n",
            "\n",
            "Train Epoch: 45 [50000/50000 (100%)]\tLoss: 0.000045\n",
            "\n",
            "Validation set: Average loss: 3.5183, Accuracy: 6481/10000 (65%)\n",
            "\n",
            "Train Epoch: 46 [50000/50000 (100%)]\tLoss: 0.000040\n",
            "\n",
            "Validation set: Average loss: 3.5391, Accuracy: 6484/10000 (65%)\n",
            "\n",
            "Train Epoch: 47 [50000/50000 (100%)]\tLoss: 0.000037\n",
            "\n",
            "Validation set: Average loss: 3.5582, Accuracy: 6487/10000 (65%)\n",
            "\n",
            "Train Epoch: 48 [50000/50000 (100%)]\tLoss: 0.000034\n",
            "\n",
            "Validation set: Average loss: 3.5754, Accuracy: 6485/10000 (65%)\n",
            "\n",
            "Train Epoch: 49 [50000/50000 (100%)]\tLoss: 0.000031\n",
            "\n",
            "Validation set: Average loss: 3.5921, Accuracy: 6485/10000 (65%)\n",
            "\n",
            "Train Epoch: 50 [50000/50000 (100%)]\tLoss: 0.000029\n",
            "\n",
            "Validation set: Average loss: 3.6076, Accuracy: 6485/10000 (65%)\n",
            "\n",
            "Train Epoch: 51 [50000/50000 (100%)]\tLoss: 0.000027\n",
            "\n",
            "Validation set: Average loss: 3.6222, Accuracy: 6487/10000 (65%)\n",
            "\n",
            "Train Epoch: 52 [50000/50000 (100%)]\tLoss: 0.000025\n",
            "\n",
            "Validation set: Average loss: 3.6359, Accuracy: 6491/10000 (65%)\n",
            "\n",
            "Train Epoch: 53 [50000/50000 (100%)]\tLoss: 0.000024\n",
            "\n",
            "Validation set: Average loss: 3.6492, Accuracy: 6489/10000 (65%)\n",
            "\n",
            "Train Epoch: 54 [50000/50000 (100%)]\tLoss: 0.000023\n",
            "\n",
            "Validation set: Average loss: 3.6615, Accuracy: 6493/10000 (65%)\n",
            "\n",
            "Train Epoch: 55 [50000/50000 (100%)]\tLoss: 0.000021\n",
            "\n",
            "Validation set: Average loss: 3.6733, Accuracy: 6492/10000 (65%)\n",
            "\n",
            "Train Epoch: 56 [50000/50000 (100%)]\tLoss: 0.000020\n",
            "\n",
            "Validation set: Average loss: 3.6846, Accuracy: 6492/10000 (65%)\n",
            "\n",
            "Train Epoch: 57 [50000/50000 (100%)]\tLoss: 0.000019\n",
            "\n",
            "Validation set: Average loss: 3.6954, Accuracy: 6490/10000 (65%)\n",
            "\n",
            "Train Epoch: 58 [50000/50000 (100%)]\tLoss: 0.000019\n",
            "\n",
            "Validation set: Average loss: 3.7057, Accuracy: 6491/10000 (65%)\n",
            "\n",
            "Train Epoch: 59 [50000/50000 (100%)]\tLoss: 0.000018\n",
            "\n",
            "Validation set: Average loss: 3.7157, Accuracy: 6492/10000 (65%)\n",
            "\n",
            "Train Epoch: 60 [50000/50000 (100%)]\tLoss: 0.000017\n",
            "\n",
            "Validation set: Average loss: 3.7253, Accuracy: 6491/10000 (65%)\n",
            "\n",
            "Train Epoch: 61 [50000/50000 (100%)]\tLoss: 0.000016\n",
            "\n",
            "Validation set: Average loss: 3.7345, Accuracy: 6490/10000 (65%)\n",
            "\n",
            "Train Epoch: 62 [50000/50000 (100%)]\tLoss: 0.000016\n",
            "\n",
            "Validation set: Average loss: 3.7434, Accuracy: 6491/10000 (65%)\n",
            "\n",
            "Train Epoch: 63 [50000/50000 (100%)]\tLoss: 0.000015\n",
            "\n",
            "Validation set: Average loss: 3.7520, Accuracy: 6491/10000 (65%)\n",
            "\n",
            "Train Epoch: 64 [50000/50000 (100%)]\tLoss: 0.000015\n",
            "\n",
            "Validation set: Average loss: 3.7603, Accuracy: 6491/10000 (65%)\n",
            "\n",
            "Train Epoch: 65 [50000/50000 (100%)]\tLoss: 0.000014\n",
            "\n",
            "Validation set: Average loss: 3.7684, Accuracy: 6490/10000 (65%)\n",
            "\n",
            "Train Epoch: 66 [50000/50000 (100%)]\tLoss: 0.000014\n",
            "\n",
            "Validation set: Average loss: 3.7763, Accuracy: 6490/10000 (65%)\n",
            "\n",
            "Train Epoch: 67 [50000/50000 (100%)]\tLoss: 0.000013\n",
            "\n",
            "Validation set: Average loss: 3.7840, Accuracy: 6492/10000 (65%)\n",
            "\n",
            "Train Epoch: 68 [50000/50000 (100%)]\tLoss: 0.000013\n",
            "\n",
            "Validation set: Average loss: 3.7915, Accuracy: 6492/10000 (65%)\n",
            "\n",
            "Train Epoch: 69 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 3.7988, Accuracy: 6492/10000 (65%)\n",
            "\n",
            "Train Epoch: 70 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 3.8059, Accuracy: 6492/10000 (65%)\n",
            "\n",
            "Train Epoch: 71 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 3.8127, Accuracy: 6490/10000 (65%)\n",
            "\n",
            "Train Epoch: 72 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 3.8193, Accuracy: 6490/10000 (65%)\n",
            "\n",
            "Train Epoch: 73 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 3.8258, Accuracy: 6489/10000 (65%)\n",
            "\n",
            "Train Epoch: 74 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 3.8321, Accuracy: 6488/10000 (65%)\n",
            "\n",
            "Train Epoch: 75 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 3.8383, Accuracy: 6487/10000 (65%)\n",
            "\n",
            "Train Epoch: 76 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 3.8444, Accuracy: 6487/10000 (65%)\n",
            "\n",
            "Train Epoch: 77 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 3.8503, Accuracy: 6487/10000 (65%)\n",
            "\n",
            "Train Epoch: 78 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 3.8562, Accuracy: 6487/10000 (65%)\n",
            "\n",
            "Train Epoch: 79 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 3.8619, Accuracy: 6488/10000 (65%)\n",
            "\n",
            "Train Epoch: 80 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 3.8675, Accuracy: 6490/10000 (65%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SignGate(nn.Module):\n",
        "  def __init__(self, **kwargs):\n",
        "    super(SignGate, self).__init__()\n",
        "\n",
        "  def build(self, input_shape):\n",
        "    super(SignGate, self).build(input_shape)  \n",
        "\n",
        "  def forward(self, x):\n",
        "    output = torch.sign(F.relu(x))\n",
        "    return output\n",
        "\n",
        "  def compute_output_shape(self, input_shape):\n",
        "    return input_shape"
      ],
      "metadata": {
        "id": "wG2GoOezc9v2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "SignGate()(F.relu(torch.Tensor([-2, -1.1, 0, 5.6, -4.5, -0.2, 0.8])))"
      ],
      "metadata": {
        "id": "LPACQZh0FZsW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce5fd824-9f65-4493-9162-ffa7f6c97ff9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0., 0., 0., 1., 0., 0., 1.])"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv4Galu(nn.Module):\n",
        "\n",
        "  def __init__(self, image_size, channels):\n",
        "    \n",
        "    super(Conv4Galu, self).__init__()\n",
        "\n",
        "    # NPF Network\n",
        "    self.NPF_C1 = nn.Conv2d(channels, 64, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPF_C2 = nn.Conv2d(64, 64, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPF_C3 = nn.Conv2d(64, 128, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPF_C4 = nn.Conv2d(128, 128, kernel_size = (3, 3), padding = 'same')\n",
        "\n",
        "    self.NPF_F = nn.Flatten()\n",
        "    self.NPF_D1 = nn.Linear(image_size*128, 256)\n",
        "    self.NPF_D2 = nn.Linear(256, 256)\n",
        "\n",
        "\n",
        "    # NPV Network\n",
        "    self.NPV_C1 = nn.Conv2d(channels, 64, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPV_C2 = nn.Conv2d(64, 64, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPV_C3 = nn.Conv2d(64, 128, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPV_C4 = nn.Conv2d(128, 128, kernel_size = (3, 3),  padding = 'same')\n",
        "    \n",
        "    self.NPV_F = nn.Flatten()\n",
        "    self.NPV_D1 = nn.Linear(image_size*128, 256)\n",
        "    self.NPV_D2 = nn.Linear(256, 256)\n",
        "\n",
        "    self.outputs = nn.Linear(256, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    # Calculate pre-activations(Qfi) and activations(Zfi) for NPF network\n",
        "    Zf1 = F.relu(self.NPF_C1(x))\n",
        "    Zf2 = F.relu(self.NPF_C2(Zf1))\n",
        "    Zf3 = F.relu(self.NPF_C3(Zf2))\n",
        "    Zf4 = F.relu(self.NPF_C4(Zf3))\n",
        "\n",
        "    Zf4_ = self.NPF_F(Zf4)\n",
        "    Zf5 = F.relu(self.NPF_D1(Zf4_))\n",
        "    Zf6 = F.relu(self.NPF_D2(Zf5))\n",
        "\n",
        "    # Gating values\n",
        "    G1 = SignGate()(Zf1)\n",
        "    G2 = SignGate()(Zf2)\n",
        "    G3 = SignGate()(Zf3)\n",
        "    G4 = SignGate()(Zf4)\n",
        "    G5 = SignGate()(Zf5)\n",
        "    G6 = SignGate()(Zf6)\n",
        "\n",
        "    # Calculate pre-activations(Qvi) and activations(Zvi) for NPV network\n",
        "\n",
        "    Qv1 = self.NPV_C1(x)\n",
        "    Zv1 = torch.mul(G1, Qv1)\n",
        "    Qv2 = self.NPV_C2(Zv1)\n",
        "    Zv2 = torch.mul(G2, Qv2)\n",
        "    Qv3 = self.NPV_C3(Zv2)\n",
        "    Zv3 = torch.mul(G3, Qv3)\n",
        "    Qv4 = self.NPV_C4(Zv3)\n",
        "\n",
        "    # print(Qv4.size(), G4.size())\n",
        "\n",
        "    Zv4 = torch.mul(G4, Qv4)\n",
        "\n",
        "    Zv4 = self.NPV_F(Zv4)\n",
        "    Qv5 = self.NPV_D1(Zv4)\n",
        "    Zv5 = torch.mul(G5, Qv5)\n",
        "    Qv6 = self.NPV_D2(Zv5)\n",
        "    Zv6 = torch.mul(G6, Qv6)\n",
        "\n",
        "    return F.log_softmax(self.outputs(Zv6))"
      ],
      "metadata": {
        "id": "kC1ZLrwBc4KG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoupled Learning with hard relu"
      ],
      "metadata": {
        "id": "iO5GLTgwQwd5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoupled_hard_relu_model = Conv4Galu(args['image_size'], args['channels'])\n",
        "decoupled_hard_relu_model.to(device)\n",
        "decoupled_hard_relu_model"
      ],
      "metadata": {
        "id": "W03Nzvtl5Nmq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d97faa7-ab90-48d8-bb1d-e8fc216fb1ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv4Galu(\n",
              "  (NPF_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPF_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPF_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (NPV_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPV_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPV_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (outputs): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(decoupled_hard_relu_model.parameters(), lr=args['lr'])\n",
        "for epoch in range(1, args['epochs']+1):\n",
        "  train(decoupled_hard_relu_model, epoch, train_loader, lossFn, optimizer)\n",
        "  validate(decoupled_hard_relu_model, validation_loader, lossFn)"
      ],
      "metadata": {
        "id": "t2F39v0AQ2WB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f6d8193-4bab-4b09-ea72-2cfa9d95deee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:70: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [50000/50000 (100%)]\tLoss: 1.901805\n",
            "\n",
            "Validation set: Average loss: 1.5688, Accuracy: 4326/10000 (43%)\n",
            "\n",
            "Train Epoch: 2 [50000/50000 (100%)]\tLoss: 1.391816\n",
            "\n",
            "Validation set: Average loss: 1.3241, Accuracy: 5213/10000 (52%)\n",
            "\n",
            "Train Epoch: 3 [50000/50000 (100%)]\tLoss: 1.153991\n",
            "\n",
            "Validation set: Average loss: 1.2211, Accuracy: 5584/10000 (56%)\n",
            "\n",
            "Train Epoch: 4 [50000/50000 (100%)]\tLoss: 0.927972\n",
            "\n",
            "Validation set: Average loss: 1.2981, Accuracy: 5570/10000 (56%)\n",
            "\n",
            "Train Epoch: 5 [50000/50000 (100%)]\tLoss: 0.632888\n",
            "\n",
            "Validation set: Average loss: 1.4499, Accuracy: 5521/10000 (55%)\n",
            "\n",
            "Train Epoch: 6 [50000/50000 (100%)]\tLoss: 0.306870\n",
            "\n",
            "Validation set: Average loss: 2.0554, Accuracy: 5308/10000 (53%)\n",
            "\n",
            "Train Epoch: 7 [50000/50000 (100%)]\tLoss: 0.147833\n",
            "\n",
            "Validation set: Average loss: 2.1565, Accuracy: 5576/10000 (56%)\n",
            "\n",
            "Train Epoch: 8 [50000/50000 (100%)]\tLoss: 0.083732\n",
            "\n",
            "Validation set: Average loss: 2.7163, Accuracy: 5586/10000 (56%)\n",
            "\n",
            "Train Epoch: 9 [50000/50000 (100%)]\tLoss: 0.060095\n",
            "\n",
            "Validation set: Average loss: 2.7848, Accuracy: 5592/10000 (56%)\n",
            "\n",
            "Train Epoch: 10 [50000/50000 (100%)]\tLoss: 0.040527\n",
            "\n",
            "Validation set: Average loss: 3.1899, Accuracy: 5622/10000 (56%)\n",
            "\n",
            "Train Epoch: 11 [50000/50000 (100%)]\tLoss: 0.028772\n",
            "\n",
            "Validation set: Average loss: 3.2980, Accuracy: 5638/10000 (56%)\n",
            "\n",
            "Train Epoch: 12 [50000/50000 (100%)]\tLoss: 0.023332\n",
            "\n",
            "Validation set: Average loss: 3.5892, Accuracy: 5514/10000 (55%)\n",
            "\n",
            "Train Epoch: 13 [50000/50000 (100%)]\tLoss: 0.027703\n",
            "\n",
            "Validation set: Average loss: 3.4600, Accuracy: 5582/10000 (56%)\n",
            "\n",
            "Train Epoch: 14 [50000/50000 (100%)]\tLoss: 0.012440\n",
            "\n",
            "Validation set: Average loss: 3.6310, Accuracy: 5706/10000 (57%)\n",
            "\n",
            "Train Epoch: 15 [50000/50000 (100%)]\tLoss: 0.009275\n",
            "\n",
            "Validation set: Average loss: 3.7389, Accuracy: 5614/10000 (56%)\n",
            "\n",
            "Train Epoch: 16 [50000/50000 (100%)]\tLoss: 0.011600\n",
            "\n",
            "Validation set: Average loss: 4.1120, Accuracy: 5498/10000 (55%)\n",
            "\n",
            "Train Epoch: 17 [50000/50000 (100%)]\tLoss: 0.008275\n",
            "\n",
            "Validation set: Average loss: 4.0225, Accuracy: 5723/10000 (57%)\n",
            "\n",
            "Train Epoch: 18 [50000/50000 (100%)]\tLoss: 0.004866\n",
            "\n",
            "Validation set: Average loss: 4.2451, Accuracy: 5638/10000 (56%)\n",
            "\n",
            "Train Epoch: 19 [50000/50000 (100%)]\tLoss: 0.001775\n",
            "\n",
            "Validation set: Average loss: 4.2131, Accuracy: 5735/10000 (57%)\n",
            "\n",
            "Train Epoch: 20 [50000/50000 (100%)]\tLoss: 0.000160\n",
            "\n",
            "Validation set: Average loss: 4.2862, Accuracy: 5769/10000 (58%)\n",
            "\n",
            "Train Epoch: 21 [50000/50000 (100%)]\tLoss: 0.000071\n",
            "\n",
            "Validation set: Average loss: 4.3327, Accuracy: 5759/10000 (58%)\n",
            "\n",
            "Train Epoch: 22 [50000/50000 (100%)]\tLoss: 0.000056\n",
            "\n",
            "Validation set: Average loss: 4.3719, Accuracy: 5763/10000 (58%)\n",
            "\n",
            "Train Epoch: 23 [50000/50000 (100%)]\tLoss: 0.000048\n",
            "\n",
            "Validation set: Average loss: 4.4081, Accuracy: 5761/10000 (58%)\n",
            "\n",
            "Train Epoch: 24 [50000/50000 (100%)]\tLoss: 0.000042\n",
            "\n",
            "Validation set: Average loss: 4.4388, Accuracy: 5759/10000 (58%)\n",
            "\n",
            "Train Epoch: 25 [50000/50000 (100%)]\tLoss: 0.000037\n",
            "\n",
            "Validation set: Average loss: 4.4681, Accuracy: 5761/10000 (58%)\n",
            "\n",
            "Train Epoch: 26 [50000/50000 (100%)]\tLoss: 0.000034\n",
            "\n",
            "Validation set: Average loss: 4.4942, Accuracy: 5764/10000 (58%)\n",
            "\n",
            "Train Epoch: 27 [50000/50000 (100%)]\tLoss: 0.000031\n",
            "\n",
            "Validation set: Average loss: 4.5190, Accuracy: 5767/10000 (58%)\n",
            "\n",
            "Train Epoch: 28 [50000/50000 (100%)]\tLoss: 0.000028\n",
            "\n",
            "Validation set: Average loss: 4.5416, Accuracy: 5764/10000 (58%)\n",
            "\n",
            "Train Epoch: 29 [50000/50000 (100%)]\tLoss: 0.000026\n",
            "\n",
            "Validation set: Average loss: 4.5633, Accuracy: 5768/10000 (58%)\n",
            "\n",
            "Train Epoch: 30 [50000/50000 (100%)]\tLoss: 0.000024\n",
            "\n",
            "Validation set: Average loss: 4.5832, Accuracy: 5766/10000 (58%)\n",
            "\n",
            "Train Epoch: 31 [50000/50000 (100%)]\tLoss: 0.000023\n",
            "\n",
            "Validation set: Average loss: 4.6020, Accuracy: 5770/10000 (58%)\n",
            "\n",
            "Train Epoch: 32 [50000/50000 (100%)]\tLoss: 0.000022\n",
            "\n",
            "Validation set: Average loss: 4.6196, Accuracy: 5765/10000 (58%)\n",
            "\n",
            "Train Epoch: 33 [50000/50000 (100%)]\tLoss: 0.000020\n",
            "\n",
            "Validation set: Average loss: 4.6366, Accuracy: 5766/10000 (58%)\n",
            "\n",
            "Train Epoch: 34 [50000/50000 (100%)]\tLoss: 0.000019\n",
            "\n",
            "Validation set: Average loss: 4.6528, Accuracy: 5767/10000 (58%)\n",
            "\n",
            "Train Epoch: 35 [50000/50000 (100%)]\tLoss: 0.000018\n",
            "\n",
            "Validation set: Average loss: 4.6684, Accuracy: 5767/10000 (58%)\n",
            "\n",
            "Train Epoch: 36 [50000/50000 (100%)]\tLoss: 0.000018\n",
            "\n",
            "Validation set: Average loss: 4.6831, Accuracy: 5766/10000 (58%)\n",
            "\n",
            "Train Epoch: 37 [50000/50000 (100%)]\tLoss: 0.000017\n",
            "\n",
            "Validation set: Average loss: 4.6976, Accuracy: 5767/10000 (58%)\n",
            "\n",
            "Train Epoch: 38 [50000/50000 (100%)]\tLoss: 0.000016\n",
            "\n",
            "Validation set: Average loss: 4.7111, Accuracy: 5766/10000 (58%)\n",
            "\n",
            "Train Epoch: 39 [50000/50000 (100%)]\tLoss: 0.000015\n",
            "\n",
            "Validation set: Average loss: 4.7245, Accuracy: 5767/10000 (58%)\n",
            "\n",
            "Train Epoch: 40 [50000/50000 (100%)]\tLoss: 0.000015\n",
            "\n",
            "Validation set: Average loss: 4.7371, Accuracy: 5763/10000 (58%)\n",
            "\n",
            "Train Epoch: 41 [50000/50000 (100%)]\tLoss: 0.000014\n",
            "\n",
            "Validation set: Average loss: 4.7493, Accuracy: 5762/10000 (58%)\n",
            "\n",
            "Train Epoch: 42 [50000/50000 (100%)]\tLoss: 0.000014\n",
            "\n",
            "Validation set: Average loss: 4.7613, Accuracy: 5762/10000 (58%)\n",
            "\n",
            "Train Epoch: 43 [50000/50000 (100%)]\tLoss: 0.000013\n",
            "\n",
            "Validation set: Average loss: 4.7729, Accuracy: 5762/10000 (58%)\n",
            "\n",
            "Train Epoch: 44 [50000/50000 (100%)]\tLoss: 0.000013\n",
            "\n",
            "Validation set: Average loss: 4.7840, Accuracy: 5762/10000 (58%)\n",
            "\n",
            "Train Epoch: 45 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 4.7950, Accuracy: 5761/10000 (58%)\n",
            "\n",
            "Train Epoch: 46 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 4.8057, Accuracy: 5760/10000 (58%)\n",
            "\n",
            "Train Epoch: 47 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 4.8160, Accuracy: 5761/10000 (58%)\n",
            "\n",
            "Train Epoch: 48 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 4.8260, Accuracy: 5761/10000 (58%)\n",
            "\n",
            "Train Epoch: 49 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 4.8357, Accuracy: 5763/10000 (58%)\n",
            "\n",
            "Train Epoch: 50 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 4.8452, Accuracy: 5763/10000 (58%)\n",
            "\n",
            "Train Epoch: 51 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 4.8545, Accuracy: 5765/10000 (58%)\n",
            "\n",
            "Train Epoch: 52 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 4.8635, Accuracy: 5765/10000 (58%)\n",
            "\n",
            "Train Epoch: 53 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 4.8722, Accuracy: 5767/10000 (58%)\n",
            "\n",
            "Train Epoch: 54 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.8809, Accuracy: 5767/10000 (58%)\n",
            "\n",
            "Train Epoch: 55 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.8893, Accuracy: 5766/10000 (58%)\n",
            "\n",
            "Train Epoch: 56 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.8974, Accuracy: 5767/10000 (58%)\n",
            "\n",
            "Train Epoch: 57 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.9055, Accuracy: 5767/10000 (58%)\n",
            "\n",
            "Train Epoch: 58 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.9134, Accuracy: 5767/10000 (58%)\n",
            "\n",
            "Train Epoch: 59 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.9212, Accuracy: 5767/10000 (58%)\n",
            "\n",
            "Train Epoch: 60 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.9287, Accuracy: 5767/10000 (58%)\n",
            "\n",
            "Train Epoch: 61 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.9361, Accuracy: 5769/10000 (58%)\n",
            "\n",
            "Train Epoch: 62 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.9434, Accuracy: 5769/10000 (58%)\n",
            "\n",
            "Train Epoch: 63 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.9506, Accuracy: 5770/10000 (58%)\n",
            "\n",
            "Train Epoch: 64 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.9576, Accuracy: 5770/10000 (58%)\n",
            "\n",
            "Train Epoch: 65 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.9645, Accuracy: 5769/10000 (58%)\n",
            "\n",
            "Train Epoch: 66 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.9712, Accuracy: 5769/10000 (58%)\n",
            "\n",
            "Train Epoch: 67 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.9779, Accuracy: 5769/10000 (58%)\n",
            "\n",
            "Train Epoch: 68 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.9844, Accuracy: 5769/10000 (58%)\n",
            "\n",
            "Train Epoch: 69 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.9909, Accuracy: 5769/10000 (58%)\n",
            "\n",
            "Train Epoch: 70 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.9972, Accuracy: 5769/10000 (58%)\n",
            "\n",
            "Train Epoch: 71 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 5.0034, Accuracy: 5769/10000 (58%)\n",
            "\n",
            "Train Epoch: 72 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 5.0095, Accuracy: 5768/10000 (58%)\n",
            "\n",
            "Train Epoch: 73 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 5.0155, Accuracy: 5771/10000 (58%)\n",
            "\n",
            "Train Epoch: 74 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 5.0215, Accuracy: 5770/10000 (58%)\n",
            "\n",
            "Train Epoch: 75 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 5.0273, Accuracy: 5769/10000 (58%)\n",
            "\n",
            "Train Epoch: 76 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 5.0330, Accuracy: 5769/10000 (58%)\n",
            "\n",
            "Train Epoch: 77 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 5.0387, Accuracy: 5770/10000 (58%)\n",
            "\n",
            "Train Epoch: 78 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 5.0443, Accuracy: 5770/10000 (58%)\n",
            "\n",
            "Train Epoch: 79 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 5.0498, Accuracy: 5768/10000 (58%)\n",
            "\n",
            "Train Epoch: 80 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 5.0552, Accuracy: 5769/10000 (58%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FRNPF(II)"
      ],
      "metadata": {
        "id": "mf8eB2zVQqZJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frnpf_ii_model = Conv4Galu(args['image_size'], args['channels'])\n",
        "frnpf_ii_model.to(device)\n",
        "frnpf_ii_model"
      ],
      "metadata": {
        "id": "x8jVcgLOQp1L",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33c8a987-b716-46ac-ea75-c19d0469fb75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv4Galu(\n",
              "  (NPF_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPF_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPF_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (NPV_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPV_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPV_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (outputs): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in frnpf_ii_model.named_parameters():\n",
        "  if name[0:3]=='NPF':\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "iySAVoWb5P7t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in frnpf_ii_model.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    print(name)"
      ],
      "metadata": {
        "id": "-eN-Pn6yRrFa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b11bd66-b417-4d47-88e4-d84dc09caf0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NPV_C1.weight\n",
            "NPV_C1.bias\n",
            "NPV_C2.weight\n",
            "NPV_C2.bias\n",
            "NPV_C3.weight\n",
            "NPV_C3.bias\n",
            "NPV_C4.weight\n",
            "NPV_C4.bias\n",
            "NPV_D1.weight\n",
            "NPV_D1.bias\n",
            "NPV_D2.weight\n",
            "NPV_D2.bias\n",
            "outputs.weight\n",
            "outputs.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(frnpf_ii_model.parameters(), lr=args['lr'])\n",
        "for epoch in range(1, args['epochs']+1):\n",
        "  train(frnpf_ii_model, epoch, train_loader, lossFn, optimizer)\n",
        "  validate(frnpf_ii_model, validation_loader, lossFn)"
      ],
      "metadata": {
        "id": "jCsn8ohzRvHa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "313bec67-28a4-4e09-ecb7-485fe1f967d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:70: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [50000/50000 (100%)]\tLoss: 1.898570\n",
            "\n",
            "Validation set: Average loss: 1.5425, Accuracy: 4475/10000 (45%)\n",
            "\n",
            "Train Epoch: 2 [50000/50000 (100%)]\tLoss: 1.403471\n",
            "\n",
            "Validation set: Average loss: 1.4165, Accuracy: 5048/10000 (50%)\n",
            "\n",
            "Train Epoch: 3 [50000/50000 (100%)]\tLoss: 1.166733\n",
            "\n",
            "Validation set: Average loss: 1.2674, Accuracy: 5505/10000 (55%)\n",
            "\n",
            "Train Epoch: 4 [50000/50000 (100%)]\tLoss: 0.927989\n",
            "\n",
            "Validation set: Average loss: 1.2580, Accuracy: 5616/10000 (56%)\n",
            "\n",
            "Train Epoch: 5 [50000/50000 (100%)]\tLoss: 0.619012\n",
            "\n",
            "Validation set: Average loss: 1.4655, Accuracy: 5521/10000 (55%)\n",
            "\n",
            "Train Epoch: 6 [50000/50000 (100%)]\tLoss: 0.297060\n",
            "\n",
            "Validation set: Average loss: 1.9188, Accuracy: 5407/10000 (54%)\n",
            "\n",
            "Train Epoch: 7 [50000/50000 (100%)]\tLoss: 0.148777\n",
            "\n",
            "Validation set: Average loss: 2.5157, Accuracy: 5145/10000 (51%)\n",
            "\n",
            "Train Epoch: 8 [50000/50000 (100%)]\tLoss: 0.088980\n",
            "\n",
            "Validation set: Average loss: 2.6831, Accuracy: 5454/10000 (55%)\n",
            "\n",
            "Train Epoch: 9 [50000/50000 (100%)]\tLoss: 0.056636\n",
            "\n",
            "Validation set: Average loss: 2.8653, Accuracy: 5544/10000 (55%)\n",
            "\n",
            "Train Epoch: 10 [50000/50000 (100%)]\tLoss: 0.041428\n",
            "\n",
            "Validation set: Average loss: 3.1109, Accuracy: 5546/10000 (55%)\n",
            "\n",
            "Train Epoch: 11 [50000/50000 (100%)]\tLoss: 0.038813\n",
            "\n",
            "Validation set: Average loss: 3.1330, Accuracy: 5442/10000 (54%)\n",
            "\n",
            "Train Epoch: 12 [50000/50000 (100%)]\tLoss: 0.012709\n",
            "\n",
            "Validation set: Average loss: 3.5988, Accuracy: 5589/10000 (56%)\n",
            "\n",
            "Train Epoch: 13 [50000/50000 (100%)]\tLoss: 0.010627\n",
            "\n",
            "Validation set: Average loss: 3.7065, Accuracy: 5594/10000 (56%)\n",
            "\n",
            "Train Epoch: 14 [50000/50000 (100%)]\tLoss: 0.008804\n",
            "\n",
            "Validation set: Average loss: 3.9939, Accuracy: 5597/10000 (56%)\n",
            "\n",
            "Train Epoch: 15 [50000/50000 (100%)]\tLoss: 0.016355\n",
            "\n",
            "Validation set: Average loss: 3.9836, Accuracy: 5558/10000 (56%)\n",
            "\n",
            "Train Epoch: 16 [50000/50000 (100%)]\tLoss: 0.024615\n",
            "\n",
            "Validation set: Average loss: 3.8942, Accuracy: 5614/10000 (56%)\n",
            "\n",
            "Train Epoch: 17 [50000/50000 (100%)]\tLoss: 0.023474\n",
            "\n",
            "Validation set: Average loss: 3.7791, Accuracy: 5541/10000 (55%)\n",
            "\n",
            "Train Epoch: 18 [50000/50000 (100%)]\tLoss: 0.012332\n",
            "\n",
            "Validation set: Average loss: 4.1101, Accuracy: 5412/10000 (54%)\n",
            "\n",
            "Train Epoch: 19 [50000/50000 (100%)]\tLoss: 0.012178\n",
            "\n",
            "Validation set: Average loss: 3.9870, Accuracy: 5604/10000 (56%)\n",
            "\n",
            "Train Epoch: 20 [50000/50000 (100%)]\tLoss: 0.006006\n",
            "\n",
            "Validation set: Average loss: 4.6032, Accuracy: 5340/10000 (53%)\n",
            "\n",
            "Train Epoch: 21 [50000/50000 (100%)]\tLoss: 0.004178\n",
            "\n",
            "Validation set: Average loss: 4.1904, Accuracy: 5627/10000 (56%)\n",
            "\n",
            "Train Epoch: 22 [50000/50000 (100%)]\tLoss: 0.000373\n",
            "\n",
            "Validation set: Average loss: 4.2783, Accuracy: 5650/10000 (56%)\n",
            "\n",
            "Train Epoch: 23 [50000/50000 (100%)]\tLoss: 0.000092\n",
            "\n",
            "Validation set: Average loss: 4.3354, Accuracy: 5672/10000 (57%)\n",
            "\n",
            "Train Epoch: 24 [50000/50000 (100%)]\tLoss: 0.000068\n",
            "\n",
            "Validation set: Average loss: 4.3847, Accuracy: 5671/10000 (57%)\n",
            "\n",
            "Train Epoch: 25 [50000/50000 (100%)]\tLoss: 0.000057\n",
            "\n",
            "Validation set: Average loss: 4.4247, Accuracy: 5667/10000 (57%)\n",
            "\n",
            "Train Epoch: 26 [50000/50000 (100%)]\tLoss: 0.000049\n",
            "\n",
            "Validation set: Average loss: 4.4631, Accuracy: 5665/10000 (57%)\n",
            "\n",
            "Train Epoch: 27 [50000/50000 (100%)]\tLoss: 0.000043\n",
            "\n",
            "Validation set: Average loss: 4.4941, Accuracy: 5669/10000 (57%)\n",
            "\n",
            "Train Epoch: 28 [50000/50000 (100%)]\tLoss: 0.000039\n",
            "\n",
            "Validation set: Average loss: 4.5241, Accuracy: 5668/10000 (57%)\n",
            "\n",
            "Train Epoch: 29 [50000/50000 (100%)]\tLoss: 0.000035\n",
            "\n",
            "Validation set: Average loss: 4.5494, Accuracy: 5669/10000 (57%)\n",
            "\n",
            "Train Epoch: 30 [50000/50000 (100%)]\tLoss: 0.000032\n",
            "\n",
            "Validation set: Average loss: 4.5744, Accuracy: 5671/10000 (57%)\n",
            "\n",
            "Train Epoch: 31 [50000/50000 (100%)]\tLoss: 0.000030\n",
            "\n",
            "Validation set: Average loss: 4.5975, Accuracy: 5671/10000 (57%)\n",
            "\n",
            "Train Epoch: 32 [50000/50000 (100%)]\tLoss: 0.000028\n",
            "\n",
            "Validation set: Average loss: 4.6188, Accuracy: 5673/10000 (57%)\n",
            "\n",
            "Train Epoch: 33 [50000/50000 (100%)]\tLoss: 0.000026\n",
            "\n",
            "Validation set: Average loss: 4.6386, Accuracy: 5673/10000 (57%)\n",
            "\n",
            "Train Epoch: 34 [50000/50000 (100%)]\tLoss: 0.000024\n",
            "\n",
            "Validation set: Average loss: 4.6579, Accuracy: 5675/10000 (57%)\n",
            "\n",
            "Train Epoch: 35 [50000/50000 (100%)]\tLoss: 0.000023\n",
            "\n",
            "Validation set: Average loss: 4.6759, Accuracy: 5677/10000 (57%)\n",
            "\n",
            "Train Epoch: 36 [50000/50000 (100%)]\tLoss: 0.000021\n",
            "\n",
            "Validation set: Average loss: 4.6928, Accuracy: 5678/10000 (57%)\n",
            "\n",
            "Train Epoch: 37 [50000/50000 (100%)]\tLoss: 0.000020\n",
            "\n",
            "Validation set: Average loss: 4.7094, Accuracy: 5677/10000 (57%)\n",
            "\n",
            "Train Epoch: 38 [50000/50000 (100%)]\tLoss: 0.000019\n",
            "\n",
            "Validation set: Average loss: 4.7250, Accuracy: 5679/10000 (57%)\n",
            "\n",
            "Train Epoch: 39 [50000/50000 (100%)]\tLoss: 0.000018\n",
            "\n",
            "Validation set: Average loss: 4.7401, Accuracy: 5677/10000 (57%)\n",
            "\n",
            "Train Epoch: 40 [50000/50000 (100%)]\tLoss: 0.000018\n",
            "\n",
            "Validation set: Average loss: 4.7546, Accuracy: 5677/10000 (57%)\n",
            "\n",
            "Train Epoch: 41 [50000/50000 (100%)]\tLoss: 0.000017\n",
            "\n",
            "Validation set: Average loss: 4.7684, Accuracy: 5677/10000 (57%)\n",
            "\n",
            "Train Epoch: 42 [50000/50000 (100%)]\tLoss: 0.000016\n",
            "\n",
            "Validation set: Average loss: 4.7815, Accuracy: 5679/10000 (57%)\n",
            "\n",
            "Train Epoch: 43 [50000/50000 (100%)]\tLoss: 0.000016\n",
            "\n",
            "Validation set: Average loss: 4.7941, Accuracy: 5682/10000 (57%)\n",
            "\n",
            "Train Epoch: 44 [50000/50000 (100%)]\tLoss: 0.000015\n",
            "\n",
            "Validation set: Average loss: 4.8064, Accuracy: 5679/10000 (57%)\n",
            "\n",
            "Train Epoch: 45 [50000/50000 (100%)]\tLoss: 0.000014\n",
            "\n",
            "Validation set: Average loss: 4.8184, Accuracy: 5681/10000 (57%)\n",
            "\n",
            "Train Epoch: 46 [50000/50000 (100%)]\tLoss: 0.000014\n",
            "\n",
            "Validation set: Average loss: 4.8301, Accuracy: 5680/10000 (57%)\n",
            "\n",
            "Train Epoch: 47 [50000/50000 (100%)]\tLoss: 0.000013\n",
            "\n",
            "Validation set: Average loss: 4.8413, Accuracy: 5677/10000 (57%)\n",
            "\n",
            "Train Epoch: 48 [50000/50000 (100%)]\tLoss: 0.000013\n",
            "\n",
            "Validation set: Average loss: 4.8521, Accuracy: 5676/10000 (57%)\n",
            "\n",
            "Train Epoch: 49 [50000/50000 (100%)]\tLoss: 0.000013\n",
            "\n",
            "Validation set: Average loss: 4.8626, Accuracy: 5679/10000 (57%)\n",
            "\n",
            "Train Epoch: 50 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 4.8728, Accuracy: 5679/10000 (57%)\n",
            "\n",
            "Train Epoch: 51 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 4.8829, Accuracy: 5679/10000 (57%)\n",
            "\n",
            "Train Epoch: 52 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 4.8927, Accuracy: 5681/10000 (57%)\n",
            "\n",
            "Train Epoch: 53 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 4.9022, Accuracy: 5681/10000 (57%)\n",
            "\n",
            "Train Epoch: 54 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 4.9115, Accuracy: 5681/10000 (57%)\n",
            "\n",
            "Train Epoch: 55 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 4.9205, Accuracy: 5680/10000 (57%)\n",
            "\n",
            "Train Epoch: 56 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 4.9294, Accuracy: 5680/10000 (57%)\n",
            "\n",
            "Train Epoch: 57 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 4.9379, Accuracy: 5679/10000 (57%)\n",
            "\n",
            "Train Epoch: 58 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 4.9463, Accuracy: 5679/10000 (57%)\n",
            "\n",
            "Train Epoch: 59 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.9545, Accuracy: 5679/10000 (57%)\n",
            "\n",
            "Train Epoch: 60 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.9626, Accuracy: 5679/10000 (57%)\n",
            "\n",
            "Train Epoch: 61 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.9705, Accuracy: 5678/10000 (57%)\n",
            "\n",
            "Train Epoch: 62 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.9783, Accuracy: 5679/10000 (57%)\n",
            "\n",
            "Train Epoch: 63 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.9860, Accuracy: 5679/10000 (57%)\n",
            "\n",
            "Train Epoch: 64 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.9934, Accuracy: 5680/10000 (57%)\n",
            "\n",
            "Train Epoch: 65 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 5.0007, Accuracy: 5680/10000 (57%)\n",
            "\n",
            "Train Epoch: 66 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 5.0077, Accuracy: 5680/10000 (57%)\n",
            "\n",
            "Train Epoch: 67 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 5.0149, Accuracy: 5681/10000 (57%)\n",
            "\n",
            "Train Epoch: 68 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 5.0218, Accuracy: 5680/10000 (57%)\n",
            "\n",
            "Train Epoch: 69 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 5.0286, Accuracy: 5680/10000 (57%)\n",
            "\n",
            "Train Epoch: 70 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 5.0352, Accuracy: 5679/10000 (57%)\n",
            "\n",
            "Train Epoch: 71 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 5.0417, Accuracy: 5680/10000 (57%)\n",
            "\n",
            "Train Epoch: 72 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 5.0481, Accuracy: 5678/10000 (57%)\n",
            "\n",
            "Train Epoch: 73 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 5.0545, Accuracy: 5677/10000 (57%)\n",
            "\n",
            "Train Epoch: 74 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 5.0607, Accuracy: 5677/10000 (57%)\n",
            "\n",
            "Train Epoch: 75 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 5.0668, Accuracy: 5676/10000 (57%)\n",
            "\n",
            "Train Epoch: 76 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 5.0728, Accuracy: 5677/10000 (57%)\n",
            "\n",
            "Train Epoch: 77 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 5.0788, Accuracy: 5677/10000 (57%)\n",
            "\n",
            "Train Epoch: 78 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 5.0846, Accuracy: 5675/10000 (57%)\n",
            "\n",
            "Train Epoch: 79 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 5.0903, Accuracy: 5675/10000 (57%)\n",
            "\n",
            "Train Epoch: 80 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 5.0960, Accuracy: 5674/10000 (57%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FRNPF(DI)"
      ],
      "metadata": {
        "id": "Aauyr0myRv0y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frnpf_di_model = Conv4Galu(args['image_size'], args['channels'])\n",
        "frnpf_di_model.to(device)\n",
        "frnpf_di_model"
      ],
      "metadata": {
        "id": "lc8_R6vmRxHD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "53ab86ec-6020-4cd8-ea49-4d17376cc8c7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv4Galu(\n",
              "  (NPF_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPF_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPF_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (NPV_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPV_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPV_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (outputs): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in frnpf_di_model.named_parameters():\n",
        "  print(name, param)"
      ],
      "metadata": {
        "id": "KAz4l7skSRqg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f02155f4-44ae-42a8-ae58-d5d380baabd1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NPF_C1.weight Parameter containing:\n",
            "tensor([[[[-0.0019,  0.0185, -0.1181],\n",
            "          [ 0.1679, -0.0833,  0.1155],\n",
            "          [ 0.1736,  0.0489,  0.1676]],\n",
            "\n",
            "         [[-0.1057,  0.0603,  0.0241],\n",
            "          [-0.1840,  0.0324, -0.1352],\n",
            "          [-0.1487,  0.0581, -0.0167]],\n",
            "\n",
            "         [[-0.1195, -0.1121, -0.0433],\n",
            "          [-0.0900, -0.1721,  0.1814],\n",
            "          [ 0.1073,  0.1085, -0.1574]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0981, -0.0385, -0.0231],\n",
            "          [ 0.0371, -0.1603,  0.1794],\n",
            "          [ 0.1700, -0.0906,  0.1851]],\n",
            "\n",
            "         [[-0.0426, -0.1535, -0.0716],\n",
            "          [ 0.0549, -0.1895,  0.1919],\n",
            "          [ 0.1463,  0.0401, -0.0376]],\n",
            "\n",
            "         [[ 0.1339,  0.1742,  0.0941],\n",
            "          [ 0.0716,  0.1272, -0.0439],\n",
            "          [-0.1876,  0.1524,  0.1535]]],\n",
            "\n",
            "\n",
            "        [[[-0.0071, -0.1299,  0.0887],\n",
            "          [-0.0907, -0.0325,  0.0181],\n",
            "          [ 0.1828,  0.1630, -0.1769]],\n",
            "\n",
            "         [[ 0.0117,  0.0538,  0.1873],\n",
            "          [ 0.1240,  0.0830,  0.0821],\n",
            "          [ 0.0004,  0.0901, -0.1896]],\n",
            "\n",
            "         [[ 0.0818,  0.0066, -0.0457],\n",
            "          [ 0.0660, -0.1797, -0.0697],\n",
            "          [ 0.0661, -0.1089, -0.0047]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0438, -0.0797,  0.1151],\n",
            "          [-0.1055, -0.0805, -0.0680],\n",
            "          [ 0.1921,  0.0666,  0.1408]],\n",
            "\n",
            "         [[-0.0478, -0.0041, -0.0763],\n",
            "          [ 0.0883,  0.0862,  0.0428],\n",
            "          [ 0.1663,  0.1448,  0.0518]],\n",
            "\n",
            "         [[-0.0613,  0.1634,  0.0267],\n",
            "          [-0.0299,  0.1287,  0.0608],\n",
            "          [ 0.0402,  0.0248, -0.1894]]],\n",
            "\n",
            "\n",
            "        [[[-0.0814, -0.0463,  0.0582],\n",
            "          [-0.1882,  0.1799, -0.1860],\n",
            "          [-0.1882,  0.0466,  0.0059]],\n",
            "\n",
            "         [[ 0.1700,  0.0132,  0.0779],\n",
            "          [-0.1389, -0.0499, -0.1000],\n",
            "          [ 0.0890, -0.0929, -0.0418]],\n",
            "\n",
            "         [[ 0.0551, -0.0578, -0.0259],\n",
            "          [ 0.1611, -0.1148,  0.0117],\n",
            "          [-0.0584,  0.0301, -0.1435]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0351, -0.0674, -0.1152],\n",
            "          [ 0.0221, -0.0566, -0.0489],\n",
            "          [ 0.1514, -0.0549, -0.1193]],\n",
            "\n",
            "         [[-0.1671, -0.0615,  0.0523],\n",
            "          [-0.0764,  0.0512, -0.1637],\n",
            "          [ 0.0996, -0.1436,  0.0546]],\n",
            "\n",
            "         [[-0.0545, -0.0014,  0.1552],\n",
            "          [-0.0063, -0.1123,  0.0035],\n",
            "          [ 0.0119, -0.1650,  0.1612]]]], device='cuda:0', requires_grad=True)\n",
            "NPF_C1.bias Parameter containing:\n",
            "tensor([ 0.0507, -0.0374,  0.0686,  0.0936, -0.1476,  0.0326,  0.0784, -0.0010,\n",
            "         0.1679,  0.1448,  0.0427,  0.1723,  0.0723, -0.1154, -0.0947,  0.0309,\n",
            "         0.1168,  0.0258, -0.1883, -0.0564, -0.1253,  0.0949,  0.1425, -0.1790,\n",
            "         0.1669, -0.1765, -0.0433,  0.1527, -0.1213, -0.0179,  0.1378,  0.1404,\n",
            "        -0.1050,  0.0012,  0.0288,  0.0907,  0.1108, -0.0660,  0.1608,  0.0733,\n",
            "         0.1532, -0.0157,  0.1386, -0.0389, -0.1313, -0.1835,  0.0316,  0.0509,\n",
            "         0.1810, -0.0077,  0.1519,  0.1837,  0.0317, -0.1821, -0.0197,  0.1348,\n",
            "         0.1251,  0.0374, -0.0794, -0.0379, -0.0227, -0.1849,  0.1429,  0.0758],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPF_C2.weight Parameter containing:\n",
            "tensor([[[[ 2.3050e-02,  9.7423e-03, -3.0328e-02],\n",
            "          [-1.1057e-02, -2.8745e-02,  1.4103e-02],\n",
            "          [-2.1061e-02,  2.4912e-02,  3.2820e-02]],\n",
            "\n",
            "         [[-2.0113e-02,  8.9148e-03,  3.5359e-02],\n",
            "          [-3.5498e-02, -3.9398e-02,  1.3431e-02],\n",
            "          [-8.0731e-03,  3.3200e-02, -9.1476e-03]],\n",
            "\n",
            "         [[-1.6896e-02,  3.7888e-02,  3.6665e-02],\n",
            "          [-2.1892e-02,  3.7905e-02,  2.7186e-04],\n",
            "          [-2.2139e-02,  2.2319e-03, -9.9140e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.5962e-03, -1.5240e-02, -1.2136e-02],\n",
            "          [ 9.3066e-03, -2.6377e-02, -2.6668e-02],\n",
            "          [-4.1001e-02, -3.6063e-02,  1.5221e-02]],\n",
            "\n",
            "         [[ 8.5772e-03, -5.7238e-03,  2.1997e-02],\n",
            "          [ 2.7872e-03, -3.1276e-02, -1.9033e-02],\n",
            "          [-3.0390e-02, -2.4563e-02, -9.2500e-03]],\n",
            "\n",
            "         [[-2.6959e-02, -2.0910e-02,  3.3012e-02],\n",
            "          [-2.3273e-02,  3.0797e-02, -3.5342e-02],\n",
            "          [-3.1127e-02, -2.8122e-02,  7.8464e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4939e-02,  2.1405e-02, -1.1557e-02],\n",
            "          [-1.2812e-02,  1.8119e-02, -3.8073e-02],\n",
            "          [-1.8989e-02,  2.3196e-02, -2.1959e-02]],\n",
            "\n",
            "         [[-2.3799e-02,  2.7656e-02,  9.0041e-03],\n",
            "          [-6.0298e-03, -1.2593e-02,  1.3218e-02],\n",
            "          [-2.6411e-02, -8.0229e-03,  9.0015e-03]],\n",
            "\n",
            "         [[ 3.6170e-02, -3.9856e-02, -4.0191e-02],\n",
            "          [-2.0353e-02, -4.5344e-03, -3.9957e-03],\n",
            "          [-1.6540e-02,  2.2474e-03,  2.0647e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.4668e-02,  3.9175e-02,  1.0445e-02],\n",
            "          [-4.8766e-03,  1.6828e-02,  3.0415e-02],\n",
            "          [ 2.6316e-02,  1.6213e-02, -1.9126e-02]],\n",
            "\n",
            "         [[-2.7786e-02,  3.9720e-02, -1.5639e-02],\n",
            "          [-2.0594e-03,  3.5200e-02, -1.2429e-02],\n",
            "          [ 3.1135e-02, -2.0582e-02,  2.3940e-02]],\n",
            "\n",
            "         [[ 2.8568e-02, -3.9296e-02, -6.9419e-04],\n",
            "          [ 1.7912e-02, -2.3108e-03,  1.9998e-02],\n",
            "          [-3.7852e-02,  6.0045e-04,  2.2390e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.5948e-02, -3.6266e-02, -2.1204e-02],\n",
            "          [-3.4749e-02, -3.2496e-02, -2.4829e-03],\n",
            "          [-2.5546e-02,  1.8828e-03,  1.8059e-02]],\n",
            "\n",
            "         [[-3.0833e-02,  3.0601e-02,  1.3304e-02],\n",
            "          [ 1.3857e-02, -3.0404e-03, -2.2800e-02],\n",
            "          [ 4.0085e-02, -2.4362e-03,  5.3667e-03]],\n",
            "\n",
            "         [[ 3.4160e-02, -1.8976e-02,  4.0099e-03],\n",
            "          [ 3.9427e-02, -3.1099e-02, -3.1934e-02],\n",
            "          [ 4.0394e-02,  3.2673e-02,  2.0292e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.1849e-02,  3.2705e-02,  4.8001e-03],\n",
            "          [-2.3129e-02, -4.1569e-02, -3.5809e-02],\n",
            "          [-7.7584e-03,  2.3792e-02,  1.0590e-02]],\n",
            "\n",
            "         [[ 2.1330e-02,  4.1392e-02,  4.1442e-02],\n",
            "          [ 3.7934e-02, -1.1746e-02,  4.4341e-03],\n",
            "          [ 1.5941e-02, -3.5016e-02,  6.1964e-03]],\n",
            "\n",
            "         [[-3.6170e-02, -1.0793e-03, -1.1604e-02],\n",
            "          [ 9.4459e-03,  1.3204e-02, -3.6051e-02],\n",
            "          [-2.6505e-02,  3.0533e-02, -1.9045e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.2573e-02,  8.7907e-04, -6.2927e-03],\n",
            "          [ 1.8192e-02,  3.6045e-02, -3.2062e-03],\n",
            "          [-2.4391e-02, -2.2975e-02,  4.0510e-02]],\n",
            "\n",
            "         [[ 4.1273e-02,  2.8220e-02, -3.0040e-03],\n",
            "          [-1.8752e-02,  1.1680e-02,  3.6637e-02],\n",
            "          [ 1.0067e-02,  3.2954e-02,  3.9213e-02]],\n",
            "\n",
            "         [[-1.0767e-02,  4.9945e-03,  2.5332e-02],\n",
            "          [ 4.0083e-02,  3.6481e-02,  1.6216e-02],\n",
            "          [ 3.9324e-02,  3.0139e-02,  1.3916e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.8309e-02, -1.6250e-03,  2.3825e-02],\n",
            "          [ 9.2420e-04,  8.9100e-03, -1.3412e-02],\n",
            "          [-2.2988e-02,  3.5348e-02,  1.4593e-02]],\n",
            "\n",
            "         [[-3.7686e-02,  1.4035e-02,  3.6904e-02],\n",
            "          [-1.2283e-02, -4.1201e-04, -2.2881e-03],\n",
            "          [-2.1777e-02,  1.5302e-02, -3.7006e-02]],\n",
            "\n",
            "         [[-9.5005e-03, -2.6625e-02, -6.9656e-04],\n",
            "          [-1.1776e-02,  2.6034e-04, -5.1499e-03],\n",
            "          [-2.8387e-02,  4.1547e-02, -3.8971e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 7.3000e-03,  6.0646e-03, -2.2821e-02],\n",
            "          [ 1.9517e-02,  1.2351e-02, -6.5803e-03],\n",
            "          [-2.1004e-02, -9.6188e-03,  2.7817e-02]],\n",
            "\n",
            "         [[ 3.9924e-03,  3.4592e-02, -7.7009e-03],\n",
            "          [ 3.9408e-02,  3.4901e-02, -2.6357e-02],\n",
            "          [ 2.7112e-02,  5.9224e-03,  1.4333e-02]],\n",
            "\n",
            "         [[ 3.2337e-02, -3.7864e-02,  3.5905e-02],\n",
            "          [-2.1611e-02, -1.6168e-02, -3.4146e-02],\n",
            "          [ 1.4478e-02,  3.8937e-02, -1.6994e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.6206e-03,  2.4556e-02,  2.8275e-02],\n",
            "          [ 1.2896e-02, -1.9515e-02,  3.3433e-02],\n",
            "          [ 3.4223e-02,  2.0612e-02, -1.8237e-02]],\n",
            "\n",
            "         [[ 1.5909e-02, -2.1551e-02, -1.5698e-02],\n",
            "          [-1.4236e-02,  3.8901e-02, -1.0314e-02],\n",
            "          [ 9.8497e-05, -1.3704e-02, -1.6363e-02]],\n",
            "\n",
            "         [[-3.6518e-02, -1.2236e-02,  1.7272e-02],\n",
            "          [ 3.9401e-02, -5.9157e-03,  1.9607e-02],\n",
            "          [ 1.2513e-02, -2.0983e-02,  1.9361e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.2928e-02, -2.8836e-02, -9.1165e-03],\n",
            "          [-3.3904e-03, -1.2998e-02,  3.3610e-02],\n",
            "          [ 3.5843e-02, -4.1185e-02,  2.4671e-02]],\n",
            "\n",
            "         [[ 2.3443e-02, -3.8110e-02,  2.7408e-02],\n",
            "          [-2.1905e-03, -3.5241e-02, -3.3339e-02],\n",
            "          [ 6.7193e-03, -2.5329e-02, -6.6557e-03]],\n",
            "\n",
            "         [[ 1.3374e-02, -1.0066e-02, -3.2282e-02],\n",
            "          [-4.0891e-02, -3.9892e-02, -2.2107e-02],\n",
            "          [-3.4137e-02,  4.0821e-02,  1.3423e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8331e-02,  3.5403e-02,  2.5455e-02],\n",
            "          [-2.6983e-02, -3.5554e-02,  2.2675e-02],\n",
            "          [ 3.2986e-02, -1.1327e-02,  2.7946e-03]],\n",
            "\n",
            "         [[-3.1433e-02, -4.9170e-03,  3.9814e-02],\n",
            "          [ 2.7925e-02, -6.2895e-03,  1.4153e-02],\n",
            "          [ 4.1610e-02, -1.7690e-02,  3.7680e-02]],\n",
            "\n",
            "         [[ 3.2697e-02,  8.1476e-04, -3.3376e-02],\n",
            "          [ 1.7988e-02,  3.3406e-02, -3.8238e-02],\n",
            "          [-4.1034e-02, -3.9709e-02,  3.1792e-02]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPF_C2.bias Parameter containing:\n",
            "tensor([-0.0320,  0.0339, -0.0111, -0.0154, -0.0371,  0.0092,  0.0186,  0.0117,\n",
            "        -0.0320, -0.0057, -0.0305, -0.0037, -0.0101,  0.0183, -0.0288,  0.0070,\n",
            "        -0.0407, -0.0201, -0.0303, -0.0268, -0.0398, -0.0193,  0.0024, -0.0025,\n",
            "        -0.0224, -0.0064,  0.0412,  0.0157,  0.0261, -0.0281,  0.0024, -0.0147,\n",
            "         0.0175, -0.0154,  0.0359, -0.0019, -0.0376,  0.0313, -0.0078,  0.0325,\n",
            "        -0.0344, -0.0102,  0.0268, -0.0390,  0.0107, -0.0269, -0.0069,  0.0001,\n",
            "        -0.0389, -0.0165,  0.0209, -0.0056, -0.0037,  0.0023,  0.0208,  0.0387,\n",
            "         0.0214,  0.0067, -0.0269, -0.0299, -0.0042,  0.0050,  0.0065,  0.0019],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPF_C3.weight Parameter containing:\n",
            "tensor([[[[ 0.0170, -0.0162, -0.0239],\n",
            "          [-0.0278,  0.0172,  0.0040],\n",
            "          [ 0.0362, -0.0411, -0.0279]],\n",
            "\n",
            "         [[-0.0121,  0.0017,  0.0128],\n",
            "          [-0.0144,  0.0201,  0.0118],\n",
            "          [ 0.0396,  0.0174, -0.0222]],\n",
            "\n",
            "         [[-0.0018,  0.0402,  0.0169],\n",
            "          [ 0.0172,  0.0202,  0.0013],\n",
            "          [ 0.0170, -0.0238,  0.0320]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0208, -0.0216, -0.0292],\n",
            "          [-0.0045, -0.0110,  0.0409],\n",
            "          [-0.0219,  0.0090,  0.0290]],\n",
            "\n",
            "         [[ 0.0393, -0.0233,  0.0062],\n",
            "          [ 0.0019, -0.0022, -0.0330],\n",
            "          [-0.0031, -0.0079, -0.0012]],\n",
            "\n",
            "         [[ 0.0097, -0.0121,  0.0394],\n",
            "          [-0.0073, -0.0160, -0.0323],\n",
            "          [-0.0359, -0.0133,  0.0244]]],\n",
            "\n",
            "\n",
            "        [[[-0.0036, -0.0048, -0.0188],\n",
            "          [-0.0293, -0.0097, -0.0131],\n",
            "          [-0.0196,  0.0067, -0.0275]],\n",
            "\n",
            "         [[ 0.0095, -0.0208, -0.0339],\n",
            "          [ 0.0404,  0.0371, -0.0286],\n",
            "          [ 0.0354,  0.0296, -0.0314]],\n",
            "\n",
            "         [[-0.0043, -0.0265, -0.0100],\n",
            "          [-0.0143,  0.0223, -0.0212],\n",
            "          [ 0.0292,  0.0196,  0.0120]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0138, -0.0175,  0.0113],\n",
            "          [-0.0009,  0.0316,  0.0228],\n",
            "          [-0.0115, -0.0116, -0.0344]],\n",
            "\n",
            "         [[-0.0273,  0.0389,  0.0247],\n",
            "          [ 0.0162,  0.0251, -0.0108],\n",
            "          [ 0.0246, -0.0016,  0.0116]],\n",
            "\n",
            "         [[ 0.0268,  0.0195, -0.0057],\n",
            "          [ 0.0242, -0.0250,  0.0233],\n",
            "          [-0.0320,  0.0377, -0.0206]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0109, -0.0009, -0.0071],\n",
            "          [ 0.0414, -0.0037,  0.0145],\n",
            "          [ 0.0314, -0.0181, -0.0079]],\n",
            "\n",
            "         [[-0.0281,  0.0046, -0.0011],\n",
            "          [-0.0074, -0.0063, -0.0344],\n",
            "          [ 0.0024,  0.0193, -0.0312]],\n",
            "\n",
            "         [[ 0.0202, -0.0119,  0.0185],\n",
            "          [ 0.0400, -0.0387,  0.0330],\n",
            "          [ 0.0392, -0.0173,  0.0202]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0146, -0.0089, -0.0344],\n",
            "          [ 0.0282,  0.0397,  0.0337],\n",
            "          [ 0.0299,  0.0227, -0.0369]],\n",
            "\n",
            "         [[ 0.0345,  0.0044,  0.0331],\n",
            "          [ 0.0052, -0.0098,  0.0255],\n",
            "          [-0.0230,  0.0071,  0.0415]],\n",
            "\n",
            "         [[-0.0100,  0.0099,  0.0168],\n",
            "          [-0.0056, -0.0373, -0.0211],\n",
            "          [-0.0064,  0.0006, -0.0315]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0078, -0.0250, -0.0134],\n",
            "          [ 0.0179, -0.0404, -0.0168],\n",
            "          [-0.0018,  0.0131, -0.0241]],\n",
            "\n",
            "         [[ 0.0112, -0.0302, -0.0146],\n",
            "          [ 0.0398,  0.0168,  0.0395],\n",
            "          [-0.0364, -0.0044,  0.0127]],\n",
            "\n",
            "         [[-0.0167, -0.0338, -0.0274],\n",
            "          [ 0.0079,  0.0346, -0.0081],\n",
            "          [-0.0357,  0.0202,  0.0256]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0382,  0.0134,  0.0221],\n",
            "          [ 0.0131, -0.0134, -0.0093],\n",
            "          [-0.0408, -0.0055, -0.0321]],\n",
            "\n",
            "         [[-0.0219, -0.0164, -0.0015],\n",
            "          [-0.0258,  0.0285,  0.0169],\n",
            "          [-0.0346,  0.0381,  0.0357]],\n",
            "\n",
            "         [[ 0.0372,  0.0322, -0.0084],\n",
            "          [-0.0097, -0.0393,  0.0384],\n",
            "          [-0.0042,  0.0240,  0.0132]]],\n",
            "\n",
            "\n",
            "        [[[-0.0152, -0.0378,  0.0359],\n",
            "          [-0.0318,  0.0030, -0.0304],\n",
            "          [-0.0276,  0.0065,  0.0082]],\n",
            "\n",
            "         [[ 0.0079,  0.0308,  0.0311],\n",
            "          [ 0.0376,  0.0125,  0.0278],\n",
            "          [-0.0363,  0.0376,  0.0414]],\n",
            "\n",
            "         [[-0.0319, -0.0338,  0.0188],\n",
            "          [ 0.0209, -0.0294, -0.0092],\n",
            "          [ 0.0384, -0.0380, -0.0136]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0304,  0.0168, -0.0351],\n",
            "          [ 0.0237,  0.0289, -0.0246],\n",
            "          [-0.0015, -0.0254, -0.0013]],\n",
            "\n",
            "         [[ 0.0094, -0.0318,  0.0316],\n",
            "          [-0.0269, -0.0414, -0.0219],\n",
            "          [-0.0241,  0.0084,  0.0188]],\n",
            "\n",
            "         [[-0.0400,  0.0333,  0.0017],\n",
            "          [-0.0329, -0.0226,  0.0207],\n",
            "          [-0.0316, -0.0030,  0.0216]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0054, -0.0092,  0.0095],\n",
            "          [ 0.0006, -0.0048,  0.0063],\n",
            "          [-0.0119, -0.0225, -0.0338]],\n",
            "\n",
            "         [[-0.0293, -0.0063, -0.0409],\n",
            "          [ 0.0201, -0.0037,  0.0152],\n",
            "          [ 0.0353,  0.0325,  0.0211]],\n",
            "\n",
            "         [[ 0.0105,  0.0010,  0.0255],\n",
            "          [-0.0218,  0.0281,  0.0306],\n",
            "          [-0.0314, -0.0339,  0.0130]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0404, -0.0284,  0.0306],\n",
            "          [-0.0176, -0.0082,  0.0036],\n",
            "          [ 0.0075, -0.0165,  0.0067]],\n",
            "\n",
            "         [[-0.0321, -0.0018,  0.0332],\n",
            "          [-0.0305, -0.0008,  0.0281],\n",
            "          [ 0.0138,  0.0069,  0.0394]],\n",
            "\n",
            "         [[-0.0075, -0.0008, -0.0049],\n",
            "          [-0.0274,  0.0316,  0.0314],\n",
            "          [-0.0393,  0.0180,  0.0016]]]], device='cuda:0', requires_grad=True)\n",
            "NPF_C3.bias Parameter containing:\n",
            "tensor([ 0.0285, -0.0407,  0.0123, -0.0192, -0.0121,  0.0363, -0.0006,  0.0023,\n",
            "         0.0290, -0.0383, -0.0187, -0.0323,  0.0320,  0.0102,  0.0093,  0.0181,\n",
            "        -0.0109,  0.0077, -0.0268,  0.0076,  0.0367,  0.0289, -0.0209,  0.0150,\n",
            "         0.0241, -0.0017, -0.0233,  0.0014,  0.0104,  0.0106,  0.0171, -0.0146,\n",
            "        -0.0030,  0.0096,  0.0319, -0.0074,  0.0336, -0.0382,  0.0042, -0.0409,\n",
            "         0.0152, -0.0043, -0.0313,  0.0299, -0.0043, -0.0169, -0.0353,  0.0025,\n",
            "         0.0380, -0.0253, -0.0093, -0.0034,  0.0119, -0.0087, -0.0326,  0.0397,\n",
            "        -0.0267,  0.0084, -0.0209,  0.0138,  0.0353,  0.0161, -0.0165,  0.0101,\n",
            "         0.0083, -0.0387,  0.0023, -0.0386, -0.0380,  0.0049,  0.0335,  0.0366,\n",
            "        -0.0064,  0.0308,  0.0209,  0.0160, -0.0226,  0.0282, -0.0074, -0.0194,\n",
            "         0.0130, -0.0361, -0.0240,  0.0194,  0.0117,  0.0403,  0.0053, -0.0343,\n",
            "         0.0380,  0.0270, -0.0295, -0.0266, -0.0397,  0.0308, -0.0245, -0.0274,\n",
            "         0.0372, -0.0103, -0.0053,  0.0188,  0.0404,  0.0380, -0.0191,  0.0301,\n",
            "        -0.0265, -0.0313,  0.0287,  0.0010,  0.0295,  0.0130,  0.0378, -0.0201,\n",
            "        -0.0161, -0.0239,  0.0288, -0.0047, -0.0004, -0.0280, -0.0196, -0.0110,\n",
            "         0.0076, -0.0264, -0.0371, -0.0286, -0.0416, -0.0261,  0.0293, -0.0177],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPF_C4.weight Parameter containing:\n",
            "tensor([[[[ 0.0112,  0.0174, -0.0086],\n",
            "          [-0.0231, -0.0091, -0.0006],\n",
            "          [-0.0118,  0.0112,  0.0089]],\n",
            "\n",
            "         [[ 0.0278,  0.0197,  0.0162],\n",
            "          [ 0.0211,  0.0241,  0.0020],\n",
            "          [ 0.0011, -0.0187,  0.0012]],\n",
            "\n",
            "         [[ 0.0065,  0.0052, -0.0153],\n",
            "          [ 0.0011,  0.0232,  0.0148],\n",
            "          [ 0.0133, -0.0160, -0.0225]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0091, -0.0171, -0.0016],\n",
            "          [ 0.0086, -0.0167, -0.0214],\n",
            "          [ 0.0175, -0.0183, -0.0281]],\n",
            "\n",
            "         [[-0.0060, -0.0169,  0.0227],\n",
            "          [ 0.0272,  0.0104, -0.0264],\n",
            "          [-0.0230, -0.0234,  0.0036]],\n",
            "\n",
            "         [[-0.0186, -0.0269, -0.0107],\n",
            "          [-0.0238, -0.0059, -0.0051],\n",
            "          [ 0.0014, -0.0132,  0.0168]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0254,  0.0033,  0.0163],\n",
            "          [-0.0105, -0.0200, -0.0208],\n",
            "          [-0.0224,  0.0092,  0.0189]],\n",
            "\n",
            "         [[ 0.0208,  0.0016, -0.0072],\n",
            "          [ 0.0148,  0.0229,  0.0292],\n",
            "          [-0.0096,  0.0099,  0.0198]],\n",
            "\n",
            "         [[ 0.0213, -0.0136,  0.0110],\n",
            "          [-0.0234, -0.0272, -0.0148],\n",
            "          [ 0.0259, -0.0160, -0.0039]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0093,  0.0289,  0.0019],\n",
            "          [-0.0232,  0.0034,  0.0198],\n",
            "          [-0.0003,  0.0216,  0.0278]],\n",
            "\n",
            "         [[ 0.0256,  0.0095,  0.0099],\n",
            "          [ 0.0023,  0.0274,  0.0240],\n",
            "          [-0.0066,  0.0291,  0.0148]],\n",
            "\n",
            "         [[ 0.0024, -0.0147, -0.0170],\n",
            "          [-0.0149,  0.0294, -0.0045],\n",
            "          [ 0.0057,  0.0278,  0.0139]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0016,  0.0008, -0.0168],\n",
            "          [-0.0229,  0.0224, -0.0245],\n",
            "          [ 0.0028, -0.0240, -0.0238]],\n",
            "\n",
            "         [[ 0.0252,  0.0177, -0.0041],\n",
            "          [ 0.0018,  0.0022, -0.0124],\n",
            "          [-0.0182, -0.0231,  0.0050]],\n",
            "\n",
            "         [[-0.0020,  0.0278, -0.0090],\n",
            "          [-0.0277,  0.0163, -0.0077],\n",
            "          [-0.0081, -0.0220, -0.0030]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0008, -0.0013,  0.0105],\n",
            "          [ 0.0137,  0.0126,  0.0245],\n",
            "          [-0.0099,  0.0294, -0.0015]],\n",
            "\n",
            "         [[ 0.0152,  0.0264,  0.0251],\n",
            "          [ 0.0270, -0.0070,  0.0229],\n",
            "          [ 0.0117, -0.0226, -0.0114]],\n",
            "\n",
            "         [[ 0.0144, -0.0233,  0.0281],\n",
            "          [-0.0251,  0.0200,  0.0059],\n",
            "          [ 0.0218, -0.0240, -0.0023]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0095, -0.0095,  0.0292],\n",
            "          [-0.0020,  0.0056, -0.0264],\n",
            "          [-0.0154,  0.0042,  0.0002]],\n",
            "\n",
            "         [[ 0.0219,  0.0065, -0.0152],\n",
            "          [-0.0194,  0.0026, -0.0248],\n",
            "          [-0.0294, -0.0007,  0.0018]],\n",
            "\n",
            "         [[ 0.0251, -0.0090, -0.0248],\n",
            "          [ 0.0067, -0.0039, -0.0139],\n",
            "          [ 0.0282,  0.0053,  0.0280]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0016, -0.0159,  0.0075],\n",
            "          [ 0.0044,  0.0198,  0.0208],\n",
            "          [-0.0119, -0.0116,  0.0029]],\n",
            "\n",
            "         [[-0.0174,  0.0093,  0.0061],\n",
            "          [-0.0095,  0.0261, -0.0054],\n",
            "          [-0.0029,  0.0018,  0.0042]],\n",
            "\n",
            "         [[-0.0158, -0.0186, -0.0137],\n",
            "          [ 0.0060, -0.0294,  0.0026],\n",
            "          [-0.0288,  0.0270,  0.0029]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0278,  0.0094, -0.0201],\n",
            "          [ 0.0143,  0.0070, -0.0149],\n",
            "          [-0.0117, -0.0078,  0.0180]],\n",
            "\n",
            "         [[-0.0249, -0.0287,  0.0246],\n",
            "          [ 0.0043, -0.0140,  0.0283],\n",
            "          [-0.0124, -0.0040, -0.0121]],\n",
            "\n",
            "         [[ 0.0005, -0.0115,  0.0245],\n",
            "          [ 0.0092, -0.0056,  0.0243],\n",
            "          [-0.0278, -0.0027,  0.0143]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0080,  0.0148,  0.0005],\n",
            "          [-0.0126, -0.0142, -0.0093],\n",
            "          [ 0.0207,  0.0136, -0.0031]],\n",
            "\n",
            "         [[-0.0152, -0.0248, -0.0201],\n",
            "          [-0.0092, -0.0162, -0.0104],\n",
            "          [-0.0199,  0.0223,  0.0204]],\n",
            "\n",
            "         [[-0.0170,  0.0189,  0.0086],\n",
            "          [-0.0198, -0.0081,  0.0078],\n",
            "          [-0.0008, -0.0282, -0.0205]]],\n",
            "\n",
            "\n",
            "        [[[-0.0243,  0.0066, -0.0191],\n",
            "          [-0.0016,  0.0259, -0.0065],\n",
            "          [-0.0283,  0.0215, -0.0254]],\n",
            "\n",
            "         [[ 0.0166, -0.0283,  0.0176],\n",
            "          [-0.0130, -0.0070,  0.0220],\n",
            "          [-0.0233,  0.0290, -0.0013]],\n",
            "\n",
            "         [[-0.0284, -0.0244, -0.0222],\n",
            "          [-0.0193,  0.0116,  0.0031],\n",
            "          [ 0.0221,  0.0007, -0.0067]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0263,  0.0290,  0.0211],\n",
            "          [-0.0206,  0.0206, -0.0149],\n",
            "          [-0.0288, -0.0206, -0.0165]],\n",
            "\n",
            "         [[-0.0150,  0.0014,  0.0092],\n",
            "          [-0.0148,  0.0205,  0.0186],\n",
            "          [ 0.0070, -0.0030,  0.0031]],\n",
            "\n",
            "         [[ 0.0211, -0.0219,  0.0057],\n",
            "          [-0.0025,  0.0247, -0.0206],\n",
            "          [-0.0188, -0.0124,  0.0258]]]], device='cuda:0', requires_grad=True)\n",
            "NPF_C4.bias Parameter containing:\n",
            "tensor([ 0.0091,  0.0125,  0.0134,  0.0006, -0.0105, -0.0044,  0.0048,  0.0281,\n",
            "        -0.0251, -0.0276,  0.0290, -0.0100, -0.0189, -0.0251,  0.0052,  0.0085,\n",
            "         0.0013,  0.0071,  0.0099, -0.0241,  0.0058, -0.0273, -0.0239, -0.0253,\n",
            "         0.0265, -0.0250, -0.0186,  0.0270,  0.0233,  0.0193, -0.0040, -0.0041,\n",
            "        -0.0118,  0.0172, -0.0184, -0.0259, -0.0113,  0.0189, -0.0184,  0.0040,\n",
            "        -0.0103, -0.0251, -0.0143, -0.0276,  0.0039, -0.0285, -0.0235, -0.0089,\n",
            "        -0.0147,  0.0225, -0.0027,  0.0004,  0.0218,  0.0265,  0.0270, -0.0208,\n",
            "         0.0117,  0.0137, -0.0052,  0.0133, -0.0189, -0.0171,  0.0210,  0.0173,\n",
            "        -0.0119, -0.0063, -0.0172, -0.0021,  0.0070,  0.0110, -0.0155, -0.0280,\n",
            "        -0.0155, -0.0159,  0.0168, -0.0250, -0.0259, -0.0087,  0.0111,  0.0206,\n",
            "        -0.0111,  0.0231, -0.0039,  0.0167,  0.0183,  0.0020,  0.0077, -0.0076,\n",
            "         0.0216,  0.0222, -0.0138, -0.0138, -0.0221,  0.0022,  0.0054,  0.0050,\n",
            "         0.0265, -0.0174,  0.0020, -0.0202,  0.0196, -0.0152,  0.0121, -0.0045,\n",
            "         0.0233,  0.0267, -0.0207,  0.0090, -0.0154,  0.0089, -0.0219, -0.0151,\n",
            "         0.0109,  0.0092,  0.0116, -0.0214, -0.0261, -0.0234,  0.0063,  0.0254,\n",
            "        -0.0178,  0.0162, -0.0165,  0.0258,  0.0039, -0.0245,  0.0282, -0.0078],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPF_D1.weight Parameter containing:\n",
            "tensor([[-1.1601e-03, -2.0837e-03,  2.2884e-03,  ...,  1.5079e-03,\n",
            "          1.7942e-03,  2.0226e-03],\n",
            "        [ 1.3426e-03,  1.3492e-04,  8.2935e-04,  ..., -1.8151e-03,\n",
            "         -1.0398e-04,  1.6438e-03],\n",
            "        [-5.0434e-05,  3.4996e-04, -7.8343e-04,  ..., -9.0619e-05,\n",
            "          4.7495e-04,  1.2460e-04],\n",
            "        ...,\n",
            "        [ 1.2657e-03, -1.2970e-03,  2.2735e-03,  ..., -9.4928e-04,\n",
            "          1.2608e-03, -8.7973e-04],\n",
            "        [ 3.4745e-04, -1.3193e-03,  1.4004e-03,  ...,  2.5312e-03,\n",
            "          2.2194e-03, -5.9444e-04],\n",
            "        [-2.0477e-03, -6.8684e-04,  2.6548e-03,  ...,  3.2463e-04,\n",
            "          4.7202e-04,  5.4719e-04]], device='cuda:0', requires_grad=True)\n",
            "NPF_D1.bias Parameter containing:\n",
            "tensor([ 2.0466e-03,  1.8290e-03,  2.1118e-03, -7.6980e-04, -2.1184e-03,\n",
            "         9.8909e-04,  1.0359e-03, -7.7918e-04, -3.1391e-04, -1.0562e-04,\n",
            "        -2.0958e-03,  1.4568e-03, -1.9732e-03, -2.2075e-03,  5.0070e-04,\n",
            "        -1.8714e-03, -9.1165e-04, -4.2361e-06,  1.3901e-03, -8.4962e-04,\n",
            "         1.5650e-03,  2.2811e-03,  3.3351e-04,  2.2634e-03, -2.7334e-03,\n",
            "         1.1720e-03, -1.5310e-03,  2.6911e-03, -3.6808e-05, -4.1005e-05,\n",
            "        -4.7232e-05,  2.4969e-03,  7.5979e-04, -1.4511e-03,  1.2626e-03,\n",
            "        -2.7321e-03, -1.9343e-03,  1.1135e-05, -1.3098e-04,  1.4404e-03,\n",
            "        -2.0748e-03, -2.7135e-03,  1.8458e-03, -2.4812e-03,  2.4995e-03,\n",
            "        -2.3771e-03,  2.2536e-03, -1.4074e-03, -3.9180e-04,  8.9265e-04,\n",
            "         9.1843e-04,  2.6067e-03,  1.2471e-04, -1.4271e-03,  9.1253e-05,\n",
            "        -2.2232e-03, -5.1763e-04, -4.9815e-04,  1.0091e-03,  4.5332e-04,\n",
            "        -1.9493e-03,  4.8076e-05, -1.3843e-03,  4.3411e-05, -1.5724e-04,\n",
            "         1.8635e-03, -8.7453e-04,  2.7965e-04, -1.4034e-04, -1.8009e-03,\n",
            "         7.2309e-05,  2.3185e-03, -1.9296e-03,  1.0485e-03, -1.2601e-03,\n",
            "        -1.3995e-03,  2.5031e-03,  4.5950e-04,  2.1045e-04, -1.2028e-03,\n",
            "         1.5932e-03,  2.5847e-03,  2.7299e-03, -2.1847e-03,  1.9856e-03,\n",
            "         4.8917e-04, -2.0786e-03, -5.3608e-04,  2.5002e-03, -9.7283e-04,\n",
            "        -1.9677e-04, -1.2076e-03, -5.3192e-04, -2.5026e-03,  2.1871e-03,\n",
            "        -4.1205e-04, -2.0127e-03, -1.4267e-03,  1.6355e-03,  1.3120e-03,\n",
            "         1.3073e-03, -1.2869e-03, -5.4092e-04, -2.5305e-03, -2.4107e-03,\n",
            "        -1.4673e-03,  8.7582e-04,  2.4859e-03,  5.1730e-04, -3.4560e-04,\n",
            "         3.7494e-04,  7.4629e-04, -2.5234e-03,  1.2313e-03, -5.5505e-04,\n",
            "        -7.0762e-04, -2.2297e-03, -1.0607e-04, -2.0528e-03, -2.5525e-03,\n",
            "        -1.9157e-03, -1.4190e-03,  1.9733e-03, -1.2583e-03, -2.0874e-03,\n",
            "         1.9016e-03, -2.6462e-03, -1.2230e-03, -5.4270e-04,  2.3715e-03,\n",
            "        -1.0096e-03, -2.2210e-03, -2.6067e-03, -6.8427e-04, -5.0042e-04,\n",
            "         2.3600e-03,  3.9536e-04, -1.8165e-03,  2.6423e-03, -2.5316e-04,\n",
            "         2.5747e-03,  1.5583e-03, -1.9552e-03, -2.0094e-03, -5.8648e-04,\n",
            "         2.5032e-03, -1.6174e-03,  9.1426e-04,  1.0425e-03,  3.7813e-04,\n",
            "        -2.1685e-04, -2.2025e-04,  1.2162e-03,  7.4922e-04, -1.2916e-03,\n",
            "         1.2301e-04,  1.1577e-03, -2.2082e-03,  1.8949e-03, -4.2092e-04,\n",
            "        -2.4065e-03, -2.7887e-04, -1.4531e-03, -1.7312e-03, -1.5194e-03,\n",
            "         2.1062e-03, -1.3778e-03, -2.2831e-03, -1.2076e-03, -1.1962e-03,\n",
            "        -2.0682e-03,  2.0668e-03, -5.9558e-04,  2.4693e-03, -4.3322e-04,\n",
            "        -2.7061e-03, -2.2318e-03,  1.2958e-03,  2.6173e-03,  2.1012e-03,\n",
            "        -1.3099e-03, -4.8982e-04,  2.4839e-03, -2.7499e-03,  2.0113e-03,\n",
            "        -1.5318e-04, -4.1205e-04, -1.2965e-04, -4.7626e-04, -5.2981e-04,\n",
            "        -2.4925e-03, -2.3263e-03,  1.1141e-03, -1.5413e-03,  1.3905e-03,\n",
            "        -6.2636e-04,  1.9779e-03,  1.0492e-03,  3.2952e-04,  6.7673e-04,\n",
            "        -2.7317e-03,  2.6732e-03,  1.0736e-03, -1.3170e-03, -1.0307e-03,\n",
            "        -1.8790e-03, -2.7501e-03,  2.3040e-04, -1.9736e-03,  1.6985e-03,\n",
            "        -1.1890e-03, -1.2032e-03,  1.5660e-04, -8.0313e-04, -1.7941e-03,\n",
            "        -4.4281e-04,  8.3723e-04,  8.8728e-04, -2.5553e-03, -1.4603e-03,\n",
            "        -1.0810e-03,  8.3187e-05,  1.1642e-03, -1.7357e-03,  1.3346e-03,\n",
            "         5.5196e-05,  2.4193e-03,  1.5412e-03,  3.9400e-04, -2.8978e-04,\n",
            "         4.8680e-04, -1.8574e-03,  2.1619e-03, -2.4564e-03,  2.6543e-03,\n",
            "        -1.7216e-03,  2.1374e-03,  4.1259e-04,  2.0540e-03, -7.6977e-04,\n",
            "         1.6026e-03, -2.0394e-03,  3.7964e-05,  1.1139e-03, -2.6579e-03,\n",
            "         2.6925e-03,  2.4071e-04, -1.3398e-03, -7.6033e-04,  1.0181e-04,\n",
            "        -7.8756e-04,  2.1077e-04, -4.1265e-04, -1.7912e-03,  2.6746e-04,\n",
            "         5.2355e-04], device='cuda:0', requires_grad=True)\n",
            "NPF_D2.weight Parameter containing:\n",
            "tensor([[ 0.0494,  0.0253,  0.0130,  ..., -0.0246,  0.0099,  0.0110],\n",
            "        [-0.0508,  0.0248,  0.0624,  ..., -0.0343, -0.0226, -0.0372],\n",
            "        [ 0.0232,  0.0587, -0.0050,  ..., -0.0458, -0.0497, -0.0250],\n",
            "        ...,\n",
            "        [ 0.0080, -0.0474,  0.0040,  ...,  0.0070,  0.0289, -0.0083],\n",
            "        [ 0.0358,  0.0342,  0.0065,  ...,  0.0448,  0.0458,  0.0058],\n",
            "        [-0.0381,  0.0594,  0.0138,  ..., -0.0546,  0.0419, -0.0433]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPF_D2.bias Parameter containing:\n",
            "tensor([-2.9439e-02, -1.8264e-02, -4.2113e-02,  1.7624e-03,  3.3140e-02,\n",
            "        -5.1636e-02, -5.5752e-02, -2.6649e-02,  1.9006e-02,  9.5635e-03,\n",
            "        -1.0779e-02, -8.6162e-03, -4.1569e-02, -3.0969e-03, -1.2854e-02,\n",
            "         2.5284e-02, -5.8000e-02, -1.2150e-04,  2.4200e-02, -2.3694e-02,\n",
            "         2.4583e-02, -2.6733e-02, -3.9708e-03,  2.9235e-03, -3.4881e-02,\n",
            "         2.2852e-02,  1.0077e-02, -2.9474e-02, -4.2703e-02,  1.2073e-02,\n",
            "         5.4464e-02, -4.1981e-02,  3.4028e-02,  2.0408e-02, -3.4406e-02,\n",
            "        -1.2948e-03, -4.7231e-02, -2.7457e-02, -4.2283e-02, -5.0628e-02,\n",
            "        -4.8803e-02, -5.8357e-02,  6.1824e-04, -7.3734e-03,  3.7137e-02,\n",
            "        -3.4995e-02,  5.0610e-02,  1.2743e-02,  3.2632e-02,  3.7613e-03,\n",
            "         9.2475e-03, -1.2166e-02,  4.9414e-02, -1.5462e-02,  3.1486e-02,\n",
            "         1.8549e-02, -2.3920e-02,  4.8054e-02,  1.3951e-03,  1.6268e-02,\n",
            "         3.0835e-03,  5.1147e-02, -1.6032e-02,  1.8830e-02, -4.8825e-02,\n",
            "        -2.2344e-02,  1.7920e-02, -3.7740e-02, -1.3695e-02,  1.1124e-02,\n",
            "        -4.3444e-02,  2.3491e-02,  1.7272e-03,  7.0875e-03, -7.8461e-03,\n",
            "         1.0134e-02,  1.8584e-02,  2.6439e-02, -1.3445e-02, -6.1981e-02,\n",
            "         2.3885e-03, -5.1001e-02,  1.2345e-02,  3.5077e-02, -1.6335e-02,\n",
            "         5.3891e-02, -4.1027e-02,  8.1743e-03,  3.6389e-02,  9.8160e-03,\n",
            "        -6.6497e-03,  1.7084e-03, -4.1238e-02,  5.0441e-03, -5.2954e-02,\n",
            "        -4.1142e-02,  3.7778e-02,  3.1654e-02,  2.5449e-02, -1.6549e-02,\n",
            "        -2.0963e-02, -3.6746e-03, -4.7026e-02, -6.9244e-04,  5.6624e-02,\n",
            "        -2.7189e-02,  3.5593e-02, -4.1432e-02,  3.1597e-02, -5.7752e-02,\n",
            "        -2.8435e-03, -6.4919e-03, -1.8076e-02, -4.5738e-03, -6.0932e-02,\n",
            "         5.2716e-02, -2.7849e-02,  6.4739e-03, -4.8080e-02,  3.5859e-02,\n",
            "        -3.2790e-02, -7.1926e-03, -3.9068e-02, -2.7240e-02,  4.3649e-02,\n",
            "        -5.5974e-03,  5.0650e-02, -2.1976e-03,  1.4882e-02, -1.4570e-02,\n",
            "         3.4888e-02, -5.6951e-02,  1.7452e-02,  4.9189e-02,  4.6425e-02,\n",
            "        -4.9486e-02, -3.2209e-02,  9.0456e-03,  1.9989e-02,  2.9052e-02,\n",
            "        -3.8398e-02, -9.1091e-03,  5.8114e-02, -2.1850e-02, -3.2623e-02,\n",
            "        -4.3052e-02,  1.4135e-02, -9.8709e-03,  2.3642e-02,  5.5002e-02,\n",
            "         1.0596e-02, -2.9142e-02,  2.6996e-02, -2.2529e-02, -5.9645e-02,\n",
            "        -5.4341e-02,  3.7358e-02, -2.0263e-02,  3.5824e-03, -9.7575e-03,\n",
            "         4.7646e-02, -8.1893e-03,  2.8210e-02,  2.8403e-02, -1.7031e-02,\n",
            "         4.3566e-02, -3.3739e-02,  2.7640e-02, -2.2161e-02, -2.7646e-02,\n",
            "         1.6883e-02,  8.3928e-03,  7.9742e-03, -2.0460e-02,  1.4910e-02,\n",
            "         4.3783e-02,  4.0095e-02,  1.2035e-02,  7.8069e-03,  5.9331e-02,\n",
            "        -5.9800e-02, -3.6971e-02, -3.3194e-02,  2.4686e-02,  5.9489e-03,\n",
            "        -3.9459e-02,  5.5829e-02, -5.8433e-02, -2.8835e-02, -6.0639e-02,\n",
            "        -3.2456e-02,  1.9836e-02,  5.1427e-02,  1.5982e-02,  2.0368e-02,\n",
            "        -5.2773e-02, -4.2492e-02, -1.7966e-02,  5.7834e-02, -4.7718e-02,\n",
            "        -5.0299e-02, -2.7385e-02, -2.8345e-02, -3.4731e-03, -3.6192e-02,\n",
            "         5.5890e-02, -5.0337e-02,  1.9315e-02,  2.5794e-02,  3.6615e-02,\n",
            "         8.7649e-03, -1.2733e-02,  5.1243e-03, -5.2565e-03, -2.5012e-02,\n",
            "        -5.2014e-02, -3.9780e-02,  4.8034e-02,  4.6749e-02, -4.2073e-02,\n",
            "        -5.8551e-02,  1.2646e-02, -3.7809e-03, -2.2126e-02, -5.1467e-02,\n",
            "        -5.0516e-02, -5.6033e-02,  4.8497e-02, -3.5840e-02,  3.8153e-02,\n",
            "         1.1859e-02,  3.8909e-03, -3.5863e-02, -9.4619e-03, -7.7300e-05,\n",
            "        -4.4322e-02, -5.9720e-02, -9.7678e-03,  3.9760e-02,  6.0961e-02,\n",
            "         3.9368e-02,  6.7193e-03, -2.7068e-02, -3.4658e-02, -5.9324e-02,\n",
            "         6.1662e-02,  2.7688e-02, -3.4105e-03,  1.2746e-02, -2.6376e-02,\n",
            "        -5.8869e-02, -3.7176e-02,  5.4805e-02, -4.5098e-02, -3.2072e-02,\n",
            "         3.5219e-02], device='cuda:0', requires_grad=True)\n",
            "NPV_C1.weight Parameter containing:\n",
            "tensor([[[[ 0.1702, -0.0410, -0.1715],\n",
            "          [-0.1727, -0.1691,  0.1663],\n",
            "          [-0.0101, -0.1337,  0.0772]],\n",
            "\n",
            "         [[ 0.0743,  0.1482,  0.0419],\n",
            "          [ 0.1614,  0.1694,  0.1859],\n",
            "          [-0.1185, -0.0738,  0.0040]],\n",
            "\n",
            "         [[ 0.0363, -0.0772, -0.1612],\n",
            "          [ 0.0859,  0.0229,  0.0993],\n",
            "          [ 0.0268, -0.1790,  0.1827]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1779, -0.1019, -0.1768],\n",
            "          [-0.1688,  0.0673,  0.0757],\n",
            "          [ 0.1021,  0.0230,  0.0172]],\n",
            "\n",
            "         [[-0.1060,  0.0220,  0.0491],\n",
            "          [ 0.0193,  0.0763, -0.0260],\n",
            "          [-0.0401, -0.1085, -0.0292]],\n",
            "\n",
            "         [[-0.0725,  0.0668,  0.0805],\n",
            "          [ 0.0910, -0.0254,  0.0105],\n",
            "          [-0.1620, -0.1402,  0.1393]]],\n",
            "\n",
            "\n",
            "        [[[-0.1743, -0.1056,  0.0858],\n",
            "          [ 0.1476, -0.0166, -0.0909],\n",
            "          [ 0.1034, -0.1136, -0.0495]],\n",
            "\n",
            "         [[-0.1307,  0.1124, -0.0006],\n",
            "          [-0.0614,  0.1173, -0.1692],\n",
            "          [-0.0389,  0.1868,  0.0260]],\n",
            "\n",
            "         [[-0.0134, -0.0680,  0.0858],\n",
            "          [ 0.0989,  0.0621, -0.1651],\n",
            "          [-0.0100, -0.0766,  0.1436]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1146,  0.0594,  0.1794],\n",
            "          [-0.0902,  0.1062,  0.1016],\n",
            "          [ 0.0030, -0.0459, -0.0912]],\n",
            "\n",
            "         [[-0.0790,  0.1894, -0.0759],\n",
            "          [ 0.0057, -0.0130,  0.0134],\n",
            "          [ 0.0984, -0.1103,  0.0471]],\n",
            "\n",
            "         [[-0.1643,  0.0140,  0.0439],\n",
            "          [ 0.0277,  0.0672, -0.1452],\n",
            "          [-0.0354,  0.0165, -0.0689]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0635, -0.1574, -0.1164],\n",
            "          [ 0.0090,  0.1154,  0.1278],\n",
            "          [ 0.1436,  0.0321, -0.0963]],\n",
            "\n",
            "         [[-0.0914,  0.0944,  0.1823],\n",
            "          [-0.1550, -0.0940, -0.1480],\n",
            "          [-0.1010, -0.1865, -0.0256]],\n",
            "\n",
            "         [[ 0.0908,  0.0892,  0.0189],\n",
            "          [ 0.1255,  0.1116,  0.0328],\n",
            "          [-0.1714,  0.0962,  0.0869]]],\n",
            "\n",
            "\n",
            "        [[[-0.1654, -0.1914, -0.1517],\n",
            "          [ 0.1294,  0.0595,  0.0156],\n",
            "          [ 0.1310,  0.0984, -0.0277]],\n",
            "\n",
            "         [[ 0.0623,  0.0603,  0.0457],\n",
            "          [-0.0720, -0.1320, -0.0053],\n",
            "          [-0.0809,  0.0605, -0.0083]],\n",
            "\n",
            "         [[-0.1451, -0.0556, -0.1564],\n",
            "          [-0.1920, -0.0923, -0.1241],\n",
            "          [-0.1158,  0.0806, -0.1910]]]], device='cuda:0', requires_grad=True)\n",
            "NPV_C1.bias Parameter containing:\n",
            "tensor([ 0.1360,  0.0330, -0.1504,  0.1085, -0.0124, -0.0843,  0.1011,  0.0657,\n",
            "        -0.1680, -0.0143, -0.0744, -0.1760,  0.0395,  0.1175,  0.1187,  0.0322,\n",
            "        -0.0170, -0.0094, -0.0723, -0.1105, -0.1598, -0.1207, -0.1817,  0.0272,\n",
            "        -0.1605,  0.0230, -0.0691,  0.0023,  0.0248,  0.1161, -0.0184, -0.1789,\n",
            "        -0.0585, -0.1670, -0.1498,  0.0496, -0.1021,  0.1302,  0.1419,  0.0301,\n",
            "        -0.0621,  0.0660, -0.1356,  0.1769,  0.1480, -0.0332, -0.1666, -0.1354,\n",
            "         0.0033, -0.1591,  0.1543,  0.0701,  0.0120,  0.1138, -0.1279, -0.0945,\n",
            "         0.1131, -0.0975,  0.0081, -0.0486,  0.1721,  0.1269, -0.0028, -0.0407],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_C2.weight Parameter containing:\n",
            "tensor([[[[ 0.0117,  0.0134,  0.0057],\n",
            "          [ 0.0141,  0.0043, -0.0169],\n",
            "          [-0.0188,  0.0092,  0.0140]],\n",
            "\n",
            "         [[ 0.0207,  0.0378,  0.0386],\n",
            "          [-0.0025,  0.0047,  0.0346],\n",
            "          [ 0.0243, -0.0013, -0.0157]],\n",
            "\n",
            "         [[-0.0038,  0.0179,  0.0011],\n",
            "          [ 0.0312,  0.0250, -0.0085],\n",
            "          [-0.0351, -0.0400,  0.0129]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0136, -0.0027, -0.0094],\n",
            "          [ 0.0375,  0.0247, -0.0122],\n",
            "          [ 0.0003, -0.0191,  0.0029]],\n",
            "\n",
            "         [[-0.0351, -0.0091,  0.0261],\n",
            "          [ 0.0052, -0.0126, -0.0320],\n",
            "          [ 0.0291,  0.0014,  0.0303]],\n",
            "\n",
            "         [[-0.0324, -0.0034,  0.0024],\n",
            "          [-0.0180, -0.0181, -0.0379],\n",
            "          [-0.0142,  0.0389, -0.0066]]],\n",
            "\n",
            "\n",
            "        [[[-0.0405,  0.0334, -0.0408],\n",
            "          [-0.0114,  0.0316,  0.0337],\n",
            "          [ 0.0297,  0.0079, -0.0073]],\n",
            "\n",
            "         [[-0.0187, -0.0220, -0.0277],\n",
            "          [-0.0102,  0.0286, -0.0374],\n",
            "          [ 0.0210,  0.0406, -0.0387]],\n",
            "\n",
            "         [[ 0.0171,  0.0314,  0.0051],\n",
            "          [ 0.0192, -0.0019,  0.0069],\n",
            "          [ 0.0050, -0.0015,  0.0071]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0264,  0.0286,  0.0343],\n",
            "          [-0.0298,  0.0395,  0.0322],\n",
            "          [-0.0302,  0.0036, -0.0017]],\n",
            "\n",
            "         [[-0.0205, -0.0156,  0.0061],\n",
            "          [-0.0365,  0.0248, -0.0135],\n",
            "          [ 0.0056, -0.0410, -0.0401]],\n",
            "\n",
            "         [[-0.0197, -0.0257,  0.0374],\n",
            "          [ 0.0063,  0.0069,  0.0125],\n",
            "          [ 0.0214, -0.0313,  0.0212]]],\n",
            "\n",
            "\n",
            "        [[[-0.0132,  0.0052,  0.0207],\n",
            "          [-0.0053, -0.0263, -0.0035],\n",
            "          [ 0.0232,  0.0057,  0.0260]],\n",
            "\n",
            "         [[-0.0296,  0.0235, -0.0076],\n",
            "          [-0.0269, -0.0013, -0.0062],\n",
            "          [ 0.0148,  0.0179, -0.0357]],\n",
            "\n",
            "         [[ 0.0382,  0.0273,  0.0217],\n",
            "          [-0.0281,  0.0038, -0.0042],\n",
            "          [ 0.0366, -0.0363,  0.0277]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0030,  0.0043,  0.0102],\n",
            "          [ 0.0061, -0.0143, -0.0350],\n",
            "          [ 0.0089,  0.0032, -0.0233]],\n",
            "\n",
            "         [[-0.0279,  0.0256,  0.0127],\n",
            "          [ 0.0208, -0.0117, -0.0150],\n",
            "          [-0.0078,  0.0200,  0.0107]],\n",
            "\n",
            "         [[-0.0289,  0.0065, -0.0127],\n",
            "          [-0.0124, -0.0017, -0.0359],\n",
            "          [ 0.0106, -0.0404, -0.0334]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0327,  0.0195, -0.0202],\n",
            "          [ 0.0233, -0.0046,  0.0008],\n",
            "          [-0.0348,  0.0396,  0.0073]],\n",
            "\n",
            "         [[ 0.0008, -0.0410,  0.0255],\n",
            "          [-0.0052,  0.0091,  0.0209],\n",
            "          [ 0.0283, -0.0069,  0.0075]],\n",
            "\n",
            "         [[ 0.0106, -0.0116,  0.0188],\n",
            "          [ 0.0106, -0.0157,  0.0402],\n",
            "          [-0.0322, -0.0369, -0.0151]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0221, -0.0208,  0.0368],\n",
            "          [-0.0264, -0.0405, -0.0024],\n",
            "          [-0.0255,  0.0377,  0.0127]],\n",
            "\n",
            "         [[ 0.0225,  0.0050, -0.0209],\n",
            "          [ 0.0050,  0.0040, -0.0184],\n",
            "          [ 0.0100,  0.0258, -0.0385]],\n",
            "\n",
            "         [[ 0.0224, -0.0036,  0.0148],\n",
            "          [-0.0370, -0.0141, -0.0067],\n",
            "          [-0.0366, -0.0334,  0.0262]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0251, -0.0156,  0.0107],\n",
            "          [ 0.0033, -0.0368,  0.0235],\n",
            "          [ 0.0036,  0.0197, -0.0204]],\n",
            "\n",
            "         [[ 0.0275, -0.0240,  0.0242],\n",
            "          [ 0.0345, -0.0197,  0.0007],\n",
            "          [ 0.0316, -0.0102, -0.0296]],\n",
            "\n",
            "         [[ 0.0221,  0.0325,  0.0185],\n",
            "          [-0.0341,  0.0398, -0.0091],\n",
            "          [-0.0140, -0.0313,  0.0102]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0152, -0.0278,  0.0116],\n",
            "          [-0.0106,  0.0302, -0.0140],\n",
            "          [-0.0192, -0.0216,  0.0012]],\n",
            "\n",
            "         [[ 0.0296,  0.0322, -0.0048],\n",
            "          [ 0.0010,  0.0015, -0.0345],\n",
            "          [ 0.0091,  0.0310, -0.0305]],\n",
            "\n",
            "         [[ 0.0093, -0.0009, -0.0151],\n",
            "          [-0.0038, -0.0119, -0.0011],\n",
            "          [ 0.0371,  0.0036, -0.0325]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0295, -0.0322,  0.0342],\n",
            "          [-0.0359, -0.0373, -0.0228],\n",
            "          [-0.0271,  0.0056, -0.0221]],\n",
            "\n",
            "         [[ 0.0273, -0.0159, -0.0098],\n",
            "          [-0.0362,  0.0041, -0.0033],\n",
            "          [ 0.0252,  0.0075,  0.0073]],\n",
            "\n",
            "         [[-0.0098, -0.0373, -0.0401],\n",
            "          [-0.0347, -0.0057, -0.0407],\n",
            "          [-0.0193,  0.0184, -0.0082]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0136,  0.0059, -0.0351],\n",
            "          [ 0.0357,  0.0166, -0.0370],\n",
            "          [ 0.0401,  0.0193,  0.0256]],\n",
            "\n",
            "         [[-0.0273, -0.0409,  0.0268],\n",
            "          [-0.0328,  0.0115,  0.0038],\n",
            "          [-0.0033, -0.0075, -0.0339]],\n",
            "\n",
            "         [[-0.0324,  0.0122, -0.0293],\n",
            "          [-0.0336, -0.0026, -0.0124],\n",
            "          [ 0.0412, -0.0374,  0.0122]]]], device='cuda:0', requires_grad=True)\n",
            "NPV_C2.bias Parameter containing:\n",
            "tensor([-0.0375, -0.0013,  0.0022, -0.0365, -0.0123,  0.0181, -0.0207, -0.0065,\n",
            "        -0.0264,  0.0202, -0.0197,  0.0378, -0.0018,  0.0063, -0.0281, -0.0283,\n",
            "         0.0307, -0.0126, -0.0030, -0.0032,  0.0123, -0.0373,  0.0336,  0.0352,\n",
            "         0.0345, -0.0321, -0.0002, -0.0399, -0.0095,  0.0396, -0.0214,  0.0284,\n",
            "        -0.0386, -0.0108, -0.0180, -0.0231,  0.0095,  0.0348,  0.0079, -0.0123,\n",
            "         0.0008, -0.0140,  0.0222, -0.0179,  0.0162,  0.0234, -0.0015, -0.0249,\n",
            "        -0.0111,  0.0403,  0.0270,  0.0212,  0.0014, -0.0164,  0.0199, -0.0077,\n",
            "        -0.0222,  0.0197,  0.0294, -0.0407, -0.0286, -0.0157, -0.0314, -0.0024],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_C3.weight Parameter containing:\n",
            "tensor([[[[ 0.0217,  0.0159, -0.0032],\n",
            "          [ 0.0155, -0.0109, -0.0363],\n",
            "          [ 0.0100,  0.0288, -0.0223]],\n",
            "\n",
            "         [[-0.0266, -0.0324, -0.0359],\n",
            "          [ 0.0382, -0.0044,  0.0317],\n",
            "          [ 0.0154,  0.0313,  0.0413]],\n",
            "\n",
            "         [[ 0.0295,  0.0122,  0.0401],\n",
            "          [-0.0161, -0.0172,  0.0025],\n",
            "          [ 0.0147, -0.0363, -0.0226]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0291,  0.0142,  0.0043],\n",
            "          [ 0.0081, -0.0154, -0.0182],\n",
            "          [-0.0193, -0.0097, -0.0249]],\n",
            "\n",
            "         [[-0.0027, -0.0054, -0.0012],\n",
            "          [-0.0141,  0.0177,  0.0075],\n",
            "          [ 0.0415, -0.0002, -0.0012]],\n",
            "\n",
            "         [[-0.0128, -0.0170, -0.0107],\n",
            "          [-0.0021,  0.0345,  0.0069],\n",
            "          [-0.0341, -0.0314, -0.0028]]],\n",
            "\n",
            "\n",
            "        [[[-0.0076,  0.0052, -0.0285],\n",
            "          [ 0.0228, -0.0024, -0.0161],\n",
            "          [-0.0218,  0.0328, -0.0113]],\n",
            "\n",
            "         [[ 0.0180, -0.0015,  0.0081],\n",
            "          [-0.0312, -0.0027,  0.0136],\n",
            "          [ 0.0200,  0.0393,  0.0309]],\n",
            "\n",
            "         [[ 0.0410, -0.0200,  0.0090],\n",
            "          [ 0.0290,  0.0057,  0.0161],\n",
            "          [ 0.0051, -0.0343,  0.0307]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0299, -0.0156, -0.0243],\n",
            "          [-0.0215, -0.0067, -0.0233],\n",
            "          [ 0.0007,  0.0120,  0.0273]],\n",
            "\n",
            "         [[-0.0087, -0.0387,  0.0304],\n",
            "          [-0.0387,  0.0127,  0.0089],\n",
            "          [-0.0280, -0.0172, -0.0410]],\n",
            "\n",
            "         [[ 0.0094, -0.0312, -0.0141],\n",
            "          [-0.0042,  0.0050,  0.0087],\n",
            "          [-0.0191, -0.0035,  0.0234]]],\n",
            "\n",
            "\n",
            "        [[[-0.0267, -0.0385,  0.0090],\n",
            "          [ 0.0017, -0.0002, -0.0062],\n",
            "          [ 0.0167, -0.0032, -0.0264]],\n",
            "\n",
            "         [[ 0.0373,  0.0369, -0.0068],\n",
            "          [ 0.0210, -0.0224,  0.0036],\n",
            "          [ 0.0040,  0.0299,  0.0167]],\n",
            "\n",
            "         [[-0.0102, -0.0214, -0.0375],\n",
            "          [-0.0070, -0.0188,  0.0133],\n",
            "          [ 0.0378,  0.0025, -0.0404]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0362,  0.0076, -0.0198],\n",
            "          [ 0.0139, -0.0317, -0.0059],\n",
            "          [-0.0229, -0.0307, -0.0368]],\n",
            "\n",
            "         [[ 0.0246, -0.0413, -0.0115],\n",
            "          [ 0.0173, -0.0243,  0.0171],\n",
            "          [ 0.0092, -0.0388,  0.0007]],\n",
            "\n",
            "         [[-0.0409,  0.0412,  0.0188],\n",
            "          [ 0.0337,  0.0192,  0.0112],\n",
            "          [ 0.0333, -0.0049, -0.0256]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0117,  0.0416, -0.0205],\n",
            "          [ 0.0384,  0.0136, -0.0109],\n",
            "          [-0.0172,  0.0108, -0.0408]],\n",
            "\n",
            "         [[-0.0056, -0.0263, -0.0103],\n",
            "          [ 0.0246,  0.0354, -0.0183],\n",
            "          [-0.0325, -0.0009,  0.0335]],\n",
            "\n",
            "         [[ 0.0257,  0.0105,  0.0135],\n",
            "          [ 0.0170,  0.0015,  0.0063],\n",
            "          [ 0.0024, -0.0213,  0.0250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0060, -0.0101,  0.0241],\n",
            "          [-0.0368, -0.0300,  0.0281],\n",
            "          [-0.0269, -0.0349,  0.0398]],\n",
            "\n",
            "         [[-0.0296,  0.0317,  0.0413],\n",
            "          [ 0.0357,  0.0398, -0.0339],\n",
            "          [ 0.0092, -0.0390, -0.0209]],\n",
            "\n",
            "         [[-0.0251, -0.0118, -0.0356],\n",
            "          [-0.0005, -0.0193, -0.0180],\n",
            "          [-0.0108, -0.0188, -0.0146]]],\n",
            "\n",
            "\n",
            "        [[[-0.0226, -0.0279,  0.0365],\n",
            "          [ 0.0007, -0.0239, -0.0410],\n",
            "          [-0.0050, -0.0209, -0.0139]],\n",
            "\n",
            "         [[ 0.0322,  0.0097, -0.0164],\n",
            "          [ 0.0102,  0.0403, -0.0031],\n",
            "          [-0.0312, -0.0138,  0.0081]],\n",
            "\n",
            "         [[ 0.0337,  0.0101, -0.0385],\n",
            "          [-0.0055, -0.0081, -0.0057],\n",
            "          [ 0.0145,  0.0361, -0.0136]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0124,  0.0247, -0.0099],\n",
            "          [ 0.0249, -0.0336, -0.0019],\n",
            "          [ 0.0322,  0.0275,  0.0336]],\n",
            "\n",
            "         [[-0.0078, -0.0330, -0.0142],\n",
            "          [ 0.0335, -0.0248, -0.0206],\n",
            "          [-0.0309,  0.0191, -0.0266]],\n",
            "\n",
            "         [[ 0.0402, -0.0093,  0.0157],\n",
            "          [-0.0164,  0.0053,  0.0331],\n",
            "          [-0.0341, -0.0125, -0.0200]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0050,  0.0385, -0.0309],\n",
            "          [-0.0285, -0.0210, -0.0122],\n",
            "          [-0.0379, -0.0037,  0.0150]],\n",
            "\n",
            "         [[ 0.0102, -0.0091,  0.0294],\n",
            "          [ 0.0283,  0.0001,  0.0034],\n",
            "          [-0.0177, -0.0332, -0.0117]],\n",
            "\n",
            "         [[-0.0408, -0.0170, -0.0365],\n",
            "          [-0.0088, -0.0094, -0.0055],\n",
            "          [ 0.0376,  0.0012, -0.0224]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0268, -0.0318,  0.0173],\n",
            "          [-0.0218,  0.0203, -0.0278],\n",
            "          [ 0.0141, -0.0190,  0.0192]],\n",
            "\n",
            "         [[-0.0236,  0.0116,  0.0194],\n",
            "          [ 0.0021,  0.0244,  0.0283],\n",
            "          [-0.0401, -0.0231, -0.0233]],\n",
            "\n",
            "         [[-0.0150, -0.0166,  0.0403],\n",
            "          [ 0.0408,  0.0149, -0.0296],\n",
            "          [-0.0243, -0.0286, -0.0399]]]], device='cuda:0', requires_grad=True)\n",
            "NPV_C3.bias Parameter containing:\n",
            "tensor([ 0.0205, -0.0027,  0.0187, -0.0045,  0.0185, -0.0097, -0.0113, -0.0203,\n",
            "         0.0067,  0.0380, -0.0108, -0.0188, -0.0001,  0.0230, -0.0367, -0.0163,\n",
            "         0.0272, -0.0229, -0.0064, -0.0043, -0.0022,  0.0158, -0.0151,  0.0258,\n",
            "        -0.0205,  0.0321, -0.0410, -0.0030,  0.0368,  0.0110,  0.0130,  0.0193,\n",
            "         0.0196, -0.0412,  0.0306,  0.0374,  0.0065,  0.0286,  0.0197, -0.0130,\n",
            "        -0.0215,  0.0275,  0.0290, -0.0212, -0.0156, -0.0073,  0.0409, -0.0360,\n",
            "         0.0362,  0.0067,  0.0157,  0.0339, -0.0376,  0.0260, -0.0381, -0.0325,\n",
            "        -0.0245, -0.0139, -0.0410, -0.0091, -0.0009,  0.0037, -0.0217, -0.0272,\n",
            "         0.0189,  0.0089, -0.0144, -0.0047, -0.0132, -0.0014,  0.0248, -0.0269,\n",
            "         0.0305,  0.0317,  0.0096,  0.0324,  0.0260,  0.0107, -0.0314, -0.0317,\n",
            "         0.0391, -0.0169,  0.0193,  0.0308,  0.0345, -0.0196, -0.0262,  0.0157,\n",
            "        -0.0380, -0.0198, -0.0238, -0.0353,  0.0414,  0.0203, -0.0101, -0.0259,\n",
            "        -0.0095, -0.0179,  0.0205,  0.0009, -0.0212, -0.0394,  0.0290,  0.0146,\n",
            "        -0.0127,  0.0112, -0.0014,  0.0211, -0.0319, -0.0039,  0.0365,  0.0352,\n",
            "        -0.0147,  0.0020,  0.0415, -0.0015, -0.0121, -0.0287, -0.0020,  0.0074,\n",
            "        -0.0377,  0.0141,  0.0113, -0.0357, -0.0085, -0.0243, -0.0375,  0.0189],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_C4.weight Parameter containing:\n",
            "tensor([[[[-7.2642e-03,  1.8725e-02, -1.3772e-02],\n",
            "          [-1.7507e-02, -1.3259e-02, -1.9156e-04],\n",
            "          [-8.3539e-03, -7.4551e-03, -3.6623e-03]],\n",
            "\n",
            "         [[-2.0398e-02, -1.1719e-02, -1.2072e-02],\n",
            "          [-1.5466e-02,  2.7268e-03, -1.6365e-02],\n",
            "          [ 2.9198e-02,  2.2899e-02, -1.0189e-02]],\n",
            "\n",
            "         [[ 2.8148e-02,  2.6232e-03,  2.8795e-02],\n",
            "          [ 1.9025e-03,  2.8527e-02,  2.4464e-02],\n",
            "          [ 3.0389e-03,  6.4775e-03,  1.1604e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0148e-04, -4.2034e-03, -1.6703e-02],\n",
            "          [ 1.0552e-02,  1.3343e-02, -4.4137e-03],\n",
            "          [-6.0703e-03, -1.0922e-02, -1.6723e-02]],\n",
            "\n",
            "         [[ 1.7797e-02,  1.1638e-02,  8.1478e-03],\n",
            "          [-2.0974e-03,  1.5894e-02, -2.6263e-03],\n",
            "          [-1.9343e-02,  2.2637e-02, -2.7770e-02]],\n",
            "\n",
            "         [[-1.0497e-02, -3.7546e-03, -7.1459e-03],\n",
            "          [-2.2670e-02, -6.2318e-03,  1.0515e-02],\n",
            "          [-1.5801e-02,  5.6887e-03, -2.0076e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0976e-02,  4.8132e-03,  1.3558e-02],\n",
            "          [ 9.8910e-03, -4.5010e-03, -2.4968e-02],\n",
            "          [-1.3108e-02,  8.0744e-03,  2.7444e-02]],\n",
            "\n",
            "         [[-1.9899e-02,  1.7395e-02,  5.5319e-03],\n",
            "          [ 2.4855e-02, -4.5730e-03,  2.9020e-02],\n",
            "          [-1.5705e-02,  2.5388e-02, -1.8179e-02]],\n",
            "\n",
            "         [[ 2.1590e-02, -2.8471e-02,  1.4288e-02],\n",
            "          [ 8.2745e-03, -2.7951e-02, -9.9734e-03],\n",
            "          [ 6.0420e-03,  2.8004e-02,  2.6936e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.5144e-03, -1.4959e-02,  2.4389e-02],\n",
            "          [ 2.7466e-02,  7.8878e-03,  1.9139e-02],\n",
            "          [-2.4720e-02, -1.5198e-02, -2.5540e-02]],\n",
            "\n",
            "         [[-1.5755e-02,  1.6693e-02, -1.3001e-02],\n",
            "          [ 1.2409e-03,  2.0463e-03,  5.6324e-03],\n",
            "          [ 8.8068e-03,  2.7159e-02, -5.1558e-03]],\n",
            "\n",
            "         [[ 1.0670e-02, -2.9010e-02,  2.3002e-02],\n",
            "          [ 1.5578e-02,  1.3569e-02, -8.0591e-03],\n",
            "          [-2.6739e-02, -2.6947e-02,  5.2179e-03]]],\n",
            "\n",
            "\n",
            "        [[[-2.8850e-02,  4.2878e-03,  1.2730e-02],\n",
            "          [-2.4219e-02,  1.6877e-02,  4.9958e-04],\n",
            "          [-2.9059e-02, -4.1744e-04, -6.8208e-03]],\n",
            "\n",
            "         [[-7.5455e-03,  8.4972e-03, -2.5459e-02],\n",
            "          [-2.8511e-02,  1.7128e-02,  1.8268e-02],\n",
            "          [-2.7390e-02, -1.9871e-02, -1.3138e-02]],\n",
            "\n",
            "         [[ 2.7750e-02, -2.0844e-02,  1.4472e-02],\n",
            "          [ 1.1179e-02, -2.3946e-02, -1.9616e-02],\n",
            "          [-2.5335e-02,  4.3083e-03,  2.3350e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.6229e-03,  1.0913e-02, -2.7349e-02],\n",
            "          [-2.2690e-03, -1.9740e-02, -2.0710e-02],\n",
            "          [-6.5406e-03, -1.5914e-02,  1.5547e-02]],\n",
            "\n",
            "         [[ 2.8126e-02, -3.5165e-03,  3.7297e-03],\n",
            "          [-1.6315e-02,  2.6352e-02, -1.9326e-02],\n",
            "          [ 2.6053e-02,  7.6796e-03,  1.3159e-03]],\n",
            "\n",
            "         [[-1.8453e-03,  7.7653e-03, -4.2909e-03],\n",
            "          [ 7.2997e-04, -5.7854e-03,  2.7358e-02],\n",
            "          [-3.2779e-03,  9.2777e-03, -1.5327e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.2030e-02, -5.8443e-03, -2.4302e-02],\n",
            "          [ 9.5494e-03, -1.6379e-02,  1.2827e-02],\n",
            "          [-1.8017e-02, -2.4094e-03,  1.3896e-02]],\n",
            "\n",
            "         [[ 6.7912e-03, -2.3121e-02,  9.8585e-03],\n",
            "          [-2.7826e-02,  2.1179e-02, -1.6276e-02],\n",
            "          [ 1.8634e-02, -2.9044e-02, -1.6896e-02]],\n",
            "\n",
            "         [[ 2.9040e-02,  1.7220e-02,  2.8143e-02],\n",
            "          [ 2.8895e-02,  1.0942e-02,  8.8019e-03],\n",
            "          [-8.0183e-03,  5.6600e-03, -2.6545e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5805e-02, -1.5331e-03, -1.5985e-02],\n",
            "          [ 2.2513e-02, -2.1843e-02, -2.1102e-02],\n",
            "          [-2.7542e-02,  2.5122e-02, -1.7474e-02]],\n",
            "\n",
            "         [[ 2.6096e-02, -1.8383e-02, -2.8806e-02],\n",
            "          [ 2.2937e-02, -1.5319e-03, -2.1857e-02],\n",
            "          [-1.1891e-02,  5.4766e-03, -1.4315e-02]],\n",
            "\n",
            "         [[-7.7001e-03, -2.4259e-02,  2.6040e-02],\n",
            "          [-2.0379e-02, -1.0252e-02, -1.6167e-02],\n",
            "          [-2.3275e-02, -7.7806e-03,  2.7962e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.6920e-03, -1.7858e-02,  1.2792e-02],\n",
            "          [-1.1420e-03,  2.8010e-02, -2.2215e-02],\n",
            "          [ 1.8668e-02,  1.5217e-02,  1.3881e-02]],\n",
            "\n",
            "         [[ 1.1137e-02, -1.5518e-02, -2.5761e-02],\n",
            "          [ 2.1063e-02,  5.5779e-03,  2.0150e-02],\n",
            "          [-3.5567e-03,  1.9626e-02, -2.6667e-02]],\n",
            "\n",
            "         [[ 1.5827e-03, -8.7478e-03,  9.4545e-03],\n",
            "          [ 1.5364e-02, -2.9423e-02,  2.6942e-02],\n",
            "          [ 6.3926e-03,  7.9577e-05,  8.7556e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.8616e-02, -7.8212e-03,  2.4313e-02],\n",
            "          [-5.4454e-03, -2.7568e-02, -9.5371e-03],\n",
            "          [ 5.3715e-03,  9.5695e-03,  2.3832e-03]],\n",
            "\n",
            "         [[-1.8455e-03,  5.5293e-03, -1.5890e-03],\n",
            "          [ 2.5887e-02, -8.4311e-03,  1.5555e-02],\n",
            "          [ 7.5019e-03,  5.3858e-03, -1.1731e-02]],\n",
            "\n",
            "         [[ 2.2408e-02,  1.5884e-02,  2.5341e-02],\n",
            "          [ 8.8692e-03,  1.5566e-02,  2.4938e-02],\n",
            "          [-2.4224e-02,  2.4266e-02,  8.8448e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5966e-02,  2.0407e-02, -8.3030e-03],\n",
            "          [-1.6691e-02, -1.9202e-02, -2.2475e-02],\n",
            "          [-1.1895e-02,  3.7270e-03,  2.1211e-02]],\n",
            "\n",
            "         [[-2.5930e-02,  2.0602e-02,  1.6368e-02],\n",
            "          [-1.8734e-03, -1.5195e-02, -1.8600e-02],\n",
            "          [-2.5721e-02,  2.0727e-02, -4.0807e-03]],\n",
            "\n",
            "         [[ 2.2957e-02, -2.1284e-02,  3.2340e-03],\n",
            "          [ 1.6553e-02,  1.4601e-02, -2.4700e-02],\n",
            "          [-2.4479e-02,  3.1844e-03,  2.0391e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.9130e-03, -1.5603e-02,  9.9356e-03],\n",
            "          [ 1.2557e-02, -1.7769e-02, -2.7835e-02],\n",
            "          [-1.0211e-02,  2.2124e-02,  1.1239e-02]],\n",
            "\n",
            "         [[-1.9666e-02,  1.7632e-02, -7.8668e-03],\n",
            "          [-1.8069e-02, -1.7070e-02, -4.3847e-03],\n",
            "          [-1.8631e-02,  6.0918e-03,  5.7733e-03]],\n",
            "\n",
            "         [[-8.1956e-03,  9.5931e-03,  2.1968e-03],\n",
            "          [ 2.6195e-02, -2.1429e-02,  2.4280e-02],\n",
            "          [-2.4516e-02, -1.7000e-03, -2.6902e-02]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_C4.bias Parameter containing:\n",
            "tensor([-0.0233,  0.0038, -0.0167,  0.0017, -0.0130,  0.0242,  0.0098,  0.0054,\n",
            "         0.0241, -0.0281, -0.0179, -0.0163, -0.0150, -0.0075, -0.0222, -0.0021,\n",
            "        -0.0161,  0.0201,  0.0027,  0.0252, -0.0159,  0.0037, -0.0170, -0.0193,\n",
            "        -0.0125, -0.0287, -0.0143, -0.0076,  0.0187, -0.0086,  0.0005,  0.0005,\n",
            "         0.0239, -0.0242,  0.0257, -0.0055, -0.0156, -0.0233,  0.0095, -0.0025,\n",
            "        -0.0162, -0.0188, -0.0158,  0.0048,  0.0275,  0.0168, -0.0228,  0.0035,\n",
            "         0.0063,  0.0282, -0.0084, -0.0248, -0.0184, -0.0015, -0.0241, -0.0025,\n",
            "        -0.0025,  0.0265,  0.0200,  0.0163,  0.0025,  0.0183,  0.0016, -0.0218,\n",
            "         0.0020,  0.0275, -0.0054, -0.0177, -0.0090,  0.0207,  0.0246, -0.0002,\n",
            "        -0.0206,  0.0064, -0.0201,  0.0004, -0.0128, -0.0157,  0.0224, -0.0237,\n",
            "        -0.0243, -0.0127,  0.0140,  0.0202,  0.0286, -0.0250,  0.0093,  0.0014,\n",
            "        -0.0122,  0.0290,  0.0277,  0.0201, -0.0205, -0.0246,  0.0009, -0.0021,\n",
            "        -0.0074,  0.0248,  0.0065, -0.0118,  0.0173, -0.0201, -0.0294,  0.0134,\n",
            "        -0.0023,  0.0183, -0.0009,  0.0064,  0.0230,  0.0193,  0.0164, -0.0250,\n",
            "         0.0084,  0.0089,  0.0133,  0.0165,  0.0191, -0.0246,  0.0159,  0.0196,\n",
            "        -0.0131, -0.0118,  0.0178,  0.0291,  0.0268, -0.0260,  0.0032, -0.0088],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_D1.weight Parameter containing:\n",
            "tensor([[-3.8792e-04,  2.4575e-03,  1.7560e-03,  ..., -2.5757e-04,\n",
            "          4.8451e-04,  2.4768e-03],\n",
            "        [ 1.6085e-03,  9.8880e-04,  1.0883e-03,  ..., -2.1319e-03,\n",
            "          3.9446e-04,  1.2126e-03],\n",
            "        [-1.6457e-04, -9.3323e-04, -2.8569e-04,  ...,  9.5492e-04,\n",
            "         -1.0700e-03, -9.0988e-04],\n",
            "        ...,\n",
            "        [-2.1483e-03,  1.5720e-03,  2.2458e-03,  ...,  1.1880e-03,\n",
            "          4.1344e-04,  1.0676e-03],\n",
            "        [-1.7881e-03, -8.2811e-04, -2.1738e-05,  ...,  1.1361e-03,\n",
            "          1.2870e-03, -1.7313e-03],\n",
            "        [-2.4349e-03,  2.1750e-03,  2.2784e-03,  ...,  9.0722e-04,\n",
            "         -1.6614e-03, -7.9001e-04]], device='cuda:0', requires_grad=True)\n",
            "NPV_D1.bias Parameter containing:\n",
            "tensor([-1.7293e-03,  1.1506e-03,  4.5368e-04,  2.2238e-03, -1.0917e-03,\n",
            "         1.4628e-03,  7.4851e-04,  4.7187e-04,  4.4980e-04,  4.4164e-04,\n",
            "         2.3777e-03,  1.3046e-03,  1.0829e-03, -9.2801e-04, -1.8209e-03,\n",
            "         1.7245e-03, -1.0184e-03, -1.2659e-04, -1.7220e-03, -7.5425e-04,\n",
            "        -2.0609e-03, -1.3359e-03, -4.9613e-04, -1.3858e-03, -1.0979e-03,\n",
            "         1.4651e-03,  2.3188e-03,  2.6795e-04,  7.8525e-04,  9.0881e-04,\n",
            "        -2.2881e-03,  1.7262e-03,  1.8762e-03, -2.5844e-03,  2.4112e-03,\n",
            "        -2.5076e-03,  4.6261e-04, -1.4186e-03,  1.5151e-03, -2.4477e-03,\n",
            "         2.1016e-03,  1.5367e-03, -3.9686e-04, -6.9806e-04, -3.9219e-04,\n",
            "        -2.5773e-03,  7.0031e-04, -8.0653e-04, -2.3993e-03, -1.6461e-03,\n",
            "        -7.8823e-04, -7.4132e-04,  7.4638e-05, -1.2766e-03,  1.3125e-03,\n",
            "         2.6874e-04,  8.2318e-04,  2.3516e-03, -4.7614e-04,  2.2069e-03,\n",
            "         7.7329e-04, -1.8285e-04, -2.0146e-03,  6.9669e-04,  1.8384e-03,\n",
            "         1.5384e-03, -2.4892e-03, -2.7350e-03, -2.5745e-03,  5.1249e-04,\n",
            "        -1.5800e-03, -1.0113e-03,  6.4865e-04,  2.2062e-04, -2.2047e-03,\n",
            "        -1.6090e-03,  2.6658e-03,  6.1688e-04,  6.4689e-04,  9.7595e-04,\n",
            "         9.4350e-04,  6.9253e-05, -2.0698e-03,  9.4742e-04, -2.3143e-03,\n",
            "         6.2070e-04, -1.5793e-03, -6.7087e-05, -1.1357e-03, -4.9779e-04,\n",
            "        -2.5385e-03,  2.7360e-03,  2.3791e-03, -1.9708e-03,  1.0906e-03,\n",
            "         1.3715e-03, -2.3547e-03,  4.6215e-04, -2.2761e-03, -2.3822e-03,\n",
            "        -2.3306e-03,  1.5498e-03,  4.6081e-04,  1.9972e-03, -1.4676e-03,\n",
            "        -4.0181e-04, -4.9730e-04, -1.9021e-04,  4.8721e-04,  1.0586e-03,\n",
            "        -6.9944e-04, -1.4037e-03,  1.2033e-03,  1.8104e-03, -1.2484e-03,\n",
            "        -2.1162e-03, -1.8560e-03,  2.2677e-04,  1.3658e-03, -7.8060e-04,\n",
            "        -2.2129e-03,  4.8610e-04,  2.4957e-03, -3.2211e-04,  1.3209e-03,\n",
            "         2.2782e-03, -3.7630e-04,  6.7897e-04, -2.0243e-03, -2.7119e-03,\n",
            "         7.2267e-05, -1.1964e-03,  4.6058e-04, -2.2406e-03,  1.5283e-03,\n",
            "         1.4283e-03,  5.4040e-04, -4.1939e-04,  1.7948e-03,  2.0843e-03,\n",
            "         2.4138e-03, -2.7335e-03, -2.3687e-04, -1.8270e-03,  2.5321e-05,\n",
            "        -1.6385e-03, -4.1526e-04, -2.1864e-03, -1.5711e-03, -6.5090e-04,\n",
            "         1.9258e-03, -6.1930e-04,  1.3966e-03, -2.1703e-03, -1.5526e-03,\n",
            "         2.3025e-03, -1.0247e-03,  2.2240e-04,  9.0348e-04,  2.3754e-03,\n",
            "        -5.6102e-04,  3.9313e-04,  2.2708e-03, -1.9777e-03, -1.5489e-03,\n",
            "        -1.0275e-04,  1.6533e-03,  2.4441e-03, -2.6863e-03,  1.3588e-03,\n",
            "         5.5830e-04,  1.6059e-03, -2.7226e-03,  2.5678e-03, -1.1263e-03,\n",
            "        -1.2009e-03, -2.2263e-04,  1.5944e-03,  6.4960e-04,  1.8687e-03,\n",
            "        -2.2959e-03,  8.8703e-04,  1.6097e-03,  2.0857e-03,  3.6004e-04,\n",
            "        -5.9956e-04, -1.3601e-03, -2.5856e-03,  2.4500e-03,  7.3057e-04,\n",
            "        -1.1476e-03, -2.2637e-03,  4.4135e-04, -5.3937e-04, -2.3880e-03,\n",
            "        -1.5165e-03, -9.9325e-04, -2.5305e-03,  2.0115e-03, -2.2617e-05,\n",
            "         1.4759e-03,  9.7474e-04, -1.8251e-03,  1.3893e-03,  2.8886e-04,\n",
            "        -1.8922e-03, -2.2863e-03,  2.7426e-04,  2.5241e-03, -1.1213e-03,\n",
            "        -2.0870e-03, -1.4473e-03, -1.0257e-04,  2.5948e-03,  1.5732e-03,\n",
            "        -1.7268e-04,  1.4219e-03, -2.3880e-03,  8.3847e-04,  9.3391e-04,\n",
            "        -1.5229e-03,  1.5482e-03, -8.9516e-04, -2.3863e-04,  1.4544e-03,\n",
            "         1.2158e-03,  2.6584e-03, -1.3712e-03, -1.1800e-04,  3.4211e-04,\n",
            "        -1.0444e-03,  8.3916e-04,  7.4900e-04, -1.4592e-03, -4.9113e-04,\n",
            "         5.6589e-04,  2.3520e-03,  2.5193e-04,  2.2397e-03, -1.7005e-04,\n",
            "         5.4457e-04,  6.8871e-04,  1.1060e-03, -2.6542e-03, -2.2471e-03,\n",
            "        -3.2228e-04,  6.0786e-04,  1.1220e-03,  1.5163e-03, -8.9003e-04,\n",
            "        -2.0156e-03, -2.4076e-04, -1.8176e-03, -2.0926e-03,  2.6878e-04,\n",
            "         1.6702e-03], device='cuda:0', requires_grad=True)\n",
            "NPV_D2.weight Parameter containing:\n",
            "tensor([[-0.0121,  0.0591,  0.0244,  ...,  0.0342,  0.0062,  0.0272],\n",
            "        [ 0.0148, -0.0111,  0.0334,  ..., -0.0532, -0.0606, -0.0129],\n",
            "        [ 0.0241,  0.0384,  0.0045,  ..., -0.0607, -0.0118,  0.0356],\n",
            "        ...,\n",
            "        [-0.0339, -0.0398,  0.0422,  ..., -0.0270, -0.0313, -0.0511],\n",
            "        [-0.0071, -0.0161, -0.0303,  ..., -0.0205, -0.0411, -0.0544],\n",
            "        [-0.0422,  0.0084,  0.0094,  ...,  0.0176,  0.0265,  0.0420]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_D2.bias Parameter containing:\n",
            "tensor([ 0.0443, -0.0057,  0.0033,  0.0286,  0.0196,  0.0321,  0.0266, -0.0501,\n",
            "         0.0430,  0.0285, -0.0561,  0.0497,  0.0112, -0.0235, -0.0455, -0.0476,\n",
            "         0.0580,  0.0041, -0.0330, -0.0186,  0.0076,  0.0349, -0.0155,  0.0340,\n",
            "         0.0459, -0.0561, -0.0358, -0.0236,  0.0267,  0.0450, -0.0398, -0.0614,\n",
            "         0.0301, -0.0389,  0.0204, -0.0458,  0.0272, -0.0333, -0.0159,  0.0405,\n",
            "        -0.0393, -0.0053,  0.0562,  0.0492, -0.0212,  0.0604, -0.0277,  0.0261,\n",
            "        -0.0538,  0.0095, -0.0192, -0.0304,  0.0095, -0.0079, -0.0423,  0.0131,\n",
            "        -0.0050,  0.0570, -0.0438,  0.0599, -0.0250, -0.0179,  0.0113,  0.0231,\n",
            "         0.0370,  0.0202,  0.0267,  0.0511,  0.0034,  0.0320, -0.0340,  0.0050,\n",
            "         0.0005, -0.0586,  0.0154, -0.0275,  0.0231,  0.0010, -0.0038,  0.0010,\n",
            "         0.0349, -0.0453, -0.0415, -0.0532, -0.0600, -0.0162,  0.0336,  0.0606,\n",
            "         0.0131, -0.0602, -0.0407, -0.0113,  0.0287,  0.0262,  0.0173, -0.0275,\n",
            "        -0.0624, -0.0497,  0.0357,  0.0189, -0.0541, -0.0413,  0.0169, -0.0023,\n",
            "         0.0011, -0.0057,  0.0013,  0.0241, -0.0444,  0.0299,  0.0204,  0.0585,\n",
            "        -0.0187,  0.0216,  0.0260, -0.0053, -0.0099, -0.0601,  0.0219, -0.0584,\n",
            "        -0.0526, -0.0407,  0.0613,  0.0422, -0.0393, -0.0031,  0.0520,  0.0530,\n",
            "         0.0211,  0.0060, -0.0389, -0.0046, -0.0396,  0.0321, -0.0002, -0.0442,\n",
            "        -0.0011,  0.0272, -0.0528,  0.0215,  0.0132, -0.0008, -0.0204, -0.0607,\n",
            "        -0.0469, -0.0159,  0.0606, -0.0366, -0.0158, -0.0438,  0.0605, -0.0318,\n",
            "         0.0358, -0.0533, -0.0051,  0.0206,  0.0594, -0.0112, -0.0526, -0.0307,\n",
            "        -0.0101,  0.0615, -0.0295, -0.0286, -0.0270,  0.0399, -0.0144, -0.0594,\n",
            "        -0.0280,  0.0220,  0.0408, -0.0377,  0.0588, -0.0525, -0.0098, -0.0293,\n",
            "         0.0530, -0.0481,  0.0530,  0.0099,  0.0553,  0.0277,  0.0425,  0.0379,\n",
            "         0.0344,  0.0449,  0.0226, -0.0090, -0.0324, -0.0462,  0.0105,  0.0535,\n",
            "        -0.0245, -0.0174,  0.0582, -0.0548, -0.0594,  0.0383,  0.0171, -0.0084,\n",
            "         0.0083, -0.0315, -0.0076,  0.0612,  0.0234,  0.0008, -0.0171,  0.0224,\n",
            "        -0.0074, -0.0326, -0.0423, -0.0407, -0.0092,  0.0500, -0.0434,  0.0095,\n",
            "         0.0211, -0.0323, -0.0504, -0.0623,  0.0060,  0.0252, -0.0341,  0.0300,\n",
            "         0.0354,  0.0008,  0.0221,  0.0280, -0.0195,  0.0424,  0.0334,  0.0103,\n",
            "         0.0459,  0.0013, -0.0192, -0.0066, -0.0512,  0.0492, -0.0246,  0.0128,\n",
            "        -0.0522,  0.0421, -0.0526,  0.0228,  0.0590, -0.0036, -0.0365,  0.0018,\n",
            "        -0.0164, -0.0448, -0.0358, -0.0419, -0.0125, -0.0037, -0.0153,  0.0261],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "outputs.weight Parameter containing:\n",
            "tensor([[-0.0502,  0.0302,  0.0245,  ..., -0.0561,  0.0062, -0.0519],\n",
            "        [-0.0195, -0.0079, -0.0198,  ...,  0.0069,  0.0236, -0.0429],\n",
            "        [-0.0450, -0.0012, -0.0537,  ..., -0.0257,  0.0116, -0.0463],\n",
            "        ...,\n",
            "        [-0.0162, -0.0051,  0.0075,  ...,  0.0489, -0.0517,  0.0293],\n",
            "        [-0.0462, -0.0100,  0.0199,  ..., -0.0319,  0.0435,  0.0380],\n",
            "        [-0.0228,  0.0501,  0.0101,  ..., -0.0125, -0.0305, -0.0491]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "outputs.bias Parameter containing:\n",
            "tensor([ 0.0554, -0.0249, -0.0399, -0.0488, -0.0268, -0.0566,  0.0002, -0.0334,\n",
            "        -0.0555,  0.0072], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in frnpf_di_model.named_parameters():\n",
        "  if name[0:3]=='NPF':\n",
        "    paramName = \"NPV\"+name[3:]\n",
        "    param.data = frnpf_di_model.state_dict().get(paramName).data.detach().clone()\n",
        "    param.requires_grad = False\n",
        "  print(name, param)"
      ],
      "metadata": {
        "id": "TZhztZWGSWip",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a58dd18a-b744-4819-b3c1-adfb10a11e0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NPF_C1.weight Parameter containing:\n",
            "tensor([[[[ 0.1702, -0.0410, -0.1715],\n",
            "          [-0.1727, -0.1691,  0.1663],\n",
            "          [-0.0101, -0.1337,  0.0772]],\n",
            "\n",
            "         [[ 0.0743,  0.1482,  0.0419],\n",
            "          [ 0.1614,  0.1694,  0.1859],\n",
            "          [-0.1185, -0.0738,  0.0040]],\n",
            "\n",
            "         [[ 0.0363, -0.0772, -0.1612],\n",
            "          [ 0.0859,  0.0229,  0.0993],\n",
            "          [ 0.0268, -0.1790,  0.1827]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1779, -0.1019, -0.1768],\n",
            "          [-0.1688,  0.0673,  0.0757],\n",
            "          [ 0.1021,  0.0230,  0.0172]],\n",
            "\n",
            "         [[-0.1060,  0.0220,  0.0491],\n",
            "          [ 0.0193,  0.0763, -0.0260],\n",
            "          [-0.0401, -0.1085, -0.0292]],\n",
            "\n",
            "         [[-0.0725,  0.0668,  0.0805],\n",
            "          [ 0.0910, -0.0254,  0.0105],\n",
            "          [-0.1620, -0.1402,  0.1393]]],\n",
            "\n",
            "\n",
            "        [[[-0.1743, -0.1056,  0.0858],\n",
            "          [ 0.1476, -0.0166, -0.0909],\n",
            "          [ 0.1034, -0.1136, -0.0495]],\n",
            "\n",
            "         [[-0.1307,  0.1124, -0.0006],\n",
            "          [-0.0614,  0.1173, -0.1692],\n",
            "          [-0.0389,  0.1868,  0.0260]],\n",
            "\n",
            "         [[-0.0134, -0.0680,  0.0858],\n",
            "          [ 0.0989,  0.0621, -0.1651],\n",
            "          [-0.0100, -0.0766,  0.1436]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1146,  0.0594,  0.1794],\n",
            "          [-0.0902,  0.1062,  0.1016],\n",
            "          [ 0.0030, -0.0459, -0.0912]],\n",
            "\n",
            "         [[-0.0790,  0.1894, -0.0759],\n",
            "          [ 0.0057, -0.0130,  0.0134],\n",
            "          [ 0.0984, -0.1103,  0.0471]],\n",
            "\n",
            "         [[-0.1643,  0.0140,  0.0439],\n",
            "          [ 0.0277,  0.0672, -0.1452],\n",
            "          [-0.0354,  0.0165, -0.0689]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0635, -0.1574, -0.1164],\n",
            "          [ 0.0090,  0.1154,  0.1278],\n",
            "          [ 0.1436,  0.0321, -0.0963]],\n",
            "\n",
            "         [[-0.0914,  0.0944,  0.1823],\n",
            "          [-0.1550, -0.0940, -0.1480],\n",
            "          [-0.1010, -0.1865, -0.0256]],\n",
            "\n",
            "         [[ 0.0908,  0.0892,  0.0189],\n",
            "          [ 0.1255,  0.1116,  0.0328],\n",
            "          [-0.1714,  0.0962,  0.0869]]],\n",
            "\n",
            "\n",
            "        [[[-0.1654, -0.1914, -0.1517],\n",
            "          [ 0.1294,  0.0595,  0.0156],\n",
            "          [ 0.1310,  0.0984, -0.0277]],\n",
            "\n",
            "         [[ 0.0623,  0.0603,  0.0457],\n",
            "          [-0.0720, -0.1320, -0.0053],\n",
            "          [-0.0809,  0.0605, -0.0083]],\n",
            "\n",
            "         [[-0.1451, -0.0556, -0.1564],\n",
            "          [-0.1920, -0.0923, -0.1241],\n",
            "          [-0.1158,  0.0806, -0.1910]]]], device='cuda:0')\n",
            "NPF_C1.bias Parameter containing:\n",
            "tensor([ 0.1360,  0.0330, -0.1504,  0.1085, -0.0124, -0.0843,  0.1011,  0.0657,\n",
            "        -0.1680, -0.0143, -0.0744, -0.1760,  0.0395,  0.1175,  0.1187,  0.0322,\n",
            "        -0.0170, -0.0094, -0.0723, -0.1105, -0.1598, -0.1207, -0.1817,  0.0272,\n",
            "        -0.1605,  0.0230, -0.0691,  0.0023,  0.0248,  0.1161, -0.0184, -0.1789,\n",
            "        -0.0585, -0.1670, -0.1498,  0.0496, -0.1021,  0.1302,  0.1419,  0.0301,\n",
            "        -0.0621,  0.0660, -0.1356,  0.1769,  0.1480, -0.0332, -0.1666, -0.1354,\n",
            "         0.0033, -0.1591,  0.1543,  0.0701,  0.0120,  0.1138, -0.1279, -0.0945,\n",
            "         0.1131, -0.0975,  0.0081, -0.0486,  0.1721,  0.1269, -0.0028, -0.0407],\n",
            "       device='cuda:0')\n",
            "NPF_C2.weight Parameter containing:\n",
            "tensor([[[[ 0.0117,  0.0134,  0.0057],\n",
            "          [ 0.0141,  0.0043, -0.0169],\n",
            "          [-0.0188,  0.0092,  0.0140]],\n",
            "\n",
            "         [[ 0.0207,  0.0378,  0.0386],\n",
            "          [-0.0025,  0.0047,  0.0346],\n",
            "          [ 0.0243, -0.0013, -0.0157]],\n",
            "\n",
            "         [[-0.0038,  0.0179,  0.0011],\n",
            "          [ 0.0312,  0.0250, -0.0085],\n",
            "          [-0.0351, -0.0400,  0.0129]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0136, -0.0027, -0.0094],\n",
            "          [ 0.0375,  0.0247, -0.0122],\n",
            "          [ 0.0003, -0.0191,  0.0029]],\n",
            "\n",
            "         [[-0.0351, -0.0091,  0.0261],\n",
            "          [ 0.0052, -0.0126, -0.0320],\n",
            "          [ 0.0291,  0.0014,  0.0303]],\n",
            "\n",
            "         [[-0.0324, -0.0034,  0.0024],\n",
            "          [-0.0180, -0.0181, -0.0379],\n",
            "          [-0.0142,  0.0389, -0.0066]]],\n",
            "\n",
            "\n",
            "        [[[-0.0405,  0.0334, -0.0408],\n",
            "          [-0.0114,  0.0316,  0.0337],\n",
            "          [ 0.0297,  0.0079, -0.0073]],\n",
            "\n",
            "         [[-0.0187, -0.0220, -0.0277],\n",
            "          [-0.0102,  0.0286, -0.0374],\n",
            "          [ 0.0210,  0.0406, -0.0387]],\n",
            "\n",
            "         [[ 0.0171,  0.0314,  0.0051],\n",
            "          [ 0.0192, -0.0019,  0.0069],\n",
            "          [ 0.0050, -0.0015,  0.0071]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0264,  0.0286,  0.0343],\n",
            "          [-0.0298,  0.0395,  0.0322],\n",
            "          [-0.0302,  0.0036, -0.0017]],\n",
            "\n",
            "         [[-0.0205, -0.0156,  0.0061],\n",
            "          [-0.0365,  0.0248, -0.0135],\n",
            "          [ 0.0056, -0.0410, -0.0401]],\n",
            "\n",
            "         [[-0.0197, -0.0257,  0.0374],\n",
            "          [ 0.0063,  0.0069,  0.0125],\n",
            "          [ 0.0214, -0.0313,  0.0212]]],\n",
            "\n",
            "\n",
            "        [[[-0.0132,  0.0052,  0.0207],\n",
            "          [-0.0053, -0.0263, -0.0035],\n",
            "          [ 0.0232,  0.0057,  0.0260]],\n",
            "\n",
            "         [[-0.0296,  0.0235, -0.0076],\n",
            "          [-0.0269, -0.0013, -0.0062],\n",
            "          [ 0.0148,  0.0179, -0.0357]],\n",
            "\n",
            "         [[ 0.0382,  0.0273,  0.0217],\n",
            "          [-0.0281,  0.0038, -0.0042],\n",
            "          [ 0.0366, -0.0363,  0.0277]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0030,  0.0043,  0.0102],\n",
            "          [ 0.0061, -0.0143, -0.0350],\n",
            "          [ 0.0089,  0.0032, -0.0233]],\n",
            "\n",
            "         [[-0.0279,  0.0256,  0.0127],\n",
            "          [ 0.0208, -0.0117, -0.0150],\n",
            "          [-0.0078,  0.0200,  0.0107]],\n",
            "\n",
            "         [[-0.0289,  0.0065, -0.0127],\n",
            "          [-0.0124, -0.0017, -0.0359],\n",
            "          [ 0.0106, -0.0404, -0.0334]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0327,  0.0195, -0.0202],\n",
            "          [ 0.0233, -0.0046,  0.0008],\n",
            "          [-0.0348,  0.0396,  0.0073]],\n",
            "\n",
            "         [[ 0.0008, -0.0410,  0.0255],\n",
            "          [-0.0052,  0.0091,  0.0209],\n",
            "          [ 0.0283, -0.0069,  0.0075]],\n",
            "\n",
            "         [[ 0.0106, -0.0116,  0.0188],\n",
            "          [ 0.0106, -0.0157,  0.0402],\n",
            "          [-0.0322, -0.0369, -0.0151]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0221, -0.0208,  0.0368],\n",
            "          [-0.0264, -0.0405, -0.0024],\n",
            "          [-0.0255,  0.0377,  0.0127]],\n",
            "\n",
            "         [[ 0.0225,  0.0050, -0.0209],\n",
            "          [ 0.0050,  0.0040, -0.0184],\n",
            "          [ 0.0100,  0.0258, -0.0385]],\n",
            "\n",
            "         [[ 0.0224, -0.0036,  0.0148],\n",
            "          [-0.0370, -0.0141, -0.0067],\n",
            "          [-0.0366, -0.0334,  0.0262]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0251, -0.0156,  0.0107],\n",
            "          [ 0.0033, -0.0368,  0.0235],\n",
            "          [ 0.0036,  0.0197, -0.0204]],\n",
            "\n",
            "         [[ 0.0275, -0.0240,  0.0242],\n",
            "          [ 0.0345, -0.0197,  0.0007],\n",
            "          [ 0.0316, -0.0102, -0.0296]],\n",
            "\n",
            "         [[ 0.0221,  0.0325,  0.0185],\n",
            "          [-0.0341,  0.0398, -0.0091],\n",
            "          [-0.0140, -0.0313,  0.0102]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0152, -0.0278,  0.0116],\n",
            "          [-0.0106,  0.0302, -0.0140],\n",
            "          [-0.0192, -0.0216,  0.0012]],\n",
            "\n",
            "         [[ 0.0296,  0.0322, -0.0048],\n",
            "          [ 0.0010,  0.0015, -0.0345],\n",
            "          [ 0.0091,  0.0310, -0.0305]],\n",
            "\n",
            "         [[ 0.0093, -0.0009, -0.0151],\n",
            "          [-0.0038, -0.0119, -0.0011],\n",
            "          [ 0.0371,  0.0036, -0.0325]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0295, -0.0322,  0.0342],\n",
            "          [-0.0359, -0.0373, -0.0228],\n",
            "          [-0.0271,  0.0056, -0.0221]],\n",
            "\n",
            "         [[ 0.0273, -0.0159, -0.0098],\n",
            "          [-0.0362,  0.0041, -0.0033],\n",
            "          [ 0.0252,  0.0075,  0.0073]],\n",
            "\n",
            "         [[-0.0098, -0.0373, -0.0401],\n",
            "          [-0.0347, -0.0057, -0.0407],\n",
            "          [-0.0193,  0.0184, -0.0082]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0136,  0.0059, -0.0351],\n",
            "          [ 0.0357,  0.0166, -0.0370],\n",
            "          [ 0.0401,  0.0193,  0.0256]],\n",
            "\n",
            "         [[-0.0273, -0.0409,  0.0268],\n",
            "          [-0.0328,  0.0115,  0.0038],\n",
            "          [-0.0033, -0.0075, -0.0339]],\n",
            "\n",
            "         [[-0.0324,  0.0122, -0.0293],\n",
            "          [-0.0336, -0.0026, -0.0124],\n",
            "          [ 0.0412, -0.0374,  0.0122]]]], device='cuda:0')\n",
            "NPF_C2.bias Parameter containing:\n",
            "tensor([-0.0375, -0.0013,  0.0022, -0.0365, -0.0123,  0.0181, -0.0207, -0.0065,\n",
            "        -0.0264,  0.0202, -0.0197,  0.0378, -0.0018,  0.0063, -0.0281, -0.0283,\n",
            "         0.0307, -0.0126, -0.0030, -0.0032,  0.0123, -0.0373,  0.0336,  0.0352,\n",
            "         0.0345, -0.0321, -0.0002, -0.0399, -0.0095,  0.0396, -0.0214,  0.0284,\n",
            "        -0.0386, -0.0108, -0.0180, -0.0231,  0.0095,  0.0348,  0.0079, -0.0123,\n",
            "         0.0008, -0.0140,  0.0222, -0.0179,  0.0162,  0.0234, -0.0015, -0.0249,\n",
            "        -0.0111,  0.0403,  0.0270,  0.0212,  0.0014, -0.0164,  0.0199, -0.0077,\n",
            "        -0.0222,  0.0197,  0.0294, -0.0407, -0.0286, -0.0157, -0.0314, -0.0024],\n",
            "       device='cuda:0')\n",
            "NPF_C3.weight Parameter containing:\n",
            "tensor([[[[ 0.0217,  0.0159, -0.0032],\n",
            "          [ 0.0155, -0.0109, -0.0363],\n",
            "          [ 0.0100,  0.0288, -0.0223]],\n",
            "\n",
            "         [[-0.0266, -0.0324, -0.0359],\n",
            "          [ 0.0382, -0.0044,  0.0317],\n",
            "          [ 0.0154,  0.0313,  0.0413]],\n",
            "\n",
            "         [[ 0.0295,  0.0122,  0.0401],\n",
            "          [-0.0161, -0.0172,  0.0025],\n",
            "          [ 0.0147, -0.0363, -0.0226]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0291,  0.0142,  0.0043],\n",
            "          [ 0.0081, -0.0154, -0.0182],\n",
            "          [-0.0193, -0.0097, -0.0249]],\n",
            "\n",
            "         [[-0.0027, -0.0054, -0.0012],\n",
            "          [-0.0141,  0.0177,  0.0075],\n",
            "          [ 0.0415, -0.0002, -0.0012]],\n",
            "\n",
            "         [[-0.0128, -0.0170, -0.0107],\n",
            "          [-0.0021,  0.0345,  0.0069],\n",
            "          [-0.0341, -0.0314, -0.0028]]],\n",
            "\n",
            "\n",
            "        [[[-0.0076,  0.0052, -0.0285],\n",
            "          [ 0.0228, -0.0024, -0.0161],\n",
            "          [-0.0218,  0.0328, -0.0113]],\n",
            "\n",
            "         [[ 0.0180, -0.0015,  0.0081],\n",
            "          [-0.0312, -0.0027,  0.0136],\n",
            "          [ 0.0200,  0.0393,  0.0309]],\n",
            "\n",
            "         [[ 0.0410, -0.0200,  0.0090],\n",
            "          [ 0.0290,  0.0057,  0.0161],\n",
            "          [ 0.0051, -0.0343,  0.0307]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0299, -0.0156, -0.0243],\n",
            "          [-0.0215, -0.0067, -0.0233],\n",
            "          [ 0.0007,  0.0120,  0.0273]],\n",
            "\n",
            "         [[-0.0087, -0.0387,  0.0304],\n",
            "          [-0.0387,  0.0127,  0.0089],\n",
            "          [-0.0280, -0.0172, -0.0410]],\n",
            "\n",
            "         [[ 0.0094, -0.0312, -0.0141],\n",
            "          [-0.0042,  0.0050,  0.0087],\n",
            "          [-0.0191, -0.0035,  0.0234]]],\n",
            "\n",
            "\n",
            "        [[[-0.0267, -0.0385,  0.0090],\n",
            "          [ 0.0017, -0.0002, -0.0062],\n",
            "          [ 0.0167, -0.0032, -0.0264]],\n",
            "\n",
            "         [[ 0.0373,  0.0369, -0.0068],\n",
            "          [ 0.0210, -0.0224,  0.0036],\n",
            "          [ 0.0040,  0.0299,  0.0167]],\n",
            "\n",
            "         [[-0.0102, -0.0214, -0.0375],\n",
            "          [-0.0070, -0.0188,  0.0133],\n",
            "          [ 0.0378,  0.0025, -0.0404]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0362,  0.0076, -0.0198],\n",
            "          [ 0.0139, -0.0317, -0.0059],\n",
            "          [-0.0229, -0.0307, -0.0368]],\n",
            "\n",
            "         [[ 0.0246, -0.0413, -0.0115],\n",
            "          [ 0.0173, -0.0243,  0.0171],\n",
            "          [ 0.0092, -0.0388,  0.0007]],\n",
            "\n",
            "         [[-0.0409,  0.0412,  0.0188],\n",
            "          [ 0.0337,  0.0192,  0.0112],\n",
            "          [ 0.0333, -0.0049, -0.0256]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0117,  0.0416, -0.0205],\n",
            "          [ 0.0384,  0.0136, -0.0109],\n",
            "          [-0.0172,  0.0108, -0.0408]],\n",
            "\n",
            "         [[-0.0056, -0.0263, -0.0103],\n",
            "          [ 0.0246,  0.0354, -0.0183],\n",
            "          [-0.0325, -0.0009,  0.0335]],\n",
            "\n",
            "         [[ 0.0257,  0.0105,  0.0135],\n",
            "          [ 0.0170,  0.0015,  0.0063],\n",
            "          [ 0.0024, -0.0213,  0.0250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0060, -0.0101,  0.0241],\n",
            "          [-0.0368, -0.0300,  0.0281],\n",
            "          [-0.0269, -0.0349,  0.0398]],\n",
            "\n",
            "         [[-0.0296,  0.0317,  0.0413],\n",
            "          [ 0.0357,  0.0398, -0.0339],\n",
            "          [ 0.0092, -0.0390, -0.0209]],\n",
            "\n",
            "         [[-0.0251, -0.0118, -0.0356],\n",
            "          [-0.0005, -0.0193, -0.0180],\n",
            "          [-0.0108, -0.0188, -0.0146]]],\n",
            "\n",
            "\n",
            "        [[[-0.0226, -0.0279,  0.0365],\n",
            "          [ 0.0007, -0.0239, -0.0410],\n",
            "          [-0.0050, -0.0209, -0.0139]],\n",
            "\n",
            "         [[ 0.0322,  0.0097, -0.0164],\n",
            "          [ 0.0102,  0.0403, -0.0031],\n",
            "          [-0.0312, -0.0138,  0.0081]],\n",
            "\n",
            "         [[ 0.0337,  0.0101, -0.0385],\n",
            "          [-0.0055, -0.0081, -0.0057],\n",
            "          [ 0.0145,  0.0361, -0.0136]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0124,  0.0247, -0.0099],\n",
            "          [ 0.0249, -0.0336, -0.0019],\n",
            "          [ 0.0322,  0.0275,  0.0336]],\n",
            "\n",
            "         [[-0.0078, -0.0330, -0.0142],\n",
            "          [ 0.0335, -0.0248, -0.0206],\n",
            "          [-0.0309,  0.0191, -0.0266]],\n",
            "\n",
            "         [[ 0.0402, -0.0093,  0.0157],\n",
            "          [-0.0164,  0.0053,  0.0331],\n",
            "          [-0.0341, -0.0125, -0.0200]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0050,  0.0385, -0.0309],\n",
            "          [-0.0285, -0.0210, -0.0122],\n",
            "          [-0.0379, -0.0037,  0.0150]],\n",
            "\n",
            "         [[ 0.0102, -0.0091,  0.0294],\n",
            "          [ 0.0283,  0.0001,  0.0034],\n",
            "          [-0.0177, -0.0332, -0.0117]],\n",
            "\n",
            "         [[-0.0408, -0.0170, -0.0365],\n",
            "          [-0.0088, -0.0094, -0.0055],\n",
            "          [ 0.0376,  0.0012, -0.0224]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0268, -0.0318,  0.0173],\n",
            "          [-0.0218,  0.0203, -0.0278],\n",
            "          [ 0.0141, -0.0190,  0.0192]],\n",
            "\n",
            "         [[-0.0236,  0.0116,  0.0194],\n",
            "          [ 0.0021,  0.0244,  0.0283],\n",
            "          [-0.0401, -0.0231, -0.0233]],\n",
            "\n",
            "         [[-0.0150, -0.0166,  0.0403],\n",
            "          [ 0.0408,  0.0149, -0.0296],\n",
            "          [-0.0243, -0.0286, -0.0399]]]], device='cuda:0')\n",
            "NPF_C3.bias Parameter containing:\n",
            "tensor([ 0.0205, -0.0027,  0.0187, -0.0045,  0.0185, -0.0097, -0.0113, -0.0203,\n",
            "         0.0067,  0.0380, -0.0108, -0.0188, -0.0001,  0.0230, -0.0367, -0.0163,\n",
            "         0.0272, -0.0229, -0.0064, -0.0043, -0.0022,  0.0158, -0.0151,  0.0258,\n",
            "        -0.0205,  0.0321, -0.0410, -0.0030,  0.0368,  0.0110,  0.0130,  0.0193,\n",
            "         0.0196, -0.0412,  0.0306,  0.0374,  0.0065,  0.0286,  0.0197, -0.0130,\n",
            "        -0.0215,  0.0275,  0.0290, -0.0212, -0.0156, -0.0073,  0.0409, -0.0360,\n",
            "         0.0362,  0.0067,  0.0157,  0.0339, -0.0376,  0.0260, -0.0381, -0.0325,\n",
            "        -0.0245, -0.0139, -0.0410, -0.0091, -0.0009,  0.0037, -0.0217, -0.0272,\n",
            "         0.0189,  0.0089, -0.0144, -0.0047, -0.0132, -0.0014,  0.0248, -0.0269,\n",
            "         0.0305,  0.0317,  0.0096,  0.0324,  0.0260,  0.0107, -0.0314, -0.0317,\n",
            "         0.0391, -0.0169,  0.0193,  0.0308,  0.0345, -0.0196, -0.0262,  0.0157,\n",
            "        -0.0380, -0.0198, -0.0238, -0.0353,  0.0414,  0.0203, -0.0101, -0.0259,\n",
            "        -0.0095, -0.0179,  0.0205,  0.0009, -0.0212, -0.0394,  0.0290,  0.0146,\n",
            "        -0.0127,  0.0112, -0.0014,  0.0211, -0.0319, -0.0039,  0.0365,  0.0352,\n",
            "        -0.0147,  0.0020,  0.0415, -0.0015, -0.0121, -0.0287, -0.0020,  0.0074,\n",
            "        -0.0377,  0.0141,  0.0113, -0.0357, -0.0085, -0.0243, -0.0375,  0.0189],\n",
            "       device='cuda:0')\n",
            "NPF_C4.weight Parameter containing:\n",
            "tensor([[[[-7.2642e-03,  1.8725e-02, -1.3772e-02],\n",
            "          [-1.7507e-02, -1.3259e-02, -1.9156e-04],\n",
            "          [-8.3539e-03, -7.4551e-03, -3.6623e-03]],\n",
            "\n",
            "         [[-2.0398e-02, -1.1719e-02, -1.2072e-02],\n",
            "          [-1.5466e-02,  2.7268e-03, -1.6365e-02],\n",
            "          [ 2.9198e-02,  2.2899e-02, -1.0189e-02]],\n",
            "\n",
            "         [[ 2.8148e-02,  2.6232e-03,  2.8795e-02],\n",
            "          [ 1.9025e-03,  2.8527e-02,  2.4464e-02],\n",
            "          [ 3.0389e-03,  6.4775e-03,  1.1604e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0148e-04, -4.2034e-03, -1.6703e-02],\n",
            "          [ 1.0552e-02,  1.3343e-02, -4.4137e-03],\n",
            "          [-6.0703e-03, -1.0922e-02, -1.6723e-02]],\n",
            "\n",
            "         [[ 1.7797e-02,  1.1638e-02,  8.1478e-03],\n",
            "          [-2.0974e-03,  1.5894e-02, -2.6263e-03],\n",
            "          [-1.9343e-02,  2.2637e-02, -2.7770e-02]],\n",
            "\n",
            "         [[-1.0497e-02, -3.7546e-03, -7.1459e-03],\n",
            "          [-2.2670e-02, -6.2318e-03,  1.0515e-02],\n",
            "          [-1.5801e-02,  5.6887e-03, -2.0076e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0976e-02,  4.8132e-03,  1.3558e-02],\n",
            "          [ 9.8910e-03, -4.5010e-03, -2.4968e-02],\n",
            "          [-1.3108e-02,  8.0744e-03,  2.7444e-02]],\n",
            "\n",
            "         [[-1.9899e-02,  1.7395e-02,  5.5319e-03],\n",
            "          [ 2.4855e-02, -4.5730e-03,  2.9020e-02],\n",
            "          [-1.5705e-02,  2.5388e-02, -1.8179e-02]],\n",
            "\n",
            "         [[ 2.1590e-02, -2.8471e-02,  1.4288e-02],\n",
            "          [ 8.2745e-03, -2.7951e-02, -9.9734e-03],\n",
            "          [ 6.0420e-03,  2.8004e-02,  2.6936e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.5144e-03, -1.4959e-02,  2.4389e-02],\n",
            "          [ 2.7466e-02,  7.8878e-03,  1.9139e-02],\n",
            "          [-2.4720e-02, -1.5198e-02, -2.5540e-02]],\n",
            "\n",
            "         [[-1.5755e-02,  1.6693e-02, -1.3001e-02],\n",
            "          [ 1.2409e-03,  2.0463e-03,  5.6324e-03],\n",
            "          [ 8.8068e-03,  2.7159e-02, -5.1558e-03]],\n",
            "\n",
            "         [[ 1.0670e-02, -2.9010e-02,  2.3002e-02],\n",
            "          [ 1.5578e-02,  1.3569e-02, -8.0591e-03],\n",
            "          [-2.6739e-02, -2.6947e-02,  5.2179e-03]]],\n",
            "\n",
            "\n",
            "        [[[-2.8850e-02,  4.2878e-03,  1.2730e-02],\n",
            "          [-2.4219e-02,  1.6877e-02,  4.9958e-04],\n",
            "          [-2.9059e-02, -4.1744e-04, -6.8208e-03]],\n",
            "\n",
            "         [[-7.5455e-03,  8.4972e-03, -2.5459e-02],\n",
            "          [-2.8511e-02,  1.7128e-02,  1.8268e-02],\n",
            "          [-2.7390e-02, -1.9871e-02, -1.3138e-02]],\n",
            "\n",
            "         [[ 2.7750e-02, -2.0844e-02,  1.4472e-02],\n",
            "          [ 1.1179e-02, -2.3946e-02, -1.9616e-02],\n",
            "          [-2.5335e-02,  4.3083e-03,  2.3350e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.6229e-03,  1.0913e-02, -2.7349e-02],\n",
            "          [-2.2690e-03, -1.9740e-02, -2.0710e-02],\n",
            "          [-6.5406e-03, -1.5914e-02,  1.5547e-02]],\n",
            "\n",
            "         [[ 2.8126e-02, -3.5165e-03,  3.7297e-03],\n",
            "          [-1.6315e-02,  2.6352e-02, -1.9326e-02],\n",
            "          [ 2.6053e-02,  7.6796e-03,  1.3159e-03]],\n",
            "\n",
            "         [[-1.8453e-03,  7.7653e-03, -4.2909e-03],\n",
            "          [ 7.2997e-04, -5.7854e-03,  2.7358e-02],\n",
            "          [-3.2779e-03,  9.2777e-03, -1.5327e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.2030e-02, -5.8443e-03, -2.4302e-02],\n",
            "          [ 9.5494e-03, -1.6379e-02,  1.2827e-02],\n",
            "          [-1.8017e-02, -2.4094e-03,  1.3896e-02]],\n",
            "\n",
            "         [[ 6.7912e-03, -2.3121e-02,  9.8585e-03],\n",
            "          [-2.7826e-02,  2.1179e-02, -1.6276e-02],\n",
            "          [ 1.8634e-02, -2.9044e-02, -1.6896e-02]],\n",
            "\n",
            "         [[ 2.9040e-02,  1.7220e-02,  2.8143e-02],\n",
            "          [ 2.8895e-02,  1.0942e-02,  8.8019e-03],\n",
            "          [-8.0183e-03,  5.6600e-03, -2.6545e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5805e-02, -1.5331e-03, -1.5985e-02],\n",
            "          [ 2.2513e-02, -2.1843e-02, -2.1102e-02],\n",
            "          [-2.7542e-02,  2.5122e-02, -1.7474e-02]],\n",
            "\n",
            "         [[ 2.6096e-02, -1.8383e-02, -2.8806e-02],\n",
            "          [ 2.2937e-02, -1.5319e-03, -2.1857e-02],\n",
            "          [-1.1891e-02,  5.4766e-03, -1.4315e-02]],\n",
            "\n",
            "         [[-7.7001e-03, -2.4259e-02,  2.6040e-02],\n",
            "          [-2.0379e-02, -1.0252e-02, -1.6167e-02],\n",
            "          [-2.3275e-02, -7.7806e-03,  2.7962e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.6920e-03, -1.7858e-02,  1.2792e-02],\n",
            "          [-1.1420e-03,  2.8010e-02, -2.2215e-02],\n",
            "          [ 1.8668e-02,  1.5217e-02,  1.3881e-02]],\n",
            "\n",
            "         [[ 1.1137e-02, -1.5518e-02, -2.5761e-02],\n",
            "          [ 2.1063e-02,  5.5779e-03,  2.0150e-02],\n",
            "          [-3.5567e-03,  1.9626e-02, -2.6667e-02]],\n",
            "\n",
            "         [[ 1.5827e-03, -8.7478e-03,  9.4545e-03],\n",
            "          [ 1.5364e-02, -2.9423e-02,  2.6942e-02],\n",
            "          [ 6.3926e-03,  7.9577e-05,  8.7556e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.8616e-02, -7.8212e-03,  2.4313e-02],\n",
            "          [-5.4454e-03, -2.7568e-02, -9.5371e-03],\n",
            "          [ 5.3715e-03,  9.5695e-03,  2.3832e-03]],\n",
            "\n",
            "         [[-1.8455e-03,  5.5293e-03, -1.5890e-03],\n",
            "          [ 2.5887e-02, -8.4311e-03,  1.5555e-02],\n",
            "          [ 7.5019e-03,  5.3858e-03, -1.1731e-02]],\n",
            "\n",
            "         [[ 2.2408e-02,  1.5884e-02,  2.5341e-02],\n",
            "          [ 8.8692e-03,  1.5566e-02,  2.4938e-02],\n",
            "          [-2.4224e-02,  2.4266e-02,  8.8448e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5966e-02,  2.0407e-02, -8.3030e-03],\n",
            "          [-1.6691e-02, -1.9202e-02, -2.2475e-02],\n",
            "          [-1.1895e-02,  3.7270e-03,  2.1211e-02]],\n",
            "\n",
            "         [[-2.5930e-02,  2.0602e-02,  1.6368e-02],\n",
            "          [-1.8734e-03, -1.5195e-02, -1.8600e-02],\n",
            "          [-2.5721e-02,  2.0727e-02, -4.0807e-03]],\n",
            "\n",
            "         [[ 2.2957e-02, -2.1284e-02,  3.2340e-03],\n",
            "          [ 1.6553e-02,  1.4601e-02, -2.4700e-02],\n",
            "          [-2.4479e-02,  3.1844e-03,  2.0391e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.9130e-03, -1.5603e-02,  9.9356e-03],\n",
            "          [ 1.2557e-02, -1.7769e-02, -2.7835e-02],\n",
            "          [-1.0211e-02,  2.2124e-02,  1.1239e-02]],\n",
            "\n",
            "         [[-1.9666e-02,  1.7632e-02, -7.8668e-03],\n",
            "          [-1.8069e-02, -1.7070e-02, -4.3847e-03],\n",
            "          [-1.8631e-02,  6.0918e-03,  5.7733e-03]],\n",
            "\n",
            "         [[-8.1956e-03,  9.5931e-03,  2.1968e-03],\n",
            "          [ 2.6195e-02, -2.1429e-02,  2.4280e-02],\n",
            "          [-2.4516e-02, -1.7000e-03, -2.6902e-02]]]], device='cuda:0')\n",
            "NPF_C4.bias Parameter containing:\n",
            "tensor([-0.0233,  0.0038, -0.0167,  0.0017, -0.0130,  0.0242,  0.0098,  0.0054,\n",
            "         0.0241, -0.0281, -0.0179, -0.0163, -0.0150, -0.0075, -0.0222, -0.0021,\n",
            "        -0.0161,  0.0201,  0.0027,  0.0252, -0.0159,  0.0037, -0.0170, -0.0193,\n",
            "        -0.0125, -0.0287, -0.0143, -0.0076,  0.0187, -0.0086,  0.0005,  0.0005,\n",
            "         0.0239, -0.0242,  0.0257, -0.0055, -0.0156, -0.0233,  0.0095, -0.0025,\n",
            "        -0.0162, -0.0188, -0.0158,  0.0048,  0.0275,  0.0168, -0.0228,  0.0035,\n",
            "         0.0063,  0.0282, -0.0084, -0.0248, -0.0184, -0.0015, -0.0241, -0.0025,\n",
            "        -0.0025,  0.0265,  0.0200,  0.0163,  0.0025,  0.0183,  0.0016, -0.0218,\n",
            "         0.0020,  0.0275, -0.0054, -0.0177, -0.0090,  0.0207,  0.0246, -0.0002,\n",
            "        -0.0206,  0.0064, -0.0201,  0.0004, -0.0128, -0.0157,  0.0224, -0.0237,\n",
            "        -0.0243, -0.0127,  0.0140,  0.0202,  0.0286, -0.0250,  0.0093,  0.0014,\n",
            "        -0.0122,  0.0290,  0.0277,  0.0201, -0.0205, -0.0246,  0.0009, -0.0021,\n",
            "        -0.0074,  0.0248,  0.0065, -0.0118,  0.0173, -0.0201, -0.0294,  0.0134,\n",
            "        -0.0023,  0.0183, -0.0009,  0.0064,  0.0230,  0.0193,  0.0164, -0.0250,\n",
            "         0.0084,  0.0089,  0.0133,  0.0165,  0.0191, -0.0246,  0.0159,  0.0196,\n",
            "        -0.0131, -0.0118,  0.0178,  0.0291,  0.0268, -0.0260,  0.0032, -0.0088],\n",
            "       device='cuda:0')\n",
            "NPF_D1.weight Parameter containing:\n",
            "tensor([[-3.8792e-04,  2.4575e-03,  1.7560e-03,  ..., -2.5757e-04,\n",
            "          4.8451e-04,  2.4768e-03],\n",
            "        [ 1.6085e-03,  9.8880e-04,  1.0883e-03,  ..., -2.1319e-03,\n",
            "          3.9446e-04,  1.2126e-03],\n",
            "        [-1.6457e-04, -9.3323e-04, -2.8569e-04,  ...,  9.5492e-04,\n",
            "         -1.0700e-03, -9.0988e-04],\n",
            "        ...,\n",
            "        [-2.1483e-03,  1.5720e-03,  2.2458e-03,  ...,  1.1880e-03,\n",
            "          4.1344e-04,  1.0676e-03],\n",
            "        [-1.7881e-03, -8.2811e-04, -2.1738e-05,  ...,  1.1361e-03,\n",
            "          1.2870e-03, -1.7313e-03],\n",
            "        [-2.4349e-03,  2.1750e-03,  2.2784e-03,  ...,  9.0722e-04,\n",
            "         -1.6614e-03, -7.9001e-04]], device='cuda:0')\n",
            "NPF_D1.bias Parameter containing:\n",
            "tensor([-1.7293e-03,  1.1506e-03,  4.5368e-04,  2.2238e-03, -1.0917e-03,\n",
            "         1.4628e-03,  7.4851e-04,  4.7187e-04,  4.4980e-04,  4.4164e-04,\n",
            "         2.3777e-03,  1.3046e-03,  1.0829e-03, -9.2801e-04, -1.8209e-03,\n",
            "         1.7245e-03, -1.0184e-03, -1.2659e-04, -1.7220e-03, -7.5425e-04,\n",
            "        -2.0609e-03, -1.3359e-03, -4.9613e-04, -1.3858e-03, -1.0979e-03,\n",
            "         1.4651e-03,  2.3188e-03,  2.6795e-04,  7.8525e-04,  9.0881e-04,\n",
            "        -2.2881e-03,  1.7262e-03,  1.8762e-03, -2.5844e-03,  2.4112e-03,\n",
            "        -2.5076e-03,  4.6261e-04, -1.4186e-03,  1.5151e-03, -2.4477e-03,\n",
            "         2.1016e-03,  1.5367e-03, -3.9686e-04, -6.9806e-04, -3.9219e-04,\n",
            "        -2.5773e-03,  7.0031e-04, -8.0653e-04, -2.3993e-03, -1.6461e-03,\n",
            "        -7.8823e-04, -7.4132e-04,  7.4638e-05, -1.2766e-03,  1.3125e-03,\n",
            "         2.6874e-04,  8.2318e-04,  2.3516e-03, -4.7614e-04,  2.2069e-03,\n",
            "         7.7329e-04, -1.8285e-04, -2.0146e-03,  6.9669e-04,  1.8384e-03,\n",
            "         1.5384e-03, -2.4892e-03, -2.7350e-03, -2.5745e-03,  5.1249e-04,\n",
            "        -1.5800e-03, -1.0113e-03,  6.4865e-04,  2.2062e-04, -2.2047e-03,\n",
            "        -1.6090e-03,  2.6658e-03,  6.1688e-04,  6.4689e-04,  9.7595e-04,\n",
            "         9.4350e-04,  6.9253e-05, -2.0698e-03,  9.4742e-04, -2.3143e-03,\n",
            "         6.2070e-04, -1.5793e-03, -6.7087e-05, -1.1357e-03, -4.9779e-04,\n",
            "        -2.5385e-03,  2.7360e-03,  2.3791e-03, -1.9708e-03,  1.0906e-03,\n",
            "         1.3715e-03, -2.3547e-03,  4.6215e-04, -2.2761e-03, -2.3822e-03,\n",
            "        -2.3306e-03,  1.5498e-03,  4.6081e-04,  1.9972e-03, -1.4676e-03,\n",
            "        -4.0181e-04, -4.9730e-04, -1.9021e-04,  4.8721e-04,  1.0586e-03,\n",
            "        -6.9944e-04, -1.4037e-03,  1.2033e-03,  1.8104e-03, -1.2484e-03,\n",
            "        -2.1162e-03, -1.8560e-03,  2.2677e-04,  1.3658e-03, -7.8060e-04,\n",
            "        -2.2129e-03,  4.8610e-04,  2.4957e-03, -3.2211e-04,  1.3209e-03,\n",
            "         2.2782e-03, -3.7630e-04,  6.7897e-04, -2.0243e-03, -2.7119e-03,\n",
            "         7.2267e-05, -1.1964e-03,  4.6058e-04, -2.2406e-03,  1.5283e-03,\n",
            "         1.4283e-03,  5.4040e-04, -4.1939e-04,  1.7948e-03,  2.0843e-03,\n",
            "         2.4138e-03, -2.7335e-03, -2.3687e-04, -1.8270e-03,  2.5321e-05,\n",
            "        -1.6385e-03, -4.1526e-04, -2.1864e-03, -1.5711e-03, -6.5090e-04,\n",
            "         1.9258e-03, -6.1930e-04,  1.3966e-03, -2.1703e-03, -1.5526e-03,\n",
            "         2.3025e-03, -1.0247e-03,  2.2240e-04,  9.0348e-04,  2.3754e-03,\n",
            "        -5.6102e-04,  3.9313e-04,  2.2708e-03, -1.9777e-03, -1.5489e-03,\n",
            "        -1.0275e-04,  1.6533e-03,  2.4441e-03, -2.6863e-03,  1.3588e-03,\n",
            "         5.5830e-04,  1.6059e-03, -2.7226e-03,  2.5678e-03, -1.1263e-03,\n",
            "        -1.2009e-03, -2.2263e-04,  1.5944e-03,  6.4960e-04,  1.8687e-03,\n",
            "        -2.2959e-03,  8.8703e-04,  1.6097e-03,  2.0857e-03,  3.6004e-04,\n",
            "        -5.9956e-04, -1.3601e-03, -2.5856e-03,  2.4500e-03,  7.3057e-04,\n",
            "        -1.1476e-03, -2.2637e-03,  4.4135e-04, -5.3937e-04, -2.3880e-03,\n",
            "        -1.5165e-03, -9.9325e-04, -2.5305e-03,  2.0115e-03, -2.2617e-05,\n",
            "         1.4759e-03,  9.7474e-04, -1.8251e-03,  1.3893e-03,  2.8886e-04,\n",
            "        -1.8922e-03, -2.2863e-03,  2.7426e-04,  2.5241e-03, -1.1213e-03,\n",
            "        -2.0870e-03, -1.4473e-03, -1.0257e-04,  2.5948e-03,  1.5732e-03,\n",
            "        -1.7268e-04,  1.4219e-03, -2.3880e-03,  8.3847e-04,  9.3391e-04,\n",
            "        -1.5229e-03,  1.5482e-03, -8.9516e-04, -2.3863e-04,  1.4544e-03,\n",
            "         1.2158e-03,  2.6584e-03, -1.3712e-03, -1.1800e-04,  3.4211e-04,\n",
            "        -1.0444e-03,  8.3916e-04,  7.4900e-04, -1.4592e-03, -4.9113e-04,\n",
            "         5.6589e-04,  2.3520e-03,  2.5193e-04,  2.2397e-03, -1.7005e-04,\n",
            "         5.4457e-04,  6.8871e-04,  1.1060e-03, -2.6542e-03, -2.2471e-03,\n",
            "        -3.2228e-04,  6.0786e-04,  1.1220e-03,  1.5163e-03, -8.9003e-04,\n",
            "        -2.0156e-03, -2.4076e-04, -1.8176e-03, -2.0926e-03,  2.6878e-04,\n",
            "         1.6702e-03], device='cuda:0')\n",
            "NPF_D2.weight Parameter containing:\n",
            "tensor([[-0.0121,  0.0591,  0.0244,  ...,  0.0342,  0.0062,  0.0272],\n",
            "        [ 0.0148, -0.0111,  0.0334,  ..., -0.0532, -0.0606, -0.0129],\n",
            "        [ 0.0241,  0.0384,  0.0045,  ..., -0.0607, -0.0118,  0.0356],\n",
            "        ...,\n",
            "        [-0.0339, -0.0398,  0.0422,  ..., -0.0270, -0.0313, -0.0511],\n",
            "        [-0.0071, -0.0161, -0.0303,  ..., -0.0205, -0.0411, -0.0544],\n",
            "        [-0.0422,  0.0084,  0.0094,  ...,  0.0176,  0.0265,  0.0420]],\n",
            "       device='cuda:0')\n",
            "NPF_D2.bias Parameter containing:\n",
            "tensor([ 0.0443, -0.0057,  0.0033,  0.0286,  0.0196,  0.0321,  0.0266, -0.0501,\n",
            "         0.0430,  0.0285, -0.0561,  0.0497,  0.0112, -0.0235, -0.0455, -0.0476,\n",
            "         0.0580,  0.0041, -0.0330, -0.0186,  0.0076,  0.0349, -0.0155,  0.0340,\n",
            "         0.0459, -0.0561, -0.0358, -0.0236,  0.0267,  0.0450, -0.0398, -0.0614,\n",
            "         0.0301, -0.0389,  0.0204, -0.0458,  0.0272, -0.0333, -0.0159,  0.0405,\n",
            "        -0.0393, -0.0053,  0.0562,  0.0492, -0.0212,  0.0604, -0.0277,  0.0261,\n",
            "        -0.0538,  0.0095, -0.0192, -0.0304,  0.0095, -0.0079, -0.0423,  0.0131,\n",
            "        -0.0050,  0.0570, -0.0438,  0.0599, -0.0250, -0.0179,  0.0113,  0.0231,\n",
            "         0.0370,  0.0202,  0.0267,  0.0511,  0.0034,  0.0320, -0.0340,  0.0050,\n",
            "         0.0005, -0.0586,  0.0154, -0.0275,  0.0231,  0.0010, -0.0038,  0.0010,\n",
            "         0.0349, -0.0453, -0.0415, -0.0532, -0.0600, -0.0162,  0.0336,  0.0606,\n",
            "         0.0131, -0.0602, -0.0407, -0.0113,  0.0287,  0.0262,  0.0173, -0.0275,\n",
            "        -0.0624, -0.0497,  0.0357,  0.0189, -0.0541, -0.0413,  0.0169, -0.0023,\n",
            "         0.0011, -0.0057,  0.0013,  0.0241, -0.0444,  0.0299,  0.0204,  0.0585,\n",
            "        -0.0187,  0.0216,  0.0260, -0.0053, -0.0099, -0.0601,  0.0219, -0.0584,\n",
            "        -0.0526, -0.0407,  0.0613,  0.0422, -0.0393, -0.0031,  0.0520,  0.0530,\n",
            "         0.0211,  0.0060, -0.0389, -0.0046, -0.0396,  0.0321, -0.0002, -0.0442,\n",
            "        -0.0011,  0.0272, -0.0528,  0.0215,  0.0132, -0.0008, -0.0204, -0.0607,\n",
            "        -0.0469, -0.0159,  0.0606, -0.0366, -0.0158, -0.0438,  0.0605, -0.0318,\n",
            "         0.0358, -0.0533, -0.0051,  0.0206,  0.0594, -0.0112, -0.0526, -0.0307,\n",
            "        -0.0101,  0.0615, -0.0295, -0.0286, -0.0270,  0.0399, -0.0144, -0.0594,\n",
            "        -0.0280,  0.0220,  0.0408, -0.0377,  0.0588, -0.0525, -0.0098, -0.0293,\n",
            "         0.0530, -0.0481,  0.0530,  0.0099,  0.0553,  0.0277,  0.0425,  0.0379,\n",
            "         0.0344,  0.0449,  0.0226, -0.0090, -0.0324, -0.0462,  0.0105,  0.0535,\n",
            "        -0.0245, -0.0174,  0.0582, -0.0548, -0.0594,  0.0383,  0.0171, -0.0084,\n",
            "         0.0083, -0.0315, -0.0076,  0.0612,  0.0234,  0.0008, -0.0171,  0.0224,\n",
            "        -0.0074, -0.0326, -0.0423, -0.0407, -0.0092,  0.0500, -0.0434,  0.0095,\n",
            "         0.0211, -0.0323, -0.0504, -0.0623,  0.0060,  0.0252, -0.0341,  0.0300,\n",
            "         0.0354,  0.0008,  0.0221,  0.0280, -0.0195,  0.0424,  0.0334,  0.0103,\n",
            "         0.0459,  0.0013, -0.0192, -0.0066, -0.0512,  0.0492, -0.0246,  0.0128,\n",
            "        -0.0522,  0.0421, -0.0526,  0.0228,  0.0590, -0.0036, -0.0365,  0.0018,\n",
            "        -0.0164, -0.0448, -0.0358, -0.0419, -0.0125, -0.0037, -0.0153,  0.0261],\n",
            "       device='cuda:0')\n",
            "NPV_C1.weight Parameter containing:\n",
            "tensor([[[[ 0.1702, -0.0410, -0.1715],\n",
            "          [-0.1727, -0.1691,  0.1663],\n",
            "          [-0.0101, -0.1337,  0.0772]],\n",
            "\n",
            "         [[ 0.0743,  0.1482,  0.0419],\n",
            "          [ 0.1614,  0.1694,  0.1859],\n",
            "          [-0.1185, -0.0738,  0.0040]],\n",
            "\n",
            "         [[ 0.0363, -0.0772, -0.1612],\n",
            "          [ 0.0859,  0.0229,  0.0993],\n",
            "          [ 0.0268, -0.1790,  0.1827]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1779, -0.1019, -0.1768],\n",
            "          [-0.1688,  0.0673,  0.0757],\n",
            "          [ 0.1021,  0.0230,  0.0172]],\n",
            "\n",
            "         [[-0.1060,  0.0220,  0.0491],\n",
            "          [ 0.0193,  0.0763, -0.0260],\n",
            "          [-0.0401, -0.1085, -0.0292]],\n",
            "\n",
            "         [[-0.0725,  0.0668,  0.0805],\n",
            "          [ 0.0910, -0.0254,  0.0105],\n",
            "          [-0.1620, -0.1402,  0.1393]]],\n",
            "\n",
            "\n",
            "        [[[-0.1743, -0.1056,  0.0858],\n",
            "          [ 0.1476, -0.0166, -0.0909],\n",
            "          [ 0.1034, -0.1136, -0.0495]],\n",
            "\n",
            "         [[-0.1307,  0.1124, -0.0006],\n",
            "          [-0.0614,  0.1173, -0.1692],\n",
            "          [-0.0389,  0.1868,  0.0260]],\n",
            "\n",
            "         [[-0.0134, -0.0680,  0.0858],\n",
            "          [ 0.0989,  0.0621, -0.1651],\n",
            "          [-0.0100, -0.0766,  0.1436]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1146,  0.0594,  0.1794],\n",
            "          [-0.0902,  0.1062,  0.1016],\n",
            "          [ 0.0030, -0.0459, -0.0912]],\n",
            "\n",
            "         [[-0.0790,  0.1894, -0.0759],\n",
            "          [ 0.0057, -0.0130,  0.0134],\n",
            "          [ 0.0984, -0.1103,  0.0471]],\n",
            "\n",
            "         [[-0.1643,  0.0140,  0.0439],\n",
            "          [ 0.0277,  0.0672, -0.1452],\n",
            "          [-0.0354,  0.0165, -0.0689]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0635, -0.1574, -0.1164],\n",
            "          [ 0.0090,  0.1154,  0.1278],\n",
            "          [ 0.1436,  0.0321, -0.0963]],\n",
            "\n",
            "         [[-0.0914,  0.0944,  0.1823],\n",
            "          [-0.1550, -0.0940, -0.1480],\n",
            "          [-0.1010, -0.1865, -0.0256]],\n",
            "\n",
            "         [[ 0.0908,  0.0892,  0.0189],\n",
            "          [ 0.1255,  0.1116,  0.0328],\n",
            "          [-0.1714,  0.0962,  0.0869]]],\n",
            "\n",
            "\n",
            "        [[[-0.1654, -0.1914, -0.1517],\n",
            "          [ 0.1294,  0.0595,  0.0156],\n",
            "          [ 0.1310,  0.0984, -0.0277]],\n",
            "\n",
            "         [[ 0.0623,  0.0603,  0.0457],\n",
            "          [-0.0720, -0.1320, -0.0053],\n",
            "          [-0.0809,  0.0605, -0.0083]],\n",
            "\n",
            "         [[-0.1451, -0.0556, -0.1564],\n",
            "          [-0.1920, -0.0923, -0.1241],\n",
            "          [-0.1158,  0.0806, -0.1910]]]], device='cuda:0', requires_grad=True)\n",
            "NPV_C1.bias Parameter containing:\n",
            "tensor([ 0.1360,  0.0330, -0.1504,  0.1085, -0.0124, -0.0843,  0.1011,  0.0657,\n",
            "        -0.1680, -0.0143, -0.0744, -0.1760,  0.0395,  0.1175,  0.1187,  0.0322,\n",
            "        -0.0170, -0.0094, -0.0723, -0.1105, -0.1598, -0.1207, -0.1817,  0.0272,\n",
            "        -0.1605,  0.0230, -0.0691,  0.0023,  0.0248,  0.1161, -0.0184, -0.1789,\n",
            "        -0.0585, -0.1670, -0.1498,  0.0496, -0.1021,  0.1302,  0.1419,  0.0301,\n",
            "        -0.0621,  0.0660, -0.1356,  0.1769,  0.1480, -0.0332, -0.1666, -0.1354,\n",
            "         0.0033, -0.1591,  0.1543,  0.0701,  0.0120,  0.1138, -0.1279, -0.0945,\n",
            "         0.1131, -0.0975,  0.0081, -0.0486,  0.1721,  0.1269, -0.0028, -0.0407],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_C2.weight Parameter containing:\n",
            "tensor([[[[ 0.0117,  0.0134,  0.0057],\n",
            "          [ 0.0141,  0.0043, -0.0169],\n",
            "          [-0.0188,  0.0092,  0.0140]],\n",
            "\n",
            "         [[ 0.0207,  0.0378,  0.0386],\n",
            "          [-0.0025,  0.0047,  0.0346],\n",
            "          [ 0.0243, -0.0013, -0.0157]],\n",
            "\n",
            "         [[-0.0038,  0.0179,  0.0011],\n",
            "          [ 0.0312,  0.0250, -0.0085],\n",
            "          [-0.0351, -0.0400,  0.0129]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0136, -0.0027, -0.0094],\n",
            "          [ 0.0375,  0.0247, -0.0122],\n",
            "          [ 0.0003, -0.0191,  0.0029]],\n",
            "\n",
            "         [[-0.0351, -0.0091,  0.0261],\n",
            "          [ 0.0052, -0.0126, -0.0320],\n",
            "          [ 0.0291,  0.0014,  0.0303]],\n",
            "\n",
            "         [[-0.0324, -0.0034,  0.0024],\n",
            "          [-0.0180, -0.0181, -0.0379],\n",
            "          [-0.0142,  0.0389, -0.0066]]],\n",
            "\n",
            "\n",
            "        [[[-0.0405,  0.0334, -0.0408],\n",
            "          [-0.0114,  0.0316,  0.0337],\n",
            "          [ 0.0297,  0.0079, -0.0073]],\n",
            "\n",
            "         [[-0.0187, -0.0220, -0.0277],\n",
            "          [-0.0102,  0.0286, -0.0374],\n",
            "          [ 0.0210,  0.0406, -0.0387]],\n",
            "\n",
            "         [[ 0.0171,  0.0314,  0.0051],\n",
            "          [ 0.0192, -0.0019,  0.0069],\n",
            "          [ 0.0050, -0.0015,  0.0071]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0264,  0.0286,  0.0343],\n",
            "          [-0.0298,  0.0395,  0.0322],\n",
            "          [-0.0302,  0.0036, -0.0017]],\n",
            "\n",
            "         [[-0.0205, -0.0156,  0.0061],\n",
            "          [-0.0365,  0.0248, -0.0135],\n",
            "          [ 0.0056, -0.0410, -0.0401]],\n",
            "\n",
            "         [[-0.0197, -0.0257,  0.0374],\n",
            "          [ 0.0063,  0.0069,  0.0125],\n",
            "          [ 0.0214, -0.0313,  0.0212]]],\n",
            "\n",
            "\n",
            "        [[[-0.0132,  0.0052,  0.0207],\n",
            "          [-0.0053, -0.0263, -0.0035],\n",
            "          [ 0.0232,  0.0057,  0.0260]],\n",
            "\n",
            "         [[-0.0296,  0.0235, -0.0076],\n",
            "          [-0.0269, -0.0013, -0.0062],\n",
            "          [ 0.0148,  0.0179, -0.0357]],\n",
            "\n",
            "         [[ 0.0382,  0.0273,  0.0217],\n",
            "          [-0.0281,  0.0038, -0.0042],\n",
            "          [ 0.0366, -0.0363,  0.0277]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0030,  0.0043,  0.0102],\n",
            "          [ 0.0061, -0.0143, -0.0350],\n",
            "          [ 0.0089,  0.0032, -0.0233]],\n",
            "\n",
            "         [[-0.0279,  0.0256,  0.0127],\n",
            "          [ 0.0208, -0.0117, -0.0150],\n",
            "          [-0.0078,  0.0200,  0.0107]],\n",
            "\n",
            "         [[-0.0289,  0.0065, -0.0127],\n",
            "          [-0.0124, -0.0017, -0.0359],\n",
            "          [ 0.0106, -0.0404, -0.0334]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0327,  0.0195, -0.0202],\n",
            "          [ 0.0233, -0.0046,  0.0008],\n",
            "          [-0.0348,  0.0396,  0.0073]],\n",
            "\n",
            "         [[ 0.0008, -0.0410,  0.0255],\n",
            "          [-0.0052,  0.0091,  0.0209],\n",
            "          [ 0.0283, -0.0069,  0.0075]],\n",
            "\n",
            "         [[ 0.0106, -0.0116,  0.0188],\n",
            "          [ 0.0106, -0.0157,  0.0402],\n",
            "          [-0.0322, -0.0369, -0.0151]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0221, -0.0208,  0.0368],\n",
            "          [-0.0264, -0.0405, -0.0024],\n",
            "          [-0.0255,  0.0377,  0.0127]],\n",
            "\n",
            "         [[ 0.0225,  0.0050, -0.0209],\n",
            "          [ 0.0050,  0.0040, -0.0184],\n",
            "          [ 0.0100,  0.0258, -0.0385]],\n",
            "\n",
            "         [[ 0.0224, -0.0036,  0.0148],\n",
            "          [-0.0370, -0.0141, -0.0067],\n",
            "          [-0.0366, -0.0334,  0.0262]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0251, -0.0156,  0.0107],\n",
            "          [ 0.0033, -0.0368,  0.0235],\n",
            "          [ 0.0036,  0.0197, -0.0204]],\n",
            "\n",
            "         [[ 0.0275, -0.0240,  0.0242],\n",
            "          [ 0.0345, -0.0197,  0.0007],\n",
            "          [ 0.0316, -0.0102, -0.0296]],\n",
            "\n",
            "         [[ 0.0221,  0.0325,  0.0185],\n",
            "          [-0.0341,  0.0398, -0.0091],\n",
            "          [-0.0140, -0.0313,  0.0102]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0152, -0.0278,  0.0116],\n",
            "          [-0.0106,  0.0302, -0.0140],\n",
            "          [-0.0192, -0.0216,  0.0012]],\n",
            "\n",
            "         [[ 0.0296,  0.0322, -0.0048],\n",
            "          [ 0.0010,  0.0015, -0.0345],\n",
            "          [ 0.0091,  0.0310, -0.0305]],\n",
            "\n",
            "         [[ 0.0093, -0.0009, -0.0151],\n",
            "          [-0.0038, -0.0119, -0.0011],\n",
            "          [ 0.0371,  0.0036, -0.0325]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0295, -0.0322,  0.0342],\n",
            "          [-0.0359, -0.0373, -0.0228],\n",
            "          [-0.0271,  0.0056, -0.0221]],\n",
            "\n",
            "         [[ 0.0273, -0.0159, -0.0098],\n",
            "          [-0.0362,  0.0041, -0.0033],\n",
            "          [ 0.0252,  0.0075,  0.0073]],\n",
            "\n",
            "         [[-0.0098, -0.0373, -0.0401],\n",
            "          [-0.0347, -0.0057, -0.0407],\n",
            "          [-0.0193,  0.0184, -0.0082]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0136,  0.0059, -0.0351],\n",
            "          [ 0.0357,  0.0166, -0.0370],\n",
            "          [ 0.0401,  0.0193,  0.0256]],\n",
            "\n",
            "         [[-0.0273, -0.0409,  0.0268],\n",
            "          [-0.0328,  0.0115,  0.0038],\n",
            "          [-0.0033, -0.0075, -0.0339]],\n",
            "\n",
            "         [[-0.0324,  0.0122, -0.0293],\n",
            "          [-0.0336, -0.0026, -0.0124],\n",
            "          [ 0.0412, -0.0374,  0.0122]]]], device='cuda:0', requires_grad=True)\n",
            "NPV_C2.bias Parameter containing:\n",
            "tensor([-0.0375, -0.0013,  0.0022, -0.0365, -0.0123,  0.0181, -0.0207, -0.0065,\n",
            "        -0.0264,  0.0202, -0.0197,  0.0378, -0.0018,  0.0063, -0.0281, -0.0283,\n",
            "         0.0307, -0.0126, -0.0030, -0.0032,  0.0123, -0.0373,  0.0336,  0.0352,\n",
            "         0.0345, -0.0321, -0.0002, -0.0399, -0.0095,  0.0396, -0.0214,  0.0284,\n",
            "        -0.0386, -0.0108, -0.0180, -0.0231,  0.0095,  0.0348,  0.0079, -0.0123,\n",
            "         0.0008, -0.0140,  0.0222, -0.0179,  0.0162,  0.0234, -0.0015, -0.0249,\n",
            "        -0.0111,  0.0403,  0.0270,  0.0212,  0.0014, -0.0164,  0.0199, -0.0077,\n",
            "        -0.0222,  0.0197,  0.0294, -0.0407, -0.0286, -0.0157, -0.0314, -0.0024],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_C3.weight Parameter containing:\n",
            "tensor([[[[ 0.0217,  0.0159, -0.0032],\n",
            "          [ 0.0155, -0.0109, -0.0363],\n",
            "          [ 0.0100,  0.0288, -0.0223]],\n",
            "\n",
            "         [[-0.0266, -0.0324, -0.0359],\n",
            "          [ 0.0382, -0.0044,  0.0317],\n",
            "          [ 0.0154,  0.0313,  0.0413]],\n",
            "\n",
            "         [[ 0.0295,  0.0122,  0.0401],\n",
            "          [-0.0161, -0.0172,  0.0025],\n",
            "          [ 0.0147, -0.0363, -0.0226]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0291,  0.0142,  0.0043],\n",
            "          [ 0.0081, -0.0154, -0.0182],\n",
            "          [-0.0193, -0.0097, -0.0249]],\n",
            "\n",
            "         [[-0.0027, -0.0054, -0.0012],\n",
            "          [-0.0141,  0.0177,  0.0075],\n",
            "          [ 0.0415, -0.0002, -0.0012]],\n",
            "\n",
            "         [[-0.0128, -0.0170, -0.0107],\n",
            "          [-0.0021,  0.0345,  0.0069],\n",
            "          [-0.0341, -0.0314, -0.0028]]],\n",
            "\n",
            "\n",
            "        [[[-0.0076,  0.0052, -0.0285],\n",
            "          [ 0.0228, -0.0024, -0.0161],\n",
            "          [-0.0218,  0.0328, -0.0113]],\n",
            "\n",
            "         [[ 0.0180, -0.0015,  0.0081],\n",
            "          [-0.0312, -0.0027,  0.0136],\n",
            "          [ 0.0200,  0.0393,  0.0309]],\n",
            "\n",
            "         [[ 0.0410, -0.0200,  0.0090],\n",
            "          [ 0.0290,  0.0057,  0.0161],\n",
            "          [ 0.0051, -0.0343,  0.0307]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0299, -0.0156, -0.0243],\n",
            "          [-0.0215, -0.0067, -0.0233],\n",
            "          [ 0.0007,  0.0120,  0.0273]],\n",
            "\n",
            "         [[-0.0087, -0.0387,  0.0304],\n",
            "          [-0.0387,  0.0127,  0.0089],\n",
            "          [-0.0280, -0.0172, -0.0410]],\n",
            "\n",
            "         [[ 0.0094, -0.0312, -0.0141],\n",
            "          [-0.0042,  0.0050,  0.0087],\n",
            "          [-0.0191, -0.0035,  0.0234]]],\n",
            "\n",
            "\n",
            "        [[[-0.0267, -0.0385,  0.0090],\n",
            "          [ 0.0017, -0.0002, -0.0062],\n",
            "          [ 0.0167, -0.0032, -0.0264]],\n",
            "\n",
            "         [[ 0.0373,  0.0369, -0.0068],\n",
            "          [ 0.0210, -0.0224,  0.0036],\n",
            "          [ 0.0040,  0.0299,  0.0167]],\n",
            "\n",
            "         [[-0.0102, -0.0214, -0.0375],\n",
            "          [-0.0070, -0.0188,  0.0133],\n",
            "          [ 0.0378,  0.0025, -0.0404]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0362,  0.0076, -0.0198],\n",
            "          [ 0.0139, -0.0317, -0.0059],\n",
            "          [-0.0229, -0.0307, -0.0368]],\n",
            "\n",
            "         [[ 0.0246, -0.0413, -0.0115],\n",
            "          [ 0.0173, -0.0243,  0.0171],\n",
            "          [ 0.0092, -0.0388,  0.0007]],\n",
            "\n",
            "         [[-0.0409,  0.0412,  0.0188],\n",
            "          [ 0.0337,  0.0192,  0.0112],\n",
            "          [ 0.0333, -0.0049, -0.0256]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0117,  0.0416, -0.0205],\n",
            "          [ 0.0384,  0.0136, -0.0109],\n",
            "          [-0.0172,  0.0108, -0.0408]],\n",
            "\n",
            "         [[-0.0056, -0.0263, -0.0103],\n",
            "          [ 0.0246,  0.0354, -0.0183],\n",
            "          [-0.0325, -0.0009,  0.0335]],\n",
            "\n",
            "         [[ 0.0257,  0.0105,  0.0135],\n",
            "          [ 0.0170,  0.0015,  0.0063],\n",
            "          [ 0.0024, -0.0213,  0.0250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0060, -0.0101,  0.0241],\n",
            "          [-0.0368, -0.0300,  0.0281],\n",
            "          [-0.0269, -0.0349,  0.0398]],\n",
            "\n",
            "         [[-0.0296,  0.0317,  0.0413],\n",
            "          [ 0.0357,  0.0398, -0.0339],\n",
            "          [ 0.0092, -0.0390, -0.0209]],\n",
            "\n",
            "         [[-0.0251, -0.0118, -0.0356],\n",
            "          [-0.0005, -0.0193, -0.0180],\n",
            "          [-0.0108, -0.0188, -0.0146]]],\n",
            "\n",
            "\n",
            "        [[[-0.0226, -0.0279,  0.0365],\n",
            "          [ 0.0007, -0.0239, -0.0410],\n",
            "          [-0.0050, -0.0209, -0.0139]],\n",
            "\n",
            "         [[ 0.0322,  0.0097, -0.0164],\n",
            "          [ 0.0102,  0.0403, -0.0031],\n",
            "          [-0.0312, -0.0138,  0.0081]],\n",
            "\n",
            "         [[ 0.0337,  0.0101, -0.0385],\n",
            "          [-0.0055, -0.0081, -0.0057],\n",
            "          [ 0.0145,  0.0361, -0.0136]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0124,  0.0247, -0.0099],\n",
            "          [ 0.0249, -0.0336, -0.0019],\n",
            "          [ 0.0322,  0.0275,  0.0336]],\n",
            "\n",
            "         [[-0.0078, -0.0330, -0.0142],\n",
            "          [ 0.0335, -0.0248, -0.0206],\n",
            "          [-0.0309,  0.0191, -0.0266]],\n",
            "\n",
            "         [[ 0.0402, -0.0093,  0.0157],\n",
            "          [-0.0164,  0.0053,  0.0331],\n",
            "          [-0.0341, -0.0125, -0.0200]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0050,  0.0385, -0.0309],\n",
            "          [-0.0285, -0.0210, -0.0122],\n",
            "          [-0.0379, -0.0037,  0.0150]],\n",
            "\n",
            "         [[ 0.0102, -0.0091,  0.0294],\n",
            "          [ 0.0283,  0.0001,  0.0034],\n",
            "          [-0.0177, -0.0332, -0.0117]],\n",
            "\n",
            "         [[-0.0408, -0.0170, -0.0365],\n",
            "          [-0.0088, -0.0094, -0.0055],\n",
            "          [ 0.0376,  0.0012, -0.0224]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0268, -0.0318,  0.0173],\n",
            "          [-0.0218,  0.0203, -0.0278],\n",
            "          [ 0.0141, -0.0190,  0.0192]],\n",
            "\n",
            "         [[-0.0236,  0.0116,  0.0194],\n",
            "          [ 0.0021,  0.0244,  0.0283],\n",
            "          [-0.0401, -0.0231, -0.0233]],\n",
            "\n",
            "         [[-0.0150, -0.0166,  0.0403],\n",
            "          [ 0.0408,  0.0149, -0.0296],\n",
            "          [-0.0243, -0.0286, -0.0399]]]], device='cuda:0', requires_grad=True)\n",
            "NPV_C3.bias Parameter containing:\n",
            "tensor([ 0.0205, -0.0027,  0.0187, -0.0045,  0.0185, -0.0097, -0.0113, -0.0203,\n",
            "         0.0067,  0.0380, -0.0108, -0.0188, -0.0001,  0.0230, -0.0367, -0.0163,\n",
            "         0.0272, -0.0229, -0.0064, -0.0043, -0.0022,  0.0158, -0.0151,  0.0258,\n",
            "        -0.0205,  0.0321, -0.0410, -0.0030,  0.0368,  0.0110,  0.0130,  0.0193,\n",
            "         0.0196, -0.0412,  0.0306,  0.0374,  0.0065,  0.0286,  0.0197, -0.0130,\n",
            "        -0.0215,  0.0275,  0.0290, -0.0212, -0.0156, -0.0073,  0.0409, -0.0360,\n",
            "         0.0362,  0.0067,  0.0157,  0.0339, -0.0376,  0.0260, -0.0381, -0.0325,\n",
            "        -0.0245, -0.0139, -0.0410, -0.0091, -0.0009,  0.0037, -0.0217, -0.0272,\n",
            "         0.0189,  0.0089, -0.0144, -0.0047, -0.0132, -0.0014,  0.0248, -0.0269,\n",
            "         0.0305,  0.0317,  0.0096,  0.0324,  0.0260,  0.0107, -0.0314, -0.0317,\n",
            "         0.0391, -0.0169,  0.0193,  0.0308,  0.0345, -0.0196, -0.0262,  0.0157,\n",
            "        -0.0380, -0.0198, -0.0238, -0.0353,  0.0414,  0.0203, -0.0101, -0.0259,\n",
            "        -0.0095, -0.0179,  0.0205,  0.0009, -0.0212, -0.0394,  0.0290,  0.0146,\n",
            "        -0.0127,  0.0112, -0.0014,  0.0211, -0.0319, -0.0039,  0.0365,  0.0352,\n",
            "        -0.0147,  0.0020,  0.0415, -0.0015, -0.0121, -0.0287, -0.0020,  0.0074,\n",
            "        -0.0377,  0.0141,  0.0113, -0.0357, -0.0085, -0.0243, -0.0375,  0.0189],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_C4.weight Parameter containing:\n",
            "tensor([[[[-7.2642e-03,  1.8725e-02, -1.3772e-02],\n",
            "          [-1.7507e-02, -1.3259e-02, -1.9156e-04],\n",
            "          [-8.3539e-03, -7.4551e-03, -3.6623e-03]],\n",
            "\n",
            "         [[-2.0398e-02, -1.1719e-02, -1.2072e-02],\n",
            "          [-1.5466e-02,  2.7268e-03, -1.6365e-02],\n",
            "          [ 2.9198e-02,  2.2899e-02, -1.0189e-02]],\n",
            "\n",
            "         [[ 2.8148e-02,  2.6232e-03,  2.8795e-02],\n",
            "          [ 1.9025e-03,  2.8527e-02,  2.4464e-02],\n",
            "          [ 3.0389e-03,  6.4775e-03,  1.1604e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0148e-04, -4.2034e-03, -1.6703e-02],\n",
            "          [ 1.0552e-02,  1.3343e-02, -4.4137e-03],\n",
            "          [-6.0703e-03, -1.0922e-02, -1.6723e-02]],\n",
            "\n",
            "         [[ 1.7797e-02,  1.1638e-02,  8.1478e-03],\n",
            "          [-2.0974e-03,  1.5894e-02, -2.6263e-03],\n",
            "          [-1.9343e-02,  2.2637e-02, -2.7770e-02]],\n",
            "\n",
            "         [[-1.0497e-02, -3.7546e-03, -7.1459e-03],\n",
            "          [-2.2670e-02, -6.2318e-03,  1.0515e-02],\n",
            "          [-1.5801e-02,  5.6887e-03, -2.0076e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0976e-02,  4.8132e-03,  1.3558e-02],\n",
            "          [ 9.8910e-03, -4.5010e-03, -2.4968e-02],\n",
            "          [-1.3108e-02,  8.0744e-03,  2.7444e-02]],\n",
            "\n",
            "         [[-1.9899e-02,  1.7395e-02,  5.5319e-03],\n",
            "          [ 2.4855e-02, -4.5730e-03,  2.9020e-02],\n",
            "          [-1.5705e-02,  2.5388e-02, -1.8179e-02]],\n",
            "\n",
            "         [[ 2.1590e-02, -2.8471e-02,  1.4288e-02],\n",
            "          [ 8.2745e-03, -2.7951e-02, -9.9734e-03],\n",
            "          [ 6.0420e-03,  2.8004e-02,  2.6936e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.5144e-03, -1.4959e-02,  2.4389e-02],\n",
            "          [ 2.7466e-02,  7.8878e-03,  1.9139e-02],\n",
            "          [-2.4720e-02, -1.5198e-02, -2.5540e-02]],\n",
            "\n",
            "         [[-1.5755e-02,  1.6693e-02, -1.3001e-02],\n",
            "          [ 1.2409e-03,  2.0463e-03,  5.6324e-03],\n",
            "          [ 8.8068e-03,  2.7159e-02, -5.1558e-03]],\n",
            "\n",
            "         [[ 1.0670e-02, -2.9010e-02,  2.3002e-02],\n",
            "          [ 1.5578e-02,  1.3569e-02, -8.0591e-03],\n",
            "          [-2.6739e-02, -2.6947e-02,  5.2179e-03]]],\n",
            "\n",
            "\n",
            "        [[[-2.8850e-02,  4.2878e-03,  1.2730e-02],\n",
            "          [-2.4219e-02,  1.6877e-02,  4.9958e-04],\n",
            "          [-2.9059e-02, -4.1744e-04, -6.8208e-03]],\n",
            "\n",
            "         [[-7.5455e-03,  8.4972e-03, -2.5459e-02],\n",
            "          [-2.8511e-02,  1.7128e-02,  1.8268e-02],\n",
            "          [-2.7390e-02, -1.9871e-02, -1.3138e-02]],\n",
            "\n",
            "         [[ 2.7750e-02, -2.0844e-02,  1.4472e-02],\n",
            "          [ 1.1179e-02, -2.3946e-02, -1.9616e-02],\n",
            "          [-2.5335e-02,  4.3083e-03,  2.3350e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.6229e-03,  1.0913e-02, -2.7349e-02],\n",
            "          [-2.2690e-03, -1.9740e-02, -2.0710e-02],\n",
            "          [-6.5406e-03, -1.5914e-02,  1.5547e-02]],\n",
            "\n",
            "         [[ 2.8126e-02, -3.5165e-03,  3.7297e-03],\n",
            "          [-1.6315e-02,  2.6352e-02, -1.9326e-02],\n",
            "          [ 2.6053e-02,  7.6796e-03,  1.3159e-03]],\n",
            "\n",
            "         [[-1.8453e-03,  7.7653e-03, -4.2909e-03],\n",
            "          [ 7.2997e-04, -5.7854e-03,  2.7358e-02],\n",
            "          [-3.2779e-03,  9.2777e-03, -1.5327e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.2030e-02, -5.8443e-03, -2.4302e-02],\n",
            "          [ 9.5494e-03, -1.6379e-02,  1.2827e-02],\n",
            "          [-1.8017e-02, -2.4094e-03,  1.3896e-02]],\n",
            "\n",
            "         [[ 6.7912e-03, -2.3121e-02,  9.8585e-03],\n",
            "          [-2.7826e-02,  2.1179e-02, -1.6276e-02],\n",
            "          [ 1.8634e-02, -2.9044e-02, -1.6896e-02]],\n",
            "\n",
            "         [[ 2.9040e-02,  1.7220e-02,  2.8143e-02],\n",
            "          [ 2.8895e-02,  1.0942e-02,  8.8019e-03],\n",
            "          [-8.0183e-03,  5.6600e-03, -2.6545e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5805e-02, -1.5331e-03, -1.5985e-02],\n",
            "          [ 2.2513e-02, -2.1843e-02, -2.1102e-02],\n",
            "          [-2.7542e-02,  2.5122e-02, -1.7474e-02]],\n",
            "\n",
            "         [[ 2.6096e-02, -1.8383e-02, -2.8806e-02],\n",
            "          [ 2.2937e-02, -1.5319e-03, -2.1857e-02],\n",
            "          [-1.1891e-02,  5.4766e-03, -1.4315e-02]],\n",
            "\n",
            "         [[-7.7001e-03, -2.4259e-02,  2.6040e-02],\n",
            "          [-2.0379e-02, -1.0252e-02, -1.6167e-02],\n",
            "          [-2.3275e-02, -7.7806e-03,  2.7962e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.6920e-03, -1.7858e-02,  1.2792e-02],\n",
            "          [-1.1420e-03,  2.8010e-02, -2.2215e-02],\n",
            "          [ 1.8668e-02,  1.5217e-02,  1.3881e-02]],\n",
            "\n",
            "         [[ 1.1137e-02, -1.5518e-02, -2.5761e-02],\n",
            "          [ 2.1063e-02,  5.5779e-03,  2.0150e-02],\n",
            "          [-3.5567e-03,  1.9626e-02, -2.6667e-02]],\n",
            "\n",
            "         [[ 1.5827e-03, -8.7478e-03,  9.4545e-03],\n",
            "          [ 1.5364e-02, -2.9423e-02,  2.6942e-02],\n",
            "          [ 6.3926e-03,  7.9577e-05,  8.7556e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.8616e-02, -7.8212e-03,  2.4313e-02],\n",
            "          [-5.4454e-03, -2.7568e-02, -9.5371e-03],\n",
            "          [ 5.3715e-03,  9.5695e-03,  2.3832e-03]],\n",
            "\n",
            "         [[-1.8455e-03,  5.5293e-03, -1.5890e-03],\n",
            "          [ 2.5887e-02, -8.4311e-03,  1.5555e-02],\n",
            "          [ 7.5019e-03,  5.3858e-03, -1.1731e-02]],\n",
            "\n",
            "         [[ 2.2408e-02,  1.5884e-02,  2.5341e-02],\n",
            "          [ 8.8692e-03,  1.5566e-02,  2.4938e-02],\n",
            "          [-2.4224e-02,  2.4266e-02,  8.8448e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5966e-02,  2.0407e-02, -8.3030e-03],\n",
            "          [-1.6691e-02, -1.9202e-02, -2.2475e-02],\n",
            "          [-1.1895e-02,  3.7270e-03,  2.1211e-02]],\n",
            "\n",
            "         [[-2.5930e-02,  2.0602e-02,  1.6368e-02],\n",
            "          [-1.8734e-03, -1.5195e-02, -1.8600e-02],\n",
            "          [-2.5721e-02,  2.0727e-02, -4.0807e-03]],\n",
            "\n",
            "         [[ 2.2957e-02, -2.1284e-02,  3.2340e-03],\n",
            "          [ 1.6553e-02,  1.4601e-02, -2.4700e-02],\n",
            "          [-2.4479e-02,  3.1844e-03,  2.0391e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.9130e-03, -1.5603e-02,  9.9356e-03],\n",
            "          [ 1.2557e-02, -1.7769e-02, -2.7835e-02],\n",
            "          [-1.0211e-02,  2.2124e-02,  1.1239e-02]],\n",
            "\n",
            "         [[-1.9666e-02,  1.7632e-02, -7.8668e-03],\n",
            "          [-1.8069e-02, -1.7070e-02, -4.3847e-03],\n",
            "          [-1.8631e-02,  6.0918e-03,  5.7733e-03]],\n",
            "\n",
            "         [[-8.1956e-03,  9.5931e-03,  2.1968e-03],\n",
            "          [ 2.6195e-02, -2.1429e-02,  2.4280e-02],\n",
            "          [-2.4516e-02, -1.7000e-03, -2.6902e-02]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_C4.bias Parameter containing:\n",
            "tensor([-0.0233,  0.0038, -0.0167,  0.0017, -0.0130,  0.0242,  0.0098,  0.0054,\n",
            "         0.0241, -0.0281, -0.0179, -0.0163, -0.0150, -0.0075, -0.0222, -0.0021,\n",
            "        -0.0161,  0.0201,  0.0027,  0.0252, -0.0159,  0.0037, -0.0170, -0.0193,\n",
            "        -0.0125, -0.0287, -0.0143, -0.0076,  0.0187, -0.0086,  0.0005,  0.0005,\n",
            "         0.0239, -0.0242,  0.0257, -0.0055, -0.0156, -0.0233,  0.0095, -0.0025,\n",
            "        -0.0162, -0.0188, -0.0158,  0.0048,  0.0275,  0.0168, -0.0228,  0.0035,\n",
            "         0.0063,  0.0282, -0.0084, -0.0248, -0.0184, -0.0015, -0.0241, -0.0025,\n",
            "        -0.0025,  0.0265,  0.0200,  0.0163,  0.0025,  0.0183,  0.0016, -0.0218,\n",
            "         0.0020,  0.0275, -0.0054, -0.0177, -0.0090,  0.0207,  0.0246, -0.0002,\n",
            "        -0.0206,  0.0064, -0.0201,  0.0004, -0.0128, -0.0157,  0.0224, -0.0237,\n",
            "        -0.0243, -0.0127,  0.0140,  0.0202,  0.0286, -0.0250,  0.0093,  0.0014,\n",
            "        -0.0122,  0.0290,  0.0277,  0.0201, -0.0205, -0.0246,  0.0009, -0.0021,\n",
            "        -0.0074,  0.0248,  0.0065, -0.0118,  0.0173, -0.0201, -0.0294,  0.0134,\n",
            "        -0.0023,  0.0183, -0.0009,  0.0064,  0.0230,  0.0193,  0.0164, -0.0250,\n",
            "         0.0084,  0.0089,  0.0133,  0.0165,  0.0191, -0.0246,  0.0159,  0.0196,\n",
            "        -0.0131, -0.0118,  0.0178,  0.0291,  0.0268, -0.0260,  0.0032, -0.0088],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_D1.weight Parameter containing:\n",
            "tensor([[-3.8792e-04,  2.4575e-03,  1.7560e-03,  ..., -2.5757e-04,\n",
            "          4.8451e-04,  2.4768e-03],\n",
            "        [ 1.6085e-03,  9.8880e-04,  1.0883e-03,  ..., -2.1319e-03,\n",
            "          3.9446e-04,  1.2126e-03],\n",
            "        [-1.6457e-04, -9.3323e-04, -2.8569e-04,  ...,  9.5492e-04,\n",
            "         -1.0700e-03, -9.0988e-04],\n",
            "        ...,\n",
            "        [-2.1483e-03,  1.5720e-03,  2.2458e-03,  ...,  1.1880e-03,\n",
            "          4.1344e-04,  1.0676e-03],\n",
            "        [-1.7881e-03, -8.2811e-04, -2.1738e-05,  ...,  1.1361e-03,\n",
            "          1.2870e-03, -1.7313e-03],\n",
            "        [-2.4349e-03,  2.1750e-03,  2.2784e-03,  ...,  9.0722e-04,\n",
            "         -1.6614e-03, -7.9001e-04]], device='cuda:0', requires_grad=True)\n",
            "NPV_D1.bias Parameter containing:\n",
            "tensor([-1.7293e-03,  1.1506e-03,  4.5368e-04,  2.2238e-03, -1.0917e-03,\n",
            "         1.4628e-03,  7.4851e-04,  4.7187e-04,  4.4980e-04,  4.4164e-04,\n",
            "         2.3777e-03,  1.3046e-03,  1.0829e-03, -9.2801e-04, -1.8209e-03,\n",
            "         1.7245e-03, -1.0184e-03, -1.2659e-04, -1.7220e-03, -7.5425e-04,\n",
            "        -2.0609e-03, -1.3359e-03, -4.9613e-04, -1.3858e-03, -1.0979e-03,\n",
            "         1.4651e-03,  2.3188e-03,  2.6795e-04,  7.8525e-04,  9.0881e-04,\n",
            "        -2.2881e-03,  1.7262e-03,  1.8762e-03, -2.5844e-03,  2.4112e-03,\n",
            "        -2.5076e-03,  4.6261e-04, -1.4186e-03,  1.5151e-03, -2.4477e-03,\n",
            "         2.1016e-03,  1.5367e-03, -3.9686e-04, -6.9806e-04, -3.9219e-04,\n",
            "        -2.5773e-03,  7.0031e-04, -8.0653e-04, -2.3993e-03, -1.6461e-03,\n",
            "        -7.8823e-04, -7.4132e-04,  7.4638e-05, -1.2766e-03,  1.3125e-03,\n",
            "         2.6874e-04,  8.2318e-04,  2.3516e-03, -4.7614e-04,  2.2069e-03,\n",
            "         7.7329e-04, -1.8285e-04, -2.0146e-03,  6.9669e-04,  1.8384e-03,\n",
            "         1.5384e-03, -2.4892e-03, -2.7350e-03, -2.5745e-03,  5.1249e-04,\n",
            "        -1.5800e-03, -1.0113e-03,  6.4865e-04,  2.2062e-04, -2.2047e-03,\n",
            "        -1.6090e-03,  2.6658e-03,  6.1688e-04,  6.4689e-04,  9.7595e-04,\n",
            "         9.4350e-04,  6.9253e-05, -2.0698e-03,  9.4742e-04, -2.3143e-03,\n",
            "         6.2070e-04, -1.5793e-03, -6.7087e-05, -1.1357e-03, -4.9779e-04,\n",
            "        -2.5385e-03,  2.7360e-03,  2.3791e-03, -1.9708e-03,  1.0906e-03,\n",
            "         1.3715e-03, -2.3547e-03,  4.6215e-04, -2.2761e-03, -2.3822e-03,\n",
            "        -2.3306e-03,  1.5498e-03,  4.6081e-04,  1.9972e-03, -1.4676e-03,\n",
            "        -4.0181e-04, -4.9730e-04, -1.9021e-04,  4.8721e-04,  1.0586e-03,\n",
            "        -6.9944e-04, -1.4037e-03,  1.2033e-03,  1.8104e-03, -1.2484e-03,\n",
            "        -2.1162e-03, -1.8560e-03,  2.2677e-04,  1.3658e-03, -7.8060e-04,\n",
            "        -2.2129e-03,  4.8610e-04,  2.4957e-03, -3.2211e-04,  1.3209e-03,\n",
            "         2.2782e-03, -3.7630e-04,  6.7897e-04, -2.0243e-03, -2.7119e-03,\n",
            "         7.2267e-05, -1.1964e-03,  4.6058e-04, -2.2406e-03,  1.5283e-03,\n",
            "         1.4283e-03,  5.4040e-04, -4.1939e-04,  1.7948e-03,  2.0843e-03,\n",
            "         2.4138e-03, -2.7335e-03, -2.3687e-04, -1.8270e-03,  2.5321e-05,\n",
            "        -1.6385e-03, -4.1526e-04, -2.1864e-03, -1.5711e-03, -6.5090e-04,\n",
            "         1.9258e-03, -6.1930e-04,  1.3966e-03, -2.1703e-03, -1.5526e-03,\n",
            "         2.3025e-03, -1.0247e-03,  2.2240e-04,  9.0348e-04,  2.3754e-03,\n",
            "        -5.6102e-04,  3.9313e-04,  2.2708e-03, -1.9777e-03, -1.5489e-03,\n",
            "        -1.0275e-04,  1.6533e-03,  2.4441e-03, -2.6863e-03,  1.3588e-03,\n",
            "         5.5830e-04,  1.6059e-03, -2.7226e-03,  2.5678e-03, -1.1263e-03,\n",
            "        -1.2009e-03, -2.2263e-04,  1.5944e-03,  6.4960e-04,  1.8687e-03,\n",
            "        -2.2959e-03,  8.8703e-04,  1.6097e-03,  2.0857e-03,  3.6004e-04,\n",
            "        -5.9956e-04, -1.3601e-03, -2.5856e-03,  2.4500e-03,  7.3057e-04,\n",
            "        -1.1476e-03, -2.2637e-03,  4.4135e-04, -5.3937e-04, -2.3880e-03,\n",
            "        -1.5165e-03, -9.9325e-04, -2.5305e-03,  2.0115e-03, -2.2617e-05,\n",
            "         1.4759e-03,  9.7474e-04, -1.8251e-03,  1.3893e-03,  2.8886e-04,\n",
            "        -1.8922e-03, -2.2863e-03,  2.7426e-04,  2.5241e-03, -1.1213e-03,\n",
            "        -2.0870e-03, -1.4473e-03, -1.0257e-04,  2.5948e-03,  1.5732e-03,\n",
            "        -1.7268e-04,  1.4219e-03, -2.3880e-03,  8.3847e-04,  9.3391e-04,\n",
            "        -1.5229e-03,  1.5482e-03, -8.9516e-04, -2.3863e-04,  1.4544e-03,\n",
            "         1.2158e-03,  2.6584e-03, -1.3712e-03, -1.1800e-04,  3.4211e-04,\n",
            "        -1.0444e-03,  8.3916e-04,  7.4900e-04, -1.4592e-03, -4.9113e-04,\n",
            "         5.6589e-04,  2.3520e-03,  2.5193e-04,  2.2397e-03, -1.7005e-04,\n",
            "         5.4457e-04,  6.8871e-04,  1.1060e-03, -2.6542e-03, -2.2471e-03,\n",
            "        -3.2228e-04,  6.0786e-04,  1.1220e-03,  1.5163e-03, -8.9003e-04,\n",
            "        -2.0156e-03, -2.4076e-04, -1.8176e-03, -2.0926e-03,  2.6878e-04,\n",
            "         1.6702e-03], device='cuda:0', requires_grad=True)\n",
            "NPV_D2.weight Parameter containing:\n",
            "tensor([[-0.0121,  0.0591,  0.0244,  ...,  0.0342,  0.0062,  0.0272],\n",
            "        [ 0.0148, -0.0111,  0.0334,  ..., -0.0532, -0.0606, -0.0129],\n",
            "        [ 0.0241,  0.0384,  0.0045,  ..., -0.0607, -0.0118,  0.0356],\n",
            "        ...,\n",
            "        [-0.0339, -0.0398,  0.0422,  ..., -0.0270, -0.0313, -0.0511],\n",
            "        [-0.0071, -0.0161, -0.0303,  ..., -0.0205, -0.0411, -0.0544],\n",
            "        [-0.0422,  0.0084,  0.0094,  ...,  0.0176,  0.0265,  0.0420]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_D2.bias Parameter containing:\n",
            "tensor([ 0.0443, -0.0057,  0.0033,  0.0286,  0.0196,  0.0321,  0.0266, -0.0501,\n",
            "         0.0430,  0.0285, -0.0561,  0.0497,  0.0112, -0.0235, -0.0455, -0.0476,\n",
            "         0.0580,  0.0041, -0.0330, -0.0186,  0.0076,  0.0349, -0.0155,  0.0340,\n",
            "         0.0459, -0.0561, -0.0358, -0.0236,  0.0267,  0.0450, -0.0398, -0.0614,\n",
            "         0.0301, -0.0389,  0.0204, -0.0458,  0.0272, -0.0333, -0.0159,  0.0405,\n",
            "        -0.0393, -0.0053,  0.0562,  0.0492, -0.0212,  0.0604, -0.0277,  0.0261,\n",
            "        -0.0538,  0.0095, -0.0192, -0.0304,  0.0095, -0.0079, -0.0423,  0.0131,\n",
            "        -0.0050,  0.0570, -0.0438,  0.0599, -0.0250, -0.0179,  0.0113,  0.0231,\n",
            "         0.0370,  0.0202,  0.0267,  0.0511,  0.0034,  0.0320, -0.0340,  0.0050,\n",
            "         0.0005, -0.0586,  0.0154, -0.0275,  0.0231,  0.0010, -0.0038,  0.0010,\n",
            "         0.0349, -0.0453, -0.0415, -0.0532, -0.0600, -0.0162,  0.0336,  0.0606,\n",
            "         0.0131, -0.0602, -0.0407, -0.0113,  0.0287,  0.0262,  0.0173, -0.0275,\n",
            "        -0.0624, -0.0497,  0.0357,  0.0189, -0.0541, -0.0413,  0.0169, -0.0023,\n",
            "         0.0011, -0.0057,  0.0013,  0.0241, -0.0444,  0.0299,  0.0204,  0.0585,\n",
            "        -0.0187,  0.0216,  0.0260, -0.0053, -0.0099, -0.0601,  0.0219, -0.0584,\n",
            "        -0.0526, -0.0407,  0.0613,  0.0422, -0.0393, -0.0031,  0.0520,  0.0530,\n",
            "         0.0211,  0.0060, -0.0389, -0.0046, -0.0396,  0.0321, -0.0002, -0.0442,\n",
            "        -0.0011,  0.0272, -0.0528,  0.0215,  0.0132, -0.0008, -0.0204, -0.0607,\n",
            "        -0.0469, -0.0159,  0.0606, -0.0366, -0.0158, -0.0438,  0.0605, -0.0318,\n",
            "         0.0358, -0.0533, -0.0051,  0.0206,  0.0594, -0.0112, -0.0526, -0.0307,\n",
            "        -0.0101,  0.0615, -0.0295, -0.0286, -0.0270,  0.0399, -0.0144, -0.0594,\n",
            "        -0.0280,  0.0220,  0.0408, -0.0377,  0.0588, -0.0525, -0.0098, -0.0293,\n",
            "         0.0530, -0.0481,  0.0530,  0.0099,  0.0553,  0.0277,  0.0425,  0.0379,\n",
            "         0.0344,  0.0449,  0.0226, -0.0090, -0.0324, -0.0462,  0.0105,  0.0535,\n",
            "        -0.0245, -0.0174,  0.0582, -0.0548, -0.0594,  0.0383,  0.0171, -0.0084,\n",
            "         0.0083, -0.0315, -0.0076,  0.0612,  0.0234,  0.0008, -0.0171,  0.0224,\n",
            "        -0.0074, -0.0326, -0.0423, -0.0407, -0.0092,  0.0500, -0.0434,  0.0095,\n",
            "         0.0211, -0.0323, -0.0504, -0.0623,  0.0060,  0.0252, -0.0341,  0.0300,\n",
            "         0.0354,  0.0008,  0.0221,  0.0280, -0.0195,  0.0424,  0.0334,  0.0103,\n",
            "         0.0459,  0.0013, -0.0192, -0.0066, -0.0512,  0.0492, -0.0246,  0.0128,\n",
            "        -0.0522,  0.0421, -0.0526,  0.0228,  0.0590, -0.0036, -0.0365,  0.0018,\n",
            "        -0.0164, -0.0448, -0.0358, -0.0419, -0.0125, -0.0037, -0.0153,  0.0261],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "outputs.weight Parameter containing:\n",
            "tensor([[-0.0502,  0.0302,  0.0245,  ..., -0.0561,  0.0062, -0.0519],\n",
            "        [-0.0195, -0.0079, -0.0198,  ...,  0.0069,  0.0236, -0.0429],\n",
            "        [-0.0450, -0.0012, -0.0537,  ..., -0.0257,  0.0116, -0.0463],\n",
            "        ...,\n",
            "        [-0.0162, -0.0051,  0.0075,  ...,  0.0489, -0.0517,  0.0293],\n",
            "        [-0.0462, -0.0100,  0.0199,  ..., -0.0319,  0.0435,  0.0380],\n",
            "        [-0.0228,  0.0501,  0.0101,  ..., -0.0125, -0.0305, -0.0491]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "outputs.bias Parameter containing:\n",
            "tensor([ 0.0554, -0.0249, -0.0399, -0.0488, -0.0268, -0.0566,  0.0002, -0.0334,\n",
            "        -0.0555,  0.0072], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in frnpf_di_model.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    print(name)"
      ],
      "metadata": {
        "id": "DpVBDSUgSeFh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dccdbcb-735b-4d9a-f619-3892c8a1b130"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NPV_C1.weight\n",
            "NPV_C1.bias\n",
            "NPV_C2.weight\n",
            "NPV_C2.bias\n",
            "NPV_C3.weight\n",
            "NPV_C3.bias\n",
            "NPV_C4.weight\n",
            "NPV_C4.bias\n",
            "NPV_D1.weight\n",
            "NPV_D1.bias\n",
            "NPV_D2.weight\n",
            "NPV_D2.bias\n",
            "outputs.weight\n",
            "outputs.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(frnpf_di_model.parameters(), lr=args['lr'])\n",
        "for epoch in range(1, args['epochs']+1):\n",
        "  train(frnpf_di_model, epoch, train_loader, lossFn, optimizer)\n",
        "  validate(frnpf_di_model, validation_loader, lossFn)"
      ],
      "metadata": {
        "id": "jyxWSo8cSiA7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e5dff58-75ff-48cd-ff92-aeee97d529d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:70: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [50000/50000 (100%)]\tLoss: 1.984891\n",
            "\n",
            "Validation set: Average loss: 1.6055, Accuracy: 4153/10000 (42%)\n",
            "\n",
            "Train Epoch: 2 [50000/50000 (100%)]\tLoss: 1.444672\n",
            "\n",
            "Validation set: Average loss: 1.4728, Accuracy: 4865/10000 (49%)\n",
            "\n",
            "Train Epoch: 3 [50000/50000 (100%)]\tLoss: 1.227002\n",
            "\n",
            "Validation set: Average loss: 1.2453, Accuracy: 5552/10000 (56%)\n",
            "\n",
            "Train Epoch: 4 [50000/50000 (100%)]\tLoss: 1.032156\n",
            "\n",
            "Validation set: Average loss: 1.2242, Accuracy: 5667/10000 (57%)\n",
            "\n",
            "Train Epoch: 5 [50000/50000 (100%)]\tLoss: 0.792091\n",
            "\n",
            "Validation set: Average loss: 1.3614, Accuracy: 5497/10000 (55%)\n",
            "\n",
            "Train Epoch: 6 [50000/50000 (100%)]\tLoss: 0.474851\n",
            "\n",
            "Validation set: Average loss: 1.6137, Accuracy: 5471/10000 (55%)\n",
            "\n",
            "Train Epoch: 7 [50000/50000 (100%)]\tLoss: 0.220017\n",
            "\n",
            "Validation set: Average loss: 2.0530, Accuracy: 5441/10000 (54%)\n",
            "\n",
            "Train Epoch: 8 [50000/50000 (100%)]\tLoss: 0.118273\n",
            "\n",
            "Validation set: Average loss: 2.5550, Accuracy: 5439/10000 (54%)\n",
            "\n",
            "Train Epoch: 9 [50000/50000 (100%)]\tLoss: 0.069813\n",
            "\n",
            "Validation set: Average loss: 2.7671, Accuracy: 5380/10000 (54%)\n",
            "\n",
            "Train Epoch: 10 [50000/50000 (100%)]\tLoss: 0.048464\n",
            "\n",
            "Validation set: Average loss: 3.2040, Accuracy: 5315/10000 (53%)\n",
            "\n",
            "Train Epoch: 11 [50000/50000 (100%)]\tLoss: 0.037717\n",
            "\n",
            "Validation set: Average loss: 3.3481, Accuracy: 5425/10000 (54%)\n",
            "\n",
            "Train Epoch: 12 [50000/50000 (100%)]\tLoss: 0.031128\n",
            "\n",
            "Validation set: Average loss: 3.4578, Accuracy: 5322/10000 (53%)\n",
            "\n",
            "Train Epoch: 13 [50000/50000 (100%)]\tLoss: 0.023113\n",
            "\n",
            "Validation set: Average loss: 3.7895, Accuracy: 5394/10000 (54%)\n",
            "\n",
            "Train Epoch: 14 [50000/50000 (100%)]\tLoss: 0.022092\n",
            "\n",
            "Validation set: Average loss: 3.6237, Accuracy: 5554/10000 (56%)\n",
            "\n",
            "Train Epoch: 15 [50000/50000 (100%)]\tLoss: 0.010313\n",
            "\n",
            "Validation set: Average loss: 3.8028, Accuracy: 5574/10000 (56%)\n",
            "\n",
            "Train Epoch: 16 [50000/50000 (100%)]\tLoss: 0.006237\n",
            "\n",
            "Validation set: Average loss: 3.9785, Accuracy: 5633/10000 (56%)\n",
            "\n",
            "Train Epoch: 17 [50000/50000 (100%)]\tLoss: 0.001067\n",
            "\n",
            "Validation set: Average loss: 4.0633, Accuracy: 5611/10000 (56%)\n",
            "\n",
            "Train Epoch: 18 [50000/50000 (100%)]\tLoss: 0.000272\n",
            "\n",
            "Validation set: Average loss: 4.1142, Accuracy: 5651/10000 (57%)\n",
            "\n",
            "Train Epoch: 19 [50000/50000 (100%)]\tLoss: 0.000079\n",
            "\n",
            "Validation set: Average loss: 4.1633, Accuracy: 5659/10000 (57%)\n",
            "\n",
            "Train Epoch: 20 [50000/50000 (100%)]\tLoss: 0.000061\n",
            "\n",
            "Validation set: Average loss: 4.2069, Accuracy: 5659/10000 (57%)\n",
            "\n",
            "Train Epoch: 21 [50000/50000 (100%)]\tLoss: 0.000051\n",
            "\n",
            "Validation set: Average loss: 4.2443, Accuracy: 5664/10000 (57%)\n",
            "\n",
            "Train Epoch: 22 [50000/50000 (100%)]\tLoss: 0.000044\n",
            "\n",
            "Validation set: Average loss: 4.2774, Accuracy: 5667/10000 (57%)\n",
            "\n",
            "Train Epoch: 23 [50000/50000 (100%)]\tLoss: 0.000039\n",
            "\n",
            "Validation set: Average loss: 4.3072, Accuracy: 5669/10000 (57%)\n",
            "\n",
            "Train Epoch: 24 [50000/50000 (100%)]\tLoss: 0.000035\n",
            "\n",
            "Validation set: Average loss: 4.3337, Accuracy: 5670/10000 (57%)\n",
            "\n",
            "Train Epoch: 25 [50000/50000 (100%)]\tLoss: 0.000032\n",
            "\n",
            "Validation set: Average loss: 4.3584, Accuracy: 5672/10000 (57%)\n",
            "\n",
            "Train Epoch: 26 [50000/50000 (100%)]\tLoss: 0.000029\n",
            "\n",
            "Validation set: Average loss: 4.3815, Accuracy: 5667/10000 (57%)\n",
            "\n",
            "Train Epoch: 27 [50000/50000 (100%)]\tLoss: 0.000027\n",
            "\n",
            "Validation set: Average loss: 4.4027, Accuracy: 5667/10000 (57%)\n",
            "\n",
            "Train Epoch: 28 [50000/50000 (100%)]\tLoss: 0.000025\n",
            "\n",
            "Validation set: Average loss: 4.4230, Accuracy: 5667/10000 (57%)\n",
            "\n",
            "Train Epoch: 29 [50000/50000 (100%)]\tLoss: 0.000023\n",
            "\n",
            "Validation set: Average loss: 4.4416, Accuracy: 5665/10000 (57%)\n",
            "\n",
            "Train Epoch: 30 [50000/50000 (100%)]\tLoss: 0.000022\n",
            "\n",
            "Validation set: Average loss: 4.4596, Accuracy: 5662/10000 (57%)\n",
            "\n",
            "Train Epoch: 31 [50000/50000 (100%)]\tLoss: 0.000021\n",
            "\n",
            "Validation set: Average loss: 4.4765, Accuracy: 5663/10000 (57%)\n",
            "\n",
            "Train Epoch: 32 [50000/50000 (100%)]\tLoss: 0.000019\n",
            "\n",
            "Validation set: Average loss: 4.4924, Accuracy: 5658/10000 (57%)\n",
            "\n",
            "Train Epoch: 33 [50000/50000 (100%)]\tLoss: 0.000018\n",
            "\n",
            "Validation set: Average loss: 4.5078, Accuracy: 5657/10000 (57%)\n",
            "\n",
            "Train Epoch: 34 [50000/50000 (100%)]\tLoss: 0.000018\n",
            "\n",
            "Validation set: Average loss: 4.5224, Accuracy: 5659/10000 (57%)\n",
            "\n",
            "Train Epoch: 35 [50000/50000 (100%)]\tLoss: 0.000017\n",
            "\n",
            "Validation set: Average loss: 4.5366, Accuracy: 5659/10000 (57%)\n",
            "\n",
            "Train Epoch: 36 [50000/50000 (100%)]\tLoss: 0.000016\n",
            "\n",
            "Validation set: Average loss: 4.5500, Accuracy: 5656/10000 (57%)\n",
            "\n",
            "Train Epoch: 37 [50000/50000 (100%)]\tLoss: 0.000015\n",
            "\n",
            "Validation set: Average loss: 4.5631, Accuracy: 5656/10000 (57%)\n",
            "\n",
            "Train Epoch: 38 [50000/50000 (100%)]\tLoss: 0.000015\n",
            "\n",
            "Validation set: Average loss: 4.5756, Accuracy: 5655/10000 (57%)\n",
            "\n",
            "Train Epoch: 39 [50000/50000 (100%)]\tLoss: 0.000014\n",
            "\n",
            "Validation set: Average loss: 4.5876, Accuracy: 5653/10000 (57%)\n",
            "\n",
            "Train Epoch: 40 [50000/50000 (100%)]\tLoss: 0.000014\n",
            "\n",
            "Validation set: Average loss: 4.5994, Accuracy: 5655/10000 (57%)\n",
            "\n",
            "Train Epoch: 41 [50000/50000 (100%)]\tLoss: 0.000013\n",
            "\n",
            "Validation set: Average loss: 4.6106, Accuracy: 5656/10000 (57%)\n",
            "\n",
            "Train Epoch: 42 [50000/50000 (100%)]\tLoss: 0.000013\n",
            "\n",
            "Validation set: Average loss: 4.6216, Accuracy: 5655/10000 (57%)\n",
            "\n",
            "Train Epoch: 43 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 4.6322, Accuracy: 5654/10000 (57%)\n",
            "\n",
            "Train Epoch: 44 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 4.6423, Accuracy: 5655/10000 (57%)\n",
            "\n",
            "Train Epoch: 45 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 4.6523, Accuracy: 5656/10000 (57%)\n",
            "\n",
            "Train Epoch: 46 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 4.6621, Accuracy: 5656/10000 (57%)\n",
            "\n",
            "Train Epoch: 47 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 4.6716, Accuracy: 5657/10000 (57%)\n",
            "\n",
            "Train Epoch: 48 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 4.6808, Accuracy: 5655/10000 (57%)\n",
            "\n",
            "Train Epoch: 49 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 4.6899, Accuracy: 5656/10000 (57%)\n",
            "\n",
            "Train Epoch: 50 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 4.6986, Accuracy: 5657/10000 (57%)\n",
            "\n",
            "Train Epoch: 51 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 4.7072, Accuracy: 5657/10000 (57%)\n",
            "\n",
            "Train Epoch: 52 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.7155, Accuracy: 5659/10000 (57%)\n",
            "\n",
            "Train Epoch: 53 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.7237, Accuracy: 5660/10000 (57%)\n",
            "\n",
            "Train Epoch: 54 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.7317, Accuracy: 5660/10000 (57%)\n",
            "\n",
            "Train Epoch: 55 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.7395, Accuracy: 5659/10000 (57%)\n",
            "\n",
            "Train Epoch: 56 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.7471, Accuracy: 5660/10000 (57%)\n",
            "\n",
            "Train Epoch: 57 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.7545, Accuracy: 5660/10000 (57%)\n",
            "\n",
            "Train Epoch: 58 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.7619, Accuracy: 5661/10000 (57%)\n",
            "\n",
            "Train Epoch: 59 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.7691, Accuracy: 5662/10000 (57%)\n",
            "\n",
            "Train Epoch: 60 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.7761, Accuracy: 5663/10000 (57%)\n",
            "\n",
            "Train Epoch: 61 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.7830, Accuracy: 5662/10000 (57%)\n",
            "\n",
            "Train Epoch: 62 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.7897, Accuracy: 5664/10000 (57%)\n",
            "\n",
            "Train Epoch: 63 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.7964, Accuracy: 5665/10000 (57%)\n",
            "\n",
            "Train Epoch: 64 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.8029, Accuracy: 5666/10000 (57%)\n",
            "\n",
            "Train Epoch: 65 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.8093, Accuracy: 5666/10000 (57%)\n",
            "\n",
            "Train Epoch: 66 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.8156, Accuracy: 5666/10000 (57%)\n",
            "\n",
            "Train Epoch: 67 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.8218, Accuracy: 5666/10000 (57%)\n",
            "\n",
            "Train Epoch: 68 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.8279, Accuracy: 5667/10000 (57%)\n",
            "\n",
            "Train Epoch: 69 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.8339, Accuracy: 5667/10000 (57%)\n",
            "\n",
            "Train Epoch: 70 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.8398, Accuracy: 5667/10000 (57%)\n",
            "\n",
            "Train Epoch: 71 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.8455, Accuracy: 5667/10000 (57%)\n",
            "\n",
            "Train Epoch: 72 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.8512, Accuracy: 5668/10000 (57%)\n",
            "\n",
            "Train Epoch: 73 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.8569, Accuracy: 5668/10000 (57%)\n",
            "\n",
            "Train Epoch: 74 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.8624, Accuracy: 5668/10000 (57%)\n",
            "\n",
            "Train Epoch: 75 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.8679, Accuracy: 5669/10000 (57%)\n",
            "\n",
            "Train Epoch: 76 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.8732, Accuracy: 5668/10000 (57%)\n",
            "\n",
            "Train Epoch: 77 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.8785, Accuracy: 5670/10000 (57%)\n",
            "\n",
            "Train Epoch: 78 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.8837, Accuracy: 5670/10000 (57%)\n",
            "\n",
            "Train Epoch: 79 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.8889, Accuracy: 5672/10000 (57%)\n",
            "\n",
            "Train Epoch: 80 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.8940, Accuracy: 5671/10000 (57%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in frnpf_di_model.named_parameters():\n",
        "  print(name, param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7MBipi4HphP5",
        "outputId": "d3dc0906-2e5b-4550-b1ae-ea4eb1619e41"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NPF_C1.weight Parameter containing:\n",
            "tensor([[[[ 0.1702, -0.0410, -0.1715],\n",
            "          [-0.1727, -0.1691,  0.1663],\n",
            "          [-0.0101, -0.1337,  0.0772]],\n",
            "\n",
            "         [[ 0.0743,  0.1482,  0.0419],\n",
            "          [ 0.1614,  0.1694,  0.1859],\n",
            "          [-0.1185, -0.0738,  0.0040]],\n",
            "\n",
            "         [[ 0.0363, -0.0772, -0.1612],\n",
            "          [ 0.0859,  0.0229,  0.0993],\n",
            "          [ 0.0268, -0.1790,  0.1827]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1779, -0.1019, -0.1768],\n",
            "          [-0.1688,  0.0673,  0.0757],\n",
            "          [ 0.1021,  0.0230,  0.0172]],\n",
            "\n",
            "         [[-0.1060,  0.0220,  0.0491],\n",
            "          [ 0.0193,  0.0763, -0.0260],\n",
            "          [-0.0401, -0.1085, -0.0292]],\n",
            "\n",
            "         [[-0.0725,  0.0668,  0.0805],\n",
            "          [ 0.0910, -0.0254,  0.0105],\n",
            "          [-0.1620, -0.1402,  0.1393]]],\n",
            "\n",
            "\n",
            "        [[[-0.1743, -0.1056,  0.0858],\n",
            "          [ 0.1476, -0.0166, -0.0909],\n",
            "          [ 0.1034, -0.1136, -0.0495]],\n",
            "\n",
            "         [[-0.1307,  0.1124, -0.0006],\n",
            "          [-0.0614,  0.1173, -0.1692],\n",
            "          [-0.0389,  0.1868,  0.0260]],\n",
            "\n",
            "         [[-0.0134, -0.0680,  0.0858],\n",
            "          [ 0.0989,  0.0621, -0.1651],\n",
            "          [-0.0100, -0.0766,  0.1436]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1146,  0.0594,  0.1794],\n",
            "          [-0.0902,  0.1062,  0.1016],\n",
            "          [ 0.0030, -0.0459, -0.0912]],\n",
            "\n",
            "         [[-0.0790,  0.1894, -0.0759],\n",
            "          [ 0.0057, -0.0130,  0.0134],\n",
            "          [ 0.0984, -0.1103,  0.0471]],\n",
            "\n",
            "         [[-0.1643,  0.0140,  0.0439],\n",
            "          [ 0.0277,  0.0672, -0.1452],\n",
            "          [-0.0354,  0.0165, -0.0689]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0635, -0.1574, -0.1164],\n",
            "          [ 0.0090,  0.1154,  0.1278],\n",
            "          [ 0.1436,  0.0321, -0.0963]],\n",
            "\n",
            "         [[-0.0914,  0.0944,  0.1823],\n",
            "          [-0.1550, -0.0940, -0.1480],\n",
            "          [-0.1010, -0.1865, -0.0256]],\n",
            "\n",
            "         [[ 0.0908,  0.0892,  0.0189],\n",
            "          [ 0.1255,  0.1116,  0.0328],\n",
            "          [-0.1714,  0.0962,  0.0869]]],\n",
            "\n",
            "\n",
            "        [[[-0.1654, -0.1914, -0.1517],\n",
            "          [ 0.1294,  0.0595,  0.0156],\n",
            "          [ 0.1310,  0.0984, -0.0277]],\n",
            "\n",
            "         [[ 0.0623,  0.0603,  0.0457],\n",
            "          [-0.0720, -0.1320, -0.0053],\n",
            "          [-0.0809,  0.0605, -0.0083]],\n",
            "\n",
            "         [[-0.1451, -0.0556, -0.1564],\n",
            "          [-0.1920, -0.0923, -0.1241],\n",
            "          [-0.1158,  0.0806, -0.1910]]]], device='cuda:0')\n",
            "NPF_C1.bias Parameter containing:\n",
            "tensor([ 0.1360,  0.0330, -0.1504,  0.1085, -0.0124, -0.0843,  0.1011,  0.0657,\n",
            "        -0.1680, -0.0143, -0.0744, -0.1760,  0.0395,  0.1175,  0.1187,  0.0322,\n",
            "        -0.0170, -0.0094, -0.0723, -0.1105, -0.1598, -0.1207, -0.1817,  0.0272,\n",
            "        -0.1605,  0.0230, -0.0691,  0.0023,  0.0248,  0.1161, -0.0184, -0.1789,\n",
            "        -0.0585, -0.1670, -0.1498,  0.0496, -0.1021,  0.1302,  0.1419,  0.0301,\n",
            "        -0.0621,  0.0660, -0.1356,  0.1769,  0.1480, -0.0332, -0.1666, -0.1354,\n",
            "         0.0033, -0.1591,  0.1543,  0.0701,  0.0120,  0.1138, -0.1279, -0.0945,\n",
            "         0.1131, -0.0975,  0.0081, -0.0486,  0.1721,  0.1269, -0.0028, -0.0407],\n",
            "       device='cuda:0')\n",
            "NPF_C2.weight Parameter containing:\n",
            "tensor([[[[ 0.0117,  0.0134,  0.0057],\n",
            "          [ 0.0141,  0.0043, -0.0169],\n",
            "          [-0.0188,  0.0092,  0.0140]],\n",
            "\n",
            "         [[ 0.0207,  0.0378,  0.0386],\n",
            "          [-0.0025,  0.0047,  0.0346],\n",
            "          [ 0.0243, -0.0013, -0.0157]],\n",
            "\n",
            "         [[-0.0038,  0.0179,  0.0011],\n",
            "          [ 0.0312,  0.0250, -0.0085],\n",
            "          [-0.0351, -0.0400,  0.0129]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0136, -0.0027, -0.0094],\n",
            "          [ 0.0375,  0.0247, -0.0122],\n",
            "          [ 0.0003, -0.0191,  0.0029]],\n",
            "\n",
            "         [[-0.0351, -0.0091,  0.0261],\n",
            "          [ 0.0052, -0.0126, -0.0320],\n",
            "          [ 0.0291,  0.0014,  0.0303]],\n",
            "\n",
            "         [[-0.0324, -0.0034,  0.0024],\n",
            "          [-0.0180, -0.0181, -0.0379],\n",
            "          [-0.0142,  0.0389, -0.0066]]],\n",
            "\n",
            "\n",
            "        [[[-0.0405,  0.0334, -0.0408],\n",
            "          [-0.0114,  0.0316,  0.0337],\n",
            "          [ 0.0297,  0.0079, -0.0073]],\n",
            "\n",
            "         [[-0.0187, -0.0220, -0.0277],\n",
            "          [-0.0102,  0.0286, -0.0374],\n",
            "          [ 0.0210,  0.0406, -0.0387]],\n",
            "\n",
            "         [[ 0.0171,  0.0314,  0.0051],\n",
            "          [ 0.0192, -0.0019,  0.0069],\n",
            "          [ 0.0050, -0.0015,  0.0071]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0264,  0.0286,  0.0343],\n",
            "          [-0.0298,  0.0395,  0.0322],\n",
            "          [-0.0302,  0.0036, -0.0017]],\n",
            "\n",
            "         [[-0.0205, -0.0156,  0.0061],\n",
            "          [-0.0365,  0.0248, -0.0135],\n",
            "          [ 0.0056, -0.0410, -0.0401]],\n",
            "\n",
            "         [[-0.0197, -0.0257,  0.0374],\n",
            "          [ 0.0063,  0.0069,  0.0125],\n",
            "          [ 0.0214, -0.0313,  0.0212]]],\n",
            "\n",
            "\n",
            "        [[[-0.0132,  0.0052,  0.0207],\n",
            "          [-0.0053, -0.0263, -0.0035],\n",
            "          [ 0.0232,  0.0057,  0.0260]],\n",
            "\n",
            "         [[-0.0296,  0.0235, -0.0076],\n",
            "          [-0.0269, -0.0013, -0.0062],\n",
            "          [ 0.0148,  0.0179, -0.0357]],\n",
            "\n",
            "         [[ 0.0382,  0.0273,  0.0217],\n",
            "          [-0.0281,  0.0038, -0.0042],\n",
            "          [ 0.0366, -0.0363,  0.0277]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0030,  0.0043,  0.0102],\n",
            "          [ 0.0061, -0.0143, -0.0350],\n",
            "          [ 0.0089,  0.0032, -0.0233]],\n",
            "\n",
            "         [[-0.0279,  0.0256,  0.0127],\n",
            "          [ 0.0208, -0.0117, -0.0150],\n",
            "          [-0.0078,  0.0200,  0.0107]],\n",
            "\n",
            "         [[-0.0289,  0.0065, -0.0127],\n",
            "          [-0.0124, -0.0017, -0.0359],\n",
            "          [ 0.0106, -0.0404, -0.0334]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0327,  0.0195, -0.0202],\n",
            "          [ 0.0233, -0.0046,  0.0008],\n",
            "          [-0.0348,  0.0396,  0.0073]],\n",
            "\n",
            "         [[ 0.0008, -0.0410,  0.0255],\n",
            "          [-0.0052,  0.0091,  0.0209],\n",
            "          [ 0.0283, -0.0069,  0.0075]],\n",
            "\n",
            "         [[ 0.0106, -0.0116,  0.0188],\n",
            "          [ 0.0106, -0.0157,  0.0402],\n",
            "          [-0.0322, -0.0369, -0.0151]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0221, -0.0208,  0.0368],\n",
            "          [-0.0264, -0.0405, -0.0024],\n",
            "          [-0.0255,  0.0377,  0.0127]],\n",
            "\n",
            "         [[ 0.0225,  0.0050, -0.0209],\n",
            "          [ 0.0050,  0.0040, -0.0184],\n",
            "          [ 0.0100,  0.0258, -0.0385]],\n",
            "\n",
            "         [[ 0.0224, -0.0036,  0.0148],\n",
            "          [-0.0370, -0.0141, -0.0067],\n",
            "          [-0.0366, -0.0334,  0.0262]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0251, -0.0156,  0.0107],\n",
            "          [ 0.0033, -0.0368,  0.0235],\n",
            "          [ 0.0036,  0.0197, -0.0204]],\n",
            "\n",
            "         [[ 0.0275, -0.0240,  0.0242],\n",
            "          [ 0.0345, -0.0197,  0.0007],\n",
            "          [ 0.0316, -0.0102, -0.0296]],\n",
            "\n",
            "         [[ 0.0221,  0.0325,  0.0185],\n",
            "          [-0.0341,  0.0398, -0.0091],\n",
            "          [-0.0140, -0.0313,  0.0102]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0152, -0.0278,  0.0116],\n",
            "          [-0.0106,  0.0302, -0.0140],\n",
            "          [-0.0192, -0.0216,  0.0012]],\n",
            "\n",
            "         [[ 0.0296,  0.0322, -0.0048],\n",
            "          [ 0.0010,  0.0015, -0.0345],\n",
            "          [ 0.0091,  0.0310, -0.0305]],\n",
            "\n",
            "         [[ 0.0093, -0.0009, -0.0151],\n",
            "          [-0.0038, -0.0119, -0.0011],\n",
            "          [ 0.0371,  0.0036, -0.0325]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0295, -0.0322,  0.0342],\n",
            "          [-0.0359, -0.0373, -0.0228],\n",
            "          [-0.0271,  0.0056, -0.0221]],\n",
            "\n",
            "         [[ 0.0273, -0.0159, -0.0098],\n",
            "          [-0.0362,  0.0041, -0.0033],\n",
            "          [ 0.0252,  0.0075,  0.0073]],\n",
            "\n",
            "         [[-0.0098, -0.0373, -0.0401],\n",
            "          [-0.0347, -0.0057, -0.0407],\n",
            "          [-0.0193,  0.0184, -0.0082]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0136,  0.0059, -0.0351],\n",
            "          [ 0.0357,  0.0166, -0.0370],\n",
            "          [ 0.0401,  0.0193,  0.0256]],\n",
            "\n",
            "         [[-0.0273, -0.0409,  0.0268],\n",
            "          [-0.0328,  0.0115,  0.0038],\n",
            "          [-0.0033, -0.0075, -0.0339]],\n",
            "\n",
            "         [[-0.0324,  0.0122, -0.0293],\n",
            "          [-0.0336, -0.0026, -0.0124],\n",
            "          [ 0.0412, -0.0374,  0.0122]]]], device='cuda:0')\n",
            "NPF_C2.bias Parameter containing:\n",
            "tensor([-0.0375, -0.0013,  0.0022, -0.0365, -0.0123,  0.0181, -0.0207, -0.0065,\n",
            "        -0.0264,  0.0202, -0.0197,  0.0378, -0.0018,  0.0063, -0.0281, -0.0283,\n",
            "         0.0307, -0.0126, -0.0030, -0.0032,  0.0123, -0.0373,  0.0336,  0.0352,\n",
            "         0.0345, -0.0321, -0.0002, -0.0399, -0.0095,  0.0396, -0.0214,  0.0284,\n",
            "        -0.0386, -0.0108, -0.0180, -0.0231,  0.0095,  0.0348,  0.0079, -0.0123,\n",
            "         0.0008, -0.0140,  0.0222, -0.0179,  0.0162,  0.0234, -0.0015, -0.0249,\n",
            "        -0.0111,  0.0403,  0.0270,  0.0212,  0.0014, -0.0164,  0.0199, -0.0077,\n",
            "        -0.0222,  0.0197,  0.0294, -0.0407, -0.0286, -0.0157, -0.0314, -0.0024],\n",
            "       device='cuda:0')\n",
            "NPF_C3.weight Parameter containing:\n",
            "tensor([[[[ 0.0217,  0.0159, -0.0032],\n",
            "          [ 0.0155, -0.0109, -0.0363],\n",
            "          [ 0.0100,  0.0288, -0.0223]],\n",
            "\n",
            "         [[-0.0266, -0.0324, -0.0359],\n",
            "          [ 0.0382, -0.0044,  0.0317],\n",
            "          [ 0.0154,  0.0313,  0.0413]],\n",
            "\n",
            "         [[ 0.0295,  0.0122,  0.0401],\n",
            "          [-0.0161, -0.0172,  0.0025],\n",
            "          [ 0.0147, -0.0363, -0.0226]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0291,  0.0142,  0.0043],\n",
            "          [ 0.0081, -0.0154, -0.0182],\n",
            "          [-0.0193, -0.0097, -0.0249]],\n",
            "\n",
            "         [[-0.0027, -0.0054, -0.0012],\n",
            "          [-0.0141,  0.0177,  0.0075],\n",
            "          [ 0.0415, -0.0002, -0.0012]],\n",
            "\n",
            "         [[-0.0128, -0.0170, -0.0107],\n",
            "          [-0.0021,  0.0345,  0.0069],\n",
            "          [-0.0341, -0.0314, -0.0028]]],\n",
            "\n",
            "\n",
            "        [[[-0.0076,  0.0052, -0.0285],\n",
            "          [ 0.0228, -0.0024, -0.0161],\n",
            "          [-0.0218,  0.0328, -0.0113]],\n",
            "\n",
            "         [[ 0.0180, -0.0015,  0.0081],\n",
            "          [-0.0312, -0.0027,  0.0136],\n",
            "          [ 0.0200,  0.0393,  0.0309]],\n",
            "\n",
            "         [[ 0.0410, -0.0200,  0.0090],\n",
            "          [ 0.0290,  0.0057,  0.0161],\n",
            "          [ 0.0051, -0.0343,  0.0307]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0299, -0.0156, -0.0243],\n",
            "          [-0.0215, -0.0067, -0.0233],\n",
            "          [ 0.0007,  0.0120,  0.0273]],\n",
            "\n",
            "         [[-0.0087, -0.0387,  0.0304],\n",
            "          [-0.0387,  0.0127,  0.0089],\n",
            "          [-0.0280, -0.0172, -0.0410]],\n",
            "\n",
            "         [[ 0.0094, -0.0312, -0.0141],\n",
            "          [-0.0042,  0.0050,  0.0087],\n",
            "          [-0.0191, -0.0035,  0.0234]]],\n",
            "\n",
            "\n",
            "        [[[-0.0267, -0.0385,  0.0090],\n",
            "          [ 0.0017, -0.0002, -0.0062],\n",
            "          [ 0.0167, -0.0032, -0.0264]],\n",
            "\n",
            "         [[ 0.0373,  0.0369, -0.0068],\n",
            "          [ 0.0210, -0.0224,  0.0036],\n",
            "          [ 0.0040,  0.0299,  0.0167]],\n",
            "\n",
            "         [[-0.0102, -0.0214, -0.0375],\n",
            "          [-0.0070, -0.0188,  0.0133],\n",
            "          [ 0.0378,  0.0025, -0.0404]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0362,  0.0076, -0.0198],\n",
            "          [ 0.0139, -0.0317, -0.0059],\n",
            "          [-0.0229, -0.0307, -0.0368]],\n",
            "\n",
            "         [[ 0.0246, -0.0413, -0.0115],\n",
            "          [ 0.0173, -0.0243,  0.0171],\n",
            "          [ 0.0092, -0.0388,  0.0007]],\n",
            "\n",
            "         [[-0.0409,  0.0412,  0.0188],\n",
            "          [ 0.0337,  0.0192,  0.0112],\n",
            "          [ 0.0333, -0.0049, -0.0256]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0117,  0.0416, -0.0205],\n",
            "          [ 0.0384,  0.0136, -0.0109],\n",
            "          [-0.0172,  0.0108, -0.0408]],\n",
            "\n",
            "         [[-0.0056, -0.0263, -0.0103],\n",
            "          [ 0.0246,  0.0354, -0.0183],\n",
            "          [-0.0325, -0.0009,  0.0335]],\n",
            "\n",
            "         [[ 0.0257,  0.0105,  0.0135],\n",
            "          [ 0.0170,  0.0015,  0.0063],\n",
            "          [ 0.0024, -0.0213,  0.0250]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0060, -0.0101,  0.0241],\n",
            "          [-0.0368, -0.0300,  0.0281],\n",
            "          [-0.0269, -0.0349,  0.0398]],\n",
            "\n",
            "         [[-0.0296,  0.0317,  0.0413],\n",
            "          [ 0.0357,  0.0398, -0.0339],\n",
            "          [ 0.0092, -0.0390, -0.0209]],\n",
            "\n",
            "         [[-0.0251, -0.0118, -0.0356],\n",
            "          [-0.0005, -0.0193, -0.0180],\n",
            "          [-0.0108, -0.0188, -0.0146]]],\n",
            "\n",
            "\n",
            "        [[[-0.0226, -0.0279,  0.0365],\n",
            "          [ 0.0007, -0.0239, -0.0410],\n",
            "          [-0.0050, -0.0209, -0.0139]],\n",
            "\n",
            "         [[ 0.0322,  0.0097, -0.0164],\n",
            "          [ 0.0102,  0.0403, -0.0031],\n",
            "          [-0.0312, -0.0138,  0.0081]],\n",
            "\n",
            "         [[ 0.0337,  0.0101, -0.0385],\n",
            "          [-0.0055, -0.0081, -0.0057],\n",
            "          [ 0.0145,  0.0361, -0.0136]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0124,  0.0247, -0.0099],\n",
            "          [ 0.0249, -0.0336, -0.0019],\n",
            "          [ 0.0322,  0.0275,  0.0336]],\n",
            "\n",
            "         [[-0.0078, -0.0330, -0.0142],\n",
            "          [ 0.0335, -0.0248, -0.0206],\n",
            "          [-0.0309,  0.0191, -0.0266]],\n",
            "\n",
            "         [[ 0.0402, -0.0093,  0.0157],\n",
            "          [-0.0164,  0.0053,  0.0331],\n",
            "          [-0.0341, -0.0125, -0.0200]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0050,  0.0385, -0.0309],\n",
            "          [-0.0285, -0.0210, -0.0122],\n",
            "          [-0.0379, -0.0037,  0.0150]],\n",
            "\n",
            "         [[ 0.0102, -0.0091,  0.0294],\n",
            "          [ 0.0283,  0.0001,  0.0034],\n",
            "          [-0.0177, -0.0332, -0.0117]],\n",
            "\n",
            "         [[-0.0408, -0.0170, -0.0365],\n",
            "          [-0.0088, -0.0094, -0.0055],\n",
            "          [ 0.0376,  0.0012, -0.0224]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0268, -0.0318,  0.0173],\n",
            "          [-0.0218,  0.0203, -0.0278],\n",
            "          [ 0.0141, -0.0190,  0.0192]],\n",
            "\n",
            "         [[-0.0236,  0.0116,  0.0194],\n",
            "          [ 0.0021,  0.0244,  0.0283],\n",
            "          [-0.0401, -0.0231, -0.0233]],\n",
            "\n",
            "         [[-0.0150, -0.0166,  0.0403],\n",
            "          [ 0.0408,  0.0149, -0.0296],\n",
            "          [-0.0243, -0.0286, -0.0399]]]], device='cuda:0')\n",
            "NPF_C3.bias Parameter containing:\n",
            "tensor([ 0.0205, -0.0027,  0.0187, -0.0045,  0.0185, -0.0097, -0.0113, -0.0203,\n",
            "         0.0067,  0.0380, -0.0108, -0.0188, -0.0001,  0.0230, -0.0367, -0.0163,\n",
            "         0.0272, -0.0229, -0.0064, -0.0043, -0.0022,  0.0158, -0.0151,  0.0258,\n",
            "        -0.0205,  0.0321, -0.0410, -0.0030,  0.0368,  0.0110,  0.0130,  0.0193,\n",
            "         0.0196, -0.0412,  0.0306,  0.0374,  0.0065,  0.0286,  0.0197, -0.0130,\n",
            "        -0.0215,  0.0275,  0.0290, -0.0212, -0.0156, -0.0073,  0.0409, -0.0360,\n",
            "         0.0362,  0.0067,  0.0157,  0.0339, -0.0376,  0.0260, -0.0381, -0.0325,\n",
            "        -0.0245, -0.0139, -0.0410, -0.0091, -0.0009,  0.0037, -0.0217, -0.0272,\n",
            "         0.0189,  0.0089, -0.0144, -0.0047, -0.0132, -0.0014,  0.0248, -0.0269,\n",
            "         0.0305,  0.0317,  0.0096,  0.0324,  0.0260,  0.0107, -0.0314, -0.0317,\n",
            "         0.0391, -0.0169,  0.0193,  0.0308,  0.0345, -0.0196, -0.0262,  0.0157,\n",
            "        -0.0380, -0.0198, -0.0238, -0.0353,  0.0414,  0.0203, -0.0101, -0.0259,\n",
            "        -0.0095, -0.0179,  0.0205,  0.0009, -0.0212, -0.0394,  0.0290,  0.0146,\n",
            "        -0.0127,  0.0112, -0.0014,  0.0211, -0.0319, -0.0039,  0.0365,  0.0352,\n",
            "        -0.0147,  0.0020,  0.0415, -0.0015, -0.0121, -0.0287, -0.0020,  0.0074,\n",
            "        -0.0377,  0.0141,  0.0113, -0.0357, -0.0085, -0.0243, -0.0375,  0.0189],\n",
            "       device='cuda:0')\n",
            "NPF_C4.weight Parameter containing:\n",
            "tensor([[[[-7.2642e-03,  1.8725e-02, -1.3772e-02],\n",
            "          [-1.7507e-02, -1.3259e-02, -1.9156e-04],\n",
            "          [-8.3539e-03, -7.4551e-03, -3.6623e-03]],\n",
            "\n",
            "         [[-2.0398e-02, -1.1719e-02, -1.2072e-02],\n",
            "          [-1.5466e-02,  2.7268e-03, -1.6365e-02],\n",
            "          [ 2.9198e-02,  2.2899e-02, -1.0189e-02]],\n",
            "\n",
            "         [[ 2.8148e-02,  2.6232e-03,  2.8795e-02],\n",
            "          [ 1.9025e-03,  2.8527e-02,  2.4464e-02],\n",
            "          [ 3.0389e-03,  6.4775e-03,  1.1604e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0148e-04, -4.2034e-03, -1.6703e-02],\n",
            "          [ 1.0552e-02,  1.3343e-02, -4.4137e-03],\n",
            "          [-6.0703e-03, -1.0922e-02, -1.6723e-02]],\n",
            "\n",
            "         [[ 1.7797e-02,  1.1638e-02,  8.1478e-03],\n",
            "          [-2.0974e-03,  1.5894e-02, -2.6263e-03],\n",
            "          [-1.9343e-02,  2.2637e-02, -2.7770e-02]],\n",
            "\n",
            "         [[-1.0497e-02, -3.7546e-03, -7.1459e-03],\n",
            "          [-2.2670e-02, -6.2318e-03,  1.0515e-02],\n",
            "          [-1.5801e-02,  5.6887e-03, -2.0076e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0976e-02,  4.8132e-03,  1.3558e-02],\n",
            "          [ 9.8910e-03, -4.5010e-03, -2.4968e-02],\n",
            "          [-1.3108e-02,  8.0744e-03,  2.7444e-02]],\n",
            "\n",
            "         [[-1.9899e-02,  1.7395e-02,  5.5319e-03],\n",
            "          [ 2.4855e-02, -4.5730e-03,  2.9020e-02],\n",
            "          [-1.5705e-02,  2.5388e-02, -1.8179e-02]],\n",
            "\n",
            "         [[ 2.1590e-02, -2.8471e-02,  1.4288e-02],\n",
            "          [ 8.2745e-03, -2.7951e-02, -9.9734e-03],\n",
            "          [ 6.0420e-03,  2.8004e-02,  2.6936e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-9.5144e-03, -1.4959e-02,  2.4389e-02],\n",
            "          [ 2.7466e-02,  7.8878e-03,  1.9139e-02],\n",
            "          [-2.4720e-02, -1.5198e-02, -2.5540e-02]],\n",
            "\n",
            "         [[-1.5755e-02,  1.6693e-02, -1.3001e-02],\n",
            "          [ 1.2409e-03,  2.0463e-03,  5.6324e-03],\n",
            "          [ 8.8068e-03,  2.7159e-02, -5.1558e-03]],\n",
            "\n",
            "         [[ 1.0670e-02, -2.9010e-02,  2.3002e-02],\n",
            "          [ 1.5578e-02,  1.3569e-02, -8.0591e-03],\n",
            "          [-2.6739e-02, -2.6947e-02,  5.2179e-03]]],\n",
            "\n",
            "\n",
            "        [[[-2.8850e-02,  4.2878e-03,  1.2730e-02],\n",
            "          [-2.4219e-02,  1.6877e-02,  4.9958e-04],\n",
            "          [-2.9059e-02, -4.1744e-04, -6.8208e-03]],\n",
            "\n",
            "         [[-7.5455e-03,  8.4972e-03, -2.5459e-02],\n",
            "          [-2.8511e-02,  1.7128e-02,  1.8268e-02],\n",
            "          [-2.7390e-02, -1.9871e-02, -1.3138e-02]],\n",
            "\n",
            "         [[ 2.7750e-02, -2.0844e-02,  1.4472e-02],\n",
            "          [ 1.1179e-02, -2.3946e-02, -1.9616e-02],\n",
            "          [-2.5335e-02,  4.3083e-03,  2.3350e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.6229e-03,  1.0913e-02, -2.7349e-02],\n",
            "          [-2.2690e-03, -1.9740e-02, -2.0710e-02],\n",
            "          [-6.5406e-03, -1.5914e-02,  1.5547e-02]],\n",
            "\n",
            "         [[ 2.8126e-02, -3.5165e-03,  3.7297e-03],\n",
            "          [-1.6315e-02,  2.6352e-02, -1.9326e-02],\n",
            "          [ 2.6053e-02,  7.6796e-03,  1.3159e-03]],\n",
            "\n",
            "         [[-1.8453e-03,  7.7653e-03, -4.2909e-03],\n",
            "          [ 7.2997e-04, -5.7854e-03,  2.7358e-02],\n",
            "          [-3.2779e-03,  9.2777e-03, -1.5327e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.2030e-02, -5.8443e-03, -2.4302e-02],\n",
            "          [ 9.5494e-03, -1.6379e-02,  1.2827e-02],\n",
            "          [-1.8017e-02, -2.4094e-03,  1.3896e-02]],\n",
            "\n",
            "         [[ 6.7912e-03, -2.3121e-02,  9.8585e-03],\n",
            "          [-2.7826e-02,  2.1179e-02, -1.6276e-02],\n",
            "          [ 1.8634e-02, -2.9044e-02, -1.6896e-02]],\n",
            "\n",
            "         [[ 2.9040e-02,  1.7220e-02,  2.8143e-02],\n",
            "          [ 2.8895e-02,  1.0942e-02,  8.8019e-03],\n",
            "          [-8.0183e-03,  5.6600e-03, -2.6545e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5805e-02, -1.5331e-03, -1.5985e-02],\n",
            "          [ 2.2513e-02, -2.1843e-02, -2.1102e-02],\n",
            "          [-2.7542e-02,  2.5122e-02, -1.7474e-02]],\n",
            "\n",
            "         [[ 2.6096e-02, -1.8383e-02, -2.8806e-02],\n",
            "          [ 2.2937e-02, -1.5319e-03, -2.1857e-02],\n",
            "          [-1.1891e-02,  5.4766e-03, -1.4315e-02]],\n",
            "\n",
            "         [[-7.7001e-03, -2.4259e-02,  2.6040e-02],\n",
            "          [-2.0379e-02, -1.0252e-02, -1.6167e-02],\n",
            "          [-2.3275e-02, -7.7806e-03,  2.7962e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.6920e-03, -1.7858e-02,  1.2792e-02],\n",
            "          [-1.1420e-03,  2.8010e-02, -2.2215e-02],\n",
            "          [ 1.8668e-02,  1.5217e-02,  1.3881e-02]],\n",
            "\n",
            "         [[ 1.1137e-02, -1.5518e-02, -2.5761e-02],\n",
            "          [ 2.1063e-02,  5.5779e-03,  2.0150e-02],\n",
            "          [-3.5567e-03,  1.9626e-02, -2.6667e-02]],\n",
            "\n",
            "         [[ 1.5827e-03, -8.7478e-03,  9.4545e-03],\n",
            "          [ 1.5364e-02, -2.9423e-02,  2.6942e-02],\n",
            "          [ 6.3926e-03,  7.9577e-05,  8.7556e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.8616e-02, -7.8212e-03,  2.4313e-02],\n",
            "          [-5.4454e-03, -2.7568e-02, -9.5371e-03],\n",
            "          [ 5.3715e-03,  9.5695e-03,  2.3832e-03]],\n",
            "\n",
            "         [[-1.8455e-03,  5.5293e-03, -1.5890e-03],\n",
            "          [ 2.5887e-02, -8.4311e-03,  1.5555e-02],\n",
            "          [ 7.5019e-03,  5.3858e-03, -1.1731e-02]],\n",
            "\n",
            "         [[ 2.2408e-02,  1.5884e-02,  2.5341e-02],\n",
            "          [ 8.8692e-03,  1.5566e-02,  2.4938e-02],\n",
            "          [-2.4224e-02,  2.4266e-02,  8.8448e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.5966e-02,  2.0407e-02, -8.3030e-03],\n",
            "          [-1.6691e-02, -1.9202e-02, -2.2475e-02],\n",
            "          [-1.1895e-02,  3.7270e-03,  2.1211e-02]],\n",
            "\n",
            "         [[-2.5930e-02,  2.0602e-02,  1.6368e-02],\n",
            "          [-1.8734e-03, -1.5195e-02, -1.8600e-02],\n",
            "          [-2.5721e-02,  2.0727e-02, -4.0807e-03]],\n",
            "\n",
            "         [[ 2.2957e-02, -2.1284e-02,  3.2340e-03],\n",
            "          [ 1.6553e-02,  1.4601e-02, -2.4700e-02],\n",
            "          [-2.4479e-02,  3.1844e-03,  2.0391e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.9130e-03, -1.5603e-02,  9.9356e-03],\n",
            "          [ 1.2557e-02, -1.7769e-02, -2.7835e-02],\n",
            "          [-1.0211e-02,  2.2124e-02,  1.1239e-02]],\n",
            "\n",
            "         [[-1.9666e-02,  1.7632e-02, -7.8668e-03],\n",
            "          [-1.8069e-02, -1.7070e-02, -4.3847e-03],\n",
            "          [-1.8631e-02,  6.0918e-03,  5.7733e-03]],\n",
            "\n",
            "         [[-8.1956e-03,  9.5931e-03,  2.1968e-03],\n",
            "          [ 2.6195e-02, -2.1429e-02,  2.4280e-02],\n",
            "          [-2.4516e-02, -1.7000e-03, -2.6902e-02]]]], device='cuda:0')\n",
            "NPF_C4.bias Parameter containing:\n",
            "tensor([-0.0233,  0.0038, -0.0167,  0.0017, -0.0130,  0.0242,  0.0098,  0.0054,\n",
            "         0.0241, -0.0281, -0.0179, -0.0163, -0.0150, -0.0075, -0.0222, -0.0021,\n",
            "        -0.0161,  0.0201,  0.0027,  0.0252, -0.0159,  0.0037, -0.0170, -0.0193,\n",
            "        -0.0125, -0.0287, -0.0143, -0.0076,  0.0187, -0.0086,  0.0005,  0.0005,\n",
            "         0.0239, -0.0242,  0.0257, -0.0055, -0.0156, -0.0233,  0.0095, -0.0025,\n",
            "        -0.0162, -0.0188, -0.0158,  0.0048,  0.0275,  0.0168, -0.0228,  0.0035,\n",
            "         0.0063,  0.0282, -0.0084, -0.0248, -0.0184, -0.0015, -0.0241, -0.0025,\n",
            "        -0.0025,  0.0265,  0.0200,  0.0163,  0.0025,  0.0183,  0.0016, -0.0218,\n",
            "         0.0020,  0.0275, -0.0054, -0.0177, -0.0090,  0.0207,  0.0246, -0.0002,\n",
            "        -0.0206,  0.0064, -0.0201,  0.0004, -0.0128, -0.0157,  0.0224, -0.0237,\n",
            "        -0.0243, -0.0127,  0.0140,  0.0202,  0.0286, -0.0250,  0.0093,  0.0014,\n",
            "        -0.0122,  0.0290,  0.0277,  0.0201, -0.0205, -0.0246,  0.0009, -0.0021,\n",
            "        -0.0074,  0.0248,  0.0065, -0.0118,  0.0173, -0.0201, -0.0294,  0.0134,\n",
            "        -0.0023,  0.0183, -0.0009,  0.0064,  0.0230,  0.0193,  0.0164, -0.0250,\n",
            "         0.0084,  0.0089,  0.0133,  0.0165,  0.0191, -0.0246,  0.0159,  0.0196,\n",
            "        -0.0131, -0.0118,  0.0178,  0.0291,  0.0268, -0.0260,  0.0032, -0.0088],\n",
            "       device='cuda:0')\n",
            "NPF_D1.weight Parameter containing:\n",
            "tensor([[-3.8792e-04,  2.4575e-03,  1.7560e-03,  ..., -2.5757e-04,\n",
            "          4.8451e-04,  2.4768e-03],\n",
            "        [ 1.6085e-03,  9.8880e-04,  1.0883e-03,  ..., -2.1319e-03,\n",
            "          3.9446e-04,  1.2126e-03],\n",
            "        [-1.6457e-04, -9.3323e-04, -2.8569e-04,  ...,  9.5492e-04,\n",
            "         -1.0700e-03, -9.0988e-04],\n",
            "        ...,\n",
            "        [-2.1483e-03,  1.5720e-03,  2.2458e-03,  ...,  1.1880e-03,\n",
            "          4.1344e-04,  1.0676e-03],\n",
            "        [-1.7881e-03, -8.2811e-04, -2.1738e-05,  ...,  1.1361e-03,\n",
            "          1.2870e-03, -1.7313e-03],\n",
            "        [-2.4349e-03,  2.1750e-03,  2.2784e-03,  ...,  9.0722e-04,\n",
            "         -1.6614e-03, -7.9001e-04]], device='cuda:0')\n",
            "NPF_D1.bias Parameter containing:\n",
            "tensor([-1.7293e-03,  1.1506e-03,  4.5368e-04,  2.2238e-03, -1.0917e-03,\n",
            "         1.4628e-03,  7.4851e-04,  4.7187e-04,  4.4980e-04,  4.4164e-04,\n",
            "         2.3777e-03,  1.3046e-03,  1.0829e-03, -9.2801e-04, -1.8209e-03,\n",
            "         1.7245e-03, -1.0184e-03, -1.2659e-04, -1.7220e-03, -7.5425e-04,\n",
            "        -2.0609e-03, -1.3359e-03, -4.9613e-04, -1.3858e-03, -1.0979e-03,\n",
            "         1.4651e-03,  2.3188e-03,  2.6795e-04,  7.8525e-04,  9.0881e-04,\n",
            "        -2.2881e-03,  1.7262e-03,  1.8762e-03, -2.5844e-03,  2.4112e-03,\n",
            "        -2.5076e-03,  4.6261e-04, -1.4186e-03,  1.5151e-03, -2.4477e-03,\n",
            "         2.1016e-03,  1.5367e-03, -3.9686e-04, -6.9806e-04, -3.9219e-04,\n",
            "        -2.5773e-03,  7.0031e-04, -8.0653e-04, -2.3993e-03, -1.6461e-03,\n",
            "        -7.8823e-04, -7.4132e-04,  7.4638e-05, -1.2766e-03,  1.3125e-03,\n",
            "         2.6874e-04,  8.2318e-04,  2.3516e-03, -4.7614e-04,  2.2069e-03,\n",
            "         7.7329e-04, -1.8285e-04, -2.0146e-03,  6.9669e-04,  1.8384e-03,\n",
            "         1.5384e-03, -2.4892e-03, -2.7350e-03, -2.5745e-03,  5.1249e-04,\n",
            "        -1.5800e-03, -1.0113e-03,  6.4865e-04,  2.2062e-04, -2.2047e-03,\n",
            "        -1.6090e-03,  2.6658e-03,  6.1688e-04,  6.4689e-04,  9.7595e-04,\n",
            "         9.4350e-04,  6.9253e-05, -2.0698e-03,  9.4742e-04, -2.3143e-03,\n",
            "         6.2070e-04, -1.5793e-03, -6.7087e-05, -1.1357e-03, -4.9779e-04,\n",
            "        -2.5385e-03,  2.7360e-03,  2.3791e-03, -1.9708e-03,  1.0906e-03,\n",
            "         1.3715e-03, -2.3547e-03,  4.6215e-04, -2.2761e-03, -2.3822e-03,\n",
            "        -2.3306e-03,  1.5498e-03,  4.6081e-04,  1.9972e-03, -1.4676e-03,\n",
            "        -4.0181e-04, -4.9730e-04, -1.9021e-04,  4.8721e-04,  1.0586e-03,\n",
            "        -6.9944e-04, -1.4037e-03,  1.2033e-03,  1.8104e-03, -1.2484e-03,\n",
            "        -2.1162e-03, -1.8560e-03,  2.2677e-04,  1.3658e-03, -7.8060e-04,\n",
            "        -2.2129e-03,  4.8610e-04,  2.4957e-03, -3.2211e-04,  1.3209e-03,\n",
            "         2.2782e-03, -3.7630e-04,  6.7897e-04, -2.0243e-03, -2.7119e-03,\n",
            "         7.2267e-05, -1.1964e-03,  4.6058e-04, -2.2406e-03,  1.5283e-03,\n",
            "         1.4283e-03,  5.4040e-04, -4.1939e-04,  1.7948e-03,  2.0843e-03,\n",
            "         2.4138e-03, -2.7335e-03, -2.3687e-04, -1.8270e-03,  2.5321e-05,\n",
            "        -1.6385e-03, -4.1526e-04, -2.1864e-03, -1.5711e-03, -6.5090e-04,\n",
            "         1.9258e-03, -6.1930e-04,  1.3966e-03, -2.1703e-03, -1.5526e-03,\n",
            "         2.3025e-03, -1.0247e-03,  2.2240e-04,  9.0348e-04,  2.3754e-03,\n",
            "        -5.6102e-04,  3.9313e-04,  2.2708e-03, -1.9777e-03, -1.5489e-03,\n",
            "        -1.0275e-04,  1.6533e-03,  2.4441e-03, -2.6863e-03,  1.3588e-03,\n",
            "         5.5830e-04,  1.6059e-03, -2.7226e-03,  2.5678e-03, -1.1263e-03,\n",
            "        -1.2009e-03, -2.2263e-04,  1.5944e-03,  6.4960e-04,  1.8687e-03,\n",
            "        -2.2959e-03,  8.8703e-04,  1.6097e-03,  2.0857e-03,  3.6004e-04,\n",
            "        -5.9956e-04, -1.3601e-03, -2.5856e-03,  2.4500e-03,  7.3057e-04,\n",
            "        -1.1476e-03, -2.2637e-03,  4.4135e-04, -5.3937e-04, -2.3880e-03,\n",
            "        -1.5165e-03, -9.9325e-04, -2.5305e-03,  2.0115e-03, -2.2617e-05,\n",
            "         1.4759e-03,  9.7474e-04, -1.8251e-03,  1.3893e-03,  2.8886e-04,\n",
            "        -1.8922e-03, -2.2863e-03,  2.7426e-04,  2.5241e-03, -1.1213e-03,\n",
            "        -2.0870e-03, -1.4473e-03, -1.0257e-04,  2.5948e-03,  1.5732e-03,\n",
            "        -1.7268e-04,  1.4219e-03, -2.3880e-03,  8.3847e-04,  9.3391e-04,\n",
            "        -1.5229e-03,  1.5482e-03, -8.9516e-04, -2.3863e-04,  1.4544e-03,\n",
            "         1.2158e-03,  2.6584e-03, -1.3712e-03, -1.1800e-04,  3.4211e-04,\n",
            "        -1.0444e-03,  8.3916e-04,  7.4900e-04, -1.4592e-03, -4.9113e-04,\n",
            "         5.6589e-04,  2.3520e-03,  2.5193e-04,  2.2397e-03, -1.7005e-04,\n",
            "         5.4457e-04,  6.8871e-04,  1.1060e-03, -2.6542e-03, -2.2471e-03,\n",
            "        -3.2228e-04,  6.0786e-04,  1.1220e-03,  1.5163e-03, -8.9003e-04,\n",
            "        -2.0156e-03, -2.4076e-04, -1.8176e-03, -2.0926e-03,  2.6878e-04,\n",
            "         1.6702e-03], device='cuda:0')\n",
            "NPF_D2.weight Parameter containing:\n",
            "tensor([[-0.0121,  0.0591,  0.0244,  ...,  0.0342,  0.0062,  0.0272],\n",
            "        [ 0.0148, -0.0111,  0.0334,  ..., -0.0532, -0.0606, -0.0129],\n",
            "        [ 0.0241,  0.0384,  0.0045,  ..., -0.0607, -0.0118,  0.0356],\n",
            "        ...,\n",
            "        [-0.0339, -0.0398,  0.0422,  ..., -0.0270, -0.0313, -0.0511],\n",
            "        [-0.0071, -0.0161, -0.0303,  ..., -0.0205, -0.0411, -0.0544],\n",
            "        [-0.0422,  0.0084,  0.0094,  ...,  0.0176,  0.0265,  0.0420]],\n",
            "       device='cuda:0')\n",
            "NPF_D2.bias Parameter containing:\n",
            "tensor([ 0.0443, -0.0057,  0.0033,  0.0286,  0.0196,  0.0321,  0.0266, -0.0501,\n",
            "         0.0430,  0.0285, -0.0561,  0.0497,  0.0112, -0.0235, -0.0455, -0.0476,\n",
            "         0.0580,  0.0041, -0.0330, -0.0186,  0.0076,  0.0349, -0.0155,  0.0340,\n",
            "         0.0459, -0.0561, -0.0358, -0.0236,  0.0267,  0.0450, -0.0398, -0.0614,\n",
            "         0.0301, -0.0389,  0.0204, -0.0458,  0.0272, -0.0333, -0.0159,  0.0405,\n",
            "        -0.0393, -0.0053,  0.0562,  0.0492, -0.0212,  0.0604, -0.0277,  0.0261,\n",
            "        -0.0538,  0.0095, -0.0192, -0.0304,  0.0095, -0.0079, -0.0423,  0.0131,\n",
            "        -0.0050,  0.0570, -0.0438,  0.0599, -0.0250, -0.0179,  0.0113,  0.0231,\n",
            "         0.0370,  0.0202,  0.0267,  0.0511,  0.0034,  0.0320, -0.0340,  0.0050,\n",
            "         0.0005, -0.0586,  0.0154, -0.0275,  0.0231,  0.0010, -0.0038,  0.0010,\n",
            "         0.0349, -0.0453, -0.0415, -0.0532, -0.0600, -0.0162,  0.0336,  0.0606,\n",
            "         0.0131, -0.0602, -0.0407, -0.0113,  0.0287,  0.0262,  0.0173, -0.0275,\n",
            "        -0.0624, -0.0497,  0.0357,  0.0189, -0.0541, -0.0413,  0.0169, -0.0023,\n",
            "         0.0011, -0.0057,  0.0013,  0.0241, -0.0444,  0.0299,  0.0204,  0.0585,\n",
            "        -0.0187,  0.0216,  0.0260, -0.0053, -0.0099, -0.0601,  0.0219, -0.0584,\n",
            "        -0.0526, -0.0407,  0.0613,  0.0422, -0.0393, -0.0031,  0.0520,  0.0530,\n",
            "         0.0211,  0.0060, -0.0389, -0.0046, -0.0396,  0.0321, -0.0002, -0.0442,\n",
            "        -0.0011,  0.0272, -0.0528,  0.0215,  0.0132, -0.0008, -0.0204, -0.0607,\n",
            "        -0.0469, -0.0159,  0.0606, -0.0366, -0.0158, -0.0438,  0.0605, -0.0318,\n",
            "         0.0358, -0.0533, -0.0051,  0.0206,  0.0594, -0.0112, -0.0526, -0.0307,\n",
            "        -0.0101,  0.0615, -0.0295, -0.0286, -0.0270,  0.0399, -0.0144, -0.0594,\n",
            "        -0.0280,  0.0220,  0.0408, -0.0377,  0.0588, -0.0525, -0.0098, -0.0293,\n",
            "         0.0530, -0.0481,  0.0530,  0.0099,  0.0553,  0.0277,  0.0425,  0.0379,\n",
            "         0.0344,  0.0449,  0.0226, -0.0090, -0.0324, -0.0462,  0.0105,  0.0535,\n",
            "        -0.0245, -0.0174,  0.0582, -0.0548, -0.0594,  0.0383,  0.0171, -0.0084,\n",
            "         0.0083, -0.0315, -0.0076,  0.0612,  0.0234,  0.0008, -0.0171,  0.0224,\n",
            "        -0.0074, -0.0326, -0.0423, -0.0407, -0.0092,  0.0500, -0.0434,  0.0095,\n",
            "         0.0211, -0.0323, -0.0504, -0.0623,  0.0060,  0.0252, -0.0341,  0.0300,\n",
            "         0.0354,  0.0008,  0.0221,  0.0280, -0.0195,  0.0424,  0.0334,  0.0103,\n",
            "         0.0459,  0.0013, -0.0192, -0.0066, -0.0512,  0.0492, -0.0246,  0.0128,\n",
            "        -0.0522,  0.0421, -0.0526,  0.0228,  0.0590, -0.0036, -0.0365,  0.0018,\n",
            "        -0.0164, -0.0448, -0.0358, -0.0419, -0.0125, -0.0037, -0.0153,  0.0261],\n",
            "       device='cuda:0')\n",
            "NPV_C1.weight Parameter containing:\n",
            "tensor([[[[ 0.1586, -0.0621, -0.1892],\n",
            "          [-0.1834, -0.1902,  0.1383],\n",
            "          [-0.0405, -0.1706,  0.0259]],\n",
            "\n",
            "         [[ 0.0793,  0.1458,  0.0343],\n",
            "          [ 0.1796,  0.1783,  0.1766],\n",
            "          [-0.1248, -0.0864, -0.0336]],\n",
            "\n",
            "         [[ 0.0238, -0.0957, -0.1886],\n",
            "          [ 0.0946,  0.0240,  0.0776],\n",
            "          [ 0.0128, -0.1983,  0.1339]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1717, -0.1048, -0.1650],\n",
            "          [-0.1764,  0.0649,  0.0912],\n",
            "          [ 0.0987,  0.0211,  0.0316]],\n",
            "\n",
            "         [[-0.1169,  0.0198,  0.0652],\n",
            "          [-0.0017,  0.0652, -0.0149],\n",
            "          [-0.0634, -0.1268, -0.0268]],\n",
            "\n",
            "         [[-0.0754,  0.0757,  0.1068],\n",
            "          [ 0.0743, -0.0299,  0.0271],\n",
            "          [-0.1845, -0.1561,  0.1426]]],\n",
            "\n",
            "\n",
            "        [[[-0.1774, -0.1096,  0.0817],\n",
            "          [ 0.1449, -0.0206, -0.0963],\n",
            "          [ 0.1000, -0.1177, -0.0562]],\n",
            "\n",
            "         [[-0.1334,  0.1086, -0.0048],\n",
            "          [-0.0637,  0.1135, -0.1748],\n",
            "          [-0.0421,  0.1827,  0.0190]],\n",
            "\n",
            "         [[-0.0166, -0.0723,  0.0809],\n",
            "          [ 0.0954,  0.0572, -0.1717],\n",
            "          [-0.0144, -0.0817,  0.1358]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1553,  0.0778,  0.2236],\n",
            "          [-0.1011,  0.1511,  0.1689],\n",
            "          [ 0.0327,  0.0221, -0.0071]],\n",
            "\n",
            "         [[-0.1582,  0.1699, -0.0531],\n",
            "          [-0.0468, -0.0095,  0.0567],\n",
            "          [ 0.0894, -0.0809,  0.1096]],\n",
            "\n",
            "         [[-0.2683, -0.0396,  0.0290],\n",
            "          [-0.0659,  0.0215, -0.1533],\n",
            "          [-0.0826,  0.0016, -0.0523]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0913, -0.1409, -0.0987],\n",
            "          [ 0.0331,  0.1245,  0.1399],\n",
            "          [ 0.1442,  0.0104, -0.1164]],\n",
            "\n",
            "         [[-0.0885,  0.0932,  0.1817],\n",
            "          [-0.1897, -0.1385, -0.1846],\n",
            "          [-0.1811, -0.2838, -0.1118]],\n",
            "\n",
            "         [[ 0.0671,  0.0615, -0.0131],\n",
            "          [ 0.0684,  0.0471, -0.0271],\n",
            "          [-0.2890, -0.0342, -0.0322]]],\n",
            "\n",
            "\n",
            "        [[[-0.1617, -0.2046, -0.1496],\n",
            "          [ 0.1506,  0.0568,  0.0187],\n",
            "          [ 0.1889,  0.1427,  0.0062]],\n",
            "\n",
            "         [[ 0.0165, -0.0072,  0.0024],\n",
            "          [-0.0916, -0.1801, -0.0389],\n",
            "          [-0.0550,  0.0683, -0.0027]],\n",
            "\n",
            "         [[-0.1851, -0.1153, -0.1948],\n",
            "          [-0.2125, -0.1385, -0.1576],\n",
            "          [-0.0931,  0.0882, -0.1868]]]], device='cuda:0', requires_grad=True)\n",
            "NPV_C1.bias Parameter containing:\n",
            "tensor([ 3.8880e-01,  9.9175e-02, -1.4613e-01,  1.8044e-01,  3.5509e-04,\n",
            "        -8.5881e-02,  2.6501e-01,  2.1108e-01, -1.6898e-01,  1.2074e-01,\n",
            "         8.0977e-02, -1.8222e-01,  2.7311e-01,  1.9575e-01,  2.6500e-01,\n",
            "         1.9010e-01,  2.2692e-02,  2.2980e-01, -4.8665e-02, -3.2929e-02,\n",
            "        -1.8030e-01, -7.7368e-02, -4.5941e-02,  1.5820e-01, -1.2998e-01,\n",
            "         1.2090e-01, -3.0799e-02,  2.0933e-01,  1.6629e-01,  3.6135e-01,\n",
            "         1.5455e-02, -1.1312e-01, -2.6882e-02, -1.7027e-01, -1.3972e-01,\n",
            "         2.6408e-01,  4.1599e-02,  3.3202e-01,  2.3471e-01,  3.9773e-01,\n",
            "        -3.9579e-02,  2.1876e-01, -7.6282e-02,  5.1885e-01,  3.2420e-01,\n",
            "         4.6654e-02, -1.2578e-01, -1.2196e-01,  1.7609e-01, -1.3781e-01,\n",
            "         2.9168e-01,  1.4049e-01,  9.9054e-02,  9.4923e-02, -1.0317e-01,\n",
            "         1.2417e-03,  2.2715e-01,  1.6220e-02,  5.0787e-02,  1.2075e-02,\n",
            "         2.4085e-01,  2.7753e-01,  1.1218e-01,  2.4147e-01], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_C2.weight Parameter containing:\n",
            "tensor([[[[ 1.2795e-02,  1.3024e-02,  1.6718e-03],\n",
            "          [ 1.4330e-02,  2.1080e-03, -2.1093e-02],\n",
            "          [-1.9844e-02,  7.4099e-03,  1.1752e-02]],\n",
            "\n",
            "         [[ 2.3633e-02,  4.0725e-02,  4.0163e-02],\n",
            "          [-3.2600e-04,  6.8998e-03,  3.5511e-02],\n",
            "          [ 2.5155e-02, -2.5464e-04, -1.5124e-02]],\n",
            "\n",
            "         [[-3.8316e-03,  1.7812e-02,  1.1543e-03],\n",
            "          [ 3.1030e-02,  2.4818e-02, -8.5459e-03],\n",
            "          [-3.5138e-02, -4.0016e-02,  1.2861e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.7728e-02,  1.8752e-03, -3.9247e-03],\n",
            "          [ 4.1860e-02,  3.2407e-02, -6.1621e-03],\n",
            "          [ 5.7783e-03, -9.4557e-03,  8.7565e-03]],\n",
            "\n",
            "         [[-2.8839e-02, -2.1621e-03,  3.3063e-02],\n",
            "          [ 1.1870e-02, -4.8600e-03, -2.4559e-02],\n",
            "          [ 3.3111e-02,  6.4041e-03,  3.5450e-02]],\n",
            "\n",
            "         [[-2.7867e-02,  2.2883e-03,  1.0410e-02],\n",
            "          [-1.1902e-02, -1.1454e-02, -2.9738e-02],\n",
            "          [-6.4977e-03,  4.5738e-02,  1.4489e-03]]],\n",
            "\n",
            "\n",
            "        [[[-7.0314e-03,  7.3950e-02, -1.7881e-02],\n",
            "          [ 2.1394e-02,  7.3615e-02,  6.1213e-02],\n",
            "          [ 5.8304e-02,  4.2287e-02,  1.5532e-02]],\n",
            "\n",
            "         [[-2.7836e-02, -3.5369e-02, -4.1584e-02],\n",
            "          [-1.3000e-02,  2.0785e-02, -4.7175e-02],\n",
            "          [ 2.5255e-02,  3.9250e-02, -4.2590e-02]],\n",
            "\n",
            "         [[ 1.8798e-02,  3.2952e-02,  6.7914e-03],\n",
            "          [ 2.0299e-02, -1.0945e-03,  7.9682e-03],\n",
            "          [ 5.8119e-03, -9.8711e-04,  7.3113e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3936e-02,  1.0200e-02,  2.4182e-02],\n",
            "          [-4.8683e-02,  1.2764e-02,  1.4222e-02],\n",
            "          [-4.8500e-02, -1.9068e-02, -1.6693e-02]],\n",
            "\n",
            "         [[-1.6837e-02, -1.6284e-02,  9.0357e-03],\n",
            "          [-1.8264e-02,  3.8696e-02, -7.2175e-04],\n",
            "          [ 3.5757e-02, -1.5141e-02, -1.9236e-02]],\n",
            "\n",
            "         [[-4.9397e-02, -4.9020e-02,  3.0795e-02],\n",
            "          [-3.4402e-02, -2.8008e-02, -7.7625e-03],\n",
            "          [-4.8633e-03, -5.0278e-02,  1.0889e-02]]],\n",
            "\n",
            "\n",
            "        [[[-8.0700e-03,  4.3863e-03,  2.4622e-02],\n",
            "          [ 1.0127e-02, -1.3672e-02,  7.5933e-03],\n",
            "          [ 3.9439e-02,  2.4301e-02,  4.2224e-02]],\n",
            "\n",
            "         [[-2.9486e-02,  2.2227e-02, -3.3412e-03],\n",
            "          [-2.3551e-02,  2.1548e-05, -1.4969e-03],\n",
            "          [ 1.9465e-02,  2.1685e-02, -3.0252e-02]],\n",
            "\n",
            "         [[ 3.8556e-02,  2.8072e-02,  2.2019e-02],\n",
            "          [-2.8489e-02,  4.1115e-03, -3.8508e-03],\n",
            "          [ 3.5412e-02, -3.7366e-02,  2.6904e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0159e-02,  9.9945e-03,  1.7511e-02],\n",
            "          [ 2.1846e-02, -1.0371e-02, -2.8384e-02],\n",
            "          [ 2.8068e-02,  9.4955e-03, -1.5796e-02]],\n",
            "\n",
            "         [[-3.2027e-02,  2.2613e-02,  1.1787e-02],\n",
            "          [ 2.3113e-02, -1.0625e-02, -1.4844e-02],\n",
            "          [ 1.1432e-03,  2.8015e-02,  1.6296e-02]],\n",
            "\n",
            "         [[-1.2561e-02,  3.3647e-02,  2.5101e-02],\n",
            "          [-5.6824e-03,  1.8102e-02, -7.5204e-04],\n",
            "          [ 6.1169e-03, -3.5216e-02, -1.3572e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-3.9630e-02,  1.9004e-02, -2.3150e-02],\n",
            "          [ 1.3975e-02, -1.1281e-02, -8.6513e-03],\n",
            "          [-4.0349e-02,  3.3102e-02, -2.8999e-03]],\n",
            "\n",
            "         [[ 7.6434e-04, -3.8855e-02,  2.7666e-02],\n",
            "          [-6.5618e-03,  9.7036e-03,  2.1912e-02],\n",
            "          [ 2.6553e-02, -7.2565e-03,  7.2816e-03]],\n",
            "\n",
            "         [[ 9.9435e-03, -1.2460e-02,  1.7940e-02],\n",
            "          [ 1.0583e-02, -1.5878e-02,  3.9786e-02],\n",
            "          [-3.2352e-02, -3.6952e-02, -1.5144e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.1872e-02, -2.0627e-02,  3.9000e-02],\n",
            "          [-3.0408e-02, -4.2366e-02,  1.4810e-04],\n",
            "          [-3.3391e-02,  3.3912e-02,  1.2934e-02]],\n",
            "\n",
            "         [[ 2.4937e-02,  7.9324e-03, -1.8246e-02],\n",
            "          [ 3.5615e-03,  4.3753e-03, -1.7149e-02],\n",
            "          [ 5.7683e-03,  2.3160e-02, -4.0370e-02]],\n",
            "\n",
            "         [[ 2.1592e-02, -5.9415e-03,  1.1441e-02],\n",
            "          [-3.7157e-02, -1.4831e-02, -7.9543e-03],\n",
            "          [-3.7806e-02, -3.4902e-02,  2.4479e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1110e-02, -2.0997e-02,  5.2595e-03],\n",
            "          [-5.0049e-04, -4.1871e-02,  1.9163e-02],\n",
            "          [ 1.9541e-04,  1.6780e-02, -2.4237e-02]],\n",
            "\n",
            "         [[ 2.5604e-02, -2.6141e-02,  2.2438e-02],\n",
            "          [ 3.2366e-02, -2.2218e-02, -1.5932e-03],\n",
            "          [ 2.9493e-02, -1.2454e-02, -3.1869e-02]],\n",
            "\n",
            "         [[ 2.2094e-02,  3.2593e-02,  1.8666e-02],\n",
            "          [-3.4020e-02,  4.0003e-02, -8.9435e-03],\n",
            "          [-1.3891e-02, -3.1252e-02,  1.0247e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.0652e-02, -3.1341e-02,  9.2212e-03],\n",
            "          [-1.4530e-02,  2.7138e-02, -1.8140e-02],\n",
            "          [-2.2247e-02, -2.4878e-02, -3.7754e-03]],\n",
            "\n",
            "         [[ 2.7464e-02,  2.9834e-02, -6.1930e-03],\n",
            "          [-1.6554e-03, -1.4129e-03, -3.6410e-02],\n",
            "          [ 6.1336e-03,  2.7428e-02, -3.3355e-02]],\n",
            "\n",
            "         [[ 4.9857e-03, -4.2330e-03, -1.8912e-02],\n",
            "          [-9.2343e-03, -1.6535e-02, -5.5364e-03],\n",
            "          [ 3.1269e-02, -1.5474e-03, -3.6740e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.8036e-02, -3.4495e-02,  3.2434e-02],\n",
            "          [-3.6494e-02, -3.7229e-02, -2.3079e-02],\n",
            "          [-2.9056e-02,  5.4047e-03, -2.2524e-02]],\n",
            "\n",
            "         [[ 2.5706e-02, -1.7955e-02, -1.2128e-02],\n",
            "          [-3.8464e-02,  1.6495e-03, -6.4057e-03],\n",
            "          [ 2.2855e-02,  5.7291e-03,  5.0758e-03]],\n",
            "\n",
            "         [[-1.0090e-02, -3.7446e-02, -4.0169e-02],\n",
            "          [-3.4805e-02, -6.0150e-03, -4.1091e-02],\n",
            "          [-1.9476e-02,  1.8200e-02, -8.4175e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.4779e-02,  5.1183e-03, -3.7032e-02],\n",
            "          [ 3.4379e-02,  1.5347e-02, -3.9780e-02],\n",
            "          [ 3.6821e-02,  1.6630e-02,  2.1696e-02]],\n",
            "\n",
            "         [[-2.9506e-02, -4.2962e-02,  2.4732e-02],\n",
            "          [-3.5223e-02,  8.9858e-03,  1.0706e-03],\n",
            "          [-4.7435e-03, -9.2958e-03, -3.5815e-02]],\n",
            "\n",
            "         [[-3.8931e-02,  4.6293e-03, -3.7342e-02],\n",
            "          [-4.2858e-02, -1.2652e-02, -2.2433e-02],\n",
            "          [ 2.8342e-02, -5.0848e-02, -1.2884e-04]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_C2.bias Parameter containing:\n",
            "tensor([-3.8265e-02,  2.0721e-02,  8.5584e-02, -5.4678e-02,  3.8442e-02,\n",
            "        -1.3765e-02,  8.4818e-02, -3.2240e-02, -2.2234e-02,  1.0975e-01,\n",
            "         1.5773e-01,  1.8387e-02,  1.3562e-04,  5.7770e-02, -4.2290e-02,\n",
            "        -3.5542e-02,  1.1503e-01, -1.7490e-02,  7.8498e-02,  1.5750e-02,\n",
            "         4.7021e-02, -2.1531e-02,  1.2862e-01, -2.0444e-02,  2.7607e-02,\n",
            "        -3.2524e-02,  1.8749e-01, -1.7656e-02,  8.1484e-03,  9.8821e-02,\n",
            "         5.7917e-02,  7.8176e-02, -3.9260e-02, -1.2805e-03, -1.1943e-02,\n",
            "        -1.5526e-02,  1.8017e-02,  1.6393e-01,  9.1474e-02,  2.6674e-02,\n",
            "         4.5712e-02, -2.2768e-02,  2.3648e-01,  1.0135e-01,  3.4693e-02,\n",
            "         1.0925e-01, -2.6574e-02, -5.0358e-02,  2.8488e-02,  1.7977e-01,\n",
            "         1.0913e-01,  1.2870e-01,  8.5307e-02,  5.5321e-02,  2.7930e-02,\n",
            "         5.3752e-02, -9.9367e-02,  1.1695e-02,  8.4253e-02, -1.8408e-02,\n",
            "        -4.2894e-02, -2.3478e-02, -5.1338e-02, -1.4456e-02], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_C3.weight Parameter containing:\n",
            "tensor([[[[ 0.0206,  0.0149, -0.0040],\n",
            "          [ 0.0143, -0.0117, -0.0372],\n",
            "          [ 0.0087,  0.0279, -0.0235]],\n",
            "\n",
            "         [[-0.0352, -0.0382, -0.0408],\n",
            "          [ 0.0293, -0.0104,  0.0271],\n",
            "          [ 0.0074,  0.0270,  0.0385]],\n",
            "\n",
            "         [[ 0.0240,  0.0115,  0.0451],\n",
            "          [-0.0253, -0.0188,  0.0082],\n",
            "          [ 0.0085, -0.0334, -0.0140]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0296,  0.0128,  0.0022],\n",
            "          [ 0.0086, -0.0166, -0.0199],\n",
            "          [-0.0199, -0.0119, -0.0273]],\n",
            "\n",
            "         [[-0.0039, -0.0060, -0.0016],\n",
            "          [-0.0150,  0.0173,  0.0072],\n",
            "          [ 0.0408, -0.0008, -0.0014]],\n",
            "\n",
            "         [[-0.0125, -0.0163, -0.0098],\n",
            "          [-0.0017,  0.0355,  0.0079],\n",
            "          [-0.0336, -0.0305, -0.0019]]],\n",
            "\n",
            "\n",
            "        [[[-0.0067,  0.0064, -0.0273],\n",
            "          [ 0.0238, -0.0016, -0.0153],\n",
            "          [-0.0209,  0.0332, -0.0114]],\n",
            "\n",
            "         [[ 0.0203, -0.0028,  0.0052],\n",
            "          [-0.0282, -0.0046,  0.0089],\n",
            "          [ 0.0230,  0.0378,  0.0272]],\n",
            "\n",
            "         [[ 0.0487, -0.0141,  0.0122],\n",
            "          [ 0.0385,  0.0117,  0.0189],\n",
            "          [ 0.0107, -0.0297,  0.0330]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0274, -0.0177, -0.0250],\n",
            "          [-0.0237, -0.0084, -0.0234],\n",
            "          [-0.0013,  0.0109,  0.0274]],\n",
            "\n",
            "         [[-0.0095, -0.0389,  0.0301],\n",
            "          [-0.0396,  0.0124,  0.0085],\n",
            "          [-0.0298, -0.0185, -0.0420]],\n",
            "\n",
            "         [[ 0.0089, -0.0314, -0.0143],\n",
            "          [-0.0046,  0.0052,  0.0088],\n",
            "          [-0.0188, -0.0033,  0.0236]]],\n",
            "\n",
            "\n",
            "        [[[-0.0260, -0.0375,  0.0091],\n",
            "          [ 0.0014, -0.0011, -0.0084],\n",
            "          [ 0.0148, -0.0060, -0.0292]],\n",
            "\n",
            "         [[ 0.0588,  0.0659,  0.0196],\n",
            "          [ 0.0444,  0.0069,  0.0317],\n",
            "          [ 0.0183,  0.0494,  0.0372]],\n",
            "\n",
            "         [[-0.0279, -0.0368, -0.0515],\n",
            "          [-0.0282, -0.0403, -0.0087],\n",
            "          [ 0.0138, -0.0247, -0.0662]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0337,  0.0052, -0.0213],\n",
            "          [ 0.0112, -0.0331, -0.0073],\n",
            "          [-0.0231, -0.0299, -0.0371]],\n",
            "\n",
            "         [[ 0.0243, -0.0413, -0.0102],\n",
            "          [ 0.0173, -0.0242,  0.0180],\n",
            "          [ 0.0089, -0.0394,  0.0009]],\n",
            "\n",
            "         [[-0.0417,  0.0406,  0.0180],\n",
            "          [ 0.0331,  0.0187,  0.0107],\n",
            "          [ 0.0327, -0.0057, -0.0262]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0118,  0.0413, -0.0209],\n",
            "          [ 0.0385,  0.0134, -0.0110],\n",
            "          [-0.0172,  0.0107, -0.0410]],\n",
            "\n",
            "         [[-0.0073, -0.0284, -0.0122],\n",
            "          [ 0.0238,  0.0342, -0.0195],\n",
            "          [-0.0334, -0.0019,  0.0326]],\n",
            "\n",
            "         [[ 0.0243,  0.0090,  0.0119],\n",
            "          [ 0.0165,  0.0006,  0.0052],\n",
            "          [ 0.0015, -0.0228,  0.0238]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0057, -0.0097,  0.0244],\n",
            "          [-0.0366, -0.0297,  0.0282],\n",
            "          [-0.0266, -0.0348,  0.0397]],\n",
            "\n",
            "         [[-0.0295,  0.0318,  0.0415],\n",
            "          [ 0.0357,  0.0399, -0.0337],\n",
            "          [ 0.0093, -0.0389, -0.0209]],\n",
            "\n",
            "         [[-0.0251, -0.0118, -0.0355],\n",
            "          [-0.0006, -0.0194, -0.0181],\n",
            "          [-0.0108, -0.0188, -0.0146]]],\n",
            "\n",
            "\n",
            "        [[[-0.0226, -0.0279,  0.0365],\n",
            "          [ 0.0008, -0.0238, -0.0409],\n",
            "          [-0.0050, -0.0210, -0.0139]],\n",
            "\n",
            "         [[ 0.0323,  0.0098, -0.0163],\n",
            "          [ 0.0103,  0.0404, -0.0031],\n",
            "          [-0.0311, -0.0137,  0.0082]],\n",
            "\n",
            "         [[ 0.0337,  0.0102, -0.0385],\n",
            "          [-0.0057, -0.0082, -0.0059],\n",
            "          [ 0.0141,  0.0358, -0.0139]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0124,  0.0246, -0.0099],\n",
            "          [ 0.0249, -0.0336, -0.0018],\n",
            "          [ 0.0322,  0.0275,  0.0336]],\n",
            "\n",
            "         [[-0.0078, -0.0330, -0.0142],\n",
            "          [ 0.0334, -0.0249, -0.0206],\n",
            "          [-0.0309,  0.0191, -0.0266]],\n",
            "\n",
            "         [[ 0.0403, -0.0093,  0.0157],\n",
            "          [-0.0164,  0.0053,  0.0331],\n",
            "          [-0.0341, -0.0125, -0.0200]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0044,  0.0380, -0.0311],\n",
            "          [-0.0291, -0.0216, -0.0124],\n",
            "          [-0.0384, -0.0043,  0.0146]],\n",
            "\n",
            "         [[ 0.0098, -0.0104,  0.0274],\n",
            "          [ 0.0275, -0.0027, -0.0005],\n",
            "          [-0.0189, -0.0363, -0.0163]],\n",
            "\n",
            "         [[-0.0469, -0.0254, -0.0446],\n",
            "          [-0.0157, -0.0183, -0.0143],\n",
            "          [ 0.0314, -0.0070, -0.0301]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0270, -0.0314,  0.0182],\n",
            "          [-0.0215,  0.0208, -0.0269],\n",
            "          [ 0.0143, -0.0184,  0.0201]],\n",
            "\n",
            "         [[-0.0231,  0.0122,  0.0198],\n",
            "          [ 0.0025,  0.0249,  0.0286],\n",
            "          [-0.0400, -0.0230, -0.0231]],\n",
            "\n",
            "         [[-0.0149, -0.0164,  0.0407],\n",
            "          [ 0.0410,  0.0151, -0.0291],\n",
            "          [-0.0241, -0.0282, -0.0393]]]], device='cuda:0', requires_grad=True)\n",
            "NPV_C3.bias Parameter containing:\n",
            "tensor([ 5.8658e-02, -1.1918e-02,  2.7629e-03,  3.0597e-02,  2.4231e-02,\n",
            "         3.3997e-02, -1.2993e-02, -7.2624e-03,  2.1831e-02,  5.7206e-02,\n",
            "        -1.0662e-02, -9.9026e-05,  4.6477e-02,  2.2147e-02,  8.9550e-03,\n",
            "        -1.3397e-02,  3.7313e-02,  5.5154e-02, -5.1937e-03, -9.2502e-03,\n",
            "         1.5530e-02,  9.0005e-03, -8.2568e-03,  7.0932e-02,  4.2019e-02,\n",
            "         2.0602e-02, -3.6063e-02, -1.8038e-02, -9.7656e-03,  2.6640e-02,\n",
            "         8.2072e-02,  1.1894e-02,  8.5857e-03, -4.1213e-02,  3.1918e-02,\n",
            "         4.7979e-02, -1.1668e-02,  6.3337e-02,  4.6868e-02, -1.5207e-02,\n",
            "        -3.1621e-02,  6.2072e-02,  2.0664e-02,  3.3704e-02,  7.0749e-03,\n",
            "         1.3230e-02,  4.5258e-02, -3.5713e-02,  3.9267e-02,  3.5242e-02,\n",
            "         4.0443e-02,  6.0486e-02, -3.7095e-02,  3.5151e-02,  7.6439e-03,\n",
            "         2.8472e-03, -3.6970e-02, -3.6991e-03,  1.4517e-02, -5.1120e-02,\n",
            "         5.8266e-02,  7.7693e-02, -6.5555e-03, -7.1601e-02, -3.6778e-03,\n",
            "        -4.7257e-03, -1.2178e-02, -3.0296e-02,  1.3369e-02,  4.0319e-02,\n",
            "         3.3399e-02,  3.4223e-03, -1.3327e-03,  5.0022e-02,  4.1625e-02,\n",
            "         4.6928e-02,  4.0794e-02,  3.8608e-02, -3.5267e-02, -3.1845e-02,\n",
            "         3.1173e-02,  5.7686e-03,  4.1055e-02,  5.9281e-02,  4.9483e-02,\n",
            "         1.5365e-03,  2.8851e-02,  1.9094e-02, -2.2999e-03, -2.0765e-02,\n",
            "        -2.4859e-02, -3.3241e-02, -3.1006e-02,  1.2156e-02, -2.3571e-02,\n",
            "        -3.9846e-02,  7.1746e-03, -1.8311e-02,  2.0103e-02,  1.0006e-02,\n",
            "         4.1712e-03, -3.3153e-02,  6.4653e-02,  6.6523e-02, -3.2338e-02,\n",
            "         8.2669e-02, -1.9340e-02,  6.5498e-02,  5.4921e-04,  3.3903e-02,\n",
            "         5.9238e-02,  3.6908e-02,  4.7171e-02,  4.1041e-02,  4.6634e-02,\n",
            "        -1.8769e-02, -1.3927e-02, -2.8591e-02,  1.6134e-02, -2.3112e-03,\n",
            "        -2.2031e-02,  1.5270e-02,  9.7948e-03, -3.6457e-02,  1.3749e-02,\n",
            "        -2.5938e-02, -3.7902e-02,  5.2230e-03], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_C4.weight Parameter containing:\n",
            "tensor([[[[ 2.4454e-03,  2.8294e-02, -5.5443e-03],\n",
            "          [-6.6847e-03, -3.5573e-03,  1.0005e-02],\n",
            "          [ 1.3160e-03,  6.4468e-04,  7.0669e-03]],\n",
            "\n",
            "         [[-7.2675e-03, -1.5046e-03, -3.2803e-03],\n",
            "          [-2.8632e-03,  1.3469e-02, -6.3629e-03],\n",
            "          [ 4.1701e-02,  3.4896e-02,  1.2846e-03]],\n",
            "\n",
            "         [[ 4.0260e-03, -1.7382e-02,  1.3823e-02],\n",
            "          [-2.2063e-02,  1.1956e-02,  1.3596e-02],\n",
            "          [-1.7282e-02, -9.5268e-03,  2.9690e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.7385e-05, -4.5446e-03, -1.6399e-02],\n",
            "          [ 1.0352e-02,  1.3650e-02, -4.1555e-03],\n",
            "          [-7.1255e-03, -1.1854e-02, -1.6691e-02]],\n",
            "\n",
            "         [[ 1.7470e-02,  1.1244e-02,  7.7693e-03],\n",
            "          [-2.4872e-03,  1.5603e-02, -2.9169e-03],\n",
            "          [-1.9275e-02,  2.2711e-02, -2.7731e-02]],\n",
            "\n",
            "         [[-1.0865e-02, -5.3024e-03, -1.0728e-02],\n",
            "          [-2.1926e-02, -6.6157e-03,  9.6640e-03],\n",
            "          [-1.5576e-02,  3.4301e-03, -2.2296e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.4479e-02,  7.1722e-03,  9.7376e-03],\n",
            "          [ 1.2544e-02, -5.5421e-03, -3.2140e-02],\n",
            "          [-1.4330e-02,  6.4103e-03,  2.5454e-02]],\n",
            "\n",
            "         [[-1.9578e-02,  2.1071e-02,  5.0798e-03],\n",
            "          [ 2.5177e-02, -4.3617e-03,  2.5125e-02],\n",
            "          [-2.0858e-02,  2.5316e-02, -2.4163e-02]],\n",
            "\n",
            "         [[ 1.4882e-02, -4.3172e-02,  1.0708e-02],\n",
            "          [ 6.6623e-03, -3.2468e-02, -1.1260e-02],\n",
            "          [ 4.9208e-03,  3.0869e-02,  2.8691e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-8.3948e-03, -1.3663e-02,  2.5323e-02],\n",
            "          [ 2.7332e-02,  7.4345e-03,  1.8858e-02],\n",
            "          [-2.4884e-02, -1.5742e-02, -2.6145e-02]],\n",
            "\n",
            "         [[-1.5791e-02,  1.6591e-02, -1.3100e-02],\n",
            "          [ 1.3827e-03,  2.2141e-03,  5.7314e-03],\n",
            "          [ 9.1710e-03,  2.7518e-02, -4.8100e-03]],\n",
            "\n",
            "         [[ 1.6280e-02, -2.5662e-02,  2.4554e-02],\n",
            "          [ 2.3105e-02,  2.0045e-02, -8.3601e-03],\n",
            "          [-2.3764e-02, -2.3826e-02,  5.2890e-03]]],\n",
            "\n",
            "\n",
            "        [[[-2.8070e-02,  5.6426e-03,  1.9644e-02],\n",
            "          [-2.2974e-02,  1.9323e-02,  7.9765e-03],\n",
            "          [-2.6895e-02,  2.1784e-03,  5.3605e-04]],\n",
            "\n",
            "         [[-5.6596e-03,  8.9005e-03, -2.1077e-02],\n",
            "          [-2.6411e-02,  1.7802e-02,  2.3467e-02],\n",
            "          [-2.4498e-02, -1.8286e-02, -7.6300e-03]],\n",
            "\n",
            "         [[ 2.6850e-02, -2.2523e-02,  1.2204e-02],\n",
            "          [ 1.1134e-02, -2.5010e-02, -2.1763e-02],\n",
            "          [-2.5940e-02,  2.9173e-03, -6.0935e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.0137e-03,  1.0491e-02, -2.7718e-02],\n",
            "          [-2.5110e-03, -1.9970e-02, -2.1030e-02],\n",
            "          [-6.7107e-03, -1.6024e-02,  1.5382e-02]],\n",
            "\n",
            "         [[ 2.8131e-02, -3.5061e-03,  3.7372e-03],\n",
            "          [-1.6312e-02,  2.6354e-02, -1.9321e-02],\n",
            "          [ 2.6065e-02,  7.6885e-03,  1.3167e-03]],\n",
            "\n",
            "         [[-2.9840e-03,  6.7482e-03, -5.8566e-03],\n",
            "          [ 2.5719e-04, -6.0576e-03,  2.6830e-02],\n",
            "          [-3.9983e-03,  9.0565e-03, -1.5697e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-1.1773e-02, -5.5434e-03, -2.3964e-02],\n",
            "          [ 9.8521e-03, -1.6047e-02,  1.3192e-02],\n",
            "          [-1.7696e-02, -2.0552e-03,  1.4234e-02]],\n",
            "\n",
            "         [[ 6.9268e-03, -2.2977e-02,  9.9900e-03],\n",
            "          [-2.7654e-02,  2.1343e-02, -1.6087e-02],\n",
            "          [ 1.8820e-02, -2.8849e-02, -1.6687e-02]],\n",
            "\n",
            "         [[ 3.0032e-02,  1.8149e-02,  2.9018e-02],\n",
            "          [ 2.9804e-02,  1.1852e-02,  9.6269e-03],\n",
            "          [-7.3335e-03,  6.3620e-03, -2.5884e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5808e-02, -1.5322e-03, -1.5990e-02],\n",
            "          [ 2.2511e-02, -2.1838e-02, -2.1104e-02],\n",
            "          [-2.7539e-02,  2.5124e-02, -1.7475e-02]],\n",
            "\n",
            "         [[ 2.6096e-02, -1.8386e-02, -2.8803e-02],\n",
            "          [ 2.2936e-02, -1.5313e-03, -2.1854e-02],\n",
            "          [-1.1890e-02,  5.4764e-03, -1.4316e-02]],\n",
            "\n",
            "         [[-7.7319e-03, -2.4281e-02,  2.6021e-02],\n",
            "          [-2.0405e-02, -1.0289e-02, -1.6216e-02],\n",
            "          [-2.3293e-02, -7.7919e-03,  2.7950e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.4348e-03, -2.2034e-02,  1.9003e-02],\n",
            "          [-5.7733e-03,  3.3121e-02, -6.6066e-03],\n",
            "          [ 2.6333e-02,  2.7615e-02,  4.1788e-02]],\n",
            "\n",
            "         [[ 1.1617e-02, -2.0851e-02, -2.5921e-02],\n",
            "          [ 2.5214e-02,  5.6474e-03,  2.7262e-02],\n",
            "          [ 3.4017e-03,  2.3502e-02, -1.3943e-02]],\n",
            "\n",
            "         [[-6.2927e-03, -9.8941e-03,  1.0183e-02],\n",
            "          [ 1.4180e-02, -2.8019e-02,  2.3264e-02],\n",
            "          [ 1.8673e-03,  1.6985e-03,  4.0528e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.8874e-02, -7.7120e-03,  2.4072e-02],\n",
            "          [-5.3255e-03, -2.7018e-02, -9.6888e-03],\n",
            "          [ 5.1629e-03,  8.7470e-03,  1.1779e-03]],\n",
            "\n",
            "         [[-1.9085e-03,  5.4312e-03, -1.5485e-03],\n",
            "          [ 2.5887e-02, -8.4376e-03,  1.5590e-02],\n",
            "          [ 7.4100e-03,  5.2030e-03, -1.1790e-02]],\n",
            "\n",
            "         [[ 1.1457e-02,  5.0424e-03,  1.6055e-02],\n",
            "          [ 2.8938e-03,  5.4813e-03,  1.7064e-02],\n",
            "          [-2.8151e-02,  1.5314e-02, -5.9978e-04]]],\n",
            "\n",
            "\n",
            "        [[[ 1.6305e-02,  2.0742e-02, -8.1120e-03],\n",
            "          [-1.5988e-02, -1.8601e-02, -2.1985e-02],\n",
            "          [-1.0960e-02,  4.6728e-03,  2.2070e-02]],\n",
            "\n",
            "         [[-2.5830e-02,  2.0755e-02,  1.6469e-02],\n",
            "          [-1.5911e-03, -1.4914e-02, -1.8355e-02],\n",
            "          [-2.5427e-02,  2.1054e-02, -3.8039e-03]],\n",
            "\n",
            "         [[ 2.2834e-02, -2.1443e-02,  3.1506e-03],\n",
            "          [ 1.6273e-02,  1.4251e-02, -2.4991e-02],\n",
            "          [-2.4590e-02,  2.9539e-03,  2.0232e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.9092e-03, -1.5605e-02,  9.9270e-03],\n",
            "          [ 1.2739e-02, -1.7616e-02, -2.7700e-02],\n",
            "          [-1.0216e-02,  2.2119e-02,  1.1230e-02]],\n",
            "\n",
            "         [[-1.9667e-02,  1.7633e-02, -7.8635e-03],\n",
            "          [-1.8069e-02, -1.7068e-02, -4.3851e-03],\n",
            "          [-1.8629e-02,  6.0973e-03,  5.7725e-03]],\n",
            "\n",
            "         [[-8.2015e-03,  9.5618e-03,  2.1449e-03],\n",
            "          [ 2.6154e-02, -2.1474e-02,  2.4219e-02],\n",
            "          [-2.4545e-02, -1.7435e-03, -2.6964e-02]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_C4.bias Parameter containing:\n",
            "tensor([ 0.0028,  0.0181, -0.0094,  0.0029,  0.0036,  0.0505,  0.0507,  0.0127,\n",
            "         0.0203, -0.0280, -0.0181,  0.0116, -0.0150, -0.0074,  0.0083,  0.0303,\n",
            "         0.0116,  0.0363,  0.0052,  0.0260,  0.0532, -0.0170, -0.0028,  0.0192,\n",
            "        -0.0009,  0.0099, -0.0143,  0.0101,  0.0191,  0.0108,  0.0215,  0.0285,\n",
            "         0.0323, -0.0204,  0.0609,  0.0312, -0.0161, -0.0223, -0.0093, -0.0389,\n",
            "         0.1183,  0.0035, -0.0051,  0.0042,  0.0363,  0.0461,  0.0149,  0.0437,\n",
            "        -0.0109,  0.0218, -0.0135,  0.0214, -0.0108, -0.0063, -0.0413,  0.0013,\n",
            "        -0.0047,  0.0462,  0.0095,  0.0242, -0.0098,  0.0294, -0.0065, -0.0027,\n",
            "         0.0096,  0.0348,  0.0094,  0.0538, -0.0070,  0.0156,  0.0177,  0.0019,\n",
            "        -0.0167,  0.0250, -0.0201, -0.0254, -0.0108, -0.0145,  0.0416,  0.0127,\n",
            "        -0.0236, -0.0108,  0.0137,  0.0254,  0.0240, -0.0250,  0.0108,  0.0169,\n",
            "        -0.0436,  0.0350,  0.0305,  0.0245, -0.0155,  0.0047,  0.0171, -0.0021,\n",
            "        -0.0357,  0.0517,  0.0157,  0.0376,  0.0116, -0.0007, -0.0294,  0.0187,\n",
            "        -0.0036,  0.0111,  0.0169,  0.0061,  0.0442,  0.0300,  0.0193, -0.0205,\n",
            "         0.0071,  0.0030,  0.0155,  0.0312,  0.0228, -0.0008,  0.0065,  0.0632,\n",
            "        -0.0129, -0.0514,  0.0229,  0.0538,  0.0427, -0.0249,  0.0227, -0.0078],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_D1.weight Parameter containing:\n",
            "tensor([[-3.0023e-04,  6.0074e-04, -2.8234e-04,  ..., -2.5822e-04,\n",
            "          4.9905e-04,  2.3747e-03],\n",
            "        [ 1.0131e-03, -1.7602e-03, -9.7961e-06,  ..., -2.1307e-03,\n",
            "          3.9197e-04,  1.1674e-03],\n",
            "        [-3.6395e-05,  7.2287e-04,  8.4244e-04,  ...,  9.5327e-04,\n",
            "         -1.0838e-03, -8.0702e-04],\n",
            "        ...,\n",
            "        [-2.1494e-03,  1.5694e-03,  2.2425e-03,  ...,  1.1880e-03,\n",
            "          4.1344e-04,  1.0676e-03],\n",
            "        [-1.7881e-03, -8.2811e-04, -2.1738e-05,  ...,  1.1361e-03,\n",
            "          1.2870e-03, -1.7313e-03],\n",
            "        [-2.2478e-03,  2.8066e-03,  3.5349e-04,  ...,  9.1337e-04,\n",
            "         -1.6853e-03, -6.3947e-04]], device='cuda:0', requires_grad=True)\n",
            "NPV_D1.bias Parameter containing:\n",
            "tensor([ 8.6063e-04,  3.9196e-03, -3.6497e-03,  2.3992e-03, -1.0904e-03,\n",
            "         5.5265e-03, -3.9155e-03, -4.7094e-03, -8.7364e-04,  7.5567e-05,\n",
            "         2.4123e-03,  2.2220e-03, -4.7840e-04, -4.2845e-03, -1.8349e-03,\n",
            "         1.7234e-03, -9.2989e-04,  8.8280e-03, -2.4807e-03, -1.9099e-03,\n",
            "        -2.0661e-03, -2.6096e-03, -7.4076e-05, -1.4348e-03,  2.4551e-03,\n",
            "         1.0610e-03,  4.5251e-03, -3.4898e-03,  8.3485e-04, -1.2968e-04,\n",
            "        -2.9535e-03,  2.3803e-03, -3.3915e-03, -2.4941e-03,  6.5216e-03,\n",
            "         1.1231e-03,  6.2266e-04, -4.6174e-03,  1.1387e-04, -3.5782e-05,\n",
            "         1.2679e-03, -7.2181e-04,  8.9854e-05,  9.6166e-04, -3.0442e-03,\n",
            "        -2.5436e-03,  2.4251e-03, -8.4343e-04, -2.9125e-03, -6.1892e-03,\n",
            "         4.3135e-04,  5.6867e-03,  2.4657e-04, -2.9897e-03,  8.1884e-04,\n",
            "         3.0991e-04,  9.3189e-04,  9.0035e-03, -4.1585e-03,  4.1624e-03,\n",
            "         7.7354e-04, -2.2876e-03, -2.0146e-03, -3.5218e-03,  1.8719e-03,\n",
            "         1.7298e-03, -4.4944e-03, -4.7730e-03, -3.3151e-03, -1.4443e-03,\n",
            "        -1.2630e-03, -3.2899e-04, -3.8286e-03,  2.6272e-03, -2.3353e-03,\n",
            "        -2.2347e-03,  4.6611e-04,  6.7995e-04,  4.6725e-03, -2.9745e-03,\n",
            "         2.4707e-03,  1.0555e-04, -2.3118e-03,  3.2668e-03, -4.7012e-03,\n",
            "        -3.8226e-03,  1.1334e-03, -7.3907e-04, -1.2227e-03, -3.6681e-03,\n",
            "        -2.4770e-03,  3.3172e-03,  8.5947e-03, -4.4229e-04, -1.7151e-03,\n",
            "         3.9979e-03, -7.3761e-03, -3.3309e-03, -7.5489e-03, -3.2199e-03,\n",
            "         3.0908e-03,  2.6799e-03,  5.0888e-04,  1.9523e-03, -3.3192e-03,\n",
            "        -3.5951e-03,  3.7574e-03, -2.3381e-03,  2.4124e-05, -4.5186e-03,\n",
            "         2.9022e-03, -2.9476e-03,  1.5208e-03,  4.2011e-04,  6.2707e-03,\n",
            "        -3.3202e-03, -1.4965e-03, -7.9202e-04,  1.4478e-03, -8.6096e-04,\n",
            "        -3.6465e-03,  2.6677e-04,  1.5602e-03, -9.1552e-03, -2.1625e-03,\n",
            "        -3.1356e-03, -4.1133e-04, -5.2367e-03, -6.0285e-03, -3.7716e-03,\n",
            "         2.3528e-03,  2.6120e-03,  2.8292e-03, -3.8737e-03,  1.0755e-02,\n",
            "        -2.8219e-05,  1.0858e-03,  6.9041e-03,  1.4606e-03,  5.0132e-03,\n",
            "         3.2870e-03, -6.0537e-03, -4.4542e-03,  6.0147e-04, -1.6961e-04,\n",
            "         3.1129e-03,  3.0899e-04, -4.4671e-03, -1.1268e-03,  1.8175e-03,\n",
            "         2.0084e-03, -6.2695e-04,  1.8250e-03, -2.5199e-04, -1.8888e-03,\n",
            "         2.1750e-03,  1.3587e-03, -2.6374e-03, -3.9235e-03,  1.9813e-03,\n",
            "        -7.5301e-05, -3.7903e-03,  4.0137e-04, -1.5143e-03, -8.5199e-04,\n",
            "        -1.1307e-03,  1.6533e-03, -2.7511e-03, -2.8921e-03,  1.3765e-03,\n",
            "         1.9832e-03,  5.2144e-03, -5.9422e-03,  7.5305e-03, -1.2540e-02,\n",
            "        -7.6304e-03, -7.2869e-04,  1.7376e-03,  8.6251e-03,  3.0583e-03,\n",
            "         1.8618e-03,  4.5052e-04,  3.2217e-04, -3.8037e-03,  3.8198e-04,\n",
            "         8.1526e-04,  5.9766e-04, -2.2936e-03,  3.4624e-03,  1.3666e-03,\n",
            "        -1.1267e-03, -6.4027e-03,  6.9965e-04, -5.7267e-04, -1.5861e-03,\n",
            "        -6.1869e-03, -5.8489e-03, -1.5588e-03,  2.6132e-04,  9.1375e-04,\n",
            "         2.4585e-03,  1.3410e-03,  1.0934e-03,  1.1336e-03,  2.7686e-04,\n",
            "        -4.5604e-03, -4.2578e-03, -1.5421e-04,  2.5125e-03,  3.4905e-03,\n",
            "        -2.0870e-03, -2.8835e-03,  1.1452e-04,  4.5453e-03,  2.4088e-03,\n",
            "        -3.8710e-04, -5.6093e-03, -7.3643e-03,  1.1369e-02,  6.9153e-03,\n",
            "        -6.4760e-04,  6.5001e-03, -3.0167e-04,  3.5995e-04,  3.2056e-03,\n",
            "         2.0438e-04,  4.0571e-03, -2.0880e-03, -2.9999e-04,  3.9887e-03,\n",
            "        -1.4828e-03, -3.2567e-03, -2.8694e-03, -2.5234e-03,  4.5766e-03,\n",
            "        -2.7437e-04,  6.7241e-03, -1.1746e-03,  2.2042e-03, -9.6143e-04,\n",
            "         3.4065e-04, -3.1262e-03, -6.9494e-04, -1.0530e-02, -5.9354e-04,\n",
            "         2.6175e-03,  4.5465e-04,  4.2043e-04, -1.6494e-03, -8.9003e-04,\n",
            "        -2.2590e-03, -3.9418e-03, -2.1291e-03, -2.0940e-03,  2.6878e-04,\n",
            "        -9.5293e-04], device='cuda:0', requires_grad=True)\n",
            "NPV_D2.weight Parameter containing:\n",
            "tensor([[-0.0120,  0.0577,  0.0185,  ...,  0.0342,  0.0062,  0.0300],\n",
            "        [ 0.0150, -0.0106,  0.0334,  ..., -0.0532, -0.0606, -0.0127],\n",
            "        [ 0.0232,  0.0341,  0.0058,  ..., -0.0607, -0.0118,  0.0387],\n",
            "        ...,\n",
            "        [-0.0289, -0.0424,  0.0422,  ..., -0.0270, -0.0313, -0.0425],\n",
            "        [-0.0071, -0.0161, -0.0303,  ..., -0.0205, -0.0411, -0.0544],\n",
            "        [-0.0409,  0.0102,  0.0087,  ...,  0.0176,  0.0265,  0.0466]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_D2.bias Parameter containing:\n",
            "tensor([ 4.9640e-02, -5.5200e-03, -1.3714e-03,  2.5640e-02,  2.3941e-02,\n",
            "         2.6074e-02,  1.3986e-02, -5.0086e-02,  4.6359e-02,  2.4721e-02,\n",
            "        -5.6053e-02,  4.8152e-02,  2.0748e-02, -2.3459e-02, -4.5537e-02,\n",
            "        -4.7603e-02,  6.9604e-02, -1.2240e-03, -3.2961e-02, -1.8637e-02,\n",
            "         6.8849e-03,  4.4881e-02, -1.5543e-02,  3.2507e-02,  3.6914e-02,\n",
            "        -5.6116e-02, -3.5767e-02, -2.3632e-02,  3.1047e-02,  5.3916e-02,\n",
            "        -3.9817e-02, -6.1422e-02,  3.1318e-02, -3.8902e-02,  2.0803e-02,\n",
            "        -4.5773e-02,  2.6504e-02, -3.3336e-02, -1.5884e-02,  3.3795e-02,\n",
            "        -3.9326e-02, -5.2541e-03,  4.3901e-02,  4.6329e-02, -2.1235e-02,\n",
            "         6.3353e-02, -2.7731e-02,  3.1681e-02, -5.3806e-02,  1.8374e-02,\n",
            "        -1.9200e-02, -3.0446e-02, -1.0903e-03, -7.9241e-03, -4.2275e-02,\n",
            "         1.5479e-02, -4.9802e-03,  5.0753e-02, -4.3826e-02,  8.1389e-02,\n",
            "        -2.5006e-02, -1.7934e-02, -1.5366e-03,  4.1239e-02,  4.7575e-02,\n",
            "         2.6739e-02,  1.9089e-02,  5.5109e-02,  3.9644e-04,  3.3645e-02,\n",
            "        -3.3990e-02,  1.5401e-02, -9.6572e-04, -5.8629e-02,  2.5858e-02,\n",
            "        -2.7546e-02,  2.1132e-02,  1.3197e-02,  3.1339e-03,  7.5012e-03,\n",
            "         1.3827e-02, -4.5316e-02, -4.1534e-02, -5.3234e-02, -6.0035e-02,\n",
            "        -1.6249e-02,  2.4466e-02,  6.2988e-02,  6.3106e-03, -6.0220e-02,\n",
            "        -4.0685e-02, -1.1310e-02,  2.2897e-02,  2.5986e-02,  1.9525e-02,\n",
            "        -2.7492e-02, -6.2440e-02, -4.9744e-02,  4.6786e-02,  2.4975e-02,\n",
            "        -5.4143e-02, -4.1255e-02,  3.2503e-02, -1.1451e-03, -8.6786e-03,\n",
            "        -5.7485e-03, -1.8174e-05,  3.2470e-02, -4.4377e-02,  2.3365e-02,\n",
            "         2.3453e-02,  6.0222e-02, -1.8657e-02,  4.1725e-02,  2.9321e-02,\n",
            "        -8.1131e-03, -9.9450e-03, -6.0074e-02,  2.0823e-02, -5.8446e-02,\n",
            "        -5.2561e-02, -4.0736e-02,  6.6417e-02,  3.5812e-02, -3.9344e-02,\n",
            "        -1.0043e-02,  4.4128e-02,  5.0786e-02,  9.4664e-03, -1.5104e-02,\n",
            "        -3.8943e-02, -4.5548e-03, -3.9626e-02,  1.4561e-02, -1.2791e-02,\n",
            "        -4.4239e-02,  5.6169e-03,  2.3975e-02, -5.2809e-02,  3.4700e-02,\n",
            "         1.1616e-02,  1.4478e-02, -2.0430e-02, -6.0730e-02, -4.6888e-02,\n",
            "        -1.5930e-02,  5.9418e-02, -3.6613e-02, -1.5844e-02, -4.3845e-02,\n",
            "         5.2060e-02, -3.1807e-02,  3.3457e-02, -5.3262e-02, -5.1050e-03,\n",
            "         1.2051e-02,  5.9793e-02, -1.0756e-02, -5.2606e-02, -3.0719e-02,\n",
            "        -1.0125e-02,  6.7022e-02, -2.9529e-02, -2.8564e-02, -2.6987e-02,\n",
            "         3.2786e-02, -1.4356e-02, -5.9372e-02, -2.8011e-02,  2.8575e-02,\n",
            "         4.5446e-02, -3.7747e-02,  5.9698e-02, -5.2459e-02, -9.7736e-03,\n",
            "        -2.9349e-02,  5.5371e-02, -4.8114e-02,  4.9033e-02,  9.4716e-03,\n",
            "         4.9984e-02,  2.4798e-02,  4.1582e-02,  2.9914e-02,  3.3580e-02,\n",
            "         4.8553e-02,  2.0942e-02, -9.0445e-03, -3.2369e-02, -4.6239e-02,\n",
            "         2.1608e-02,  4.5814e-02, -2.4475e-02, -1.7439e-02,  6.2273e-02,\n",
            "        -5.4779e-02, -5.9386e-02,  2.9744e-02,  1.5049e-02, -6.7944e-03,\n",
            "         2.1479e-02, -3.1490e-02, -7.5202e-03,  7.0203e-02,  3.2396e-02,\n",
            "         9.3788e-03, -1.7114e-02,  2.0970e-02, -7.2187e-03, -3.2610e-02,\n",
            "        -4.2348e-02, -4.0659e-02, -9.1748e-03,  6.0199e-02, -4.3351e-02,\n",
            "         8.8749e-03,  1.6162e-02, -3.2280e-02, -5.0434e-02, -6.2328e-02,\n",
            "         8.9980e-03,  3.9841e-02, -3.4128e-02,  4.2061e-02,  2.5145e-02,\n",
            "        -6.5564e-03,  5.5520e-03,  3.4106e-02, -1.9467e-02,  5.0457e-02,\n",
            "         3.4763e-02,  1.1495e-02,  4.5012e-02, -1.2182e-03, -1.9191e-02,\n",
            "        -7.5478e-03, -5.1229e-02,  4.6809e-02, -2.4582e-02,  1.2692e-02,\n",
            "        -5.2206e-02,  4.5416e-02, -5.2554e-02,  1.3361e-02,  6.5966e-02,\n",
            "        -4.3550e-03, -3.6540e-02,  9.2859e-03, -1.6439e-02, -4.4848e-02,\n",
            "        -3.5843e-02, -4.1948e-02, -1.4050e-02, -1.7951e-03, -1.5327e-02,\n",
            "         2.8468e-02], device='cuda:0', requires_grad=True)\n",
            "outputs.weight Parameter containing:\n",
            "tensor([[-0.0998,  0.0300,  0.0209,  ..., -0.1635,  0.0062, -0.0827],\n",
            "        [ 0.0409, -0.0077,  0.0064,  ...,  0.0232,  0.0236, -0.1217],\n",
            "        [-0.0570, -0.0024, -0.1571,  ..., -0.0571,  0.0116, -0.0653],\n",
            "        ...,\n",
            "        [-0.0334, -0.0057,  0.0226,  ...,  0.1432, -0.0517,  0.1374],\n",
            "        [-0.0478, -0.0088,  0.0305,  ..., -0.0900,  0.0435,  0.0678],\n",
            "        [ 0.0165,  0.0498, -0.0298,  ...,  0.0545, -0.0305, -0.0064]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "outputs.bias Parameter containing:\n",
            "tensor([-0.0435, -0.0710,  0.0284,  0.0490,  0.0322, -0.0333,  0.0038, -0.0437,\n",
            "        -0.1262, -0.0189], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frnpf_di_model.state_dict().get(\"NPV_C1.weight\").data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzlm1lLp4T3r",
        "outputId": "2e7ced65-2464-49de-98b3-05104391cc38"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.1586, -0.0621, -0.1892],\n",
              "          [-0.1834, -0.1902,  0.1383],\n",
              "          [-0.0405, -0.1706,  0.0259]],\n",
              "\n",
              "         [[ 0.0793,  0.1458,  0.0343],\n",
              "          [ 0.1796,  0.1783,  0.1766],\n",
              "          [-0.1248, -0.0864, -0.0336]],\n",
              "\n",
              "         [[ 0.0238, -0.0957, -0.1886],\n",
              "          [ 0.0946,  0.0240,  0.0776],\n",
              "          [ 0.0128, -0.1983,  0.1339]]],\n",
              "\n",
              "\n",
              "        [[[ 0.1717, -0.1048, -0.1650],\n",
              "          [-0.1764,  0.0649,  0.0912],\n",
              "          [ 0.0987,  0.0211,  0.0316]],\n",
              "\n",
              "         [[-0.1169,  0.0198,  0.0652],\n",
              "          [-0.0017,  0.0652, -0.0149],\n",
              "          [-0.0634, -0.1268, -0.0268]],\n",
              "\n",
              "         [[-0.0754,  0.0757,  0.1068],\n",
              "          [ 0.0743, -0.0299,  0.0271],\n",
              "          [-0.1845, -0.1561,  0.1426]]],\n",
              "\n",
              "\n",
              "        [[[-0.1774, -0.1096,  0.0817],\n",
              "          [ 0.1449, -0.0206, -0.0963],\n",
              "          [ 0.1000, -0.1177, -0.0562]],\n",
              "\n",
              "         [[-0.1334,  0.1086, -0.0048],\n",
              "          [-0.0637,  0.1135, -0.1748],\n",
              "          [-0.0421,  0.1827,  0.0190]],\n",
              "\n",
              "         [[-0.0166, -0.0723,  0.0809],\n",
              "          [ 0.0954,  0.0572, -0.1717],\n",
              "          [-0.0144, -0.0817,  0.1358]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[-0.1553,  0.0778,  0.2236],\n",
              "          [-0.1011,  0.1511,  0.1689],\n",
              "          [ 0.0327,  0.0221, -0.0071]],\n",
              "\n",
              "         [[-0.1582,  0.1699, -0.0531],\n",
              "          [-0.0468, -0.0095,  0.0567],\n",
              "          [ 0.0894, -0.0809,  0.1096]],\n",
              "\n",
              "         [[-0.2683, -0.0396,  0.0290],\n",
              "          [-0.0659,  0.0215, -0.1533],\n",
              "          [-0.0826,  0.0016, -0.0523]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0913, -0.1409, -0.0987],\n",
              "          [ 0.0331,  0.1245,  0.1399],\n",
              "          [ 0.1442,  0.0104, -0.1164]],\n",
              "\n",
              "         [[-0.0885,  0.0932,  0.1817],\n",
              "          [-0.1897, -0.1385, -0.1846],\n",
              "          [-0.1811, -0.2838, -0.1118]],\n",
              "\n",
              "         [[ 0.0671,  0.0615, -0.0131],\n",
              "          [ 0.0684,  0.0471, -0.0271],\n",
              "          [-0.2890, -0.0342, -0.0322]]],\n",
              "\n",
              "\n",
              "        [[[-0.1617, -0.2046, -0.1496],\n",
              "          [ 0.1506,  0.0568,  0.0187],\n",
              "          [ 0.1889,  0.1427,  0.0062]],\n",
              "\n",
              "         [[ 0.0165, -0.0072,  0.0024],\n",
              "          [-0.0916, -0.1801, -0.0389],\n",
              "          [-0.0550,  0.0683, -0.0027]],\n",
              "\n",
              "         [[-0.1851, -0.1153, -0.1948],\n",
              "          [-0.2125, -0.1385, -0.1576],\n",
              "          [-0.0931,  0.0882, -0.1868]]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frnpf_di_model.state_dict().get(\"NPF_C1.weight\").data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7gA9qBP04YG1",
        "outputId": "ea51ecf6-e1a8-4a1f-936b-8664d7c4a155"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.1702, -0.0410, -0.1715],\n",
              "          [-0.1727, -0.1691,  0.1663],\n",
              "          [-0.0101, -0.1337,  0.0772]],\n",
              "\n",
              "         [[ 0.0743,  0.1482,  0.0419],\n",
              "          [ 0.1614,  0.1694,  0.1859],\n",
              "          [-0.1185, -0.0738,  0.0040]],\n",
              "\n",
              "         [[ 0.0363, -0.0772, -0.1612],\n",
              "          [ 0.0859,  0.0229,  0.0993],\n",
              "          [ 0.0268, -0.1790,  0.1827]]],\n",
              "\n",
              "\n",
              "        [[[ 0.1779, -0.1019, -0.1768],\n",
              "          [-0.1688,  0.0673,  0.0757],\n",
              "          [ 0.1021,  0.0230,  0.0172]],\n",
              "\n",
              "         [[-0.1060,  0.0220,  0.0491],\n",
              "          [ 0.0193,  0.0763, -0.0260],\n",
              "          [-0.0401, -0.1085, -0.0292]],\n",
              "\n",
              "         [[-0.0725,  0.0668,  0.0805],\n",
              "          [ 0.0910, -0.0254,  0.0105],\n",
              "          [-0.1620, -0.1402,  0.1393]]],\n",
              "\n",
              "\n",
              "        [[[-0.1743, -0.1056,  0.0858],\n",
              "          [ 0.1476, -0.0166, -0.0909],\n",
              "          [ 0.1034, -0.1136, -0.0495]],\n",
              "\n",
              "         [[-0.1307,  0.1124, -0.0006],\n",
              "          [-0.0614,  0.1173, -0.1692],\n",
              "          [-0.0389,  0.1868,  0.0260]],\n",
              "\n",
              "         [[-0.0134, -0.0680,  0.0858],\n",
              "          [ 0.0989,  0.0621, -0.1651],\n",
              "          [-0.0100, -0.0766,  0.1436]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[-0.1146,  0.0594,  0.1794],\n",
              "          [-0.0902,  0.1062,  0.1016],\n",
              "          [ 0.0030, -0.0459, -0.0912]],\n",
              "\n",
              "         [[-0.0790,  0.1894, -0.0759],\n",
              "          [ 0.0057, -0.0130,  0.0134],\n",
              "          [ 0.0984, -0.1103,  0.0471]],\n",
              "\n",
              "         [[-0.1643,  0.0140,  0.0439],\n",
              "          [ 0.0277,  0.0672, -0.1452],\n",
              "          [-0.0354,  0.0165, -0.0689]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0635, -0.1574, -0.1164],\n",
              "          [ 0.0090,  0.1154,  0.1278],\n",
              "          [ 0.1436,  0.0321, -0.0963]],\n",
              "\n",
              "         [[-0.0914,  0.0944,  0.1823],\n",
              "          [-0.1550, -0.0940, -0.1480],\n",
              "          [-0.1010, -0.1865, -0.0256]],\n",
              "\n",
              "         [[ 0.0908,  0.0892,  0.0189],\n",
              "          [ 0.1255,  0.1116,  0.0328],\n",
              "          [-0.1714,  0.0962,  0.0869]]],\n",
              "\n",
              "\n",
              "        [[[-0.1654, -0.1914, -0.1517],\n",
              "          [ 0.1294,  0.0595,  0.0156],\n",
              "          [ 0.1310,  0.0984, -0.0277]],\n",
              "\n",
              "         [[ 0.0623,  0.0603,  0.0457],\n",
              "          [-0.0720, -0.1320, -0.0053],\n",
              "          [-0.0809,  0.0605, -0.0083]],\n",
              "\n",
              "         [[-0.1451, -0.0556, -0.1564],\n",
              "          [-0.1920, -0.0923, -0.1241],\n",
              "          [-0.1158,  0.0806, -0.1910]]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FLNPF"
      ],
      "metadata": {
        "id": "13yfVAAcSnXp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flnpf_model = Conv4Galu(args['image_size'], args['channels'])\n",
        "flnpf_model.to(device)\n",
        "flnpf_model"
      ],
      "metadata": {
        "id": "BznM_eBXZex5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b58c9bb-8f69-47b0-c6cf-f552382e2089"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv4Galu(\n",
              "  (NPF_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPF_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPF_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (NPV_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPV_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPV_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (outputs): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in relu_model.parameters():\n",
        "  print(p)"
      ],
      "metadata": {
        "id": "LsZJSC8LZlnS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "05b605a5-d605-438a-d5bb-23b730490e50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[ 0.3054,  0.3379,  0.2370],\n",
            "          [-0.1890, -0.1106,  0.1405],\n",
            "          [-0.0046, -0.4660, -0.2788]],\n",
            "\n",
            "         [[ 0.2516,  0.3130,  0.1939],\n",
            "          [-0.1023,  0.1089,  0.1193],\n",
            "          [-0.2876, -0.1791, -0.3651]],\n",
            "\n",
            "         [[ 0.0922,  0.3381,  0.2529],\n",
            "          [ 0.0614,  0.2272, -0.0814],\n",
            "          [-0.2718, -0.3674, -0.2690]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2009, -0.0522, -0.0179],\n",
            "          [-0.0160, -0.1120,  0.1334],\n",
            "          [-0.1376, -0.0971,  0.1453]],\n",
            "\n",
            "         [[ 0.0248, -0.1657, -0.0605],\n",
            "          [-0.1915, -0.2418, -0.1057],\n",
            "          [ 0.0745, -0.0089,  0.1693]],\n",
            "\n",
            "         [[-0.0560, -0.1588, -0.1330],\n",
            "          [-0.0290, -0.2459, -0.0082],\n",
            "          [-0.1343, -0.1229,  0.1984]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0337, -0.0086, -0.0188],\n",
            "          [-0.1410, -0.0671,  0.0382],\n",
            "          [ 0.0306, -0.0489,  0.1722]],\n",
            "\n",
            "         [[-0.0487,  0.0578,  0.1902],\n",
            "          [-0.0501,  0.1975,  0.1041],\n",
            "          [ 0.0345, -0.1310,  0.0189]],\n",
            "\n",
            "         [[-0.0790,  0.0385,  0.1523],\n",
            "          [ 0.1444, -0.1027,  0.1999],\n",
            "          [ 0.0498,  0.1662, -0.0961]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0671, -0.1210,  0.0465],\n",
            "          [ 0.2493, -0.0622,  0.1233],\n",
            "          [ 0.1236, -0.2036, -0.1261]],\n",
            "\n",
            "         [[ 0.0066,  0.1635, -0.0758],\n",
            "          [ 0.3178, -0.1663, -0.0888],\n",
            "          [ 0.0190, -0.1618,  0.0577]],\n",
            "\n",
            "         [[ 0.1263, -0.0396, -0.1175],\n",
            "          [ 0.3162,  0.1435, -0.2288],\n",
            "          [ 0.0098, -0.1997, -0.0145]]],\n",
            "\n",
            "\n",
            "        [[[-0.2968,  0.0627,  0.1641],\n",
            "          [-0.2303, -0.0104,  0.2723],\n",
            "          [-0.2388,  0.1403,  0.1637]],\n",
            "\n",
            "         [[-0.3378,  0.2125,  0.0042],\n",
            "          [-0.0997,  0.0339,  0.2894],\n",
            "          [-0.2104,  0.0318, -0.0221]],\n",
            "\n",
            "         [[-0.3580,  0.0335,  0.2132],\n",
            "          [-0.4088,  0.0986,  0.2971],\n",
            "          [-0.1102,  0.2487,  0.0327]]],\n",
            "\n",
            "\n",
            "        [[[-0.0835, -0.0639,  0.0303],\n",
            "          [ 0.1919, -0.0746, -0.0604],\n",
            "          [-0.0813,  0.0525,  0.0503]],\n",
            "\n",
            "         [[-0.1024, -0.0883, -0.1292],\n",
            "          [ 0.0160, -0.1800,  0.0020],\n",
            "          [ 0.1253,  0.2694,  0.2036]],\n",
            "\n",
            "         [[ 0.1563, -0.1346,  0.1370],\n",
            "          [-0.0167, -0.0951, -0.2250],\n",
            "          [ 0.0106,  0.1998, -0.0990]]]], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0367, -0.1339, -0.1751, -0.0233, -0.0020,  0.1278,  0.0185, -0.1863,\n",
            "         0.3405,  0.1768, -0.1581,  0.0421, -0.0816, -0.0285, -0.0285, -0.1606,\n",
            "         0.0446, -0.0666,  0.3462,  0.1584, -0.0196, -0.0785,  0.0113, -0.0215,\n",
            "        -0.0137, -0.0999,  0.1103, -0.0622, -0.0480,  0.2782, -0.0903,  0.2776,\n",
            "         0.0993,  0.0761,  0.1818, -0.0207, -0.0199,  0.1085,  0.1211, -0.0243,\n",
            "        -0.0149, -0.0456,  0.1355, -0.0421, -0.0529, -0.1675, -0.0847, -0.0212,\n",
            "         0.0005,  0.0244,  0.3142, -0.2756, -0.1843,  0.2089,  0.3926, -0.0328,\n",
            "         0.2792,  0.0503, -0.0200, -0.2223,  0.0880, -0.0099,  0.0072, -0.0134],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[[[ 2.6428e-02, -2.0837e-02,  5.2202e-03],\n",
            "          [-3.3183e-04, -3.3603e-02,  2.5969e-02],\n",
            "          [-5.9463e-03, -2.2088e-02,  3.9177e-02]],\n",
            "\n",
            "         [[ 2.6280e-02,  1.2994e-02, -2.2801e-02],\n",
            "          [ 2.6102e-02,  2.6531e-02, -3.0762e-02],\n",
            "          [-3.7698e-03,  7.9015e-03,  6.9915e-03]],\n",
            "\n",
            "         [[ 1.8653e-02,  1.0428e-02,  4.5990e-03],\n",
            "          [-3.7892e-02, -2.6096e-02, -1.1312e-02],\n",
            "          [-7.3374e-03,  2.0688e-02, -2.6333e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8579e-03, -1.5793e-02,  7.0147e-03],\n",
            "          [ 2.4911e-02,  8.7618e-03,  3.8479e-02],\n",
            "          [ 2.9301e-03,  2.3484e-02, -2.7621e-03]],\n",
            "\n",
            "         [[-2.5805e-02,  2.6224e-02,  1.4872e-02],\n",
            "          [-3.4825e-02,  6.5640e-02,  3.2189e-02],\n",
            "          [-3.7468e-02,  2.1165e-02,  6.8800e-02]],\n",
            "\n",
            "         [[-7.4211e-03, -1.2615e-02,  4.7974e-03],\n",
            "          [ 3.3462e-02,  3.5180e-02, -1.3018e-02],\n",
            "          [-2.8785e-02,  4.3032e-02,  3.5486e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1814e-02,  7.4760e-02,  6.3005e-02],\n",
            "          [ 4.7662e-02,  3.9713e-02,  7.1522e-02],\n",
            "          [ 1.5510e-02, -5.6331e-02,  2.8991e-03]],\n",
            "\n",
            "         [[ 1.3320e-02,  6.9257e-02,  1.7131e-02],\n",
            "          [-2.0644e-03,  1.0290e-01,  6.5056e-02],\n",
            "          [ 6.3683e-02,  3.4838e-02,  4.5937e-02]],\n",
            "\n",
            "         [[-4.7571e-02, -2.7107e-02, -3.6903e-02],\n",
            "          [ 8.4317e-03, -3.7344e-02, -3.3949e-02],\n",
            "          [-5.3564e-02, -2.8347e-02, -3.4437e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.9890e-02,  3.6295e-02,  2.4175e-02],\n",
            "          [ 2.3925e-02,  2.8996e-02, -2.8510e-02],\n",
            "          [-6.1684e-03, -3.6904e-02,  3.4159e-02]],\n",
            "\n",
            "         [[ 4.2219e-03,  4.2852e-02,  9.0144e-02],\n",
            "          [-4.4046e-02,  1.0680e-02,  1.1391e-01],\n",
            "          [-2.3260e-02,  3.5872e-02,  1.2369e-01]],\n",
            "\n",
            "         [[ 4.7282e-03,  2.9541e-02,  2.2641e-02],\n",
            "          [ 1.7076e-04, -2.3651e-02,  1.9848e-02],\n",
            "          [ 6.5484e-03,  2.8588e-02, -2.5853e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9863e-02,  2.4191e-02,  6.8944e-02],\n",
            "          [ 1.9812e-02,  6.9585e-02, -1.9271e-02],\n",
            "          [-5.4607e-03, -5.7263e-02, -1.7893e-02]],\n",
            "\n",
            "         [[-4.6311e-02,  5.5458e-02,  9.1323e-03],\n",
            "          [-2.7961e-02,  1.1014e-01,  8.8954e-02],\n",
            "          [ 4.7739e-03,  7.5282e-02,  4.1406e-02]],\n",
            "\n",
            "         [[-1.2901e-02,  3.7450e-02,  4.1063e-02],\n",
            "          [ 2.6122e-02,  4.0714e-02, -1.6098e-02],\n",
            "          [ 3.1494e-02,  9.5811e-03,  1.3129e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.8911e-02,  3.9204e-02,  2.1771e-02],\n",
            "          [ 1.6164e-02,  7.8169e-02,  1.6282e-02],\n",
            "          [ 2.2178e-02, -2.5189e-03,  4.6760e-03]],\n",
            "\n",
            "         [[ 1.1805e-03, -1.5442e-02,  8.5739e-03],\n",
            "          [-2.1741e-02, -9.2279e-03,  4.3308e-02],\n",
            "          [-3.9723e-02,  5.6723e-02,  1.2398e-01]],\n",
            "\n",
            "         [[ 4.3569e-02, -3.3302e-02,  3.3436e-03],\n",
            "          [-1.0078e-02,  2.2693e-02, -1.7590e-02],\n",
            "          [ 4.4980e-02, -3.8076e-03,  1.5642e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.2117e-01,  1.0815e-01,  3.4741e-02],\n",
            "          [ 1.7783e-01,  2.1392e-01,  1.2809e-01],\n",
            "          [ 1.0146e-01,  1.2186e-01,  9.8735e-02]],\n",
            "\n",
            "         [[-2.3676e-02, -4.0258e-02, -9.0145e-03],\n",
            "          [-5.0197e-02, -8.1657e-04, -1.7129e-02],\n",
            "          [ 2.6146e-02,  5.0852e-03,  6.0162e-05]],\n",
            "\n",
            "         [[-3.3580e-02,  5.1647e-03, -3.5949e-02],\n",
            "          [ 3.3257e-02,  2.7031e-02, -2.7345e-02],\n",
            "          [-2.9223e-02, -2.9884e-02, -3.7904e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.3673e-02,  5.5466e-02,  1.2605e-02],\n",
            "          [ 4.1761e-02,  2.4690e-03,  4.9269e-02],\n",
            "          [-2.0259e-02,  2.6104e-02, -4.8704e-02]],\n",
            "\n",
            "         [[ 9.3209e-03, -2.4040e-02, -7.2308e-02],\n",
            "          [ 1.4393e-02, -6.6285e-03, -4.9122e-02],\n",
            "          [-1.4095e-02, -3.3717e-02, -2.7153e-02]],\n",
            "\n",
            "         [[ 4.0726e-02,  5.4843e-02,  1.1883e-02],\n",
            "          [ 3.2314e-02,  5.9913e-02,  4.0408e-02],\n",
            "          [ 6.0372e-02,  3.2033e-02,  1.6720e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.3838e-03, -4.0755e-02, -1.9321e-02],\n",
            "          [-3.9935e-03,  1.1143e-02,  2.7906e-02],\n",
            "          [ 7.0814e-02,  2.0280e-02,  7.7629e-02]],\n",
            "\n",
            "         [[ 1.4618e-02, -2.5520e-02,  3.4923e-02],\n",
            "          [ 2.1312e-02, -2.7110e-02, -2.5484e-02],\n",
            "          [-2.6334e-02,  2.3804e-02, -3.5636e-02]],\n",
            "\n",
            "         [[ 5.0083e-02,  4.6009e-02,  3.4740e-03],\n",
            "          [-4.7801e-03,  2.9557e-02, -3.2871e-02],\n",
            "          [-1.8504e-02,  3.3561e-02,  1.7559e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.6921e-02, -3.3989e-03, -3.0463e-02],\n",
            "          [ 3.3622e-02,  8.3282e-03, -1.1614e-02],\n",
            "          [-2.0258e-03,  1.6488e-02, -2.7224e-03]],\n",
            "\n",
            "         [[-4.3525e-03,  1.8353e-02, -3.7918e-02],\n",
            "          [ 4.7331e-02, -1.2390e-02,  1.6134e-02],\n",
            "          [ 2.6913e-03,  1.5133e-02, -1.7942e-02]],\n",
            "\n",
            "         [[ 3.2825e-02,  2.7514e-02, -2.8440e-02],\n",
            "          [ 2.7435e-02, -1.4051e-02,  3.7146e-02],\n",
            "          [ 4.5865e-02,  2.3231e-02, -2.6363e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 8.1335e-02,  4.7802e-02,  4.4462e-02],\n",
            "          [ 7.7401e-02,  1.1507e-01,  1.0430e-01],\n",
            "          [ 1.0140e-01,  7.6434e-02,  7.5280e-02]],\n",
            "\n",
            "         [[-3.7847e-03,  2.5743e-02,  1.8092e-03],\n",
            "          [-1.5795e-02, -3.7586e-02, -9.9603e-04],\n",
            "          [-5.5362e-02, -6.2975e-02, -4.7995e-02]],\n",
            "\n",
            "         [[-2.4202e-02, -5.5203e-03,  1.2441e-02],\n",
            "          [ 1.8099e-02,  3.2032e-02, -5.1578e-02],\n",
            "          [ 2.9630e-02, -1.5738e-02, -5.3070e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.5097e-02,  1.4992e-02,  1.7963e-02],\n",
            "          [-2.5230e-02, -1.0151e-02,  2.7438e-02],\n",
            "          [-4.2987e-02, -4.4277e-05,  1.2091e-02]],\n",
            "\n",
            "         [[ 5.4764e-03,  4.4854e-02, -7.2496e-03],\n",
            "          [ 2.9941e-02, -2.7623e-02,  1.5487e-02],\n",
            "          [ 5.9598e-02, -1.7989e-02, -5.3585e-02]],\n",
            "\n",
            "         [[-1.2934e-03,  1.2629e-02, -7.1119e-04],\n",
            "          [-2.1967e-02, -2.2965e-02,  4.5433e-02],\n",
            "          [ 4.1992e-02, -2.3097e-02, -6.7698e-05]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0803,  0.0469, -0.1544, -0.0356,  0.0199,  0.1699,  0.2991,  0.0135,\n",
            "         0.0096,  0.0658, -0.0216,  0.1856,  0.0700, -0.0045,  0.2051, -0.0228,\n",
            "        -0.0959,  0.0857,  0.1459, -0.0187,  0.0635, -0.1297,  0.0376, -0.0146,\n",
            "        -0.0420,  0.0745, -0.0325, -0.0713,  0.1838,  0.0541,  0.0224,  0.0658,\n",
            "        -0.1218,  0.0314, -0.0074,  0.1703, -0.1090, -0.0147,  0.0180,  0.3207,\n",
            "         0.1902,  0.3715, -0.0569, -0.0277, -0.0568, -0.1984,  0.0806,  0.0337,\n",
            "         0.3889,  0.1344, -0.0230,  0.0401,  0.2096,  0.2731, -0.0864,  0.0689,\n",
            "         0.2585, -0.0811,  0.1925,  0.0189,  0.0859, -0.1525,  0.0018,  0.1182],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[[[ 4.0277e-02,  1.0380e-02,  3.0164e-02],\n",
            "          [ 1.9846e-02, -4.1691e-02, -3.3827e-02],\n",
            "          [ 4.0902e-02,  3.2452e-02,  1.6134e-02]],\n",
            "\n",
            "         [[ 1.2608e-02, -7.9627e-05,  4.5708e-02],\n",
            "          [-6.7351e-03, -3.9214e-03,  2.4495e-02],\n",
            "          [-2.5032e-02,  2.9349e-02, -8.5515e-03]],\n",
            "\n",
            "         [[-2.9720e-03, -4.2030e-02, -4.2651e-03],\n",
            "          [-4.9442e-02,  1.7857e-02,  1.5030e-02],\n",
            "          [-5.9047e-03,  3.9732e-02,  4.4253e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.4930e-02, -3.1861e-02, -2.4948e-02],\n",
            "          [-4.0157e-02, -2.6837e-02, -1.4970e-02],\n",
            "          [-3.5345e-02, -3.9790e-03,  5.0483e-02]],\n",
            "\n",
            "         [[ 1.5829e-02, -3.5441e-04,  1.5805e-02],\n",
            "          [ 3.3268e-02,  1.5433e-03, -1.3210e-02],\n",
            "          [-3.0299e-02,  3.1137e-02,  1.5037e-02]],\n",
            "\n",
            "         [[ 1.0266e-02,  8.5330e-02,  4.8895e-02],\n",
            "          [ 8.6624e-04,  2.5042e-02,  3.6932e-02],\n",
            "          [ 3.5160e-02,  6.9222e-02,  4.4313e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.1656e-02, -1.8712e-02, -4.3902e-02],\n",
            "          [ 2.1826e-03, -1.6270e-02,  4.6408e-03],\n",
            "          [-2.9588e-02,  2.7350e-02,  2.6239e-03]],\n",
            "\n",
            "         [[ 4.0022e-02, -1.0389e-02, -3.1895e-02],\n",
            "          [-4.0534e-03,  3.4426e-03, -1.6167e-02],\n",
            "          [ 7.8528e-03, -1.6294e-02,  5.0504e-02]],\n",
            "\n",
            "         [[-2.4621e-02,  1.2350e-02,  1.2983e-02],\n",
            "          [-1.0388e-02, -3.7106e-02,  1.0821e-03],\n",
            "          [ 4.1923e-02, -2.3746e-02, -1.0526e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.5223e-02,  5.6251e-02,  4.5678e-02],\n",
            "          [ 3.9331e-02, -1.7249e-02,  3.9172e-02],\n",
            "          [-2.3631e-02,  1.2806e-02,  3.9896e-02]],\n",
            "\n",
            "         [[-2.2933e-02,  2.5775e-02, -2.6150e-03],\n",
            "          [-3.4077e-02,  2.4766e-02,  4.2766e-03],\n",
            "          [ 1.6931e-02,  1.3056e-02,  4.0370e-03]],\n",
            "\n",
            "         [[ 2.2567e-02,  8.4013e-02,  4.3144e-02],\n",
            "          [ 1.2026e-02,  6.9710e-02,  7.2909e-02],\n",
            "          [ 6.1156e-03,  3.5228e-02,  5.6682e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.9487e-02, -2.1893e-02, -1.9732e-02],\n",
            "          [-2.8138e-02,  7.9480e-03, -3.5128e-02],\n",
            "          [-2.3354e-02,  2.7238e-02, -2.4807e-04]],\n",
            "\n",
            "         [[-2.8371e-02,  4.3373e-02, -3.2863e-03],\n",
            "          [ 2.4345e-02, -2.3708e-02,  6.2970e-03],\n",
            "          [ 2.6335e-02, -1.1120e-02,  2.0926e-02]],\n",
            "\n",
            "         [[-4.9505e-02,  1.6859e-02, -3.6352e-02],\n",
            "          [-5.0330e-02, -4.8633e-02, -2.8395e-02],\n",
            "          [ 6.2908e-03, -1.7161e-02, -1.0686e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.3427e-03, -4.1065e-05, -2.4559e-03],\n",
            "          [-4.0001e-03,  2.0156e-02, -3.0020e-03],\n",
            "          [-4.1431e-02, -2.4839e-03, -1.8367e-02]],\n",
            "\n",
            "         [[ 2.1420e-02, -1.8375e-02, -3.1465e-02],\n",
            "          [ 2.2233e-02, -1.1743e-02,  3.7198e-02],\n",
            "          [ 5.1308e-03, -2.3987e-02, -3.9221e-02]],\n",
            "\n",
            "         [[-2.8027e-02,  5.1872e-02, -2.3429e-02],\n",
            "          [-2.8781e-02, -1.1932e-02,  5.3015e-02],\n",
            "          [-3.4214e-02,  1.4762e-02, -5.2109e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-3.1138e-02, -3.4041e-02, -7.8764e-03],\n",
            "          [ 1.2299e-02, -1.2520e-03, -3.5795e-02],\n",
            "          [ 2.0459e-02, -5.3588e-02, -4.6566e-02]],\n",
            "\n",
            "         [[ 2.7624e-02, -3.0488e-03,  2.1245e-02],\n",
            "          [ 5.2675e-02,  5.8207e-02,  5.0239e-02],\n",
            "          [ 5.6733e-02,  3.5298e-02,  5.3209e-02]],\n",
            "\n",
            "         [[-2.0243e-02,  1.6220e-02,  2.8171e-02],\n",
            "          [ 4.5449e-03,  6.3991e-03, -1.0231e-02],\n",
            "          [ 1.0086e-02,  7.3080e-03,  1.5097e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.6050e-03,  3.3085e-02, -9.8852e-04],\n",
            "          [ 4.3095e-02,  1.8850e-02,  4.5466e-02],\n",
            "          [ 2.0188e-03,  4.5797e-02,  4.6248e-02]],\n",
            "\n",
            "         [[ 3.9627e-02,  9.8114e-03,  4.3553e-03],\n",
            "          [ 2.4475e-02,  3.2113e-02, -3.3406e-02],\n",
            "          [-3.3446e-03,  2.9222e-02,  8.8378e-03]],\n",
            "\n",
            "         [[ 1.8706e-02,  4.8945e-02,  5.5746e-02],\n",
            "          [ 7.1549e-02,  8.9693e-02,  6.7863e-02],\n",
            "          [-1.7312e-02,  3.0217e-02,  1.8849e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.9936e-03,  1.0657e-02,  6.1420e-03],\n",
            "          [-3.0809e-02,  2.8617e-02, -2.5824e-02],\n",
            "          [ 2.5816e-02,  1.4740e-03, -4.2449e-02]],\n",
            "\n",
            "         [[-3.8617e-02, -3.6437e-02, -1.7605e-03],\n",
            "          [-4.7852e-02, -6.7285e-02, -9.9450e-03],\n",
            "          [-2.5722e-02, -1.3681e-02,  1.6948e-02]],\n",
            "\n",
            "         [[-1.9464e-02,  2.9159e-02,  1.7505e-02],\n",
            "          [-3.7901e-02, -3.1853e-02,  6.5358e-04],\n",
            "          [-2.8576e-02, -4.8854e-02,  3.4319e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.8926e-02, -5.2058e-03, -3.9092e-02],\n",
            "          [ 3.0351e-02, -9.4955e-03, -6.1212e-03],\n",
            "          [ 6.7267e-02,  7.3737e-03,  7.8061e-03]],\n",
            "\n",
            "         [[-1.6712e-02, -4.7110e-03, -3.1685e-02],\n",
            "          [-2.5154e-02, -3.0183e-03, -3.4470e-02],\n",
            "          [ 1.4889e-03, -2.6297e-02, -3.0031e-02]],\n",
            "\n",
            "         [[ 2.0992e-02, -2.7211e-02, -8.1709e-03],\n",
            "          [ 1.1045e-02,  3.4244e-03,  4.0241e-02],\n",
            "          [-3.2184e-02, -1.4618e-02,  2.8131e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.6869e-02, -9.4669e-03, -3.7862e-02],\n",
            "          [-5.7285e-03,  3.7203e-02, -2.5358e-02],\n",
            "          [ 3.5781e-02, -1.5327e-02,  1.2775e-02]],\n",
            "\n",
            "         [[ 1.5863e-02, -3.8666e-03, -4.1259e-02],\n",
            "          [ 2.4645e-02,  1.4179e-02,  2.4365e-02],\n",
            "          [ 2.2743e-02, -3.2308e-02, -1.2290e-02]],\n",
            "\n",
            "         [[ 1.4367e-02, -3.0053e-02,  1.8602e-02],\n",
            "          [-1.5783e-02,  2.3401e-02, -2.4383e-02],\n",
            "          [-1.5164e-02,  4.4420e-02, -3.2531e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.2075e-03, -2.9952e-02, -7.6509e-04],\n",
            "          [-1.0893e-02,  1.9678e-02, -4.2487e-02],\n",
            "          [ 4.0969e-02, -1.5540e-02,  3.9269e-02]],\n",
            "\n",
            "         [[-4.3651e-02, -1.6236e-02,  1.6668e-02],\n",
            "          [ 1.9227e-03, -2.4267e-02,  2.4857e-02],\n",
            "          [-1.6647e-02, -2.3300e-02,  2.0686e-02]],\n",
            "\n",
            "         [[-2.1838e-02,  2.2032e-02,  1.7269e-02],\n",
            "          [ 2.9042e-02,  1.4634e-02,  2.1261e-02],\n",
            "          [-9.2631e-03,  1.0095e-02, -2.0586e-02]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0117,  0.0523,  0.0774, -0.0048,  0.1625,  0.0166, -0.0189, -0.0234,\n",
            "         0.0310,  0.0105, -0.0238,  0.0056,  0.0252, -0.0589, -0.0337, -0.0295,\n",
            "         0.0185,  0.0116,  0.0245,  0.0173, -0.0244, -0.0581,  0.0795,  0.0189,\n",
            "         0.0148, -0.0374, -0.0059, -0.0340, -0.0303, -0.0170,  0.1148,  0.0005,\n",
            "        -0.0223,  0.0428,  0.1451, -0.0159,  0.0081,  0.0241,  0.0451,  0.0680,\n",
            "        -0.0408, -0.0131,  0.0514, -0.0377,  0.1126,  0.0875,  0.0597,  0.0174,\n",
            "        -0.0303,  0.0171,  0.0276, -0.0151, -0.0070,  0.0454,  0.1382,  0.0398,\n",
            "        -0.0503,  0.1012,  0.0215,  0.0619, -0.0520, -0.0134,  0.0923, -0.0084,\n",
            "         0.0057,  0.0931,  0.0270,  0.1064,  0.0269,  0.0780, -0.0126,  0.0191,\n",
            "        -0.0144,  0.0128, -0.0373, -0.0039,  0.1177, -0.0041,  0.2548, -0.0580,\n",
            "        -0.0230, -0.0065, -0.1135, -0.0481, -0.0306, -0.0047,  0.0020, -0.0062,\n",
            "        -0.0597, -0.0201,  0.0550,  0.1325,  0.0547,  0.0320,  0.0182,  0.0567,\n",
            "         0.0334,  0.0066, -0.0016, -0.0189,  0.0534,  0.0163, -0.0247,  0.0025,\n",
            "         0.1158, -0.0041, -0.0561,  0.0350,  0.0867, -0.0105, -0.1077,  0.0231,\n",
            "         0.0347, -0.0033, -0.0038, -0.0430,  0.0508, -0.0347,  0.0747,  0.0778,\n",
            "         0.0736, -0.0305, -0.0328, -0.0105, -0.0354,  0.0144,  0.0416,  0.0390],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[[[ 0.0134,  0.0124,  0.0133],\n",
            "          [ 0.0408,  0.0138, -0.0144],\n",
            "          [ 0.0257, -0.0327, -0.0052]],\n",
            "\n",
            "         [[ 0.0004, -0.0326,  0.0289],\n",
            "          [-0.0082, -0.0094, -0.0194],\n",
            "          [-0.0064, -0.0007,  0.0240]],\n",
            "\n",
            "         [[-0.0106,  0.0127,  0.0208],\n",
            "          [-0.0077, -0.0305,  0.0235],\n",
            "          [ 0.0042, -0.0343, -0.0007]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0088,  0.0203, -0.0252],\n",
            "          [-0.0301,  0.0015,  0.0138],\n",
            "          [ 0.0033, -0.0321,  0.0171]],\n",
            "\n",
            "         [[ 0.0131, -0.0323, -0.0238],\n",
            "          [-0.0109, -0.0062,  0.0123],\n",
            "          [-0.0152, -0.0365, -0.0287]],\n",
            "\n",
            "         [[ 0.0135, -0.0271, -0.0126],\n",
            "          [ 0.0004,  0.0109,  0.0100],\n",
            "          [ 0.0237, -0.0039, -0.0276]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0608,  0.0510, -0.0159],\n",
            "          [ 0.0500,  0.0697,  0.0297],\n",
            "          [ 0.0194,  0.0214, -0.0126]],\n",
            "\n",
            "         [[ 0.0415,  0.0153, -0.0314],\n",
            "          [ 0.0109,  0.0348, -0.0017],\n",
            "          [-0.0078,  0.0223, -0.0454]],\n",
            "\n",
            "         [[ 0.0179,  0.0136, -0.0348],\n",
            "          [ 0.0124, -0.0188, -0.0218],\n",
            "          [-0.0280, -0.0124, -0.0165]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0031,  0.0015, -0.0221],\n",
            "          [ 0.0162,  0.0147, -0.0342],\n",
            "          [-0.0170, -0.0175,  0.0080]],\n",
            "\n",
            "         [[ 0.0282,  0.0400, -0.0202],\n",
            "          [-0.0029,  0.0218, -0.0006],\n",
            "          [-0.0151, -0.0365, -0.0305]],\n",
            "\n",
            "         [[-0.0081,  0.0005, -0.0015],\n",
            "          [-0.0072, -0.0045, -0.0128],\n",
            "          [-0.0286, -0.0092, -0.0140]]],\n",
            "\n",
            "\n",
            "        [[[-0.0296, -0.0237, -0.0455],\n",
            "          [-0.0186, -0.0159, -0.0199],\n",
            "          [-0.0369, -0.0226, -0.0333]],\n",
            "\n",
            "         [[-0.0253, -0.0516, -0.0198],\n",
            "          [-0.0233, -0.0581, -0.0427],\n",
            "          [-0.0224, -0.0041,  0.0071]],\n",
            "\n",
            "         [[-0.0298,  0.0053, -0.0030],\n",
            "          [-0.0235, -0.0149, -0.0145],\n",
            "          [ 0.0029,  0.0199, -0.0313]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0582, -0.0606, -0.0098],\n",
            "          [-0.0512, -0.0513, -0.0211],\n",
            "          [-0.0290, -0.0377, -0.0386]],\n",
            "\n",
            "         [[ 0.0021,  0.0260, -0.0143],\n",
            "          [ 0.0261,  0.0184,  0.0027],\n",
            "          [ 0.0289,  0.0304,  0.0306]],\n",
            "\n",
            "         [[-0.0239, -0.0009, -0.0206],\n",
            "          [ 0.0137, -0.0062,  0.0121],\n",
            "          [ 0.0116, -0.0169, -0.0243]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0466,  0.0582,  0.0382],\n",
            "          [ 0.0469,  0.0428, -0.0097],\n",
            "          [ 0.0206, -0.0430, -0.0232]],\n",
            "\n",
            "         [[ 0.0202, -0.0190, -0.0196],\n",
            "          [ 0.0267, -0.0060,  0.0149],\n",
            "          [ 0.0096, -0.0352, -0.0291]],\n",
            "\n",
            "         [[-0.0267, -0.0200,  0.0213],\n",
            "          [-0.0209,  0.0175, -0.0166],\n",
            "          [-0.0112, -0.0164, -0.0305]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0235, -0.0241,  0.0159],\n",
            "          [-0.0204,  0.0032, -0.0012],\n",
            "          [-0.0289,  0.0031,  0.0131]],\n",
            "\n",
            "         [[ 0.0297,  0.0091,  0.0195],\n",
            "          [ 0.0055,  0.0276,  0.0092],\n",
            "          [-0.0206, -0.0261, -0.0090]],\n",
            "\n",
            "         [[ 0.0029, -0.0188, -0.0084],\n",
            "          [ 0.0065, -0.0255, -0.0269],\n",
            "          [ 0.0051, -0.0095, -0.0066]]],\n",
            "\n",
            "\n",
            "        [[[-0.0232,  0.0014,  0.0283],\n",
            "          [ 0.0290, -0.0005, -0.0052],\n",
            "          [ 0.0162,  0.0244, -0.0121]],\n",
            "\n",
            "         [[-0.0249, -0.0051, -0.0212],\n",
            "          [ 0.0286, -0.0197, -0.0386],\n",
            "          [ 0.0111, -0.0238, -0.0415]],\n",
            "\n",
            "         [[ 0.0058,  0.0084,  0.0016],\n",
            "          [ 0.0205,  0.0287,  0.0238],\n",
            "          [ 0.0175, -0.0136, -0.0087]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0307, -0.0364, -0.0249],\n",
            "          [-0.0302, -0.0430, -0.0553],\n",
            "          [-0.0060, -0.0112, -0.0367]],\n",
            "\n",
            "         [[ 0.0007,  0.0411,  0.0137],\n",
            "          [-0.0092,  0.0221,  0.0187],\n",
            "          [-0.0046,  0.0051,  0.0050]],\n",
            "\n",
            "         [[ 0.0335,  0.0317,  0.0073],\n",
            "          [ 0.0308,  0.0225,  0.0204],\n",
            "          [ 0.0203, -0.0056, -0.0023]]],\n",
            "\n",
            "\n",
            "        [[[-0.0344, -0.0017,  0.0047],\n",
            "          [-0.0088, -0.0292, -0.0067],\n",
            "          [-0.0311,  0.0120, -0.0030]],\n",
            "\n",
            "         [[-0.0105, -0.0056, -0.0184],\n",
            "          [-0.0097, -0.0465, -0.0400],\n",
            "          [-0.0365, -0.0141,  0.0059]],\n",
            "\n",
            "         [[-0.0188, -0.0061,  0.0048],\n",
            "          [-0.0325,  0.0157, -0.0045],\n",
            "          [-0.0235,  0.0078, -0.0100]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0062,  0.0173,  0.0050],\n",
            "          [-0.0098,  0.0048,  0.0259],\n",
            "          [ 0.0492,  0.0262,  0.0169]],\n",
            "\n",
            "         [[-0.0262,  0.0018, -0.0043],\n",
            "          [ 0.0069, -0.0162, -0.0179],\n",
            "          [-0.0040, -0.0343, -0.0356]],\n",
            "\n",
            "         [[-0.0232,  0.0117, -0.0287],\n",
            "          [ 0.0052, -0.0014, -0.0121],\n",
            "          [ 0.0196, -0.0042,  0.0193]]]], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-2.0681e-02, -7.0083e-03,  7.9164e-02, -1.5063e-02,  1.1654e-02,\n",
            "         8.1356e-03,  4.0649e-02, -3.0997e-02, -3.9964e-02,  2.8621e-02,\n",
            "        -2.8249e-02,  1.5643e-02,  2.5993e-02,  1.5263e-02, -2.0168e-02,\n",
            "        -3.7159e-05,  1.2660e-01,  2.1205e-02,  2.9402e-02, -3.8959e-02,\n",
            "         8.2104e-02, -5.9322e-02, -4.7387e-02, -1.3075e-03,  1.4025e-02,\n",
            "         4.0303e-03, -2.0466e-02,  3.7914e-03, -5.7136e-02, -9.7919e-03,\n",
            "        -2.1127e-02,  1.6074e-02,  9.2887e-03,  5.6214e-02, -1.3441e-03,\n",
            "        -2.1041e-02,  5.3514e-03, -2.4324e-02,  2.3716e-02,  8.4859e-03,\n",
            "         2.4969e-02,  6.6880e-02, -6.8375e-02,  2.9831e-02,  2.0731e-02,\n",
            "        -4.5061e-02, -2.6676e-02, -7.5079e-03, -1.6184e-02,  1.1892e-01,\n",
            "        -3.1279e-02, -6.4117e-02,  2.7574e-02, -8.2456e-03,  3.1179e-02,\n",
            "         1.3997e-02,  8.0652e-03, -4.6303e-02,  5.9273e-02, -6.8813e-03,\n",
            "        -3.8176e-02,  1.3124e-01,  9.9441e-02, -5.2605e-02,  4.0567e-02,\n",
            "        -7.8636e-02, -5.2676e-03, -3.8285e-02, -7.5579e-03, -1.6452e-03,\n",
            "         1.1282e-02, -1.4039e-02, -1.7723e-02,  1.2481e-01, -2.1616e-02,\n",
            "        -1.4343e-02, -2.4840e-02, -4.9058e-02,  8.5411e-03, -2.0515e-02,\n",
            "         1.0301e-03, -3.9457e-02, -2.3849e-02,  7.2384e-02,  1.5370e-02,\n",
            "         2.0022e-02, -3.0407e-02, -5.1788e-02, -2.1095e-03, -3.1584e-02,\n",
            "         8.5809e-03,  3.6002e-02, -3.5588e-03, -3.8323e-02,  6.8188e-02,\n",
            "        -2.4315e-02,  4.7710e-02,  2.1729e-02,  5.6142e-02,  6.0805e-02,\n",
            "        -2.6695e-02, -2.2452e-02, -1.9114e-02, -3.2189e-02, -3.1818e-02,\n",
            "         5.2669e-02,  8.5757e-02,  1.0987e-01,  5.0168e-03,  5.1070e-02,\n",
            "         4.5304e-02,  3.6983e-02, -2.0325e-02,  9.4715e-02, -9.0900e-03,\n",
            "         5.4102e-02, -5.1025e-02,  2.7118e-02, -2.9361e-03, -2.4686e-02,\n",
            "         3.1643e-02, -3.6353e-02,  4.1194e-03, -8.1876e-03, -5.8619e-03,\n",
            "        -3.6086e-02,  1.6197e-02,  1.2061e-02], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 2.1958e-03,  1.3943e-03, -1.5808e-03,  ..., -1.5723e-03,\n",
            "          5.5278e-04,  2.3052e-04],\n",
            "        [ 8.7746e-04,  1.2561e-03, -6.2257e-05,  ..., -1.6636e-03,\n",
            "         -9.8102e-04, -4.9839e-04],\n",
            "        [-7.1099e-04, -4.9462e-03, -3.4833e-03,  ...,  2.7029e-03,\n",
            "         -1.6548e-03,  7.0814e-04],\n",
            "        ...,\n",
            "        [-3.4940e-05,  2.7860e-03,  1.6167e-03,  ...,  1.8612e-03,\n",
            "         -1.8230e-03,  8.6013e-04],\n",
            "        [ 1.3720e-03,  1.0459e-05,  8.0660e-04,  ..., -9.5000e-04,\n",
            "          1.0763e-03,  4.9291e-04],\n",
            "        [-1.6969e-04,  8.2414e-04,  1.5698e-03,  ...,  3.5408e-03,\n",
            "          2.7926e-03, -6.8041e-04]], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 2.7263e-03,  8.6467e-03,  2.1539e-03,  1.0545e-02,  1.1852e-02,\n",
            "        -9.4900e-03, -3.5309e-03, -5.0065e-03, -8.1237e-04,  4.0648e-03,\n",
            "         1.0590e-02, -1.3374e-03,  1.6382e-03, -1.0176e-03, -3.7117e-03,\n",
            "         7.2812e-03,  2.6486e-03, -9.1937e-03,  6.8210e-03, -2.4895e-04,\n",
            "         3.1238e-03,  6.1709e-03, -3.3188e-03,  1.7508e-02,  1.2323e-02,\n",
            "         3.9905e-04, -9.0884e-03,  1.0308e-03, -2.3503e-03, -7.4581e-03,\n",
            "         8.8726e-03,  1.4065e-02, -2.4663e-03, -9.9333e-03, -1.9305e-03,\n",
            "         6.2918e-03,  1.2618e-02, -1.1736e-03,  2.8675e-03, -2.7144e-03,\n",
            "        -1.7742e-03, -7.6778e-03,  1.2900e-03, -4.0537e-03, -4.3465e-03,\n",
            "        -1.4851e-03,  1.3188e-02,  1.3168e-03,  1.0816e-02, -4.6535e-03,\n",
            "         8.2435e-03,  3.7880e-03, -1.0372e-02, -1.0107e-03,  1.7748e-03,\n",
            "        -3.5076e-03,  6.3206e-03,  1.5215e-02,  3.6587e-03, -8.3152e-03,\n",
            "         3.9041e-03,  6.9407e-03, -7.1253e-03, -2.4715e-03, -7.9369e-03,\n",
            "        -4.5519e-04,  3.5204e-03,  2.6888e-04,  2.6759e-03, -9.9306e-04,\n",
            "        -3.0734e-03,  6.1757e-04,  1.1553e-02,  4.8287e-03,  1.3781e-02,\n",
            "        -8.9891e-03,  6.9874e-03,  5.9959e-03, -1.6914e-03, -2.0738e-03,\n",
            "        -6.5461e-03,  1.7361e-03, -1.1462e-03,  1.9788e-03,  3.4793e-03,\n",
            "        -4.5998e-03, -1.1786e-03,  5.0669e-04, -2.7846e-03, -4.0069e-03,\n",
            "        -5.2873e-03, -2.9072e-03, -4.8615e-03, -1.2108e-02, -5.5519e-04,\n",
            "        -1.8201e-03,  2.7955e-03, -2.3831e-03,  2.8414e-03, -1.0357e-02,\n",
            "        -6.0555e-03, -3.1553e-06, -1.2627e-02, -1.2564e-02,  2.8578e-03,\n",
            "        -7.0032e-03, -3.3018e-03,  1.0771e-02,  1.2855e-03,  3.3697e-03,\n",
            "        -3.5231e-03, -5.4274e-03,  1.9956e-02, -2.5386e-03,  2.7069e-02,\n",
            "        -1.6792e-03,  2.1734e-03, -1.4158e-03, -9.4536e-03,  1.1948e-02,\n",
            "        -5.3820e-04,  7.3867e-04,  7.5011e-03,  5.7812e-03,  1.9207e-03,\n",
            "        -1.7793e-03,  5.7436e-03,  8.6158e-04,  2.5181e-04, -9.5126e-04,\n",
            "         9.0333e-03,  3.8969e-03,  8.6116e-03,  1.3459e-03,  7.9260e-03,\n",
            "        -1.2244e-03,  1.6488e-03,  1.7486e-03,  1.1968e-02,  1.6828e-02,\n",
            "        -5.3845e-03,  1.7194e-02, -4.5652e-03,  3.6242e-03, -2.1628e-03,\n",
            "        -1.8354e-03,  1.1827e-02, -6.8990e-03, -7.6275e-03,  8.1118e-03,\n",
            "        -4.4711e-03,  1.3009e-02,  7.5241e-03, -2.7296e-03,  1.0149e-02,\n",
            "         5.4530e-03,  2.1573e-03,  8.5837e-04, -2.2416e-03,  2.8401e-04,\n",
            "        -2.2646e-03,  2.1203e-02,  5.0464e-03, -1.1254e-02,  2.3370e-03,\n",
            "        -1.3709e-03, -8.8217e-03, -9.3191e-05,  7.4883e-05, -9.6202e-05,\n",
            "         4.8330e-03,  3.6319e-03,  1.9279e-02, -1.4634e-02, -1.4291e-03,\n",
            "        -4.6268e-03, -7.0377e-04,  1.6611e-03,  8.5175e-04,  9.1457e-03,\n",
            "         1.1576e-02, -2.8688e-03,  2.0465e-03, -5.0813e-04,  4.4070e-03,\n",
            "        -5.2083e-03,  6.7256e-03,  1.0829e-02, -1.7118e-03, -2.2758e-03,\n",
            "         1.9560e-03,  1.7470e-03, -3.4385e-03, -8.3875e-03,  6.9816e-03,\n",
            "         2.5554e-03, -6.5648e-03, -1.1095e-02,  3.4340e-03, -2.6714e-03,\n",
            "         7.7101e-03,  5.6306e-03,  9.1360e-03,  7.4220e-03, -3.1688e-03,\n",
            "         1.4781e-02,  2.5449e-03,  5.2840e-04,  1.9922e-02,  2.0281e-03,\n",
            "         6.8481e-03, -2.2113e-03,  1.9015e-03,  3.1532e-03, -5.3112e-03,\n",
            "         4.4214e-03,  5.4815e-03, -4.9495e-03,  1.4318e-02, -2.7519e-03,\n",
            "        -1.0134e-02, -6.6514e-03, -2.1193e-03,  7.6910e-05, -8.9408e-04,\n",
            "        -1.1721e-04, -2.8052e-04, -5.0287e-03,  2.0598e-03,  2.6849e-02,\n",
            "         8.7075e-03,  7.7593e-03, -5.9263e-03,  1.0489e-02, -5.3673e-03,\n",
            "         2.0006e-03, -4.6284e-03,  6.3061e-03,  6.4907e-03, -5.6339e-04,\n",
            "        -5.6425e-04,  4.9396e-03,  3.5404e-03,  1.1089e-03,  1.0792e-02,\n",
            "        -1.0127e-03, -4.9628e-04, -5.9173e-03, -3.4118e-03,  3.0606e-03,\n",
            "         4.3294e-03,  1.3141e-02,  1.0605e-02,  5.6436e-04,  1.1461e-02,\n",
            "         6.6782e-04], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 0.0162,  0.0589, -0.0596,  ..., -0.0315, -0.0640,  0.0450],\n",
            "        [-0.0458,  0.0177,  0.0586,  ..., -0.0217, -0.0178, -0.0037],\n",
            "        [ 0.0156,  0.0231, -0.0162,  ...,  0.0427,  0.0170, -0.0185],\n",
            "        ...,\n",
            "        [-0.0354,  0.0092, -0.0410,  ..., -0.0334, -0.0368,  0.0468],\n",
            "        [ 0.0430,  0.0066,  0.0325,  ..., -0.0378,  0.0631,  0.0523],\n",
            "        [-0.0348,  0.0243,  0.0011,  ...,  0.0450,  0.0528,  0.0114]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 2.3918e-02,  2.8234e-02,  4.3066e-03,  3.3527e-02,  5.0546e-02,\n",
            "        -4.4808e-02, -2.2679e-02, -6.5189e-02,  4.3056e-02,  5.8509e-02,\n",
            "         6.1944e-02,  2.9156e-02, -3.7116e-02, -8.8279e-04, -3.8355e-02,\n",
            "        -2.6577e-02, -1.4062e-02, -4.6546e-02, -2.7822e-02, -1.3759e-02,\n",
            "         9.0281e-02,  5.6187e-02, -3.1140e-03,  7.3252e-02,  3.9047e-02,\n",
            "         7.7486e-02, -6.2006e-02, -4.8564e-02, -3.1465e-02, -5.4387e-02,\n",
            "         5.6273e-02,  7.4933e-03, -2.9030e-02, -5.1979e-02, -2.8031e-02,\n",
            "        -2.1220e-02,  6.3009e-02,  1.6348e-02,  1.3608e-02,  7.1469e-02,\n",
            "         3.6004e-02,  6.3580e-02,  3.2642e-02, -2.8624e-02, -1.6326e-02,\n",
            "        -4.6358e-02, -3.2426e-02, -7.1975e-03,  4.6036e-02,  6.4744e-02,\n",
            "        -1.8766e-02,  2.0520e-02, -8.4470e-04,  2.6783e-02, -3.3756e-02,\n",
            "        -9.3188e-03,  2.5569e-02,  6.4866e-02, -6.5806e-02,  2.8961e-02,\n",
            "         2.7762e-02, -4.0230e-02,  5.0812e-02,  5.2152e-02,  8.7180e-02,\n",
            "        -4.0330e-02,  4.8437e-02, -2.3763e-02, -6.6727e-02,  3.9273e-02,\n",
            "        -1.1820e-02,  2.1494e-02,  2.0478e-02, -5.9724e-02,  1.4689e-02,\n",
            "        -1.3222e-02,  2.1286e-02,  1.0446e-02, -3.9441e-02,  6.7894e-02,\n",
            "        -1.2999e-02, -3.1016e-04, -1.6997e-02,  7.9987e-02,  6.1335e-02,\n",
            "        -5.5966e-02, -3.2162e-02, -3.1876e-02,  8.8825e-03, -3.9006e-02,\n",
            "         2.0232e-02,  4.5209e-02,  1.0847e-04,  2.9328e-02,  6.7795e-02,\n",
            "         8.0652e-02, -2.1628e-02, -1.4609e-02, -5.6283e-02, -3.2304e-02,\n",
            "         3.7717e-02, -5.2470e-02, -8.3841e-03,  1.9144e-02,  7.7948e-02,\n",
            "         2.3058e-02, -4.0549e-03, -4.3948e-02,  6.0529e-02, -1.3097e-02,\n",
            "         3.9420e-02,  2.0400e-03, -1.6056e-02,  5.1285e-02,  3.2787e-02,\n",
            "        -1.6865e-02,  8.0792e-02, -3.7587e-02,  3.3972e-03,  6.2690e-02,\n",
            "        -6.5654e-02,  2.3820e-02,  4.5327e-02, -1.0119e-02,  2.5137e-02,\n",
            "        -9.4091e-03, -6.1067e-03,  4.8628e-02,  1.8869e-02,  9.0437e-04,\n",
            "        -1.2610e-02,  2.1686e-02,  2.7099e-03,  3.9880e-02,  6.3954e-02,\n",
            "        -4.4895e-02,  5.1859e-02,  1.2579e-02,  2.3163e-02, -2.2237e-02,\n",
            "         1.2627e-02, -3.9111e-02, -1.6720e-02,  5.7190e-04,  3.6380e-02,\n",
            "        -3.6590e-02,  1.0840e-02,  4.1467e-02, -1.9239e-02, -4.5029e-02,\n",
            "         2.1213e-02, -4.8386e-02,  4.4330e-03, -3.6866e-02,  1.9000e-02,\n",
            "         5.0727e-02, -2.3475e-02, -2.7717e-02,  5.4954e-02,  1.7503e-02,\n",
            "         6.6646e-02, -6.3616e-03,  1.5020e-02,  7.9229e-02,  6.7684e-02,\n",
            "        -6.1204e-02,  1.4962e-02, -5.6875e-02,  9.9318e-02, -3.0906e-02,\n",
            "         2.4810e-02, -3.9326e-02,  7.8340e-02,  6.6988e-02, -8.4335e-05,\n",
            "         4.4460e-03, -2.6355e-02, -8.7145e-03,  4.0099e-02, -4.8220e-02,\n",
            "        -7.2300e-03,  2.9709e-02, -3.9374e-03,  5.9588e-02,  2.7693e-02,\n",
            "        -2.3848e-02,  1.9919e-02,  3.4118e-02, -5.4962e-02, -3.0520e-03,\n",
            "         1.8928e-02,  2.1584e-02, -5.7246e-02, -6.7414e-02,  5.3667e-02,\n",
            "         2.9480e-02,  2.5637e-03,  1.4771e-02,  4.9039e-02, -1.9089e-02,\n",
            "        -2.7971e-02, -4.5007e-02, -5.4325e-02,  1.3072e-02,  1.7888e-02,\n",
            "        -4.7932e-02, -1.3828e-02,  1.9816e-02, -4.1256e-02,  3.5129e-02,\n",
            "         9.1780e-02,  4.4964e-03, -3.4662e-02,  2.7919e-02,  4.9996e-02,\n",
            "        -3.8692e-02, -3.3245e-02, -4.2547e-02, -4.6373e-02, -4.3493e-02,\n",
            "        -3.1305e-03,  3.6448e-02,  3.8549e-03,  2.0895e-02,  2.0003e-02,\n",
            "         6.7754e-02,  7.6016e-03,  9.0603e-02,  3.6765e-03,  1.3255e-02,\n",
            "         3.8544e-02, -5.8348e-02,  2.3845e-02,  7.1091e-02,  4.6622e-02,\n",
            "         1.1686e-02, -4.8189e-02,  3.9982e-02,  9.5023e-03,  1.1421e-02,\n",
            "        -1.6778e-02, -7.0090e-02,  6.0238e-02, -4.2643e-02,  3.6676e-02,\n",
            "         5.5428e-02, -4.2001e-02,  2.1625e-02, -4.3241e-02, -1.8984e-02,\n",
            "        -3.9170e-02, -6.4637e-03, -1.2816e-02, -2.5875e-02,  1.0270e-02,\n",
            "         1.2457e-02], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0180,  0.0123, -0.0101,  ..., -0.1284, -0.0634,  0.0793],\n",
            "        [ 0.1028,  0.0085, -0.1657,  ..., -0.0700, -0.0857, -0.1446],\n",
            "        [-0.1686,  0.0369,  0.1419,  ..., -0.0764, -0.0886, -0.1919],\n",
            "        ...,\n",
            "        [ 0.1494,  0.0101,  0.1955,  ...,  0.2402, -0.0017, -0.0586],\n",
            "        [-0.1565,  0.1584, -0.1642,  ..., -0.0830,  0.1602,  0.0862],\n",
            "        [ 0.1428,  0.0583, -0.0358,  ...,  0.0296, -0.1293,  0.0631]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0820, -0.1402, -0.0531,  0.0248,  0.2082, -0.0827,  0.1656, -0.0346,\n",
            "         0.0713,  0.0120], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_params = [x.data for x in relu_model.parameters()]\n",
        "\n",
        "i=0\n",
        "for (name, params) in flnpf_model.named_parameters():\n",
        "  if name[0:3]=='NPF':\n",
        "    params.data = trained_params[i]\n",
        "    params.requires_grad = False\n",
        "    i+=1\n",
        "  print(name, params)"
      ],
      "metadata": {
        "id": "PLQO8iqgZoTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b250051-1b89-4c0d-ec21-b2ea0ccad947"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NPF_C1.weight Parameter containing:\n",
            "tensor([[[[ 0.3054,  0.3379,  0.2370],\n",
            "          [-0.1890, -0.1106,  0.1405],\n",
            "          [-0.0046, -0.4660, -0.2788]],\n",
            "\n",
            "         [[ 0.2516,  0.3130,  0.1939],\n",
            "          [-0.1023,  0.1089,  0.1193],\n",
            "          [-0.2876, -0.1791, -0.3651]],\n",
            "\n",
            "         [[ 0.0922,  0.3381,  0.2529],\n",
            "          [ 0.0614,  0.2272, -0.0814],\n",
            "          [-0.2718, -0.3674, -0.2690]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2009, -0.0522, -0.0179],\n",
            "          [-0.0160, -0.1120,  0.1334],\n",
            "          [-0.1376, -0.0971,  0.1453]],\n",
            "\n",
            "         [[ 0.0248, -0.1657, -0.0605],\n",
            "          [-0.1915, -0.2418, -0.1057],\n",
            "          [ 0.0745, -0.0089,  0.1693]],\n",
            "\n",
            "         [[-0.0560, -0.1588, -0.1330],\n",
            "          [-0.0290, -0.2459, -0.0082],\n",
            "          [-0.1343, -0.1229,  0.1984]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0337, -0.0086, -0.0188],\n",
            "          [-0.1410, -0.0671,  0.0382],\n",
            "          [ 0.0306, -0.0489,  0.1722]],\n",
            "\n",
            "         [[-0.0487,  0.0578,  0.1902],\n",
            "          [-0.0501,  0.1975,  0.1041],\n",
            "          [ 0.0345, -0.1310,  0.0189]],\n",
            "\n",
            "         [[-0.0790,  0.0385,  0.1523],\n",
            "          [ 0.1444, -0.1027,  0.1999],\n",
            "          [ 0.0498,  0.1662, -0.0961]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0671, -0.1210,  0.0465],\n",
            "          [ 0.2493, -0.0622,  0.1233],\n",
            "          [ 0.1236, -0.2036, -0.1261]],\n",
            "\n",
            "         [[ 0.0066,  0.1635, -0.0758],\n",
            "          [ 0.3178, -0.1663, -0.0888],\n",
            "          [ 0.0190, -0.1618,  0.0577]],\n",
            "\n",
            "         [[ 0.1263, -0.0396, -0.1175],\n",
            "          [ 0.3162,  0.1435, -0.2288],\n",
            "          [ 0.0098, -0.1997, -0.0145]]],\n",
            "\n",
            "\n",
            "        [[[-0.2968,  0.0627,  0.1641],\n",
            "          [-0.2303, -0.0104,  0.2723],\n",
            "          [-0.2388,  0.1403,  0.1637]],\n",
            "\n",
            "         [[-0.3378,  0.2125,  0.0042],\n",
            "          [-0.0997,  0.0339,  0.2894],\n",
            "          [-0.2104,  0.0318, -0.0221]],\n",
            "\n",
            "         [[-0.3580,  0.0335,  0.2132],\n",
            "          [-0.4088,  0.0986,  0.2971],\n",
            "          [-0.1102,  0.2487,  0.0327]]],\n",
            "\n",
            "\n",
            "        [[[-0.0835, -0.0639,  0.0303],\n",
            "          [ 0.1919, -0.0746, -0.0604],\n",
            "          [-0.0813,  0.0525,  0.0503]],\n",
            "\n",
            "         [[-0.1024, -0.0883, -0.1292],\n",
            "          [ 0.0160, -0.1800,  0.0020],\n",
            "          [ 0.1253,  0.2694,  0.2036]],\n",
            "\n",
            "         [[ 0.1563, -0.1346,  0.1370],\n",
            "          [-0.0167, -0.0951, -0.2250],\n",
            "          [ 0.0106,  0.1998, -0.0990]]]], device='cuda:0')\n",
            "NPF_C1.bias Parameter containing:\n",
            "tensor([-0.0367, -0.1339, -0.1751, -0.0233, -0.0020,  0.1278,  0.0185, -0.1863,\n",
            "         0.3405,  0.1768, -0.1581,  0.0421, -0.0816, -0.0285, -0.0285, -0.1606,\n",
            "         0.0446, -0.0666,  0.3462,  0.1584, -0.0196, -0.0785,  0.0113, -0.0215,\n",
            "        -0.0137, -0.0999,  0.1103, -0.0622, -0.0480,  0.2782, -0.0903,  0.2776,\n",
            "         0.0993,  0.0761,  0.1818, -0.0207, -0.0199,  0.1085,  0.1211, -0.0243,\n",
            "        -0.0149, -0.0456,  0.1355, -0.0421, -0.0529, -0.1675, -0.0847, -0.0212,\n",
            "         0.0005,  0.0244,  0.3142, -0.2756, -0.1843,  0.2089,  0.3926, -0.0328,\n",
            "         0.2792,  0.0503, -0.0200, -0.2223,  0.0880, -0.0099,  0.0072, -0.0134],\n",
            "       device='cuda:0')\n",
            "NPF_C2.weight Parameter containing:\n",
            "tensor([[[[ 2.6428e-02, -2.0837e-02,  5.2202e-03],\n",
            "          [-3.3183e-04, -3.3603e-02,  2.5969e-02],\n",
            "          [-5.9463e-03, -2.2088e-02,  3.9177e-02]],\n",
            "\n",
            "         [[ 2.6280e-02,  1.2994e-02, -2.2801e-02],\n",
            "          [ 2.6102e-02,  2.6531e-02, -3.0762e-02],\n",
            "          [-3.7698e-03,  7.9015e-03,  6.9915e-03]],\n",
            "\n",
            "         [[ 1.8653e-02,  1.0428e-02,  4.5990e-03],\n",
            "          [-3.7892e-02, -2.6096e-02, -1.1312e-02],\n",
            "          [-7.3374e-03,  2.0688e-02, -2.6333e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.8579e-03, -1.5793e-02,  7.0147e-03],\n",
            "          [ 2.4911e-02,  8.7618e-03,  3.8479e-02],\n",
            "          [ 2.9301e-03,  2.3484e-02, -2.7621e-03]],\n",
            "\n",
            "         [[-2.5805e-02,  2.6224e-02,  1.4872e-02],\n",
            "          [-3.4825e-02,  6.5640e-02,  3.2189e-02],\n",
            "          [-3.7468e-02,  2.1165e-02,  6.8800e-02]],\n",
            "\n",
            "         [[-7.4211e-03, -1.2615e-02,  4.7974e-03],\n",
            "          [ 3.3462e-02,  3.5180e-02, -1.3018e-02],\n",
            "          [-2.8785e-02,  4.3032e-02,  3.5486e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1814e-02,  7.4760e-02,  6.3005e-02],\n",
            "          [ 4.7662e-02,  3.9713e-02,  7.1522e-02],\n",
            "          [ 1.5510e-02, -5.6331e-02,  2.8991e-03]],\n",
            "\n",
            "         [[ 1.3320e-02,  6.9257e-02,  1.7131e-02],\n",
            "          [-2.0644e-03,  1.0290e-01,  6.5056e-02],\n",
            "          [ 6.3683e-02,  3.4838e-02,  4.5937e-02]],\n",
            "\n",
            "         [[-4.7571e-02, -2.7107e-02, -3.6903e-02],\n",
            "          [ 8.4317e-03, -3.7344e-02, -3.3949e-02],\n",
            "          [-5.3564e-02, -2.8347e-02, -3.4437e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.9890e-02,  3.6295e-02,  2.4175e-02],\n",
            "          [ 2.3925e-02,  2.8996e-02, -2.8510e-02],\n",
            "          [-6.1684e-03, -3.6904e-02,  3.4159e-02]],\n",
            "\n",
            "         [[ 4.2219e-03,  4.2852e-02,  9.0144e-02],\n",
            "          [-4.4046e-02,  1.0680e-02,  1.1391e-01],\n",
            "          [-2.3260e-02,  3.5872e-02,  1.2369e-01]],\n",
            "\n",
            "         [[ 4.7282e-03,  2.9541e-02,  2.2641e-02],\n",
            "          [ 1.7076e-04, -2.3651e-02,  1.9848e-02],\n",
            "          [ 6.5484e-03,  2.8588e-02, -2.5853e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9863e-02,  2.4191e-02,  6.8944e-02],\n",
            "          [ 1.9812e-02,  6.9585e-02, -1.9271e-02],\n",
            "          [-5.4607e-03, -5.7263e-02, -1.7893e-02]],\n",
            "\n",
            "         [[-4.6311e-02,  5.5458e-02,  9.1323e-03],\n",
            "          [-2.7961e-02,  1.1014e-01,  8.8954e-02],\n",
            "          [ 4.7739e-03,  7.5282e-02,  4.1406e-02]],\n",
            "\n",
            "         [[-1.2901e-02,  3.7450e-02,  4.1063e-02],\n",
            "          [ 2.6122e-02,  4.0714e-02, -1.6098e-02],\n",
            "          [ 3.1494e-02,  9.5811e-03,  1.3129e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.8911e-02,  3.9204e-02,  2.1771e-02],\n",
            "          [ 1.6164e-02,  7.8169e-02,  1.6282e-02],\n",
            "          [ 2.2178e-02, -2.5189e-03,  4.6760e-03]],\n",
            "\n",
            "         [[ 1.1805e-03, -1.5442e-02,  8.5739e-03],\n",
            "          [-2.1741e-02, -9.2279e-03,  4.3308e-02],\n",
            "          [-3.9723e-02,  5.6723e-02,  1.2398e-01]],\n",
            "\n",
            "         [[ 4.3569e-02, -3.3302e-02,  3.3436e-03],\n",
            "          [-1.0078e-02,  2.2693e-02, -1.7590e-02],\n",
            "          [ 4.4980e-02, -3.8076e-03,  1.5642e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.2117e-01,  1.0815e-01,  3.4741e-02],\n",
            "          [ 1.7783e-01,  2.1392e-01,  1.2809e-01],\n",
            "          [ 1.0146e-01,  1.2186e-01,  9.8735e-02]],\n",
            "\n",
            "         [[-2.3676e-02, -4.0258e-02, -9.0145e-03],\n",
            "          [-5.0197e-02, -8.1657e-04, -1.7129e-02],\n",
            "          [ 2.6146e-02,  5.0852e-03,  6.0162e-05]],\n",
            "\n",
            "         [[-3.3580e-02,  5.1647e-03, -3.5949e-02],\n",
            "          [ 3.3257e-02,  2.7031e-02, -2.7345e-02],\n",
            "          [-2.9223e-02, -2.9884e-02, -3.7904e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.3673e-02,  5.5466e-02,  1.2605e-02],\n",
            "          [ 4.1761e-02,  2.4690e-03,  4.9269e-02],\n",
            "          [-2.0259e-02,  2.6104e-02, -4.8704e-02]],\n",
            "\n",
            "         [[ 9.3209e-03, -2.4040e-02, -7.2308e-02],\n",
            "          [ 1.4393e-02, -6.6285e-03, -4.9122e-02],\n",
            "          [-1.4095e-02, -3.3717e-02, -2.7153e-02]],\n",
            "\n",
            "         [[ 4.0726e-02,  5.4843e-02,  1.1883e-02],\n",
            "          [ 3.2314e-02,  5.9913e-02,  4.0408e-02],\n",
            "          [ 6.0372e-02,  3.2033e-02,  1.6720e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 6.3838e-03, -4.0755e-02, -1.9321e-02],\n",
            "          [-3.9935e-03,  1.1143e-02,  2.7906e-02],\n",
            "          [ 7.0814e-02,  2.0280e-02,  7.7629e-02]],\n",
            "\n",
            "         [[ 1.4618e-02, -2.5520e-02,  3.4923e-02],\n",
            "          [ 2.1312e-02, -2.7110e-02, -2.5484e-02],\n",
            "          [-2.6334e-02,  2.3804e-02, -3.5636e-02]],\n",
            "\n",
            "         [[ 5.0083e-02,  4.6009e-02,  3.4740e-03],\n",
            "          [-4.7801e-03,  2.9557e-02, -3.2871e-02],\n",
            "          [-1.8504e-02,  3.3561e-02,  1.7559e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.6921e-02, -3.3989e-03, -3.0463e-02],\n",
            "          [ 3.3622e-02,  8.3282e-03, -1.1614e-02],\n",
            "          [-2.0258e-03,  1.6488e-02, -2.7224e-03]],\n",
            "\n",
            "         [[-4.3525e-03,  1.8353e-02, -3.7918e-02],\n",
            "          [ 4.7331e-02, -1.2390e-02,  1.6134e-02],\n",
            "          [ 2.6913e-03,  1.5133e-02, -1.7942e-02]],\n",
            "\n",
            "         [[ 3.2825e-02,  2.7514e-02, -2.8440e-02],\n",
            "          [ 2.7435e-02, -1.4051e-02,  3.7146e-02],\n",
            "          [ 4.5865e-02,  2.3231e-02, -2.6363e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 8.1335e-02,  4.7802e-02,  4.4462e-02],\n",
            "          [ 7.7401e-02,  1.1507e-01,  1.0430e-01],\n",
            "          [ 1.0140e-01,  7.6434e-02,  7.5280e-02]],\n",
            "\n",
            "         [[-3.7847e-03,  2.5743e-02,  1.8092e-03],\n",
            "          [-1.5795e-02, -3.7586e-02, -9.9603e-04],\n",
            "          [-5.5362e-02, -6.2975e-02, -4.7995e-02]],\n",
            "\n",
            "         [[-2.4202e-02, -5.5203e-03,  1.2441e-02],\n",
            "          [ 1.8099e-02,  3.2032e-02, -5.1578e-02],\n",
            "          [ 2.9630e-02, -1.5738e-02, -5.3070e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.5097e-02,  1.4992e-02,  1.7963e-02],\n",
            "          [-2.5230e-02, -1.0151e-02,  2.7438e-02],\n",
            "          [-4.2987e-02, -4.4277e-05,  1.2091e-02]],\n",
            "\n",
            "         [[ 5.4764e-03,  4.4854e-02, -7.2496e-03],\n",
            "          [ 2.9941e-02, -2.7623e-02,  1.5487e-02],\n",
            "          [ 5.9598e-02, -1.7989e-02, -5.3585e-02]],\n",
            "\n",
            "         [[-1.2934e-03,  1.2629e-02, -7.1119e-04],\n",
            "          [-2.1967e-02, -2.2965e-02,  4.5433e-02],\n",
            "          [ 4.1992e-02, -2.3097e-02, -6.7698e-05]]]], device='cuda:0')\n",
            "NPF_C2.bias Parameter containing:\n",
            "tensor([ 0.0803,  0.0469, -0.1544, -0.0356,  0.0199,  0.1699,  0.2991,  0.0135,\n",
            "         0.0096,  0.0658, -0.0216,  0.1856,  0.0700, -0.0045,  0.2051, -0.0228,\n",
            "        -0.0959,  0.0857,  0.1459, -0.0187,  0.0635, -0.1297,  0.0376, -0.0146,\n",
            "        -0.0420,  0.0745, -0.0325, -0.0713,  0.1838,  0.0541,  0.0224,  0.0658,\n",
            "        -0.1218,  0.0314, -0.0074,  0.1703, -0.1090, -0.0147,  0.0180,  0.3207,\n",
            "         0.1902,  0.3715, -0.0569, -0.0277, -0.0568, -0.1984,  0.0806,  0.0337,\n",
            "         0.3889,  0.1344, -0.0230,  0.0401,  0.2096,  0.2731, -0.0864,  0.0689,\n",
            "         0.2585, -0.0811,  0.1925,  0.0189,  0.0859, -0.1525,  0.0018,  0.1182],\n",
            "       device='cuda:0')\n",
            "NPF_C3.weight Parameter containing:\n",
            "tensor([[[[ 4.0277e-02,  1.0380e-02,  3.0164e-02],\n",
            "          [ 1.9846e-02, -4.1691e-02, -3.3827e-02],\n",
            "          [ 4.0902e-02,  3.2452e-02,  1.6134e-02]],\n",
            "\n",
            "         [[ 1.2608e-02, -7.9627e-05,  4.5708e-02],\n",
            "          [-6.7351e-03, -3.9214e-03,  2.4495e-02],\n",
            "          [-2.5032e-02,  2.9349e-02, -8.5515e-03]],\n",
            "\n",
            "         [[-2.9720e-03, -4.2030e-02, -4.2651e-03],\n",
            "          [-4.9442e-02,  1.7857e-02,  1.5030e-02],\n",
            "          [-5.9047e-03,  3.9732e-02,  4.4253e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.4930e-02, -3.1861e-02, -2.4948e-02],\n",
            "          [-4.0157e-02, -2.6837e-02, -1.4970e-02],\n",
            "          [-3.5345e-02, -3.9790e-03,  5.0483e-02]],\n",
            "\n",
            "         [[ 1.5829e-02, -3.5441e-04,  1.5805e-02],\n",
            "          [ 3.3268e-02,  1.5433e-03, -1.3210e-02],\n",
            "          [-3.0299e-02,  3.1137e-02,  1.5037e-02]],\n",
            "\n",
            "         [[ 1.0266e-02,  8.5330e-02,  4.8895e-02],\n",
            "          [ 8.6624e-04,  2.5042e-02,  3.6932e-02],\n",
            "          [ 3.5160e-02,  6.9222e-02,  4.4313e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.1656e-02, -1.8712e-02, -4.3902e-02],\n",
            "          [ 2.1826e-03, -1.6270e-02,  4.6408e-03],\n",
            "          [-2.9588e-02,  2.7350e-02,  2.6239e-03]],\n",
            "\n",
            "         [[ 4.0022e-02, -1.0389e-02, -3.1895e-02],\n",
            "          [-4.0534e-03,  3.4426e-03, -1.6167e-02],\n",
            "          [ 7.8528e-03, -1.6294e-02,  5.0504e-02]],\n",
            "\n",
            "         [[-2.4621e-02,  1.2350e-02,  1.2983e-02],\n",
            "          [-1.0388e-02, -3.7106e-02,  1.0821e-03],\n",
            "          [ 4.1923e-02, -2.3746e-02, -1.0526e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.5223e-02,  5.6251e-02,  4.5678e-02],\n",
            "          [ 3.9331e-02, -1.7249e-02,  3.9172e-02],\n",
            "          [-2.3631e-02,  1.2806e-02,  3.9896e-02]],\n",
            "\n",
            "         [[-2.2933e-02,  2.5775e-02, -2.6150e-03],\n",
            "          [-3.4077e-02,  2.4766e-02,  4.2766e-03],\n",
            "          [ 1.6931e-02,  1.3056e-02,  4.0370e-03]],\n",
            "\n",
            "         [[ 2.2567e-02,  8.4013e-02,  4.3144e-02],\n",
            "          [ 1.2026e-02,  6.9710e-02,  7.2909e-02],\n",
            "          [ 6.1156e-03,  3.5228e-02,  5.6682e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.9487e-02, -2.1893e-02, -1.9732e-02],\n",
            "          [-2.8138e-02,  7.9480e-03, -3.5128e-02],\n",
            "          [-2.3354e-02,  2.7238e-02, -2.4807e-04]],\n",
            "\n",
            "         [[-2.8371e-02,  4.3373e-02, -3.2863e-03],\n",
            "          [ 2.4345e-02, -2.3708e-02,  6.2970e-03],\n",
            "          [ 2.6335e-02, -1.1120e-02,  2.0926e-02]],\n",
            "\n",
            "         [[-4.9505e-02,  1.6859e-02, -3.6352e-02],\n",
            "          [-5.0330e-02, -4.8633e-02, -2.8395e-02],\n",
            "          [ 6.2908e-03, -1.7161e-02, -1.0686e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.3427e-03, -4.1065e-05, -2.4559e-03],\n",
            "          [-4.0001e-03,  2.0156e-02, -3.0020e-03],\n",
            "          [-4.1431e-02, -2.4839e-03, -1.8367e-02]],\n",
            "\n",
            "         [[ 2.1420e-02, -1.8375e-02, -3.1465e-02],\n",
            "          [ 2.2233e-02, -1.1743e-02,  3.7198e-02],\n",
            "          [ 5.1308e-03, -2.3987e-02, -3.9221e-02]],\n",
            "\n",
            "         [[-2.8027e-02,  5.1872e-02, -2.3429e-02],\n",
            "          [-2.8781e-02, -1.1932e-02,  5.3015e-02],\n",
            "          [-3.4214e-02,  1.4762e-02, -5.2109e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-3.1138e-02, -3.4041e-02, -7.8764e-03],\n",
            "          [ 1.2299e-02, -1.2520e-03, -3.5795e-02],\n",
            "          [ 2.0459e-02, -5.3588e-02, -4.6566e-02]],\n",
            "\n",
            "         [[ 2.7624e-02, -3.0488e-03,  2.1245e-02],\n",
            "          [ 5.2675e-02,  5.8207e-02,  5.0239e-02],\n",
            "          [ 5.6733e-02,  3.5298e-02,  5.3209e-02]],\n",
            "\n",
            "         [[-2.0243e-02,  1.6220e-02,  2.8171e-02],\n",
            "          [ 4.5449e-03,  6.3991e-03, -1.0231e-02],\n",
            "          [ 1.0086e-02,  7.3080e-03,  1.5097e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 6.6050e-03,  3.3085e-02, -9.8852e-04],\n",
            "          [ 4.3095e-02,  1.8850e-02,  4.5466e-02],\n",
            "          [ 2.0188e-03,  4.5797e-02,  4.6248e-02]],\n",
            "\n",
            "         [[ 3.9627e-02,  9.8114e-03,  4.3553e-03],\n",
            "          [ 2.4475e-02,  3.2113e-02, -3.3406e-02],\n",
            "          [-3.3446e-03,  2.9222e-02,  8.8378e-03]],\n",
            "\n",
            "         [[ 1.8706e-02,  4.8945e-02,  5.5746e-02],\n",
            "          [ 7.1549e-02,  8.9693e-02,  6.7863e-02],\n",
            "          [-1.7312e-02,  3.0217e-02,  1.8849e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.9936e-03,  1.0657e-02,  6.1420e-03],\n",
            "          [-3.0809e-02,  2.8617e-02, -2.5824e-02],\n",
            "          [ 2.5816e-02,  1.4740e-03, -4.2449e-02]],\n",
            "\n",
            "         [[-3.8617e-02, -3.6437e-02, -1.7605e-03],\n",
            "          [-4.7852e-02, -6.7285e-02, -9.9450e-03],\n",
            "          [-2.5722e-02, -1.3681e-02,  1.6948e-02]],\n",
            "\n",
            "         [[-1.9464e-02,  2.9159e-02,  1.7505e-02],\n",
            "          [-3.7901e-02, -3.1853e-02,  6.5358e-04],\n",
            "          [-2.8576e-02, -4.8854e-02,  3.4319e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-3.8926e-02, -5.2058e-03, -3.9092e-02],\n",
            "          [ 3.0351e-02, -9.4955e-03, -6.1212e-03],\n",
            "          [ 6.7267e-02,  7.3737e-03,  7.8061e-03]],\n",
            "\n",
            "         [[-1.6712e-02, -4.7110e-03, -3.1685e-02],\n",
            "          [-2.5154e-02, -3.0183e-03, -3.4470e-02],\n",
            "          [ 1.4889e-03, -2.6297e-02, -3.0031e-02]],\n",
            "\n",
            "         [[ 2.0992e-02, -2.7211e-02, -8.1709e-03],\n",
            "          [ 1.1045e-02,  3.4244e-03,  4.0241e-02],\n",
            "          [-3.2184e-02, -1.4618e-02,  2.8131e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.6869e-02, -9.4669e-03, -3.7862e-02],\n",
            "          [-5.7285e-03,  3.7203e-02, -2.5358e-02],\n",
            "          [ 3.5781e-02, -1.5327e-02,  1.2775e-02]],\n",
            "\n",
            "         [[ 1.5863e-02, -3.8666e-03, -4.1259e-02],\n",
            "          [ 2.4645e-02,  1.4179e-02,  2.4365e-02],\n",
            "          [ 2.2743e-02, -3.2308e-02, -1.2290e-02]],\n",
            "\n",
            "         [[ 1.4367e-02, -3.0053e-02,  1.8602e-02],\n",
            "          [-1.5783e-02,  2.3401e-02, -2.4383e-02],\n",
            "          [-1.5164e-02,  4.4420e-02, -3.2531e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.2075e-03, -2.9952e-02, -7.6509e-04],\n",
            "          [-1.0893e-02,  1.9678e-02, -4.2487e-02],\n",
            "          [ 4.0969e-02, -1.5540e-02,  3.9269e-02]],\n",
            "\n",
            "         [[-4.3651e-02, -1.6236e-02,  1.6668e-02],\n",
            "          [ 1.9227e-03, -2.4267e-02,  2.4857e-02],\n",
            "          [-1.6647e-02, -2.3300e-02,  2.0686e-02]],\n",
            "\n",
            "         [[-2.1838e-02,  2.2032e-02,  1.7269e-02],\n",
            "          [ 2.9042e-02,  1.4634e-02,  2.1261e-02],\n",
            "          [-9.2631e-03,  1.0095e-02, -2.0586e-02]]]], device='cuda:0')\n",
            "NPF_C3.bias Parameter containing:\n",
            "tensor([-0.0117,  0.0523,  0.0774, -0.0048,  0.1625,  0.0166, -0.0189, -0.0234,\n",
            "         0.0310,  0.0105, -0.0238,  0.0056,  0.0252, -0.0589, -0.0337, -0.0295,\n",
            "         0.0185,  0.0116,  0.0245,  0.0173, -0.0244, -0.0581,  0.0795,  0.0189,\n",
            "         0.0148, -0.0374, -0.0059, -0.0340, -0.0303, -0.0170,  0.1148,  0.0005,\n",
            "        -0.0223,  0.0428,  0.1451, -0.0159,  0.0081,  0.0241,  0.0451,  0.0680,\n",
            "        -0.0408, -0.0131,  0.0514, -0.0377,  0.1126,  0.0875,  0.0597,  0.0174,\n",
            "        -0.0303,  0.0171,  0.0276, -0.0151, -0.0070,  0.0454,  0.1382,  0.0398,\n",
            "        -0.0503,  0.1012,  0.0215,  0.0619, -0.0520, -0.0134,  0.0923, -0.0084,\n",
            "         0.0057,  0.0931,  0.0270,  0.1064,  0.0269,  0.0780, -0.0126,  0.0191,\n",
            "        -0.0144,  0.0128, -0.0373, -0.0039,  0.1177, -0.0041,  0.2548, -0.0580,\n",
            "        -0.0230, -0.0065, -0.1135, -0.0481, -0.0306, -0.0047,  0.0020, -0.0062,\n",
            "        -0.0597, -0.0201,  0.0550,  0.1325,  0.0547,  0.0320,  0.0182,  0.0567,\n",
            "         0.0334,  0.0066, -0.0016, -0.0189,  0.0534,  0.0163, -0.0247,  0.0025,\n",
            "         0.1158, -0.0041, -0.0561,  0.0350,  0.0867, -0.0105, -0.1077,  0.0231,\n",
            "         0.0347, -0.0033, -0.0038, -0.0430,  0.0508, -0.0347,  0.0747,  0.0778,\n",
            "         0.0736, -0.0305, -0.0328, -0.0105, -0.0354,  0.0144,  0.0416,  0.0390],\n",
            "       device='cuda:0')\n",
            "NPF_C4.weight Parameter containing:\n",
            "tensor([[[[ 0.0134,  0.0124,  0.0133],\n",
            "          [ 0.0408,  0.0138, -0.0144],\n",
            "          [ 0.0257, -0.0327, -0.0052]],\n",
            "\n",
            "         [[ 0.0004, -0.0326,  0.0289],\n",
            "          [-0.0082, -0.0094, -0.0194],\n",
            "          [-0.0064, -0.0007,  0.0240]],\n",
            "\n",
            "         [[-0.0106,  0.0127,  0.0208],\n",
            "          [-0.0077, -0.0305,  0.0235],\n",
            "          [ 0.0042, -0.0343, -0.0007]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0088,  0.0203, -0.0252],\n",
            "          [-0.0301,  0.0015,  0.0138],\n",
            "          [ 0.0033, -0.0321,  0.0171]],\n",
            "\n",
            "         [[ 0.0131, -0.0323, -0.0238],\n",
            "          [-0.0109, -0.0062,  0.0123],\n",
            "          [-0.0152, -0.0365, -0.0287]],\n",
            "\n",
            "         [[ 0.0135, -0.0271, -0.0126],\n",
            "          [ 0.0004,  0.0109,  0.0100],\n",
            "          [ 0.0237, -0.0039, -0.0276]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0608,  0.0510, -0.0159],\n",
            "          [ 0.0500,  0.0697,  0.0297],\n",
            "          [ 0.0194,  0.0214, -0.0126]],\n",
            "\n",
            "         [[ 0.0415,  0.0153, -0.0314],\n",
            "          [ 0.0109,  0.0348, -0.0017],\n",
            "          [-0.0078,  0.0223, -0.0454]],\n",
            "\n",
            "         [[ 0.0179,  0.0136, -0.0348],\n",
            "          [ 0.0124, -0.0188, -0.0218],\n",
            "          [-0.0280, -0.0124, -0.0165]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0031,  0.0015, -0.0221],\n",
            "          [ 0.0162,  0.0147, -0.0342],\n",
            "          [-0.0170, -0.0175,  0.0080]],\n",
            "\n",
            "         [[ 0.0282,  0.0400, -0.0202],\n",
            "          [-0.0029,  0.0218, -0.0006],\n",
            "          [-0.0151, -0.0365, -0.0305]],\n",
            "\n",
            "         [[-0.0081,  0.0005, -0.0015],\n",
            "          [-0.0072, -0.0045, -0.0128],\n",
            "          [-0.0286, -0.0092, -0.0140]]],\n",
            "\n",
            "\n",
            "        [[[-0.0296, -0.0237, -0.0455],\n",
            "          [-0.0186, -0.0159, -0.0199],\n",
            "          [-0.0369, -0.0226, -0.0333]],\n",
            "\n",
            "         [[-0.0253, -0.0516, -0.0198],\n",
            "          [-0.0233, -0.0581, -0.0427],\n",
            "          [-0.0224, -0.0041,  0.0071]],\n",
            "\n",
            "         [[-0.0298,  0.0053, -0.0030],\n",
            "          [-0.0235, -0.0149, -0.0145],\n",
            "          [ 0.0029,  0.0199, -0.0313]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0582, -0.0606, -0.0098],\n",
            "          [-0.0512, -0.0513, -0.0211],\n",
            "          [-0.0290, -0.0377, -0.0386]],\n",
            "\n",
            "         [[ 0.0021,  0.0260, -0.0143],\n",
            "          [ 0.0261,  0.0184,  0.0027],\n",
            "          [ 0.0289,  0.0304,  0.0306]],\n",
            "\n",
            "         [[-0.0239, -0.0009, -0.0206],\n",
            "          [ 0.0137, -0.0062,  0.0121],\n",
            "          [ 0.0116, -0.0169, -0.0243]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0466,  0.0582,  0.0382],\n",
            "          [ 0.0469,  0.0428, -0.0097],\n",
            "          [ 0.0206, -0.0430, -0.0232]],\n",
            "\n",
            "         [[ 0.0202, -0.0190, -0.0196],\n",
            "          [ 0.0267, -0.0060,  0.0149],\n",
            "          [ 0.0096, -0.0352, -0.0291]],\n",
            "\n",
            "         [[-0.0267, -0.0200,  0.0213],\n",
            "          [-0.0209,  0.0175, -0.0166],\n",
            "          [-0.0112, -0.0164, -0.0305]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0235, -0.0241,  0.0159],\n",
            "          [-0.0204,  0.0032, -0.0012],\n",
            "          [-0.0289,  0.0031,  0.0131]],\n",
            "\n",
            "         [[ 0.0297,  0.0091,  0.0195],\n",
            "          [ 0.0055,  0.0276,  0.0092],\n",
            "          [-0.0206, -0.0261, -0.0090]],\n",
            "\n",
            "         [[ 0.0029, -0.0188, -0.0084],\n",
            "          [ 0.0065, -0.0255, -0.0269],\n",
            "          [ 0.0051, -0.0095, -0.0066]]],\n",
            "\n",
            "\n",
            "        [[[-0.0232,  0.0014,  0.0283],\n",
            "          [ 0.0290, -0.0005, -0.0052],\n",
            "          [ 0.0162,  0.0244, -0.0121]],\n",
            "\n",
            "         [[-0.0249, -0.0051, -0.0212],\n",
            "          [ 0.0286, -0.0197, -0.0386],\n",
            "          [ 0.0111, -0.0238, -0.0415]],\n",
            "\n",
            "         [[ 0.0058,  0.0084,  0.0016],\n",
            "          [ 0.0205,  0.0287,  0.0238],\n",
            "          [ 0.0175, -0.0136, -0.0087]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0307, -0.0364, -0.0249],\n",
            "          [-0.0302, -0.0430, -0.0553],\n",
            "          [-0.0060, -0.0112, -0.0367]],\n",
            "\n",
            "         [[ 0.0007,  0.0411,  0.0137],\n",
            "          [-0.0092,  0.0221,  0.0187],\n",
            "          [-0.0046,  0.0051,  0.0050]],\n",
            "\n",
            "         [[ 0.0335,  0.0317,  0.0073],\n",
            "          [ 0.0308,  0.0225,  0.0204],\n",
            "          [ 0.0203, -0.0056, -0.0023]]],\n",
            "\n",
            "\n",
            "        [[[-0.0344, -0.0017,  0.0047],\n",
            "          [-0.0088, -0.0292, -0.0067],\n",
            "          [-0.0311,  0.0120, -0.0030]],\n",
            "\n",
            "         [[-0.0105, -0.0056, -0.0184],\n",
            "          [-0.0097, -0.0465, -0.0400],\n",
            "          [-0.0365, -0.0141,  0.0059]],\n",
            "\n",
            "         [[-0.0188, -0.0061,  0.0048],\n",
            "          [-0.0325,  0.0157, -0.0045],\n",
            "          [-0.0235,  0.0078, -0.0100]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0062,  0.0173,  0.0050],\n",
            "          [-0.0098,  0.0048,  0.0259],\n",
            "          [ 0.0492,  0.0262,  0.0169]],\n",
            "\n",
            "         [[-0.0262,  0.0018, -0.0043],\n",
            "          [ 0.0069, -0.0162, -0.0179],\n",
            "          [-0.0040, -0.0343, -0.0356]],\n",
            "\n",
            "         [[-0.0232,  0.0117, -0.0287],\n",
            "          [ 0.0052, -0.0014, -0.0121],\n",
            "          [ 0.0196, -0.0042,  0.0193]]]], device='cuda:0')\n",
            "NPF_C4.bias Parameter containing:\n",
            "tensor([-2.0681e-02, -7.0083e-03,  7.9164e-02, -1.5063e-02,  1.1654e-02,\n",
            "         8.1356e-03,  4.0649e-02, -3.0997e-02, -3.9964e-02,  2.8621e-02,\n",
            "        -2.8249e-02,  1.5643e-02,  2.5993e-02,  1.5263e-02, -2.0168e-02,\n",
            "        -3.7159e-05,  1.2660e-01,  2.1205e-02,  2.9402e-02, -3.8959e-02,\n",
            "         8.2104e-02, -5.9322e-02, -4.7387e-02, -1.3075e-03,  1.4025e-02,\n",
            "         4.0303e-03, -2.0466e-02,  3.7914e-03, -5.7136e-02, -9.7919e-03,\n",
            "        -2.1127e-02,  1.6074e-02,  9.2887e-03,  5.6214e-02, -1.3441e-03,\n",
            "        -2.1041e-02,  5.3514e-03, -2.4324e-02,  2.3716e-02,  8.4859e-03,\n",
            "         2.4969e-02,  6.6880e-02, -6.8375e-02,  2.9831e-02,  2.0731e-02,\n",
            "        -4.5061e-02, -2.6676e-02, -7.5079e-03, -1.6184e-02,  1.1892e-01,\n",
            "        -3.1279e-02, -6.4117e-02,  2.7574e-02, -8.2456e-03,  3.1179e-02,\n",
            "         1.3997e-02,  8.0652e-03, -4.6303e-02,  5.9273e-02, -6.8813e-03,\n",
            "        -3.8176e-02,  1.3124e-01,  9.9441e-02, -5.2605e-02,  4.0567e-02,\n",
            "        -7.8636e-02, -5.2676e-03, -3.8285e-02, -7.5579e-03, -1.6452e-03,\n",
            "         1.1282e-02, -1.4039e-02, -1.7723e-02,  1.2481e-01, -2.1616e-02,\n",
            "        -1.4343e-02, -2.4840e-02, -4.9058e-02,  8.5411e-03, -2.0515e-02,\n",
            "         1.0301e-03, -3.9457e-02, -2.3849e-02,  7.2384e-02,  1.5370e-02,\n",
            "         2.0022e-02, -3.0407e-02, -5.1788e-02, -2.1095e-03, -3.1584e-02,\n",
            "         8.5809e-03,  3.6002e-02, -3.5588e-03, -3.8323e-02,  6.8188e-02,\n",
            "        -2.4315e-02,  4.7710e-02,  2.1729e-02,  5.6142e-02,  6.0805e-02,\n",
            "        -2.6695e-02, -2.2452e-02, -1.9114e-02, -3.2189e-02, -3.1818e-02,\n",
            "         5.2669e-02,  8.5757e-02,  1.0987e-01,  5.0168e-03,  5.1070e-02,\n",
            "         4.5304e-02,  3.6983e-02, -2.0325e-02,  9.4715e-02, -9.0900e-03,\n",
            "         5.4102e-02, -5.1025e-02,  2.7118e-02, -2.9361e-03, -2.4686e-02,\n",
            "         3.1643e-02, -3.6353e-02,  4.1194e-03, -8.1876e-03, -5.8619e-03,\n",
            "        -3.6086e-02,  1.6197e-02,  1.2061e-02], device='cuda:0')\n",
            "NPF_D1.weight Parameter containing:\n",
            "tensor([[ 2.1958e-03,  1.3943e-03, -1.5808e-03,  ..., -1.5723e-03,\n",
            "          5.5278e-04,  2.3052e-04],\n",
            "        [ 8.7746e-04,  1.2561e-03, -6.2257e-05,  ..., -1.6636e-03,\n",
            "         -9.8102e-04, -4.9839e-04],\n",
            "        [-7.1099e-04, -4.9462e-03, -3.4833e-03,  ...,  2.7029e-03,\n",
            "         -1.6548e-03,  7.0814e-04],\n",
            "        ...,\n",
            "        [-3.4940e-05,  2.7860e-03,  1.6167e-03,  ...,  1.8612e-03,\n",
            "         -1.8230e-03,  8.6013e-04],\n",
            "        [ 1.3720e-03,  1.0459e-05,  8.0660e-04,  ..., -9.5000e-04,\n",
            "          1.0763e-03,  4.9291e-04],\n",
            "        [-1.6969e-04,  8.2414e-04,  1.5698e-03,  ...,  3.5408e-03,\n",
            "          2.7926e-03, -6.8041e-04]], device='cuda:0')\n",
            "NPF_D1.bias Parameter containing:\n",
            "tensor([ 2.7263e-03,  8.6467e-03,  2.1539e-03,  1.0545e-02,  1.1852e-02,\n",
            "        -9.4900e-03, -3.5309e-03, -5.0065e-03, -8.1237e-04,  4.0648e-03,\n",
            "         1.0590e-02, -1.3374e-03,  1.6382e-03, -1.0176e-03, -3.7117e-03,\n",
            "         7.2812e-03,  2.6486e-03, -9.1937e-03,  6.8210e-03, -2.4895e-04,\n",
            "         3.1238e-03,  6.1709e-03, -3.3188e-03,  1.7508e-02,  1.2323e-02,\n",
            "         3.9905e-04, -9.0884e-03,  1.0308e-03, -2.3503e-03, -7.4581e-03,\n",
            "         8.8726e-03,  1.4065e-02, -2.4663e-03, -9.9333e-03, -1.9305e-03,\n",
            "         6.2918e-03,  1.2618e-02, -1.1736e-03,  2.8675e-03, -2.7144e-03,\n",
            "        -1.7742e-03, -7.6778e-03,  1.2900e-03, -4.0537e-03, -4.3465e-03,\n",
            "        -1.4851e-03,  1.3188e-02,  1.3168e-03,  1.0816e-02, -4.6535e-03,\n",
            "         8.2435e-03,  3.7880e-03, -1.0372e-02, -1.0107e-03,  1.7748e-03,\n",
            "        -3.5076e-03,  6.3206e-03,  1.5215e-02,  3.6587e-03, -8.3152e-03,\n",
            "         3.9041e-03,  6.9407e-03, -7.1253e-03, -2.4715e-03, -7.9369e-03,\n",
            "        -4.5519e-04,  3.5204e-03,  2.6888e-04,  2.6759e-03, -9.9306e-04,\n",
            "        -3.0734e-03,  6.1757e-04,  1.1553e-02,  4.8287e-03,  1.3781e-02,\n",
            "        -8.9891e-03,  6.9874e-03,  5.9959e-03, -1.6914e-03, -2.0738e-03,\n",
            "        -6.5461e-03,  1.7361e-03, -1.1462e-03,  1.9788e-03,  3.4793e-03,\n",
            "        -4.5998e-03, -1.1786e-03,  5.0669e-04, -2.7846e-03, -4.0069e-03,\n",
            "        -5.2873e-03, -2.9072e-03, -4.8615e-03, -1.2108e-02, -5.5519e-04,\n",
            "        -1.8201e-03,  2.7955e-03, -2.3831e-03,  2.8414e-03, -1.0357e-02,\n",
            "        -6.0555e-03, -3.1553e-06, -1.2627e-02, -1.2564e-02,  2.8578e-03,\n",
            "        -7.0032e-03, -3.3018e-03,  1.0771e-02,  1.2855e-03,  3.3697e-03,\n",
            "        -3.5231e-03, -5.4274e-03,  1.9956e-02, -2.5386e-03,  2.7069e-02,\n",
            "        -1.6792e-03,  2.1734e-03, -1.4158e-03, -9.4536e-03,  1.1948e-02,\n",
            "        -5.3820e-04,  7.3867e-04,  7.5011e-03,  5.7812e-03,  1.9207e-03,\n",
            "        -1.7793e-03,  5.7436e-03,  8.6158e-04,  2.5181e-04, -9.5126e-04,\n",
            "         9.0333e-03,  3.8969e-03,  8.6116e-03,  1.3459e-03,  7.9260e-03,\n",
            "        -1.2244e-03,  1.6488e-03,  1.7486e-03,  1.1968e-02,  1.6828e-02,\n",
            "        -5.3845e-03,  1.7194e-02, -4.5652e-03,  3.6242e-03, -2.1628e-03,\n",
            "        -1.8354e-03,  1.1827e-02, -6.8990e-03, -7.6275e-03,  8.1118e-03,\n",
            "        -4.4711e-03,  1.3009e-02,  7.5241e-03, -2.7296e-03,  1.0149e-02,\n",
            "         5.4530e-03,  2.1573e-03,  8.5837e-04, -2.2416e-03,  2.8401e-04,\n",
            "        -2.2646e-03,  2.1203e-02,  5.0464e-03, -1.1254e-02,  2.3370e-03,\n",
            "        -1.3709e-03, -8.8217e-03, -9.3191e-05,  7.4883e-05, -9.6202e-05,\n",
            "         4.8330e-03,  3.6319e-03,  1.9279e-02, -1.4634e-02, -1.4291e-03,\n",
            "        -4.6268e-03, -7.0377e-04,  1.6611e-03,  8.5175e-04,  9.1457e-03,\n",
            "         1.1576e-02, -2.8688e-03,  2.0465e-03, -5.0813e-04,  4.4070e-03,\n",
            "        -5.2083e-03,  6.7256e-03,  1.0829e-02, -1.7118e-03, -2.2758e-03,\n",
            "         1.9560e-03,  1.7470e-03, -3.4385e-03, -8.3875e-03,  6.9816e-03,\n",
            "         2.5554e-03, -6.5648e-03, -1.1095e-02,  3.4340e-03, -2.6714e-03,\n",
            "         7.7101e-03,  5.6306e-03,  9.1360e-03,  7.4220e-03, -3.1688e-03,\n",
            "         1.4781e-02,  2.5449e-03,  5.2840e-04,  1.9922e-02,  2.0281e-03,\n",
            "         6.8481e-03, -2.2113e-03,  1.9015e-03,  3.1532e-03, -5.3112e-03,\n",
            "         4.4214e-03,  5.4815e-03, -4.9495e-03,  1.4318e-02, -2.7519e-03,\n",
            "        -1.0134e-02, -6.6514e-03, -2.1193e-03,  7.6910e-05, -8.9408e-04,\n",
            "        -1.1721e-04, -2.8052e-04, -5.0287e-03,  2.0598e-03,  2.6849e-02,\n",
            "         8.7075e-03,  7.7593e-03, -5.9263e-03,  1.0489e-02, -5.3673e-03,\n",
            "         2.0006e-03, -4.6284e-03,  6.3061e-03,  6.4907e-03, -5.6339e-04,\n",
            "        -5.6425e-04,  4.9396e-03,  3.5404e-03,  1.1089e-03,  1.0792e-02,\n",
            "        -1.0127e-03, -4.9628e-04, -5.9173e-03, -3.4118e-03,  3.0606e-03,\n",
            "         4.3294e-03,  1.3141e-02,  1.0605e-02,  5.6436e-04,  1.1461e-02,\n",
            "         6.6782e-04], device='cuda:0')\n",
            "NPF_D2.weight Parameter containing:\n",
            "tensor([[ 0.0162,  0.0589, -0.0596,  ..., -0.0315, -0.0640,  0.0450],\n",
            "        [-0.0458,  0.0177,  0.0586,  ..., -0.0217, -0.0178, -0.0037],\n",
            "        [ 0.0156,  0.0231, -0.0162,  ...,  0.0427,  0.0170, -0.0185],\n",
            "        ...,\n",
            "        [-0.0354,  0.0092, -0.0410,  ..., -0.0334, -0.0368,  0.0468],\n",
            "        [ 0.0430,  0.0066,  0.0325,  ..., -0.0378,  0.0631,  0.0523],\n",
            "        [-0.0348,  0.0243,  0.0011,  ...,  0.0450,  0.0528,  0.0114]],\n",
            "       device='cuda:0')\n",
            "NPF_D2.bias Parameter containing:\n",
            "tensor([ 2.3918e-02,  2.8234e-02,  4.3066e-03,  3.3527e-02,  5.0546e-02,\n",
            "        -4.4808e-02, -2.2679e-02, -6.5189e-02,  4.3056e-02,  5.8509e-02,\n",
            "         6.1944e-02,  2.9156e-02, -3.7116e-02, -8.8279e-04, -3.8355e-02,\n",
            "        -2.6577e-02, -1.4062e-02, -4.6546e-02, -2.7822e-02, -1.3759e-02,\n",
            "         9.0281e-02,  5.6187e-02, -3.1140e-03,  7.3252e-02,  3.9047e-02,\n",
            "         7.7486e-02, -6.2006e-02, -4.8564e-02, -3.1465e-02, -5.4387e-02,\n",
            "         5.6273e-02,  7.4933e-03, -2.9030e-02, -5.1979e-02, -2.8031e-02,\n",
            "        -2.1220e-02,  6.3009e-02,  1.6348e-02,  1.3608e-02,  7.1469e-02,\n",
            "         3.6004e-02,  6.3580e-02,  3.2642e-02, -2.8624e-02, -1.6326e-02,\n",
            "        -4.6358e-02, -3.2426e-02, -7.1975e-03,  4.6036e-02,  6.4744e-02,\n",
            "        -1.8766e-02,  2.0520e-02, -8.4470e-04,  2.6783e-02, -3.3756e-02,\n",
            "        -9.3188e-03,  2.5569e-02,  6.4866e-02, -6.5806e-02,  2.8961e-02,\n",
            "         2.7762e-02, -4.0230e-02,  5.0812e-02,  5.2152e-02,  8.7180e-02,\n",
            "        -4.0330e-02,  4.8437e-02, -2.3763e-02, -6.6727e-02,  3.9273e-02,\n",
            "        -1.1820e-02,  2.1494e-02,  2.0478e-02, -5.9724e-02,  1.4689e-02,\n",
            "        -1.3222e-02,  2.1286e-02,  1.0446e-02, -3.9441e-02,  6.7894e-02,\n",
            "        -1.2999e-02, -3.1016e-04, -1.6997e-02,  7.9987e-02,  6.1335e-02,\n",
            "        -5.5966e-02, -3.2162e-02, -3.1876e-02,  8.8825e-03, -3.9006e-02,\n",
            "         2.0232e-02,  4.5209e-02,  1.0847e-04,  2.9328e-02,  6.7795e-02,\n",
            "         8.0652e-02, -2.1628e-02, -1.4609e-02, -5.6283e-02, -3.2304e-02,\n",
            "         3.7717e-02, -5.2470e-02, -8.3841e-03,  1.9144e-02,  7.7948e-02,\n",
            "         2.3058e-02, -4.0549e-03, -4.3948e-02,  6.0529e-02, -1.3097e-02,\n",
            "         3.9420e-02,  2.0400e-03, -1.6056e-02,  5.1285e-02,  3.2787e-02,\n",
            "        -1.6865e-02,  8.0792e-02, -3.7587e-02,  3.3972e-03,  6.2690e-02,\n",
            "        -6.5654e-02,  2.3820e-02,  4.5327e-02, -1.0119e-02,  2.5137e-02,\n",
            "        -9.4091e-03, -6.1067e-03,  4.8628e-02,  1.8869e-02,  9.0437e-04,\n",
            "        -1.2610e-02,  2.1686e-02,  2.7099e-03,  3.9880e-02,  6.3954e-02,\n",
            "        -4.4895e-02,  5.1859e-02,  1.2579e-02,  2.3163e-02, -2.2237e-02,\n",
            "         1.2627e-02, -3.9111e-02, -1.6720e-02,  5.7190e-04,  3.6380e-02,\n",
            "        -3.6590e-02,  1.0840e-02,  4.1467e-02, -1.9239e-02, -4.5029e-02,\n",
            "         2.1213e-02, -4.8386e-02,  4.4330e-03, -3.6866e-02,  1.9000e-02,\n",
            "         5.0727e-02, -2.3475e-02, -2.7717e-02,  5.4954e-02,  1.7503e-02,\n",
            "         6.6646e-02, -6.3616e-03,  1.5020e-02,  7.9229e-02,  6.7684e-02,\n",
            "        -6.1204e-02,  1.4962e-02, -5.6875e-02,  9.9318e-02, -3.0906e-02,\n",
            "         2.4810e-02, -3.9326e-02,  7.8340e-02,  6.6988e-02, -8.4335e-05,\n",
            "         4.4460e-03, -2.6355e-02, -8.7145e-03,  4.0099e-02, -4.8220e-02,\n",
            "        -7.2300e-03,  2.9709e-02, -3.9374e-03,  5.9588e-02,  2.7693e-02,\n",
            "        -2.3848e-02,  1.9919e-02,  3.4118e-02, -5.4962e-02, -3.0520e-03,\n",
            "         1.8928e-02,  2.1584e-02, -5.7246e-02, -6.7414e-02,  5.3667e-02,\n",
            "         2.9480e-02,  2.5637e-03,  1.4771e-02,  4.9039e-02, -1.9089e-02,\n",
            "        -2.7971e-02, -4.5007e-02, -5.4325e-02,  1.3072e-02,  1.7888e-02,\n",
            "        -4.7932e-02, -1.3828e-02,  1.9816e-02, -4.1256e-02,  3.5129e-02,\n",
            "         9.1780e-02,  4.4964e-03, -3.4662e-02,  2.7919e-02,  4.9996e-02,\n",
            "        -3.8692e-02, -3.3245e-02, -4.2547e-02, -4.6373e-02, -4.3493e-02,\n",
            "        -3.1305e-03,  3.6448e-02,  3.8549e-03,  2.0895e-02,  2.0003e-02,\n",
            "         6.7754e-02,  7.6016e-03,  9.0603e-02,  3.6765e-03,  1.3255e-02,\n",
            "         3.8544e-02, -5.8348e-02,  2.3845e-02,  7.1091e-02,  4.6622e-02,\n",
            "         1.1686e-02, -4.8189e-02,  3.9982e-02,  9.5023e-03,  1.1421e-02,\n",
            "        -1.6778e-02, -7.0090e-02,  6.0238e-02, -4.2643e-02,  3.6676e-02,\n",
            "         5.5428e-02, -4.2001e-02,  2.1625e-02, -4.3241e-02, -1.8984e-02,\n",
            "        -3.9170e-02, -6.4637e-03, -1.2816e-02, -2.5875e-02,  1.0270e-02,\n",
            "         1.2457e-02], device='cuda:0')\n",
            "NPV_C1.weight Parameter containing:\n",
            "tensor([[[[-0.0523, -0.1198, -0.1790],\n",
            "          [-0.1405, -0.0987,  0.1393],\n",
            "          [-0.1083,  0.0494,  0.0667]],\n",
            "\n",
            "         [[-0.1653, -0.1153, -0.0014],\n",
            "          [ 0.1354, -0.1512,  0.0534],\n",
            "          [-0.1379, -0.0299, -0.1248]],\n",
            "\n",
            "         [[-0.1869,  0.1108, -0.0350],\n",
            "          [ 0.0768,  0.0947, -0.1353],\n",
            "          [-0.1445,  0.1039,  0.0693]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0797,  0.1380, -0.0104],\n",
            "          [-0.1582, -0.1335, -0.1757],\n",
            "          [-0.0470,  0.1859, -0.1699]],\n",
            "\n",
            "         [[ 0.1858,  0.1674, -0.1189],\n",
            "          [-0.1521,  0.0631,  0.0011],\n",
            "          [-0.0881,  0.1200, -0.1765]],\n",
            "\n",
            "         [[ 0.0302, -0.1908,  0.0095],\n",
            "          [ 0.0819, -0.0844,  0.0574],\n",
            "          [-0.1820,  0.0729, -0.0242]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1313,  0.0494, -0.1315],\n",
            "          [ 0.1657, -0.1638,  0.0509],\n",
            "          [-0.1019, -0.0700, -0.0325]],\n",
            "\n",
            "         [[-0.0372, -0.1273,  0.0425],\n",
            "          [ 0.1780, -0.0630,  0.0718],\n",
            "          [-0.1769,  0.0632, -0.0277]],\n",
            "\n",
            "         [[-0.1255, -0.1576,  0.1422],\n",
            "          [-0.1777, -0.1176,  0.0546],\n",
            "          [-0.0385, -0.1790,  0.1379]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1631,  0.0426, -0.0455],\n",
            "          [-0.1514, -0.0169, -0.0383],\n",
            "          [ 0.1541, -0.1725, -0.0780]],\n",
            "\n",
            "         [[-0.1759,  0.1272, -0.0333],\n",
            "          [-0.0898, -0.1494,  0.1010],\n",
            "          [ 0.1524, -0.0359,  0.1509]],\n",
            "\n",
            "         [[-0.0115, -0.0335,  0.1770],\n",
            "          [-0.1206, -0.1487,  0.1416],\n",
            "          [-0.0785, -0.0548,  0.1098]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1212,  0.0767,  0.0111],\n",
            "          [ 0.0287,  0.0844, -0.1476],\n",
            "          [ 0.1736, -0.0193,  0.1072]],\n",
            "\n",
            "         [[-0.0541, -0.0549, -0.0733],\n",
            "          [-0.0418, -0.0772,  0.0846],\n",
            "          [-0.0311,  0.0495,  0.0262]],\n",
            "\n",
            "         [[-0.1261,  0.1239,  0.1004],\n",
            "          [ 0.0889,  0.0937, -0.1645],\n",
            "          [-0.0068, -0.0501,  0.1614]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1151, -0.1027, -0.1891],\n",
            "          [-0.0351,  0.0832,  0.0306],\n",
            "          [-0.0976,  0.1276, -0.0135]],\n",
            "\n",
            "         [[ 0.0553, -0.0385,  0.1490],\n",
            "          [-0.1240,  0.1121, -0.0897],\n",
            "          [ 0.1312, -0.1005,  0.1500]],\n",
            "\n",
            "         [[ 0.1090,  0.1431,  0.0771],\n",
            "          [ 0.1681, -0.0390, -0.0590],\n",
            "          [ 0.0648,  0.0545,  0.0979]]]], device='cuda:0', requires_grad=True)\n",
            "NPV_C1.bias Parameter containing:\n",
            "tensor([ 0.0746, -0.0042, -0.0554,  0.1657,  0.1838, -0.0505,  0.0232, -0.0752,\n",
            "         0.1580, -0.1674, -0.1402,  0.0565, -0.1393, -0.0867, -0.1013,  0.1837,\n",
            "        -0.0084, -0.1680,  0.1207,  0.1595,  0.1320, -0.1513,  0.0776, -0.0191,\n",
            "         0.0394, -0.1526, -0.0578, -0.0442,  0.1858, -0.0574, -0.1534,  0.1033,\n",
            "         0.0106, -0.0225, -0.1218,  0.0529,  0.1553,  0.1151,  0.0388,  0.1736,\n",
            "        -0.1442,  0.1404, -0.0509,  0.1535,  0.1699, -0.1249, -0.1156,  0.1601,\n",
            "         0.0145,  0.0927, -0.0004,  0.1717,  0.0398,  0.0811, -0.0832,  0.1815,\n",
            "         0.1767, -0.0241,  0.1302, -0.1372, -0.1908, -0.1696,  0.1025,  0.1173],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_C2.weight Parameter containing:\n",
            "tensor([[[[-0.0329,  0.0125, -0.0094],\n",
            "          [ 0.0305,  0.0042, -0.0321],\n",
            "          [ 0.0284, -0.0188,  0.0073]],\n",
            "\n",
            "         [[-0.0314,  0.0339,  0.0120],\n",
            "          [-0.0099,  0.0406,  0.0060],\n",
            "          [-0.0167,  0.0313,  0.0320]],\n",
            "\n",
            "         [[ 0.0220,  0.0096,  0.0152],\n",
            "          [-0.0261,  0.0368,  0.0077],\n",
            "          [-0.0329, -0.0168,  0.0304]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0094, -0.0104, -0.0343],\n",
            "          [ 0.0207,  0.0135,  0.0363],\n",
            "          [ 0.0241,  0.0353, -0.0328]],\n",
            "\n",
            "         [[-0.0108,  0.0129, -0.0243],\n",
            "          [ 0.0208, -0.0101, -0.0162],\n",
            "          [-0.0050, -0.0011, -0.0206]],\n",
            "\n",
            "         [[ 0.0023, -0.0189, -0.0198],\n",
            "          [ 0.0074,  0.0104, -0.0004],\n",
            "          [ 0.0062,  0.0171,  0.0395]]],\n",
            "\n",
            "\n",
            "        [[[-0.0138, -0.0271, -0.0181],\n",
            "          [-0.0315, -0.0368,  0.0022],\n",
            "          [-0.0254,  0.0128,  0.0163]],\n",
            "\n",
            "         [[ 0.0210,  0.0188,  0.0066],\n",
            "          [ 0.0123,  0.0109,  0.0312],\n",
            "          [ 0.0184, -0.0349, -0.0123]],\n",
            "\n",
            "         [[-0.0387,  0.0342, -0.0202],\n",
            "          [ 0.0118,  0.0064, -0.0043],\n",
            "          [ 0.0080,  0.0304, -0.0265]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0407,  0.0314, -0.0395],\n",
            "          [ 0.0071,  0.0223,  0.0154],\n",
            "          [ 0.0066,  0.0109,  0.0226]],\n",
            "\n",
            "         [[-0.0180, -0.0169,  0.0272],\n",
            "          [-0.0086, -0.0323, -0.0349],\n",
            "          [ 0.0233, -0.0207, -0.0321]],\n",
            "\n",
            "         [[-0.0109,  0.0188,  0.0301],\n",
            "          [-0.0251, -0.0189, -0.0108],\n",
            "          [ 0.0280, -0.0250, -0.0282]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0291, -0.0231, -0.0101],\n",
            "          [ 0.0185, -0.0246,  0.0342],\n",
            "          [-0.0175, -0.0384,  0.0357]],\n",
            "\n",
            "         [[-0.0006,  0.0400,  0.0411],\n",
            "          [-0.0375,  0.0066, -0.0167],\n",
            "          [ 0.0352, -0.0224, -0.0027]],\n",
            "\n",
            "         [[-0.0064, -0.0090, -0.0009],\n",
            "          [ 0.0367,  0.0309, -0.0121],\n",
            "          [-0.0184,  0.0411,  0.0239]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0206,  0.0392, -0.0260],\n",
            "          [ 0.0307, -0.0074,  0.0166],\n",
            "          [-0.0011,  0.0328, -0.0216]],\n",
            "\n",
            "         [[ 0.0115,  0.0180, -0.0015],\n",
            "          [ 0.0135,  0.0084,  0.0243],\n",
            "          [-0.0344,  0.0022,  0.0119]],\n",
            "\n",
            "         [[ 0.0002,  0.0031, -0.0383],\n",
            "          [ 0.0149,  0.0303, -0.0088],\n",
            "          [ 0.0268, -0.0144, -0.0086]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0407, -0.0131, -0.0309],\n",
            "          [ 0.0008,  0.0403, -0.0170],\n",
            "          [ 0.0331,  0.0330, -0.0319]],\n",
            "\n",
            "         [[ 0.0179,  0.0009,  0.0298],\n",
            "          [ 0.0038,  0.0373, -0.0211],\n",
            "          [-0.0281, -0.0070, -0.0328]],\n",
            "\n",
            "         [[ 0.0101,  0.0227, -0.0003],\n",
            "          [ 0.0168, -0.0334, -0.0399],\n",
            "          [ 0.0297, -0.0031, -0.0266]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0242, -0.0283,  0.0039],\n",
            "          [ 0.0256,  0.0219, -0.0088],\n",
            "          [ 0.0016,  0.0024, -0.0360]],\n",
            "\n",
            "         [[ 0.0097, -0.0364, -0.0202],\n",
            "          [ 0.0366,  0.0230,  0.0362],\n",
            "          [-0.0038, -0.0207,  0.0244]],\n",
            "\n",
            "         [[-0.0393,  0.0034,  0.0363],\n",
            "          [ 0.0101,  0.0353,  0.0025],\n",
            "          [ 0.0280, -0.0273,  0.0358]]],\n",
            "\n",
            "\n",
            "        [[[-0.0276, -0.0247,  0.0037],\n",
            "          [ 0.0330,  0.0046,  0.0138],\n",
            "          [-0.0280, -0.0394, -0.0148]],\n",
            "\n",
            "         [[ 0.0301,  0.0229,  0.0167],\n",
            "          [ 0.0135, -0.0056, -0.0324],\n",
            "          [-0.0361, -0.0317,  0.0094]],\n",
            "\n",
            "         [[ 0.0240,  0.0399, -0.0129],\n",
            "          [ 0.0321, -0.0397,  0.0121],\n",
            "          [ 0.0058,  0.0295,  0.0365]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0243, -0.0357,  0.0187],\n",
            "          [ 0.0265, -0.0313,  0.0178],\n",
            "          [-0.0271,  0.0194, -0.0241]],\n",
            "\n",
            "         [[-0.0107, -0.0194, -0.0087],\n",
            "          [ 0.0399, -0.0303,  0.0388],\n",
            "          [ 0.0313, -0.0330,  0.0398]],\n",
            "\n",
            "         [[-0.0120, -0.0259, -0.0372],\n",
            "          [-0.0189,  0.0361,  0.0050],\n",
            "          [-0.0017,  0.0334,  0.0091]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0225, -0.0243, -0.0307],\n",
            "          [-0.0166, -0.0362, -0.0104],\n",
            "          [-0.0206,  0.0230, -0.0152]],\n",
            "\n",
            "         [[-0.0329, -0.0206,  0.0284],\n",
            "          [ 0.0374, -0.0018, -0.0011],\n",
            "          [-0.0273,  0.0163,  0.0036]],\n",
            "\n",
            "         [[ 0.0257, -0.0369,  0.0320],\n",
            "          [-0.0302, -0.0172, -0.0156],\n",
            "          [-0.0412, -0.0398,  0.0044]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0013,  0.0160, -0.0102],\n",
            "          [-0.0071, -0.0078, -0.0293],\n",
            "          [-0.0380, -0.0327, -0.0027]],\n",
            "\n",
            "         [[ 0.0212, -0.0143,  0.0250],\n",
            "          [-0.0088,  0.0075,  0.0327],\n",
            "          [ 0.0101,  0.0140,  0.0239]],\n",
            "\n",
            "         [[ 0.0168,  0.0276, -0.0225],\n",
            "          [-0.0303, -0.0222, -0.0122],\n",
            "          [ 0.0292,  0.0089,  0.0148]]]], device='cuda:0', requires_grad=True)\n",
            "NPV_C2.bias Parameter containing:\n",
            "tensor([-2.1929e-03,  2.4113e-02, -4.1528e-02,  3.1826e-02,  2.8536e-03,\n",
            "        -4.0527e-02,  1.7567e-03,  2.4544e-02,  3.5820e-02,  2.8401e-03,\n",
            "         1.0235e-02,  5.3901e-03, -8.8337e-03, -3.2733e-02,  3.3634e-02,\n",
            "        -2.1921e-02,  1.8264e-02, -1.8788e-02,  1.4594e-02, -2.4159e-03,\n",
            "         3.6036e-03,  7.1606e-03,  3.4581e-02, -1.8239e-02, -3.9566e-02,\n",
            "        -9.6106e-03, -3.6792e-02, -1.7097e-02,  5.1701e-03, -3.1689e-02,\n",
            "        -2.1800e-02,  3.9895e-02,  1.9234e-02, -2.8111e-02, -3.4500e-02,\n",
            "        -2.7600e-02,  3.6012e-02, -1.2443e-02,  6.9937e-03, -3.9965e-03,\n",
            "         4.0529e-02,  2.3754e-02,  2.3604e-02, -3.0686e-02, -3.8444e-02,\n",
            "        -1.5652e-02, -1.9167e-02,  2.5421e-02,  3.8014e-02,  1.0978e-02,\n",
            "         1.6461e-02, -7.2569e-06, -1.0793e-02,  4.0739e-02, -3.6013e-02,\n",
            "        -2.5384e-02,  2.0366e-02, -3.6632e-02,  3.9414e-02,  1.1849e-02,\n",
            "        -1.2957e-02,  3.8716e-02,  4.0567e-02,  2.1403e-02], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_C3.weight Parameter containing:\n",
            "tensor([[[[-0.0316,  0.0137, -0.0414],\n",
            "          [-0.0091, -0.0149,  0.0388],\n",
            "          [ 0.0360,  0.0131, -0.0155]],\n",
            "\n",
            "         [[-0.0155, -0.0176,  0.0322],\n",
            "          [-0.0321, -0.0284, -0.0193],\n",
            "          [ 0.0098,  0.0373,  0.0161]],\n",
            "\n",
            "         [[ 0.0093,  0.0130,  0.0141],\n",
            "          [ 0.0387,  0.0091, -0.0180],\n",
            "          [ 0.0048,  0.0141,  0.0278]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0083,  0.0370,  0.0117],\n",
            "          [ 0.0292, -0.0026,  0.0213],\n",
            "          [-0.0190,  0.0062,  0.0217]],\n",
            "\n",
            "         [[-0.0116, -0.0329, -0.0204],\n",
            "          [-0.0359,  0.0227, -0.0330],\n",
            "          [-0.0046,  0.0269,  0.0351]],\n",
            "\n",
            "         [[ 0.0232, -0.0344,  0.0003],\n",
            "          [-0.0097,  0.0330, -0.0098],\n",
            "          [-0.0392,  0.0038,  0.0199]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0185, -0.0121, -0.0148],\n",
            "          [ 0.0223, -0.0040, -0.0224],\n",
            "          [ 0.0092, -0.0139,  0.0041]],\n",
            "\n",
            "         [[ 0.0236,  0.0184,  0.0269],\n",
            "          [-0.0029,  0.0358,  0.0018],\n",
            "          [ 0.0032,  0.0274,  0.0023]],\n",
            "\n",
            "         [[ 0.0095, -0.0037, -0.0270],\n",
            "          [ 0.0389, -0.0287,  0.0320],\n",
            "          [-0.0144,  0.0050, -0.0117]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0035, -0.0252, -0.0391],\n",
            "          [ 0.0296, -0.0226,  0.0135],\n",
            "          [ 0.0046, -0.0014, -0.0031]],\n",
            "\n",
            "         [[ 0.0252, -0.0334,  0.0069],\n",
            "          [-0.0381, -0.0077, -0.0242],\n",
            "          [-0.0269,  0.0375, -0.0308]],\n",
            "\n",
            "         [[ 0.0163, -0.0270, -0.0087],\n",
            "          [-0.0208,  0.0280, -0.0254],\n",
            "          [ 0.0074,  0.0103,  0.0050]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0307, -0.0092,  0.0271],\n",
            "          [-0.0262,  0.0362,  0.0116],\n",
            "          [-0.0285, -0.0187,  0.0276]],\n",
            "\n",
            "         [[ 0.0116, -0.0016, -0.0021],\n",
            "          [-0.0203, -0.0391,  0.0106],\n",
            "          [-0.0170, -0.0333,  0.0286]],\n",
            "\n",
            "         [[ 0.0368,  0.0183,  0.0352],\n",
            "          [-0.0320,  0.0046,  0.0051],\n",
            "          [-0.0334,  0.0300, -0.0392]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0274, -0.0259,  0.0175],\n",
            "          [-0.0314, -0.0199, -0.0182],\n",
            "          [ 0.0394,  0.0094, -0.0297]],\n",
            "\n",
            "         [[-0.0037, -0.0098, -0.0241],\n",
            "          [ 0.0192,  0.0254,  0.0135],\n",
            "          [ 0.0342, -0.0382,  0.0244]],\n",
            "\n",
            "         [[-0.0379,  0.0054, -0.0167],\n",
            "          [-0.0397, -0.0190, -0.0248],\n",
            "          [-0.0370, -0.0162, -0.0081]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0033,  0.0206,  0.0265],\n",
            "          [-0.0123,  0.0322, -0.0059],\n",
            "          [ 0.0177, -0.0048, -0.0160]],\n",
            "\n",
            "         [[-0.0405,  0.0230, -0.0236],\n",
            "          [-0.0250, -0.0173, -0.0148],\n",
            "          [-0.0044, -0.0364,  0.0104]],\n",
            "\n",
            "         [[ 0.0069,  0.0037, -0.0314],\n",
            "          [-0.0273, -0.0288,  0.0200],\n",
            "          [ 0.0157, -0.0093,  0.0163]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0304,  0.0244,  0.0320],\n",
            "          [ 0.0010, -0.0148, -0.0394],\n",
            "          [-0.0268, -0.0090,  0.0066]],\n",
            "\n",
            "         [[-0.0339,  0.0276,  0.0351],\n",
            "          [-0.0283,  0.0096,  0.0367],\n",
            "          [-0.0165,  0.0207, -0.0113]],\n",
            "\n",
            "         [[ 0.0031, -0.0059, -0.0067],\n",
            "          [-0.0171,  0.0251,  0.0393],\n",
            "          [ 0.0083,  0.0367,  0.0032]]],\n",
            "\n",
            "\n",
            "        [[[-0.0058, -0.0289,  0.0309],\n",
            "          [ 0.0395, -0.0082, -0.0077],\n",
            "          [-0.0312,  0.0336, -0.0392]],\n",
            "\n",
            "         [[ 0.0335, -0.0004, -0.0162],\n",
            "          [ 0.0247, -0.0038, -0.0384],\n",
            "          [ 0.0369,  0.0045, -0.0153]],\n",
            "\n",
            "         [[-0.0320, -0.0173,  0.0042],\n",
            "          [-0.0266,  0.0251, -0.0311],\n",
            "          [-0.0407, -0.0090, -0.0216]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0342, -0.0265, -0.0262],\n",
            "          [ 0.0175,  0.0340, -0.0036],\n",
            "          [ 0.0400, -0.0292,  0.0109]],\n",
            "\n",
            "         [[ 0.0232,  0.0132, -0.0084],\n",
            "          [-0.0122,  0.0321,  0.0211],\n",
            "          [ 0.0343,  0.0032, -0.0214]],\n",
            "\n",
            "         [[-0.0363, -0.0202,  0.0129],\n",
            "          [ 0.0256,  0.0050, -0.0184],\n",
            "          [ 0.0136, -0.0072,  0.0360]]],\n",
            "\n",
            "\n",
            "        [[[-0.0090, -0.0297,  0.0264],\n",
            "          [-0.0239,  0.0306, -0.0024],\n",
            "          [ 0.0044, -0.0330,  0.0260]],\n",
            "\n",
            "         [[ 0.0003, -0.0275, -0.0112],\n",
            "          [ 0.0179, -0.0407, -0.0323],\n",
            "          [ 0.0302, -0.0280,  0.0180]],\n",
            "\n",
            "         [[ 0.0085, -0.0242, -0.0152],\n",
            "          [ 0.0408, -0.0374, -0.0310],\n",
            "          [ 0.0320, -0.0358, -0.0037]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0361, -0.0313,  0.0070],\n",
            "          [ 0.0221,  0.0081,  0.0394],\n",
            "          [ 0.0047,  0.0035, -0.0268]],\n",
            "\n",
            "         [[-0.0008, -0.0049, -0.0009],\n",
            "          [ 0.0186, -0.0048,  0.0379],\n",
            "          [ 0.0127,  0.0368,  0.0240]],\n",
            "\n",
            "         [[ 0.0133, -0.0195,  0.0338],\n",
            "          [ 0.0071, -0.0164, -0.0161],\n",
            "          [ 0.0184,  0.0220, -0.0106]]]], device='cuda:0', requires_grad=True)\n",
            "NPV_C3.bias Parameter containing:\n",
            "tensor([-0.0263, -0.0002, -0.0071,  0.0286,  0.0006,  0.0163, -0.0221, -0.0142,\n",
            "         0.0233,  0.0177, -0.0054,  0.0276, -0.0319, -0.0246, -0.0263,  0.0202,\n",
            "         0.0360,  0.0197,  0.0394, -0.0196, -0.0353, -0.0233, -0.0062,  0.0120,\n",
            "         0.0334,  0.0083,  0.0268, -0.0059,  0.0005, -0.0173, -0.0283, -0.0029,\n",
            "        -0.0264,  0.0256,  0.0103, -0.0084,  0.0274, -0.0325,  0.0248, -0.0378,\n",
            "         0.0111,  0.0237, -0.0169, -0.0300,  0.0110,  0.0396, -0.0026, -0.0142,\n",
            "         0.0221,  0.0185, -0.0408,  0.0056, -0.0353, -0.0123,  0.0360,  0.0307,\n",
            "         0.0313, -0.0411, -0.0238, -0.0294,  0.0305,  0.0253, -0.0314, -0.0101,\n",
            "        -0.0320,  0.0033,  0.0391,  0.0341, -0.0308, -0.0331, -0.0317,  0.0159,\n",
            "         0.0150, -0.0050,  0.0100,  0.0207,  0.0222,  0.0269,  0.0011, -0.0328,\n",
            "         0.0309, -0.0142,  0.0080, -0.0243, -0.0387, -0.0008, -0.0114, -0.0236,\n",
            "         0.0047,  0.0359,  0.0402,  0.0391,  0.0385,  0.0034, -0.0046, -0.0398,\n",
            "        -0.0416,  0.0355,  0.0370,  0.0352,  0.0071, -0.0411, -0.0126, -0.0189,\n",
            "        -0.0107, -0.0206,  0.0349, -0.0330, -0.0189,  0.0342, -0.0032,  0.0276,\n",
            "        -0.0064,  0.0388,  0.0115, -0.0327, -0.0347,  0.0404,  0.0070,  0.0272,\n",
            "        -0.0251,  0.0332,  0.0400,  0.0108,  0.0353,  0.0322,  0.0396,  0.0219],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_C4.weight Parameter containing:\n",
            "tensor([[[[-1.3987e-02,  4.1378e-03,  1.2272e-02],\n",
            "          [-6.5724e-03,  1.2189e-02,  1.8272e-02],\n",
            "          [-8.0062e-03, -1.6566e-02,  2.6110e-02]],\n",
            "\n",
            "         [[ 1.5505e-02,  1.5366e-02,  1.4838e-02],\n",
            "          [ 2.4461e-02,  1.2808e-02,  2.2778e-02],\n",
            "          [ 2.8639e-02,  5.6618e-03,  1.9556e-02]],\n",
            "\n",
            "         [[ 2.3040e-02, -1.3431e-03, -1.9943e-02],\n",
            "          [ 5.6939e-03,  2.2903e-02, -1.9547e-02],\n",
            "          [ 2.9361e-03,  1.1447e-02, -1.6678e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.2555e-02, -7.5311e-03,  1.8459e-02],\n",
            "          [ 2.9228e-02, -1.9396e-02, -2.2639e-02],\n",
            "          [ 1.5937e-02, -9.7435e-03,  7.8464e-03]],\n",
            "\n",
            "         [[-1.5292e-02, -2.2084e-02, -2.6433e-02],\n",
            "          [-1.8836e-03,  6.6038e-03, -2.1946e-02],\n",
            "          [-2.6066e-02, -1.0185e-02, -1.9842e-02]],\n",
            "\n",
            "         [[ 6.5042e-03,  2.1520e-02, -2.4651e-02],\n",
            "          [ 2.1290e-02,  2.8312e-02, -9.4883e-03],\n",
            "          [ 1.9545e-03,  1.5846e-02,  2.5740e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.7496e-02, -2.9254e-02,  2.2091e-02],\n",
            "          [-2.6977e-02, -1.7733e-02,  8.8770e-03],\n",
            "          [-1.9732e-02,  1.9267e-02,  1.0919e-02]],\n",
            "\n",
            "         [[ 2.6508e-02,  9.1753e-03, -2.6939e-02],\n",
            "          [ 7.2909e-03,  2.0716e-02,  2.0015e-02],\n",
            "          [ 2.2851e-02,  1.0868e-02,  2.0225e-02]],\n",
            "\n",
            "         [[-1.8206e-02, -1.3805e-02, -1.0434e-02],\n",
            "          [ 6.5070e-03,  1.0785e-02, -2.4023e-02],\n",
            "          [-4.0120e-03, -1.5783e-02,  6.8909e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.1812e-02, -2.8313e-02, -2.8132e-02],\n",
            "          [ 3.8764e-03, -1.4461e-02, -1.3023e-02],\n",
            "          [-6.6891e-03,  2.8352e-02, -5.0977e-03]],\n",
            "\n",
            "         [[ 1.0487e-02, -9.9238e-03,  1.5374e-02],\n",
            "          [ 1.1807e-02, -1.3326e-02,  1.8959e-02],\n",
            "          [ 7.9804e-03,  3.6661e-03, -3.6071e-03]],\n",
            "\n",
            "         [[-7.4160e-03, -2.3299e-03,  2.7148e-02],\n",
            "          [-9.0802e-03, -2.7691e-02, -6.4225e-05],\n",
            "          [ 2.3670e-02,  2.2796e-02, -2.0174e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.4938e-03,  4.3357e-03,  1.5171e-02],\n",
            "          [-2.7843e-02,  2.4719e-02,  9.7925e-03],\n",
            "          [-1.6024e-02, -3.3893e-03,  1.4627e-02]],\n",
            "\n",
            "         [[-2.8722e-02, -1.0019e-02,  2.2402e-02],\n",
            "          [ 2.2803e-02, -1.8381e-02, -1.8076e-02],\n",
            "          [-1.2120e-02,  2.2672e-02, -1.7483e-02]],\n",
            "\n",
            "         [[ 2.1709e-02,  6.5539e-03, -1.6737e-02],\n",
            "          [ 4.1784e-04,  1.5141e-02,  2.2220e-02],\n",
            "          [ 2.4161e-02, -2.3099e-02, -2.5627e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.2408e-02, -2.4394e-02, -1.0944e-02],\n",
            "          [ 8.6939e-04,  3.3181e-03,  2.6019e-03],\n",
            "          [-8.6477e-03, -1.9437e-02, -1.3198e-02]],\n",
            "\n",
            "         [[ 1.6164e-02,  1.5726e-02,  1.9285e-02],\n",
            "          [-1.2462e-02,  2.5846e-02, -2.9231e-02],\n",
            "          [ 1.1250e-02, -1.3885e-02, -7.4259e-03]],\n",
            "\n",
            "         [[ 2.1486e-02, -6.8979e-03, -1.7119e-02],\n",
            "          [ 2.8466e-02, -1.8331e-02,  2.2353e-02],\n",
            "          [-5.9929e-03,  1.9577e-02,  1.8139e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.6473e-02,  7.9927e-03, -1.1014e-02],\n",
            "          [ 2.5636e-02,  1.8446e-02, -2.6377e-02],\n",
            "          [ 9.7614e-03,  2.9380e-05, -2.2452e-02]],\n",
            "\n",
            "         [[ 2.9205e-02,  9.5820e-03,  1.9792e-02],\n",
            "          [ 2.2439e-02,  2.0062e-02,  2.6520e-02],\n",
            "          [-6.4400e-05,  2.5276e-02, -2.1668e-02]],\n",
            "\n",
            "         [[ 2.2930e-02,  2.3161e-02, -4.8683e-03],\n",
            "          [-1.6655e-02, -7.4393e-03, -6.2970e-03],\n",
            "          [-9.2380e-03, -2.2952e-02,  2.2054e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.6919e-02,  5.7614e-03, -7.7434e-03],\n",
            "          [-1.7302e-02, -1.5739e-04,  2.6796e-02],\n",
            "          [ 1.6449e-02,  9.0511e-03, -2.4719e-02]],\n",
            "\n",
            "         [[ 1.8619e-02, -4.9237e-03, -2.6626e-02],\n",
            "          [ 2.5396e-02,  2.6317e-02, -1.8444e-02],\n",
            "          [ 1.1642e-02,  1.7777e-02, -1.4791e-03]],\n",
            "\n",
            "         [[ 2.5807e-02,  3.2278e-04, -3.0736e-03],\n",
            "          [ 2.0568e-02,  1.7140e-02, -1.5731e-02],\n",
            "          [-1.6475e-02, -2.1433e-02, -2.0985e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.2626e-02,  1.4441e-02,  1.5292e-02],\n",
            "          [-1.7763e-02,  2.0423e-02,  2.2403e-02],\n",
            "          [ 1.3390e-02, -1.8006e-02,  2.2209e-03]],\n",
            "\n",
            "         [[ 2.7858e-02, -1.8565e-02,  1.0081e-02],\n",
            "          [-2.9341e-03,  6.3006e-03,  2.0153e-02],\n",
            "          [ 2.1210e-02, -2.7247e-02, -1.6972e-02]],\n",
            "\n",
            "         [[-2.2291e-02,  1.1907e-02, -9.0636e-04],\n",
            "          [ 2.1156e-02, -1.4847e-02,  2.9207e-02],\n",
            "          [ 1.8576e-02, -2.0152e-02, -2.7463e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.6908e-02, -3.2628e-03, -2.1869e-02],\n",
            "          [ 2.5137e-02, -2.9431e-02,  1.2236e-02],\n",
            "          [ 2.7745e-02, -1.8978e-02,  4.3492e-03]],\n",
            "\n",
            "         [[-2.0070e-02, -1.0203e-02, -7.8112e-03],\n",
            "          [ 2.4202e-02, -1.6791e-02,  3.3924e-03],\n",
            "          [ 1.3115e-02, -1.3252e-02, -5.2249e-03]],\n",
            "\n",
            "         [[-1.0279e-02, -1.9686e-03,  2.8298e-02],\n",
            "          [ 9.6006e-03, -1.9645e-02, -8.7959e-03],\n",
            "          [-1.5251e-02, -2.3740e-02, -2.9350e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.8057e-02,  3.8269e-03,  1.1593e-02],\n",
            "          [ 8.9458e-03,  2.4894e-02, -2.0289e-02],\n",
            "          [ 1.1528e-02,  1.6697e-02, -1.7025e-02]],\n",
            "\n",
            "         [[ 2.1360e-02,  5.4470e-03, -2.2757e-02],\n",
            "          [ 2.4645e-02, -6.8109e-03,  2.4615e-02],\n",
            "          [ 1.4936e-02, -1.1896e-02,  1.6058e-04]],\n",
            "\n",
            "         [[-1.5815e-02,  5.5961e-04,  2.1672e-02],\n",
            "          [-9.2937e-03,  2.3693e-02, -1.7992e-02],\n",
            "          [-1.3154e-02, -1.3133e-02,  2.2994e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.0628e-03, -1.6014e-02,  1.6613e-02],\n",
            "          [ 1.9630e-02, -1.5707e-02, -1.0336e-02],\n",
            "          [ 2.4747e-02,  5.2630e-03, -1.0895e-02]],\n",
            "\n",
            "         [[ 1.2765e-03, -1.6868e-03, -1.4910e-02],\n",
            "          [-5.9486e-03, -2.3657e-02,  1.2035e-02],\n",
            "          [-2.0261e-02, -2.4199e-02, -8.9242e-03]],\n",
            "\n",
            "         [[-1.6984e-02,  2.9449e-02,  2.2606e-02],\n",
            "          [-1.2053e-03,  1.0120e-02, -2.9270e-02],\n",
            "          [-2.4131e-02,  2.9408e-02,  2.1465e-02]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_C4.bias Parameter containing:\n",
            "tensor([-3.1804e-03,  2.8743e-02, -2.6389e-02, -4.1182e-03,  7.2811e-04,\n",
            "         2.3685e-02,  2.0030e-03, -8.8795e-03,  1.6955e-02, -3.4327e-03,\n",
            "         7.3165e-03,  1.1847e-02,  5.3573e-03, -2.6845e-02, -2.5552e-03,\n",
            "        -1.6395e-02,  1.2078e-03, -1.7314e-03,  2.2636e-02, -2.0639e-02,\n",
            "        -1.5347e-03,  2.9082e-03, -1.1918e-02, -2.7779e-02, -2.1690e-02,\n",
            "         2.1135e-02,  9.7690e-03, -1.6758e-02, -1.6572e-02,  6.2816e-04,\n",
            "         3.6587e-05, -2.1011e-02, -1.3749e-02,  5.0423e-03, -2.9448e-02,\n",
            "        -1.1506e-02,  5.3663e-03, -1.2726e-02,  8.1457e-03, -2.8358e-02,\n",
            "         2.3459e-02, -1.3856e-02, -1.1189e-02,  3.7745e-03,  1.6542e-02,\n",
            "         2.1959e-02, -2.9111e-02, -1.2866e-02,  2.1970e-02, -2.8429e-03,\n",
            "        -2.5759e-02,  2.0735e-02, -2.1030e-02, -1.1258e-02, -4.6091e-03,\n",
            "         1.9519e-02,  2.0940e-02,  2.6851e-02,  2.8096e-03,  8.2927e-03,\n",
            "         2.8580e-02, -2.1940e-02, -3.4945e-03,  1.9322e-02, -1.5751e-02,\n",
            "         2.3855e-03, -1.7073e-02, -1.4511e-02, -2.2561e-02, -2.6405e-02,\n",
            "         2.6318e-02, -2.9139e-02, -9.8486e-03,  1.4054e-02, -1.0040e-02,\n",
            "        -1.5595e-02,  1.6238e-02, -2.0100e-02,  1.8730e-02, -6.7372e-03,\n",
            "         2.0918e-02, -2.7594e-02,  8.1716e-03,  1.8600e-02, -1.1132e-02,\n",
            "        -2.1926e-02,  1.9313e-02, -6.1474e-03,  7.9333e-03, -1.4275e-02,\n",
            "         2.6843e-02,  1.0698e-02,  1.9327e-02, -2.2085e-03, -2.9058e-02,\n",
            "         4.5473e-03, -2.7373e-02,  2.3842e-02, -1.5115e-02, -1.0707e-02,\n",
            "         1.5594e-02,  1.8351e-02,  1.6147e-04,  2.7896e-02,  2.0561e-02,\n",
            "         1.0241e-02,  1.2589e-02,  7.7981e-03,  4.9848e-03,  1.8043e-02,\n",
            "        -2.2709e-02,  5.8234e-04,  2.2714e-02,  2.0783e-02, -1.2656e-02,\n",
            "        -1.0637e-02, -2.1394e-02, -1.6212e-03,  5.8577e-03, -1.9733e-02,\n",
            "         1.3217e-02,  5.4011e-03,  1.9786e-02,  2.2752e-02, -3.5726e-03,\n",
            "         4.0638e-03,  4.9354e-03, -8.3860e-03], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_D1.weight Parameter containing:\n",
            "tensor([[-4.2500e-04,  3.4232e-04,  3.0331e-04,  ..., -2.6188e-03,\n",
            "         -8.5358e-04,  1.7704e-03],\n",
            "        [ 5.5978e-04, -5.9518e-04,  1.9651e-03,  ..., -5.8598e-04,\n",
            "          8.2195e-04,  4.1392e-04],\n",
            "        [-1.7179e-03, -1.0367e-03,  1.9460e-03,  ...,  1.4128e-03,\n",
            "          3.6932e-04, -2.4133e-04],\n",
            "        ...,\n",
            "        [-2.1394e-03,  1.6810e-03,  5.1829e-04,  ...,  4.5336e-04,\n",
            "         -6.2139e-04, -2.1272e-03],\n",
            "        [ 5.1908e-04,  3.6192e-04,  1.6995e-03,  ..., -1.1338e-03,\n",
            "          9.2489e-05,  2.5449e-03],\n",
            "        [ 2.4155e-04,  8.8660e-04,  1.9848e-03,  ..., -5.5908e-04,\n",
            "         -1.2267e-03, -1.8205e-03]], device='cuda:0', requires_grad=True)\n",
            "NPV_D1.bias Parameter containing:\n",
            "tensor([ 2.5835e-03,  7.9545e-04,  1.6091e-03, -1.1304e-03,  4.0896e-04,\n",
            "         7.4755e-04,  2.0992e-03,  1.7640e-03,  6.0039e-04, -2.5609e-03,\n",
            "        -1.3363e-03,  2.5887e-03, -2.3254e-03, -2.2674e-03, -8.3025e-04,\n",
            "        -2.3997e-03, -1.2237e-03,  9.0295e-04,  2.6994e-03, -2.7424e-03,\n",
            "        -2.0622e-03,  2.0181e-03, -6.8847e-04, -2.0781e-03, -1.8605e-03,\n",
            "         1.6968e-03, -1.5229e-03,  2.1695e-04, -1.0661e-03, -1.3559e-03,\n",
            "         2.3883e-03, -1.9152e-03, -1.3119e-03, -4.2458e-04,  4.4341e-04,\n",
            "        -2.7160e-03, -2.2658e-03, -2.6922e-03,  2.5078e-03,  7.0529e-04,\n",
            "        -9.4340e-04, -2.4367e-03,  1.8531e-03,  2.3037e-03, -2.0630e-03,\n",
            "         2.1748e-04,  2.3501e-03,  1.8936e-03, -1.5620e-03,  2.9815e-04,\n",
            "         2.7706e-05, -1.5128e-03, -1.3792e-03, -4.9154e-06, -1.0732e-03,\n",
            "         1.6811e-03,  1.7972e-03, -2.5401e-03, -1.5412e-03, -3.0942e-04,\n",
            "         1.8335e-03,  2.3770e-03, -2.7681e-04, -1.9792e-03, -8.5516e-04,\n",
            "         8.8162e-04,  2.3609e-03,  2.0938e-03, -8.2865e-04, -2.6042e-03,\n",
            "         2.0806e-04, -2.2540e-03,  2.4507e-03, -3.8422e-04,  5.0761e-04,\n",
            "        -8.8656e-04, -8.6407e-04,  2.4392e-03,  7.2495e-04, -1.8146e-03,\n",
            "        -1.4216e-03, -2.4239e-03, -1.4729e-03,  1.2913e-04, -2.5494e-03,\n",
            "        -9.7774e-04,  1.3154e-03,  1.7657e-03,  2.2513e-03,  2.5850e-03,\n",
            "         4.9572e-04, -2.3799e-03,  2.0424e-04,  1.1245e-03, -6.8301e-04,\n",
            "        -2.2079e-03, -2.0586e-03,  1.1836e-03,  1.1439e-03,  1.9709e-03,\n",
            "        -1.9116e-03, -1.8836e-03,  2.6846e-03, -1.9300e-03, -2.2299e-04,\n",
            "         4.5833e-04,  1.1141e-03,  9.0192e-04, -2.7477e-03, -2.4375e-03,\n",
            "        -7.5784e-04, -1.8712e-04, -2.1308e-03, -2.2993e-06, -1.4869e-03,\n",
            "         1.1752e-03,  2.6066e-03,  1.3586e-03,  3.8712e-04, -5.3907e-04,\n",
            "         4.2717e-04,  1.0158e-03, -2.7592e-03,  1.6822e-03,  1.0844e-03,\n",
            "        -1.9496e-03,  1.7139e-03,  6.4899e-04, -1.0861e-03, -2.6110e-03,\n",
            "         4.7034e-04, -1.8391e-03, -1.1588e-03,  2.5366e-03,  8.8629e-04,\n",
            "        -1.5839e-03, -7.7694e-04, -1.4596e-03,  7.6910e-04, -1.5931e-03,\n",
            "        -1.1689e-03, -2.5765e-03, -1.7060e-03, -1.1298e-03,  2.0213e-03,\n",
            "         2.0025e-03, -1.4208e-03,  2.9944e-04,  8.3589e-04, -1.6124e-03,\n",
            "         2.2354e-03,  1.4971e-03,  9.9166e-04,  1.6359e-03,  2.6744e-03,\n",
            "        -2.0530e-03, -2.2868e-03, -1.4221e-03,  1.6467e-03,  1.5981e-04,\n",
            "         2.3573e-03,  1.5613e-03,  1.8526e-03, -1.6318e-03,  1.6608e-03,\n",
            "         2.0200e-03, -1.5749e-03, -1.6099e-03,  2.6487e-03, -1.8754e-03,\n",
            "        -8.1127e-04,  2.7024e-03,  2.3194e-03,  2.1002e-03, -2.0623e-03,\n",
            "         5.7427e-04, -1.8883e-03,  9.4353e-04,  9.3135e-04,  1.9094e-03,\n",
            "         2.6375e-03,  2.7138e-03, -3.6628e-05, -2.4011e-03,  1.4246e-03,\n",
            "        -2.2750e-03,  1.3148e-03,  1.9835e-03,  1.7976e-03, -1.3155e-03,\n",
            "        -1.7673e-03, -2.1715e-03, -7.3595e-04,  1.1820e-03,  2.1763e-04,\n",
            "         2.0384e-03, -8.9629e-05, -9.7431e-05,  2.5705e-03,  1.7854e-03,\n",
            "         3.1470e-05,  1.1560e-03, -5.4276e-04, -1.2487e-04,  1.2554e-03,\n",
            "        -2.6068e-03, -1.5469e-03, -7.6323e-04, -2.1362e-03,  1.2524e-03,\n",
            "         8.6121e-04,  4.0932e-04, -1.3691e-03, -2.3829e-03, -1.3002e-03,\n",
            "        -2.0884e-03, -1.6582e-03, -3.9460e-05,  7.9939e-04,  5.7903e-04,\n",
            "         4.1435e-04, -1.5611e-03, -1.6212e-03,  8.4609e-05,  2.4256e-05,\n",
            "         2.6600e-03, -1.8125e-03,  2.2584e-03,  1.7738e-03,  1.5278e-03,\n",
            "        -9.0816e-04, -8.9395e-04, -5.1366e-04, -1.2026e-03, -1.0050e-03,\n",
            "         2.1485e-03, -2.2495e-03, -2.7538e-03, -2.5589e-03,  4.2576e-04,\n",
            "         2.2892e-03,  7.8009e-04, -1.6795e-03, -9.2372e-04, -9.2916e-04,\n",
            "         5.9573e-04, -1.9249e-03,  2.5514e-03,  5.1317e-04, -2.6872e-04,\n",
            "         2.1257e-03,  2.5114e-03, -2.3591e-03,  3.1920e-05,  6.9456e-04,\n",
            "         2.2481e-04], device='cuda:0', requires_grad=True)\n",
            "NPV_D2.weight Parameter containing:\n",
            "tensor([[ 0.0040,  0.0240,  0.0159,  ..., -0.0503, -0.0015, -0.0344],\n",
            "        [ 0.0457,  0.0616,  0.0371,  ..., -0.0529,  0.0223, -0.0324],\n",
            "        [-0.0164,  0.0150, -0.0214,  ...,  0.0277, -0.0551,  0.0250],\n",
            "        ...,\n",
            "        [-0.0299, -0.0165, -0.0432,  ...,  0.0148, -0.0496,  0.0011],\n",
            "        [ 0.0506,  0.0245, -0.0271,  ..., -0.0013,  0.0308, -0.0110],\n",
            "        [-0.0489, -0.0263, -0.0157,  ..., -0.0624,  0.0527, -0.0604]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_D2.bias Parameter containing:\n",
            "tensor([-0.0284, -0.0494,  0.0320,  0.0366, -0.0063, -0.0413, -0.0505, -0.0160,\n",
            "        -0.0624, -0.0090, -0.0315,  0.0414,  0.0380,  0.0022,  0.0330, -0.0366,\n",
            "        -0.0537, -0.0607,  0.0250,  0.0398,  0.0055,  0.0596,  0.0599, -0.0360,\n",
            "        -0.0403,  0.0435, -0.0004, -0.0213,  0.0356, -0.0571, -0.0218,  0.0487,\n",
            "        -0.0467,  0.0216, -0.0229,  0.0065, -0.0150,  0.0188,  0.0554, -0.0203,\n",
            "         0.0514,  0.0229, -0.0390,  0.0157,  0.0154,  0.0567, -0.0213, -0.0060,\n",
            "         0.0345,  0.0005,  0.0264,  0.0556, -0.0195,  0.0510, -0.0416, -0.0501,\n",
            "        -0.0608,  0.0552, -0.0167,  0.0220, -0.0287, -0.0132, -0.0476, -0.0006,\n",
            "        -0.0324, -0.0492,  0.0221,  0.0213,  0.0095, -0.0621, -0.0132, -0.0232,\n",
            "        -0.0024, -0.0324, -0.0444, -0.0523,  0.0148, -0.0484,  0.0211, -0.0563,\n",
            "         0.0548,  0.0521, -0.0541, -0.0604,  0.0516, -0.0076,  0.0265,  0.0359,\n",
            "        -0.0437, -0.0070,  0.0431,  0.0277, -0.0336, -0.0512,  0.0457, -0.0163,\n",
            "        -0.0195, -0.0349, -0.0452, -0.0553,  0.0025, -0.0145,  0.0244, -0.0075,\n",
            "         0.0355, -0.0235,  0.0400, -0.0509,  0.0455,  0.0613,  0.0405,  0.0405,\n",
            "         0.0450,  0.0445, -0.0236, -0.0110,  0.0070, -0.0460, -0.0117,  0.0034,\n",
            "        -0.0455,  0.0516,  0.0520, -0.0260, -0.0432,  0.0585,  0.0335, -0.0273,\n",
            "         0.0112,  0.0505, -0.0238,  0.0442,  0.0276,  0.0231,  0.0235, -0.0354,\n",
            "         0.0601,  0.0601, -0.0281,  0.0601, -0.0427,  0.0170, -0.0486, -0.0043,\n",
            "         0.0528, -0.0433, -0.0559,  0.0562,  0.0596, -0.0415,  0.0059, -0.0610,\n",
            "        -0.0030,  0.0140,  0.0087, -0.0624, -0.0084,  0.0029,  0.0153, -0.0269,\n",
            "         0.0286, -0.0165,  0.0443,  0.0416, -0.0366,  0.0583,  0.0079, -0.0047,\n",
            "        -0.0333,  0.0587, -0.0348, -0.0381, -0.0279,  0.0269, -0.0620,  0.0250,\n",
            "        -0.0219,  0.0447, -0.0306, -0.0064,  0.0316, -0.0036,  0.0511, -0.0166,\n",
            "         0.0219,  0.0121, -0.0623,  0.0315,  0.0589, -0.0235,  0.0459, -0.0426,\n",
            "         0.0199, -0.0061, -0.0189,  0.0208,  0.0010,  0.0182, -0.0201,  0.0564,\n",
            "        -0.0417,  0.0036,  0.0360,  0.0043,  0.0300,  0.0058,  0.0466,  0.0120,\n",
            "        -0.0503, -0.0093, -0.0014, -0.0418,  0.0362, -0.0106,  0.0384, -0.0534,\n",
            "        -0.0271,  0.0581, -0.0313, -0.0183,  0.0161, -0.0560,  0.0457, -0.0109,\n",
            "        -0.0280,  0.0622,  0.0369,  0.0046,  0.0331, -0.0128,  0.0230,  0.0032,\n",
            "         0.0542, -0.0439, -0.0495, -0.0418,  0.0267,  0.0539,  0.0562,  0.0309,\n",
            "         0.0199, -0.0077, -0.0458,  0.0379, -0.0467, -0.0272, -0.0227, -0.0405,\n",
            "         0.0002,  0.0203,  0.0386,  0.0368, -0.0044, -0.0390,  0.0111, -0.0018],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "outputs.weight Parameter containing:\n",
            "tensor([[-0.0610,  0.0580,  0.0231,  ..., -0.0562,  0.0027, -0.0614],\n",
            "        [ 0.0510,  0.0409,  0.0208,  ..., -0.0611, -0.0522, -0.0423],\n",
            "        [ 0.0570, -0.0310,  0.0022,  ..., -0.0383,  0.0625, -0.0197],\n",
            "        ...,\n",
            "        [ 0.0233,  0.0153, -0.0035,  ..., -0.0455,  0.0357,  0.0230],\n",
            "        [-0.0288,  0.0081, -0.0058,  ...,  0.0366,  0.0099,  0.0552],\n",
            "        [-0.0426, -0.0433,  0.0339,  ..., -0.0404,  0.0361,  0.0145]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "outputs.bias Parameter containing:\n",
            "tensor([ 0.0194,  0.0241, -0.0407, -0.0112,  0.0272,  0.0158,  0.0036,  0.0262,\n",
            "        -0.0198, -0.0502], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in flnpf_model.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    print(name)"
      ],
      "metadata": {
        "id": "ApTIVD5jSwtK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "704294c8-fd30-4919-983e-bab9c1b2a83a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NPV_C1.weight\n",
            "NPV_C1.bias\n",
            "NPV_C2.weight\n",
            "NPV_C2.bias\n",
            "NPV_C3.weight\n",
            "NPV_C3.bias\n",
            "NPV_C4.weight\n",
            "NPV_C4.bias\n",
            "NPV_D1.weight\n",
            "NPV_D1.bias\n",
            "NPV_D2.weight\n",
            "NPV_D2.bias\n",
            "outputs.weight\n",
            "outputs.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(flnpf_model.parameters(), lr=args['lr'])\n",
        "for epoch in range(1, args['epochs']+1):\n",
        "  train(flnpf_model, epoch, train_loader, lossFn, optimizer)\n",
        "  validate(flnpf_model, validation_loader, lossFn)"
      ],
      "metadata": {
        "id": "sSHe5TyFVx97",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "568ef102-4100-40c7-c2f9-a047588fe47d"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:70: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [50000/50000 (100%)]\tLoss: 1.823352\n",
            "\n",
            "Validation set: Average loss: 1.5129, Accuracy: 6236/10000 (62%)\n",
            "\n",
            "Train Epoch: 2 [50000/50000 (100%)]\tLoss: 0.241539\n",
            "\n",
            "Validation set: Average loss: 1.8304, Accuracy: 6430/10000 (64%)\n",
            "\n",
            "Train Epoch: 3 [50000/50000 (100%)]\tLoss: 0.114915\n",
            "\n",
            "Validation set: Average loss: 2.1921, Accuracy: 6453/10000 (65%)\n",
            "\n",
            "Train Epoch: 4 [50000/50000 (100%)]\tLoss: 0.048384\n",
            "\n",
            "Validation set: Average loss: 2.8466, Accuracy: 6374/10000 (64%)\n",
            "\n",
            "Train Epoch: 5 [50000/50000 (100%)]\tLoss: 0.019138\n",
            "\n",
            "Validation set: Average loss: 3.7696, Accuracy: 6516/10000 (65%)\n",
            "\n",
            "Train Epoch: 6 [50000/50000 (100%)]\tLoss: 0.012317\n",
            "\n",
            "Validation set: Average loss: 4.2540, Accuracy: 6489/10000 (65%)\n",
            "\n",
            "Train Epoch: 7 [50000/50000 (100%)]\tLoss: 0.005762\n",
            "\n",
            "Validation set: Average loss: 5.1602, Accuracy: 6468/10000 (65%)\n",
            "\n",
            "Train Epoch: 8 [50000/50000 (100%)]\tLoss: 0.002082\n",
            "\n",
            "Validation set: Average loss: 5.3957, Accuracy: 6498/10000 (65%)\n",
            "\n",
            "Train Epoch: 9 [50000/50000 (100%)]\tLoss: 0.001424\n",
            "\n",
            "Validation set: Average loss: 5.6499, Accuracy: 6526/10000 (65%)\n",
            "\n",
            "Train Epoch: 10 [50000/50000 (100%)]\tLoss: 0.000134\n",
            "\n",
            "Validation set: Average loss: 5.8239, Accuracy: 6517/10000 (65%)\n",
            "\n",
            "Train Epoch: 11 [50000/50000 (100%)]\tLoss: 0.000077\n",
            "\n",
            "Validation set: Average loss: 5.9531, Accuracy: 6524/10000 (65%)\n",
            "\n",
            "Train Epoch: 12 [50000/50000 (100%)]\tLoss: 0.000060\n",
            "\n",
            "Validation set: Average loss: 6.0584, Accuracy: 6517/10000 (65%)\n",
            "\n",
            "Train Epoch: 13 [50000/50000 (100%)]\tLoss: 0.000049\n",
            "\n",
            "Validation set: Average loss: 6.1474, Accuracy: 6522/10000 (65%)\n",
            "\n",
            "Train Epoch: 14 [50000/50000 (100%)]\tLoss: 0.000042\n",
            "\n",
            "Validation set: Average loss: 6.2241, Accuracy: 6519/10000 (65%)\n",
            "\n",
            "Train Epoch: 15 [50000/50000 (100%)]\tLoss: 0.000037\n",
            "\n",
            "Validation set: Average loss: 6.2926, Accuracy: 6515/10000 (65%)\n",
            "\n",
            "Train Epoch: 16 [50000/50000 (100%)]\tLoss: 0.000033\n",
            "\n",
            "Validation set: Average loss: 6.3542, Accuracy: 6521/10000 (65%)\n",
            "\n",
            "Train Epoch: 17 [50000/50000 (100%)]\tLoss: 0.000029\n",
            "\n",
            "Validation set: Average loss: 6.4104, Accuracy: 6523/10000 (65%)\n",
            "\n",
            "Train Epoch: 18 [50000/50000 (100%)]\tLoss: 0.000027\n",
            "\n",
            "Validation set: Average loss: 6.4623, Accuracy: 6524/10000 (65%)\n",
            "\n",
            "Train Epoch: 19 [50000/50000 (100%)]\tLoss: 0.000024\n",
            "\n",
            "Validation set: Average loss: 6.5110, Accuracy: 6524/10000 (65%)\n",
            "\n",
            "Train Epoch: 20 [50000/50000 (100%)]\tLoss: 0.000023\n",
            "\n",
            "Validation set: Average loss: 6.5553, Accuracy: 6524/10000 (65%)\n",
            "\n",
            "Train Epoch: 21 [50000/50000 (100%)]\tLoss: 0.000021\n",
            "\n",
            "Validation set: Average loss: 6.5971, Accuracy: 6524/10000 (65%)\n",
            "\n",
            "Train Epoch: 22 [50000/50000 (100%)]\tLoss: 0.000019\n",
            "\n",
            "Validation set: Average loss: 6.6367, Accuracy: 6523/10000 (65%)\n",
            "\n",
            "Train Epoch: 23 [50000/50000 (100%)]\tLoss: 0.000018\n",
            "\n",
            "Validation set: Average loss: 6.6739, Accuracy: 6524/10000 (65%)\n",
            "\n",
            "Train Epoch: 24 [50000/50000 (100%)]\tLoss: 0.000017\n",
            "\n",
            "Validation set: Average loss: 6.7090, Accuracy: 6524/10000 (65%)\n",
            "\n",
            "Train Epoch: 25 [50000/50000 (100%)]\tLoss: 0.000016\n",
            "\n",
            "Validation set: Average loss: 6.7426, Accuracy: 6522/10000 (65%)\n",
            "\n",
            "Train Epoch: 26 [50000/50000 (100%)]\tLoss: 0.000015\n",
            "\n",
            "Validation set: Average loss: 6.7744, Accuracy: 6522/10000 (65%)\n",
            "\n",
            "Train Epoch: 27 [50000/50000 (100%)]\tLoss: 0.000014\n",
            "\n",
            "Validation set: Average loss: 6.8052, Accuracy: 6523/10000 (65%)\n",
            "\n",
            "Train Epoch: 28 [50000/50000 (100%)]\tLoss: 0.000014\n",
            "\n",
            "Validation set: Average loss: 6.8342, Accuracy: 6524/10000 (65%)\n",
            "\n",
            "Train Epoch: 29 [50000/50000 (100%)]\tLoss: 0.000013\n",
            "\n",
            "Validation set: Average loss: 6.8622, Accuracy: 6523/10000 (65%)\n",
            "\n",
            "Train Epoch: 30 [50000/50000 (100%)]\tLoss: 0.000013\n",
            "\n",
            "Validation set: Average loss: 6.8891, Accuracy: 6523/10000 (65%)\n",
            "\n",
            "Train Epoch: 31 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 6.9149, Accuracy: 6522/10000 (65%)\n",
            "\n",
            "Train Epoch: 32 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 6.9398, Accuracy: 6522/10000 (65%)\n",
            "\n",
            "Train Epoch: 33 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 6.9636, Accuracy: 6524/10000 (65%)\n",
            "\n",
            "Train Epoch: 34 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 6.9869, Accuracy: 6523/10000 (65%)\n",
            "\n",
            "Train Epoch: 35 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 7.0093, Accuracy: 6523/10000 (65%)\n",
            "\n",
            "Train Epoch: 36 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 7.0309, Accuracy: 6524/10000 (65%)\n",
            "\n",
            "Train Epoch: 37 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 7.0519, Accuracy: 6523/10000 (65%)\n",
            "\n",
            "Train Epoch: 38 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 7.0723, Accuracy: 6524/10000 (65%)\n",
            "\n",
            "Train Epoch: 39 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 7.0920, Accuracy: 6524/10000 (65%)\n",
            "\n",
            "Train Epoch: 40 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 7.1113, Accuracy: 6523/10000 (65%)\n",
            "\n",
            "Train Epoch: 41 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 7.1300, Accuracy: 6525/10000 (65%)\n",
            "\n",
            "Train Epoch: 42 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 7.1482, Accuracy: 6524/10000 (65%)\n",
            "\n",
            "Train Epoch: 43 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 7.1658, Accuracy: 6523/10000 (65%)\n",
            "\n",
            "Train Epoch: 44 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 7.1831, Accuracy: 6525/10000 (65%)\n",
            "\n",
            "Train Epoch: 45 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 7.2001, Accuracy: 6523/10000 (65%)\n",
            "\n",
            "Train Epoch: 46 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 7.2166, Accuracy: 6523/10000 (65%)\n",
            "\n",
            "Train Epoch: 47 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 7.2326, Accuracy: 6524/10000 (65%)\n",
            "\n",
            "Train Epoch: 48 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 7.2483, Accuracy: 6523/10000 (65%)\n",
            "\n",
            "Train Epoch: 49 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 7.2636, Accuracy: 6525/10000 (65%)\n",
            "\n",
            "Train Epoch: 50 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 7.2786, Accuracy: 6523/10000 (65%)\n",
            "\n",
            "Train Epoch: 51 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 7.2932, Accuracy: 6523/10000 (65%)\n",
            "\n",
            "Train Epoch: 52 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 7.3076, Accuracy: 6524/10000 (65%)\n",
            "\n",
            "Train Epoch: 53 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 7.3217, Accuracy: 6524/10000 (65%)\n",
            "\n",
            "Train Epoch: 54 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 7.3354, Accuracy: 6524/10000 (65%)\n",
            "\n",
            "Train Epoch: 55 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 7.3489, Accuracy: 6523/10000 (65%)\n",
            "\n",
            "Train Epoch: 56 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 7.3622, Accuracy: 6525/10000 (65%)\n",
            "\n",
            "Train Epoch: 57 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 7.3752, Accuracy: 6526/10000 (65%)\n",
            "\n",
            "Train Epoch: 58 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 7.3879, Accuracy: 6526/10000 (65%)\n",
            "\n",
            "Train Epoch: 59 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 7.4004, Accuracy: 6526/10000 (65%)\n",
            "\n",
            "Train Epoch: 60 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 7.4128, Accuracy: 6525/10000 (65%)\n",
            "\n",
            "\n",
            "Validation set: Average loss: 7.4248, Accuracy: 6525/10000 (65%)\n",
            "\n",
            "Train Epoch: 62 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 7.4366, Accuracy: 6524/10000 (65%)\n",
            "\n",
            "Train Epoch: 63 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 7.4483, Accuracy: 6525/10000 (65%)\n",
            "\n",
            "\n",
            "Validation set: Average loss: 7.4596, Accuracy: 6525/10000 (65%)\n",
            "\n",
            "Train Epoch: 65 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 7.4709, Accuracy: 6525/10000 (65%)\n",
            "\n",
            "Train Epoch: 66 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 7.4819, Accuracy: 6525/10000 (65%)\n",
            "\n",
            "Train Epoch: 67 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 7.4928, Accuracy: 6525/10000 (65%)\n",
            "\n",
            "Train Epoch: 68 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 7.5035, Accuracy: 6525/10000 (65%)\n",
            "\n",
            "Train Epoch: 69 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 7.5141, Accuracy: 6525/10000 (65%)\n",
            "\n",
            "Train Epoch: 70 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 7.5245, Accuracy: 6525/10000 (65%)\n",
            "\n",
            "Train Epoch: 71 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 7.5347, Accuracy: 6523/10000 (65%)\n",
            "\n",
            "Train Epoch: 72 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 7.5447, Accuracy: 6523/10000 (65%)\n",
            "\n",
            "Train Epoch: 73 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 7.5546, Accuracy: 6524/10000 (65%)\n",
            "\n",
            "Train Epoch: 74 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 7.5643, Accuracy: 6526/10000 (65%)\n",
            "\n",
            "Train Epoch: 75 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 7.5740, Accuracy: 6525/10000 (65%)\n",
            "\n",
            "Train Epoch: 76 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 7.5835, Accuracy: 6525/10000 (65%)\n",
            "\n",
            "Train Epoch: 77 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 7.5928, Accuracy: 6524/10000 (65%)\n",
            "\n",
            "Train Epoch: 78 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 7.6021, Accuracy: 6523/10000 (65%)\n",
            "\n",
            "Train Epoch: 79 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 7.6111, Accuracy: 6524/10000 (65%)\n",
            "\n",
            "Train Epoch: 80 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 7.6201, Accuracy: 6525/10000 (65%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "DGN with Linear activation for NPF"
      ],
      "metadata": {
        "id": "l0JLsKJKMgB8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoupled learning with Soft ReLU activation"
      ],
      "metadata": {
        "id": "2ts1cSP3MgB_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv4SoftGaluLinear(nn.Module):\n",
        "\n",
        "  def __init__(self, image_size, channels):\n",
        "      \n",
        "    super(Conv4SoftGaluLinear, self).__init__()\n",
        "\n",
        "    #NPF network\n",
        "    self.NPF_C1 = nn.Conv2d(channels, 64, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPF_C2 = nn.Conv2d(64, 64, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPF_C3 = nn.Conv2d(64, 128, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPF_C4 = nn.Conv2d(128, 128, kernel_size = (3, 3), padding = 'same')\n",
        "\n",
        "    self.NPF_F = nn.Flatten()\n",
        "    self.NPF_D1 = nn.Linear(image_size*128, 256)\n",
        "    self.NPF_D2 = nn.Linear(256, 256)\n",
        "\n",
        "    #NPV Network\n",
        "    self.NPV_C1 = nn.Conv2d(channels, 64, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPV_C2 = nn.Conv2d(64, 64, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPV_C3 = nn.Conv2d(64, 128, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPV_C4 = nn.Conv2d(128, 128, kernel_size = (3, 3),  padding = 'same')\n",
        "    self.NPV_F = nn.Flatten()\n",
        "    self.NPV_D1 = nn.Linear(image_size*128, 256)\n",
        "    self.NPV_D2 = nn.Linear(256, 256)\n",
        "    self.outputs = nn.Linear(256, 10)\n",
        "\n",
        "    \n",
        "  def forward(self, x):\n",
        "\n",
        "    # Calculate pre-activations(Qfi) and activations(Zfi) for NPF network\n",
        "    Zf1 = self.NPF_C1(x)  # Use linear activations(So Qf = Zf)\n",
        "    Zf2 = self.NPF_C2(Zf1)\n",
        "    Zf3 = self.NPF_C3(Zf2)\n",
        "    Zf4 = self.NPF_C4(Zf3)\n",
        "\n",
        "    Zf4_ = self.NPF_F(Zf4)\n",
        "    Zf5 = self.NPF_D1(Zf4_)\n",
        "    Zf6 = self.NPF_D2(Zf5)\n",
        "\n",
        "    # Gating values\n",
        "    G1 = SoftGate()(Zf1)\n",
        "    G2 = SoftGate()(Zf2)\n",
        "    G3 = SoftGate()(Zf3)\n",
        "    G4 = SoftGate()(Zf4)\n",
        "    G5 = SoftGate()(Zf5)\n",
        "    G6 = SoftGate()(Zf6)\n",
        "\n",
        "    # Calculate pre-activations(Qvi) and activations(Zvi) for NPV network\n",
        "    Qv1 = self.NPV_C1(x)\n",
        "    Zv1 = torch.mul(G1, Qv1)\n",
        "    Qv2 = self.NPV_C2(Zv1)\n",
        "    Zv2 = torch.mul(G2, Qv2)\n",
        "    Qv3 = self.NPV_C3(Zv2)\n",
        "    Zv3 = torch.mul(G3, Qv3)\n",
        "    Qv4 = self.NPV_C4(Zv3)\n",
        "    Zv4 = torch.mul(G4, Qv4)\n",
        "\n",
        "    Zv4 = self.NPV_F(Zv4)\n",
        "    Qv5 = self.NPV_D1(Zv4)\n",
        "    Zv5 = torch.mul(G5, Qv5)\n",
        "    Qv6 = self.NPV_D2(Zv5)\n",
        "    Zv6 = torch.mul(G6, Qv6)\n",
        "\n",
        "    return F.log_softmax(self.outputs(Zv6))"
      ],
      "metadata": {
        "id": "gNMsgUvWMgB_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoupled_soft_relu_linear_model = Conv4SoftGaluLinear(args['image_size'], args['channels'])\n",
        "decoupled_soft_relu_linear_model.to(device)\n",
        "decoupled_soft_relu_linear_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "645245c9-5b09-41e9-f304-b3eaebe96823",
        "id": "_MyxVstgMgB_"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv4SoftGaluLinear(\n",
              "  (NPF_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPF_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPF_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (NPV_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPV_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPV_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (outputs): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv4SoftGaluLinear(nn.Module):\n",
        "\n",
        "  def __init__(self, image_size, channels):\n",
        "      \n",
        "    super(Conv4SoftGaluLinear, self).__init__()\n",
        "    self.i = 0\n",
        "\n",
        "    #NPF network\n",
        "    self.NPF_C1 = nn.Conv2d(channels, 64, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPF_C2 = nn.Conv2d(64, 64, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPF_C3 = nn.Conv2d(64, 128, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPF_C4 = nn.Conv2d(128, 128, kernel_size = (3, 3), padding = 'same')\n",
        "\n",
        "    self.NPF_F = nn.Flatten()\n",
        "    self.NPF_D1 = nn.Linear(image_size*128, 256)\n",
        "    self.NPF_D2 = nn.Linear(256, 256)\n",
        "\n",
        "    #NPV Network\n",
        "    self.NPV_C1 = nn.Conv2d(channels, 64, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPV_C2 = nn.Conv2d(64, 64, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPV_C3 = nn.Conv2d(64, 128, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPV_C4 = nn.Conv2d(128, 128, kernel_size = (3, 3),  padding = 'same')\n",
        "    self.NPV_F = nn.Flatten()\n",
        "    self.NPV_D1 = nn.Linear(image_size*128, 256)\n",
        "    self.NPV_D2 = nn.Linear(256, 256)\n",
        "    self.outputs = nn.Linear(256, 10)\n",
        "\n",
        "    \n",
        "  def forward(self, x):\n",
        "\n",
        "    self.i += 1\n",
        "\n",
        "    # Calculate pre-activations(Qfi) and activations(Zfi) for NPF network\n",
        "    Zf1 = self.NPF_C1(x)  # Use linear activations(So Qf = Zf)\n",
        "    Zf2 = self.NPF_C2(Zf1)\n",
        "    Zf3 = self.NPF_C3(Zf2)\n",
        "    Zf4 = self.NPF_C4(Zf3)\n",
        "\n",
        "    Zf4_ = self.NPF_F(Zf4)\n",
        "    Zf5 = self.NPF_D1(Zf4_)\n",
        "    Zf6 = self.NPF_D2(Zf5)\n",
        "\n",
        "    # Gating values\n",
        "    G1 = SoftGate()(Zf1)\n",
        "    G2 = SoftGate()(Zf2)\n",
        "    G3 = SoftGate()(Zf3)\n",
        "    G4 = SoftGate()(Zf4)\n",
        "    G5 = SoftGate()(Zf5)\n",
        "    G6 = SoftGate()(Zf6)\n",
        "\n",
        "    # Calculate pre-activations(Qvi) and activations(Zvi) for NPV network\n",
        "    Qv1 = self.NPV_C1(x)\n",
        "    Zv1 = torch.mul(G1, Qv1)\n",
        "    Qv2 = self.NPV_C2(Zv1)\n",
        "    Zv2 = torch.mul(G2, Qv2)\n",
        "    Qv3 = self.NPV_C3(Zv2)\n",
        "    Zv3 = torch.mul(G3, Qv3)\n",
        "    Qv4 = self.NPV_C4(Zv3)\n",
        "    Zv4 = torch.mul(G4, Qv4)\n",
        "\n",
        "    Zv4 = self.NPV_F(Zv4)\n",
        "    Qv5 = self.NPV_D1(Zv4)\n",
        "    Zv5 = torch.mul(G5, Qv5)\n",
        "    Qv6 = self.NPV_D2(Zv5)\n",
        "    Zv6 = torch.mul(G6, Qv6)\n",
        "\n",
        "    Qv_output = self.outputs(Zv6)\n",
        " \n",
        "    return F.log_softmax(Qv_output)"
      ],
      "metadata": {
        "id": "esP8_prHj5_q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "decoupled_soft_relu_linear_model = Conv4SoftGaluLinear(args['image_size'], args['channels'])\n",
        "decoupled_soft_relu_linear_model.to(device)\n",
        "decoupled_soft_relu_linear_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b0ad3fb3-58b6-45c6-af88-db8f6be5ba1c",
        "id": "iq4ZOhCjZwy6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv4SoftGaluLinear(\n",
              "  (NPF_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPF_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPF_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (NPV_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPV_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPV_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (outputs): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(decoupled_soft_relu_linear_model.parameters(), lr=args['lr'])\n",
        "\n",
        "for epoch in range(1, args['epochs']+1):\n",
        "  train(decoupled_soft_relu_linear_model, epoch, train_loader, lossFn, optimizer)\n",
        "  validate(decoupled_soft_relu_linear_model, validation_loader, lossFn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "926574e9-7c75-4dce-9760-4122f4a734af",
        "id": "iDYayYT_Zwy7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:69: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [50000/50000 (100%)]\tLoss: 2.070893\n",
            "\n",
            "Validation set: Average loss: 1.6798, Accuracy: 3921/10000 (39%)\n",
            "\n",
            "Train Epoch: 2 [50000/50000 (100%)]\tLoss: 1.534020\n",
            "\n",
            "Validation set: Average loss: 1.5009, Accuracy: 4677/10000 (47%)\n",
            "\n",
            "Train Epoch: 3 [50000/50000 (100%)]\tLoss: 1.362790\n",
            "\n",
            "Validation set: Average loss: 1.3548, Accuracy: 5138/10000 (51%)\n",
            "\n",
            "Train Epoch: 4 [50000/50000 (100%)]\tLoss: 1.240822\n",
            "\n",
            "Validation set: Average loss: 1.3133, Accuracy: 5283/10000 (53%)\n",
            "\n",
            "Train Epoch: 5 [50000/50000 (100%)]\tLoss: 1.131280\n",
            "\n",
            "Validation set: Average loss: 1.2672, Accuracy: 5523/10000 (55%)\n",
            "\n",
            "Train Epoch: 6 [50000/50000 (100%)]\tLoss: 1.013499\n",
            "\n",
            "Validation set: Average loss: 1.2660, Accuracy: 5610/10000 (56%)\n",
            "\n",
            "Train Epoch: 7 [50000/50000 (100%)]\tLoss: 0.892516\n",
            "\n",
            "Validation set: Average loss: 1.1563, Accuracy: 5966/10000 (60%)\n",
            "\n",
            "Train Epoch: 8 [50000/50000 (100%)]\tLoss: 0.768359\n",
            "\n",
            "Validation set: Average loss: 1.1408, Accuracy: 6061/10000 (61%)\n",
            "\n",
            "Train Epoch: 9 [50000/50000 (100%)]\tLoss: 0.643240\n",
            "\n",
            "Validation set: Average loss: 1.2656, Accuracy: 5919/10000 (59%)\n",
            "\n",
            "Train Epoch: 10 [50000/50000 (100%)]\tLoss: 0.527777\n",
            "\n",
            "Validation set: Average loss: 1.3009, Accuracy: 6009/10000 (60%)\n",
            "\n",
            "Train Epoch: 11 [50000/50000 (100%)]\tLoss: 0.415829\n",
            "\n",
            "Validation set: Average loss: 1.4462, Accuracy: 6082/10000 (61%)\n",
            "\n",
            "Train Epoch: 12 [50000/50000 (100%)]\tLoss: 0.326851\n",
            "\n",
            "Validation set: Average loss: 1.4297, Accuracy: 5968/10000 (60%)\n",
            "\n",
            "Train Epoch: 13 [50000/50000 (100%)]\tLoss: 0.274050\n",
            "\n",
            "Validation set: Average loss: 1.6202, Accuracy: 5896/10000 (59%)\n",
            "\n",
            "Train Epoch: 14 [50000/50000 (100%)]\tLoss: 0.227293\n",
            "\n",
            "Validation set: Average loss: 1.6672, Accuracy: 5974/10000 (60%)\n",
            "\n",
            "Train Epoch: 15 [50000/50000 (100%)]\tLoss: 0.266236\n",
            "\n",
            "Validation set: Average loss: 1.5427, Accuracy: 6212/10000 (62%)\n",
            "\n",
            "Train Epoch: 16 [50000/50000 (100%)]\tLoss: 0.226214\n",
            "\n",
            "Validation set: Average loss: 1.6416, Accuracy: 5566/10000 (56%)\n",
            "\n",
            "Train Epoch: 17 [50000/50000 (100%)]\tLoss: 0.226945\n",
            "\n",
            "Validation set: Average loss: 1.7452, Accuracy: 5945/10000 (59%)\n",
            "\n",
            "Train Epoch: 18 [50000/50000 (100%)]\tLoss: 0.343238\n",
            "\n",
            "Validation set: Average loss: 1.5253, Accuracy: 6178/10000 (62%)\n",
            "\n",
            "Train Epoch: 19 [50000/50000 (100%)]\tLoss: 0.346627\n",
            "\n",
            "Validation set: Average loss: 1.6672, Accuracy: 5913/10000 (59%)\n",
            "\n",
            "Train Epoch: 20 [50000/50000 (100%)]\tLoss: 0.598226\n",
            "\n",
            "Validation set: Average loss: 1.2672, Accuracy: 5553/10000 (56%)\n",
            "\n",
            "Train Epoch: 21 [50000/50000 (100%)]\tLoss: 0.919003\n",
            "\n",
            "Validation set: Average loss: 1.1624, Accuracy: 6079/10000 (61%)\n",
            "\n",
            "Train Epoch: 22 [50000/50000 (100%)]\tLoss: 0.788817\n",
            "\n",
            "Validation set: Average loss: 1.1375, Accuracy: 6249/10000 (62%)\n",
            "\n",
            "Train Epoch: 23 [50000/50000 (100%)]\tLoss: 1.008645\n",
            "\n",
            "Validation set: Average loss: 1.1120, Accuracy: 6155/10000 (62%)\n",
            "\n",
            "Train Epoch: 24 [50000/50000 (100%)]\tLoss: 0.893358\n",
            "\n",
            "Validation set: Average loss: 1.1171, Accuracy: 6190/10000 (62%)\n",
            "\n",
            "Train Epoch: 25 [50000/50000 (100%)]\tLoss: 0.631652\n",
            "\n",
            "Validation set: Average loss: 1.2024, Accuracy: 6156/10000 (62%)\n",
            "\n",
            "Train Epoch: 26 [50000/50000 (100%)]\tLoss: 0.458261\n",
            "\n",
            "Validation set: Average loss: 1.7270, Accuracy: 4621/10000 (46%)\n",
            "\n",
            "Train Epoch: 27 [50000/50000 (100%)]\tLoss: 1.087391\n",
            "\n",
            "Validation set: Average loss: 1.2690, Accuracy: 5614/10000 (56%)\n",
            "\n",
            "Train Epoch: 28 [50000/50000 (100%)]\tLoss: 1.091499\n",
            "\n",
            "Validation set: Average loss: 1.1283, Accuracy: 6126/10000 (61%)\n",
            "\n",
            "Train Epoch: 29 [50000/50000 (100%)]\tLoss: 0.934184\n",
            "\n",
            "Validation set: Average loss: 1.1744, Accuracy: 6005/10000 (60%)\n",
            "\n",
            "Train Epoch: 30 [50000/50000 (100%)]\tLoss: 0.744245\n",
            "\n",
            "Validation set: Average loss: 1.2168, Accuracy: 6036/10000 (60%)\n",
            "\n",
            "Train Epoch: 31 [50000/50000 (100%)]\tLoss: 1.053925\n",
            "\n",
            "Validation set: Average loss: 1.1380, Accuracy: 6040/10000 (60%)\n",
            "\n",
            "Train Epoch: 32 [50000/50000 (100%)]\tLoss: 0.903761\n",
            "\n",
            "Validation set: Average loss: 1.1530, Accuracy: 6068/10000 (61%)\n",
            "\n",
            "Train Epoch: 33 [50000/50000 (100%)]\tLoss: 0.731060\n",
            "\n",
            "Validation set: Average loss: 1.2500, Accuracy: 5993/10000 (60%)\n",
            "\n",
            "Train Epoch: 34 [50000/50000 (100%)]\tLoss: 0.854691\n",
            "\n",
            "Validation set: Average loss: 1.1953, Accuracy: 5846/10000 (58%)\n",
            "\n",
            "Train Epoch: 35 [50000/50000 (100%)]\tLoss: 0.839993\n",
            "\n",
            "Validation set: Average loss: 1.1084, Accuracy: 6188/10000 (62%)\n",
            "\n",
            "Train Epoch: 36 [50000/50000 (100%)]\tLoss: 1.120665\n",
            "\n",
            "Validation set: Average loss: 1.3131, Accuracy: 5460/10000 (55%)\n",
            "\n",
            "Train Epoch: 37 [50000/50000 (100%)]\tLoss: 0.958350\n",
            "\n",
            "Validation set: Average loss: 1.2598, Accuracy: 5812/10000 (58%)\n",
            "\n",
            "Train Epoch: 38 [50000/50000 (100%)]\tLoss: 0.752587\n",
            "\n",
            "Validation set: Average loss: 1.3656, Accuracy: 5675/10000 (57%)\n",
            "\n",
            "Train Epoch: 39 [50000/50000 (100%)]\tLoss: 0.599899\n",
            "\n",
            "Validation set: Average loss: 1.5113, Accuracy: 5657/10000 (57%)\n",
            "\n",
            "Train Epoch: 40 [50000/50000 (100%)]\tLoss: 0.463550\n",
            "\n",
            "Validation set: Average loss: 1.6320, Accuracy: 5584/10000 (56%)\n",
            "\n",
            "Train Epoch: 41 [50000/50000 (100%)]\tLoss: 0.444055\n",
            "\n",
            "Validation set: Average loss: 1.7660, Accuracy: 5588/10000 (56%)\n",
            "\n",
            "Train Epoch: 42 [50000/50000 (100%)]\tLoss: 0.339254\n",
            "\n",
            "Validation set: Average loss: 2.0606, Accuracy: 5440/10000 (54%)\n",
            "\n",
            "Train Epoch: 43 [50000/50000 (100%)]\tLoss: 0.264290\n",
            "\n",
            "Validation set: Average loss: 2.2707, Accuracy: 5497/10000 (55%)\n",
            "\n",
            "Train Epoch: 44 [50000/50000 (100%)]\tLoss: 0.301912\n",
            "\n",
            "Validation set: Average loss: 2.1907, Accuracy: 5508/10000 (55%)\n",
            "\n",
            "Train Epoch: 45 [50000/50000 (100%)]\tLoss: 0.265261\n",
            "\n",
            "Validation set: Average loss: 2.3496, Accuracy: 5451/10000 (55%)\n",
            "\n",
            "Train Epoch: 46 [50000/50000 (100%)]\tLoss: 0.169726\n",
            "\n",
            "Validation set: Average loss: 2.7750, Accuracy: 5544/10000 (55%)\n",
            "\n",
            "Train Epoch: 47 [50000/50000 (100%)]\tLoss: 0.097121\n",
            "\n",
            "Validation set: Average loss: 3.1739, Accuracy: 5448/10000 (54%)\n",
            "\n",
            "Train Epoch: 48 [50000/50000 (100%)]\tLoss: 0.062778\n",
            "\n",
            "Validation set: Average loss: 3.5146, Accuracy: 5401/10000 (54%)\n",
            "\n",
            "Train Epoch: 49 [50000/50000 (100%)]\tLoss: 0.058699\n",
            "\n",
            "Validation set: Average loss: 3.8468, Accuracy: 5408/10000 (54%)\n",
            "\n",
            "Train Epoch: 50 [50000/50000 (100%)]\tLoss: 0.074341\n",
            "\n",
            "Validation set: Average loss: 3.9390, Accuracy: 5357/10000 (54%)\n",
            "\n",
            "Train Epoch: 51 [50000/50000 (100%)]\tLoss: 0.083259\n",
            "\n",
            "Validation set: Average loss: 3.9417, Accuracy: 5326/10000 (53%)\n",
            "\n",
            "Train Epoch: 52 [50000/50000 (100%)]\tLoss: 0.093844\n",
            "\n",
            "Validation set: Average loss: 3.8643, Accuracy: 5331/10000 (53%)\n",
            "\n",
            "Train Epoch: 53 [50000/50000 (100%)]\tLoss: 0.248987\n",
            "\n",
            "Validation set: Average loss: 2.9188, Accuracy: 5361/10000 (54%)\n",
            "\n",
            "Train Epoch: 54 [50000/50000 (100%)]\tLoss: 0.113484\n",
            "\n",
            "Validation set: Average loss: 3.3000, Accuracy: 5389/10000 (54%)\n",
            "\n",
            "Train Epoch: 55 [50000/50000 (100%)]\tLoss: 0.041919\n",
            "\n",
            "Validation set: Average loss: 3.7558, Accuracy: 5427/10000 (54%)\n",
            "\n",
            "Train Epoch: 56 [50000/50000 (100%)]\tLoss: 0.019321\n",
            "\n",
            "Validation set: Average loss: 4.0797, Accuracy: 5452/10000 (55%)\n",
            "\n",
            "Train Epoch: 57 [50000/50000 (100%)]\tLoss: 0.006961\n",
            "\n",
            "Validation set: Average loss: 4.2643, Accuracy: 5464/10000 (55%)\n",
            "\n",
            "Train Epoch: 58 [50000/50000 (100%)]\tLoss: 0.002886\n",
            "\n",
            "Validation set: Average loss: 4.4127, Accuracy: 5494/10000 (55%)\n",
            "\n",
            "Train Epoch: 59 [50000/50000 (100%)]\tLoss: 0.001254\n",
            "\n",
            "Validation set: Average loss: 4.5289, Accuracy: 5534/10000 (55%)\n",
            "\n",
            "Train Epoch: 60 [50000/50000 (100%)]\tLoss: 0.000802\n",
            "\n",
            "Validation set: Average loss: 4.6159, Accuracy: 5536/10000 (55%)\n",
            "\n",
            "Train Epoch: 61 [50000/50000 (100%)]\tLoss: 0.000605\n",
            "\n",
            "Validation set: Average loss: 4.6958, Accuracy: 5544/10000 (55%)\n",
            "\n",
            "Train Epoch: 62 [50000/50000 (100%)]\tLoss: 0.000498\n",
            "\n",
            "Validation set: Average loss: 4.7626, Accuracy: 5540/10000 (55%)\n",
            "\n",
            "Train Epoch: 63 [50000/50000 (100%)]\tLoss: 0.000423\n",
            "\n",
            "Validation set: Average loss: 4.8211, Accuracy: 5542/10000 (55%)\n",
            "\n",
            "Train Epoch: 64 [50000/50000 (100%)]\tLoss: 0.001069\n",
            "\n",
            "Validation set: Average loss: 4.8608, Accuracy: 5535/10000 (55%)\n",
            "\n",
            "Train Epoch: 65 [50000/50000 (100%)]\tLoss: 0.010811\n",
            "\n",
            "Validation set: Average loss: 4.9865, Accuracy: 5370/10000 (54%)\n",
            "\n",
            "Train Epoch: 66 [50000/50000 (100%)]\tLoss: 0.283703\n",
            "\n",
            "Validation set: Average loss: 2.3930, Accuracy: 5126/10000 (51%)\n",
            "\n",
            "Train Epoch: 67 [50000/50000 (100%)]\tLoss: 0.523380\n",
            "\n",
            "Validation set: Average loss: 2.0504, Accuracy: 5514/10000 (55%)\n",
            "\n",
            "Train Epoch: 68 [50000/50000 (100%)]\tLoss: 0.161987\n",
            "\n",
            "Validation set: Average loss: 2.5745, Accuracy: 5548/10000 (55%)\n",
            "\n",
            "Train Epoch: 69 [50000/50000 (100%)]\tLoss: 0.060196\n",
            "\n",
            "Validation set: Average loss: 3.1044, Accuracy: 5462/10000 (55%)\n",
            "\n",
            "Train Epoch: 70 [50000/50000 (100%)]\tLoss: 0.026827\n",
            "\n",
            "Validation set: Average loss: 3.5008, Accuracy: 5554/10000 (56%)\n",
            "\n",
            "Train Epoch: 71 [50000/50000 (100%)]\tLoss: 0.017037\n",
            "\n",
            "Validation set: Average loss: 3.9746, Accuracy: 5565/10000 (56%)\n",
            "\n",
            "Train Epoch: 72 [50000/50000 (100%)]\tLoss: 0.062782\n",
            "\n",
            "Validation set: Average loss: 3.8714, Accuracy: 5475/10000 (55%)\n",
            "\n",
            "Train Epoch: 73 [50000/50000 (100%)]\tLoss: 0.102761\n",
            "\n",
            "Validation set: Average loss: 3.6346, Accuracy: 5412/10000 (54%)\n",
            "\n",
            "Train Epoch: 74 [50000/50000 (100%)]\tLoss: 0.044969\n",
            "\n",
            "Validation set: Average loss: 3.9787, Accuracy: 5437/10000 (54%)\n",
            "\n",
            "Train Epoch: 75 [50000/50000 (100%)]\tLoss: 0.305552\n",
            "\n",
            "Validation set: Average loss: 1.8920, Accuracy: 4926/10000 (49%)\n",
            "\n",
            "Train Epoch: 76 [50000/50000 (100%)]\tLoss: 0.836188\n",
            "\n",
            "Validation set: Average loss: 1.5063, Accuracy: 5680/10000 (57%)\n",
            "\n",
            "Train Epoch: 77 [50000/50000 (100%)]\tLoss: 0.415598\n",
            "\n",
            "Validation set: Average loss: 1.7610, Accuracy: 5471/10000 (55%)\n",
            "\n",
            "Train Epoch: 78 [50000/50000 (100%)]\tLoss: 0.278810\n",
            "\n",
            "Validation set: Average loss: 2.2448, Accuracy: 5502/10000 (55%)\n",
            "\n",
            "Train Epoch: 79 [50000/50000 (100%)]\tLoss: 0.145493\n",
            "\n",
            "Validation set: Average loss: 2.7269, Accuracy: 5480/10000 (55%)\n",
            "\n",
            "Train Epoch: 80 [50000/50000 (100%)]\tLoss: 0.137780\n",
            "\n",
            "Validation set: Average loss: 2.9013, Accuracy: 5387/10000 (54%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Reduced Learning Rate"
      ],
      "metadata": {
        "id": "cS_JgpJ3Slj5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoupled_soft_relu_linear_model = Conv4SoftGaluLinear(args['image_size'], args['channels'])\n",
        "decoupled_soft_relu_linear_model.to(device)\n",
        "decoupled_soft_relu_linear_model"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12f0060c-8975-41ed-b06a-e281bf5060f3",
        "id": "p3WIoTQ8SkYZ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv4SoftGaluLinear(\n",
              "  (NPF_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPF_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPF_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (NPV_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPV_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPV_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (outputs): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(decoupled_soft_relu_linear_model.parameters(), lr=5e-3)  # reduce learning rate to half\n",
        "for epoch in range(1, args['epochs']+1):\n",
        "  train(decoupled_soft_relu_linear_model, epoch, train_loader, lossFn, optimizer)\n",
        "  validate(decoupled_soft_relu_linear_model, validation_loader, lossFn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d74d4242-af51-438c-dab9-50af6bc952cd",
        "id": "jhLPfyIcSkYq"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1944: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:64: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [50000/50000 (100%)]\tLoss: 2.274788\n",
            "\n",
            "Validation set: Average loss: 2.0741, Accuracy: 2705/10000 (27%)\n",
            "\n",
            "Train Epoch: 2 [50000/50000 (100%)]\tLoss: 1.766121\n",
            "\n",
            "Validation set: Average loss: 1.6139, Accuracy: 4272/10000 (43%)\n",
            "\n",
            "Train Epoch: 3 [50000/50000 (100%)]\tLoss: 1.502716\n",
            "\n",
            "Validation set: Average loss: 1.4493, Accuracy: 4889/10000 (49%)\n",
            "\n",
            "Train Epoch: 4 [50000/50000 (100%)]\tLoss: 1.361111\n",
            "\n",
            "Validation set: Average loss: 1.3722, Accuracy: 5077/10000 (51%)\n",
            "\n",
            "Train Epoch: 5 [50000/50000 (100%)]\tLoss: 1.250576\n",
            "\n",
            "Validation set: Average loss: 1.3322, Accuracy: 5280/10000 (53%)\n",
            "\n",
            "Train Epoch: 6 [50000/50000 (100%)]\tLoss: 1.150768\n",
            "\n",
            "Validation set: Average loss: 1.2953, Accuracy: 5393/10000 (54%)\n",
            "\n",
            "Train Epoch: 7 [50000/50000 (100%)]\tLoss: 1.052761\n",
            "\n",
            "Validation set: Average loss: 1.2901, Accuracy: 5541/10000 (55%)\n",
            "\n",
            "Train Epoch: 8 [50000/50000 (100%)]\tLoss: 0.952005\n",
            "\n",
            "Validation set: Average loss: 1.2892, Accuracy: 5620/10000 (56%)\n",
            "\n",
            "Train Epoch: 9 [50000/50000 (100%)]\tLoss: 0.848894\n",
            "\n",
            "Validation set: Average loss: 1.3491, Accuracy: 5560/10000 (56%)\n",
            "\n",
            "Train Epoch: 10 [50000/50000 (100%)]\tLoss: 0.744530\n",
            "\n",
            "Validation set: Average loss: 1.3196, Accuracy: 5667/10000 (57%)\n",
            "\n",
            "Train Epoch: 11 [50000/50000 (100%)]\tLoss: 0.644858\n",
            "\n",
            "Validation set: Average loss: 1.4269, Accuracy: 5608/10000 (56%)\n",
            "\n",
            "Train Epoch: 12 [50000/50000 (100%)]\tLoss: 0.549603\n",
            "\n",
            "Validation set: Average loss: 1.3952, Accuracy: 5763/10000 (58%)\n",
            "\n",
            "Train Epoch: 13 [50000/50000 (100%)]\tLoss: 0.478436\n",
            "\n",
            "Validation set: Average loss: 1.4526, Accuracy: 5823/10000 (58%)\n",
            "\n",
            "Train Epoch: 14 [50000/50000 (100%)]\tLoss: 0.413249\n",
            "\n",
            "Validation set: Average loss: 1.5107, Accuracy: 5785/10000 (58%)\n",
            "\n",
            "Train Epoch: 15 [50000/50000 (100%)]\tLoss: 0.366801\n",
            "\n",
            "Validation set: Average loss: 1.5714, Accuracy: 5860/10000 (59%)\n",
            "\n",
            "Train Epoch: 16 [50000/50000 (100%)]\tLoss: 0.309914\n",
            "\n",
            "Validation set: Average loss: 1.7338, Accuracy: 5819/10000 (58%)\n",
            "\n",
            "Train Epoch: 17 [50000/50000 (100%)]\tLoss: 0.271778\n",
            "\n",
            "Validation set: Average loss: 1.7668, Accuracy: 5881/10000 (59%)\n",
            "\n",
            "Train Epoch: 18 [50000/50000 (100%)]\tLoss: 0.235293\n",
            "\n",
            "Validation set: Average loss: 1.8285, Accuracy: 5869/10000 (59%)\n",
            "\n",
            "Train Epoch: 19 [50000/50000 (100%)]\tLoss: 0.206487\n",
            "\n",
            "Validation set: Average loss: 1.8467, Accuracy: 5933/10000 (59%)\n",
            "\n",
            "Train Epoch: 20 [50000/50000 (100%)]\tLoss: 0.174874\n",
            "\n",
            "Validation set: Average loss: 1.8907, Accuracy: 6064/10000 (61%)\n",
            "\n",
            "Train Epoch: 21 [50000/50000 (100%)]\tLoss: 0.165978\n",
            "\n",
            "Validation set: Average loss: 1.9362, Accuracy: 5969/10000 (60%)\n",
            "\n",
            "Train Epoch: 22 [50000/50000 (100%)]\tLoss: 0.125585\n",
            "\n",
            "Validation set: Average loss: 2.0763, Accuracy: 5970/10000 (60%)\n",
            "\n",
            "Train Epoch: 23 [50000/50000 (100%)]\tLoss: 0.114064\n",
            "\n",
            "Validation set: Average loss: 2.1338, Accuracy: 5984/10000 (60%)\n",
            "\n",
            "Train Epoch: 24 [50000/50000 (100%)]\tLoss: 0.102752\n",
            "\n",
            "Validation set: Average loss: 2.1681, Accuracy: 6070/10000 (61%)\n",
            "\n",
            "Train Epoch: 25 [50000/50000 (100%)]\tLoss: 0.100922\n",
            "\n",
            "Validation set: Average loss: 2.2844, Accuracy: 5996/10000 (60%)\n",
            "\n",
            "Train Epoch: 26 [50000/50000 (100%)]\tLoss: 0.073566\n",
            "\n",
            "Validation set: Average loss: 2.2938, Accuracy: 6057/10000 (61%)\n",
            "\n",
            "Train Epoch: 27 [50000/50000 (100%)]\tLoss: 0.061316\n",
            "\n",
            "Validation set: Average loss: 2.2317, Accuracy: 6137/10000 (61%)\n",
            "\n",
            "Train Epoch: 28 [50000/50000 (100%)]\tLoss: 0.066617\n",
            "\n",
            "Validation set: Average loss: 2.6765, Accuracy: 5663/10000 (57%)\n",
            "\n",
            "Train Epoch: 29 [50000/50000 (100%)]\tLoss: 0.074994\n",
            "\n",
            "Validation set: Average loss: 2.3241, Accuracy: 6078/10000 (61%)\n",
            "\n",
            "Train Epoch: 30 [50000/50000 (100%)]\tLoss: 0.047387\n",
            "\n",
            "Validation set: Average loss: 2.4366, Accuracy: 6126/10000 (61%)\n",
            "\n",
            "Train Epoch: 31 [50000/50000 (100%)]\tLoss: 0.046070\n",
            "\n",
            "Validation set: Average loss: 2.5345, Accuracy: 6103/10000 (61%)\n",
            "\n",
            "Train Epoch: 32 [50000/50000 (100%)]\tLoss: 0.047914\n",
            "\n",
            "Validation set: Average loss: 2.4597, Accuracy: 6187/10000 (62%)\n",
            "\n",
            "Train Epoch: 33 [50000/50000 (100%)]\tLoss: 0.042316\n",
            "\n",
            "Validation set: Average loss: 2.5690, Accuracy: 6225/10000 (62%)\n",
            "\n",
            "Train Epoch: 34 [50000/50000 (100%)]\tLoss: 0.038934\n",
            "\n",
            "Validation set: Average loss: 2.5301, Accuracy: 6116/10000 (61%)\n",
            "\n",
            "Train Epoch: 35 [50000/50000 (100%)]\tLoss: 0.061230\n",
            "\n",
            "Validation set: Average loss: 2.4598, Accuracy: 6084/10000 (61%)\n",
            "\n",
            "Train Epoch: 36 [50000/50000 (100%)]\tLoss: 0.041834\n",
            "\n",
            "Validation set: Average loss: 2.4315, Accuracy: 6115/10000 (61%)\n",
            "\n",
            "Train Epoch: 37 [50000/50000 (100%)]\tLoss: 0.020180\n",
            "\n",
            "Validation set: Average loss: 2.7052, Accuracy: 6127/10000 (61%)\n",
            "\n",
            "Train Epoch: 38 [50000/50000 (100%)]\tLoss: 0.017306\n",
            "\n",
            "Validation set: Average loss: 2.8820, Accuracy: 6213/10000 (62%)\n",
            "\n",
            "Train Epoch: 39 [50000/50000 (100%)]\tLoss: 0.010174\n",
            "\n",
            "Validation set: Average loss: 2.9160, Accuracy: 6294/10000 (63%)\n",
            "\n",
            "Train Epoch: 40 [50000/50000 (100%)]\tLoss: 0.017268\n",
            "\n",
            "Validation set: Average loss: 2.8319, Accuracy: 6156/10000 (62%)\n",
            "\n",
            "Train Epoch: 41 [50000/50000 (100%)]\tLoss: 0.046892\n",
            "\n",
            "Validation set: Average loss: 2.6591, Accuracy: 6140/10000 (61%)\n",
            "\n",
            "Train Epoch: 42 [50000/50000 (100%)]\tLoss: 0.027901\n",
            "\n",
            "Validation set: Average loss: 2.6941, Accuracy: 6159/10000 (62%)\n",
            "\n",
            "Train Epoch: 43 [50000/50000 (100%)]\tLoss: 0.041276\n",
            "\n",
            "Validation set: Average loss: 2.6458, Accuracy: 6040/10000 (60%)\n",
            "\n",
            "Train Epoch: 44 [50000/50000 (100%)]\tLoss: 0.026874\n",
            "\n",
            "Validation set: Average loss: 2.7101, Accuracy: 6156/10000 (62%)\n",
            "\n",
            "Train Epoch: 45 [50000/50000 (100%)]\tLoss: 0.011730\n",
            "\n",
            "Validation set: Average loss: 2.9408, Accuracy: 6170/10000 (62%)\n",
            "\n",
            "Train Epoch: 46 [50000/50000 (100%)]\tLoss: 0.004048\n",
            "\n",
            "Validation set: Average loss: 3.0246, Accuracy: 6236/10000 (62%)\n",
            "\n",
            "Train Epoch: 47 [50000/50000 (100%)]\tLoss: 0.002594\n",
            "\n",
            "Validation set: Average loss: 3.1113, Accuracy: 6269/10000 (63%)\n",
            "\n",
            "Train Epoch: 48 [50000/50000 (100%)]\tLoss: 0.000593\n",
            "\n",
            "Validation set: Average loss: 3.1189, Accuracy: 6288/10000 (63%)\n",
            "\n",
            "Train Epoch: 49 [50000/50000 (100%)]\tLoss: 0.000210\n",
            "\n",
            "Validation set: Average loss: 3.1829, Accuracy: 6274/10000 (63%)\n",
            "\n",
            "Train Epoch: 50 [50000/50000 (100%)]\tLoss: 0.000115\n",
            "\n",
            "Validation set: Average loss: 3.2158, Accuracy: 6288/10000 (63%)\n",
            "\n",
            "Train Epoch: 51 [50000/50000 (100%)]\tLoss: 0.000082\n",
            "\n",
            "Validation set: Average loss: 3.2418, Accuracy: 6293/10000 (63%)\n",
            "\n",
            "Train Epoch: 52 [50000/50000 (100%)]\tLoss: 0.000068\n",
            "\n",
            "Validation set: Average loss: 3.2639, Accuracy: 6286/10000 (63%)\n",
            "\n",
            "Train Epoch: 53 [50000/50000 (100%)]\tLoss: 0.000059\n",
            "\n",
            "Validation set: Average loss: 3.2823, Accuracy: 6287/10000 (63%)\n",
            "\n",
            "Train Epoch: 54 [50000/50000 (100%)]\tLoss: 0.000053\n",
            "\n",
            "Validation set: Average loss: 3.2998, Accuracy: 6292/10000 (63%)\n",
            "\n",
            "Train Epoch: 55 [50000/50000 (100%)]\tLoss: 0.000048\n",
            "\n",
            "Validation set: Average loss: 3.3158, Accuracy: 6296/10000 (63%)\n",
            "\n",
            "Train Epoch: 56 [50000/50000 (100%)]\tLoss: 0.000044\n",
            "\n",
            "Validation set: Average loss: 3.3304, Accuracy: 6298/10000 (63%)\n",
            "\n",
            "Train Epoch: 57 [50000/50000 (100%)]\tLoss: 0.000041\n",
            "\n",
            "Validation set: Average loss: 3.3449, Accuracy: 6293/10000 (63%)\n",
            "\n",
            "Train Epoch: 58 [50000/50000 (100%)]\tLoss: 0.000038\n",
            "\n",
            "Validation set: Average loss: 3.3577, Accuracy: 6293/10000 (63%)\n",
            "\n",
            "Train Epoch: 59 [50000/50000 (100%)]\tLoss: 0.000036\n",
            "\n",
            "Validation set: Average loss: 3.3704, Accuracy: 6295/10000 (63%)\n",
            "\n",
            "Train Epoch: 60 [50000/50000 (100%)]\tLoss: 0.000034\n",
            "\n",
            "Validation set: Average loss: 3.3822, Accuracy: 6297/10000 (63%)\n",
            "\n",
            "Train Epoch: 61 [50000/50000 (100%)]\tLoss: 0.000032\n",
            "\n",
            "Validation set: Average loss: 3.3933, Accuracy: 6300/10000 (63%)\n",
            "\n",
            "Train Epoch: 62 [50000/50000 (100%)]\tLoss: 0.000030\n",
            "\n",
            "Validation set: Average loss: 3.4043, Accuracy: 6301/10000 (63%)\n",
            "\n",
            "Train Epoch: 63 [50000/50000 (100%)]\tLoss: 0.000029\n",
            "\n",
            "Validation set: Average loss: 3.4145, Accuracy: 6302/10000 (63%)\n",
            "\n",
            "Train Epoch: 64 [50000/50000 (100%)]\tLoss: 0.000027\n",
            "\n",
            "Validation set: Average loss: 3.4242, Accuracy: 6301/10000 (63%)\n",
            "\n",
            "Train Epoch: 65 [50000/50000 (100%)]\tLoss: 0.000026\n",
            "\n",
            "Validation set: Average loss: 3.4336, Accuracy: 6307/10000 (63%)\n",
            "\n",
            "Train Epoch: 66 [50000/50000 (100%)]\tLoss: 0.000025\n",
            "\n",
            "Validation set: Average loss: 3.4425, Accuracy: 6309/10000 (63%)\n",
            "\n",
            "Train Epoch: 67 [50000/50000 (100%)]\tLoss: 0.000024\n",
            "\n",
            "Validation set: Average loss: 3.4512, Accuracy: 6309/10000 (63%)\n",
            "\n",
            "Train Epoch: 68 [50000/50000 (100%)]\tLoss: 0.000023\n",
            "\n",
            "Validation set: Average loss: 3.4597, Accuracy: 6309/10000 (63%)\n",
            "\n",
            "Train Epoch: 69 [50000/50000 (100%)]\tLoss: 0.000022\n",
            "\n",
            "Validation set: Average loss: 3.4677, Accuracy: 6311/10000 (63%)\n",
            "\n",
            "Train Epoch: 70 [50000/50000 (100%)]\tLoss: 0.000021\n",
            "\n",
            "Validation set: Average loss: 3.4756, Accuracy: 6311/10000 (63%)\n",
            "\n",
            "Train Epoch: 71 [50000/50000 (100%)]\tLoss: 0.000021\n",
            "\n",
            "Validation set: Average loss: 3.4832, Accuracy: 6308/10000 (63%)\n",
            "\n",
            "Train Epoch: 72 [50000/50000 (100%)]\tLoss: 0.000020\n",
            "\n",
            "Validation set: Average loss: 3.4905, Accuracy: 6311/10000 (63%)\n",
            "\n",
            "Train Epoch: 73 [50000/50000 (100%)]\tLoss: 0.000019\n",
            "\n",
            "Validation set: Average loss: 3.4976, Accuracy: 6312/10000 (63%)\n",
            "\n",
            "Train Epoch: 74 [50000/50000 (100%)]\tLoss: 0.000019\n",
            "\n",
            "Validation set: Average loss: 3.5045, Accuracy: 6311/10000 (63%)\n",
            "\n",
            "Train Epoch: 75 [50000/50000 (100%)]\tLoss: 0.000018\n",
            "\n",
            "Validation set: Average loss: 3.5112, Accuracy: 6310/10000 (63%)\n",
            "\n",
            "Train Epoch: 76 [50000/50000 (100%)]\tLoss: 0.000018\n",
            "\n",
            "Validation set: Average loss: 3.5178, Accuracy: 6308/10000 (63%)\n",
            "\n",
            "Train Epoch: 77 [50000/50000 (100%)]\tLoss: 0.000017\n",
            "\n",
            "Validation set: Average loss: 3.5242, Accuracy: 6307/10000 (63%)\n",
            "\n",
            "Train Epoch: 78 [50000/50000 (100%)]\tLoss: 0.000017\n",
            "\n",
            "Validation set: Average loss: 3.5304, Accuracy: 6308/10000 (63%)\n",
            "\n",
            "Train Epoch: 79 [50000/50000 (100%)]\tLoss: 0.000016\n",
            "\n",
            "Validation set: Average loss: 3.5365, Accuracy: 6307/10000 (63%)\n",
            "\n",
            "Train Epoch: 80 [50000/50000 (100%)]\tLoss: 0.000016\n",
            "\n",
            "Validation set: Average loss: 3.5425, Accuracy: 6307/10000 (63%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "GaLU Network"
      ],
      "metadata": {
        "id": "kqo4EF_5Tzm6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Conv4GaluLinear(nn.Module):\n",
        "\n",
        "  def __init__(self, image_size, channels):\n",
        "    \n",
        "    super(Conv4GaluLinear, self).__init__()\n",
        "\n",
        "    # NPF Network\n",
        "    self.NPF_C1 = nn.Conv2d(channels, 64, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPF_C2 = nn.Conv2d(64, 64, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPF_C3 = nn.Conv2d(64, 128, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPF_C4 = nn.Conv2d(128, 128, kernel_size = (3, 3), padding = 'same')\n",
        "\n",
        "    self.NPF_F = nn.Flatten()\n",
        "    self.NPF_D1 = nn.Linear(image_size*128, 256)\n",
        "    self.NPF_D2 = nn.Linear(256, 256)\n",
        "\n",
        "\n",
        "    # NPV Network\n",
        "    self.NPV_C1 = nn.Conv2d(channels, 64, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPV_C2 = nn.Conv2d(64, 64, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPV_C3 = nn.Conv2d(64, 128, kernel_size = (3, 3), padding = 'same')\n",
        "    self.NPV_C4 = nn.Conv2d(128, 128, kernel_size = (3, 3),  padding = 'same')\n",
        "    \n",
        "    self.NPV_F = nn.Flatten()\n",
        "    self.NPV_D1 = nn.Linear(image_size*128, 256)\n",
        "    self.NPV_D2 = nn.Linear(256, 256)\n",
        "\n",
        "    self.outputs = nn.Linear(256, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "\n",
        "    # Calculate pre-activations(Qfi) and activations(Zfi) for NPF network\n",
        "    Zf1 = self.NPF_C1(x)  #Use lineat activations(So Qf = Zf)\n",
        "    Zf2 = self.NPF_C2(Zf1)\n",
        "    Zf3 = self.NPF_C3(Zf2)\n",
        "    Zf4 = self.NPF_C4(Zf3)\n",
        "\n",
        "    Zf4_ = self.NPF_F(Zf4)\n",
        "    Zf5 = self.NPF_D1(Zf4_)\n",
        "    Zf6 = self.NPF_D2(Zf5)\n",
        "\n",
        "    # Gating values(use ReLU - converts negative numbers to 0, followed by Sign gate to find the gating values = 1 if Qf>0 and 0 otherwise)\n",
        "    G1 = SignGate()(F.relu(Zf1))\n",
        "    G2 = SignGate()(F.relu(Zf2))\n",
        "    G3 = SignGate()(F.relu(Zf3))\n",
        "    G4 = SignGate()(F.relu(Zf4))\n",
        "    G5 = SignGate()(F.relu(Zf5))\n",
        "    G6 = SignGate()(F.relu(Zf6))\n",
        "\n",
        "    # Calculate pre-activations(Qvi) and activations(Zvi) for NPV network\n",
        "\n",
        "    Qv1 = self.NPV_C1(x)\n",
        "    Zv1 = torch.mul(G1, Qv1)\n",
        "    Qv2 = self.NPV_C2(Zv1)\n",
        "    Zv2 = torch.mul(G2, Qv2)\n",
        "    Qv3 = self.NPV_C3(Zv2)\n",
        "    Zv3 = torch.mul(G3, Qv3)\n",
        "    Qv4 = self.NPV_C4(Zv3)\n",
        "\n",
        "    # print(Qv4.size(), G4.size())\n",
        "\n",
        "    Zv4 = torch.mul(G4, Qv4)\n",
        "\n",
        "    Zv4 = self.NPV_F(Zv4)\n",
        "    Qv5 = self.NPV_D1(Zv4)\n",
        "    Zv5 = torch.mul(G5, Qv5)\n",
        "    Qv6 = self.NPV_D2(Zv5)\n",
        "    Zv6 = torch.mul(G6, Qv6)\n",
        "\n",
        "    return F.log_softmax(self.outputs(Zv6))"
      ],
      "metadata": {
        "id": "0VuPqdIlMgCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Decoupled Learning with hard relu"
      ],
      "metadata": {
        "id": "90zgzhskMgCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "decoupled_hard_relu_linear_model = Conv4GaluLinear(args['image_size'], args['channels'])\n",
        "decoupled_hard_relu_linear_model.to(device)\n",
        "decoupled_hard_relu_linear_model"
      ],
      "metadata": {
        "id": "cKeY6E6rMgCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "327ff6ed-8704-4dee-a7e1-6c195f2a7316"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv4GaluLinear(\n",
              "  (NPF_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPF_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPF_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (NPV_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPV_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPV_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (outputs): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(decoupled_hard_relu_linear_model.parameters(), lr=args['lr'])\n",
        "for epoch in range(1, args['epochs']+1):\n",
        "  train(decoupled_hard_relu_linear_model, epoch, train_loader, lossFn, optimizer)\n",
        "  validate(decoupled_hard_relu_linear_model, validation_loader, lossFn)"
      ],
      "metadata": {
        "id": "vBmu_x3CMgCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f4c881ce-75ba-4957-b431-e6344d988241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:70: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [50000/50000 (100%)]\tLoss: 1.943714\n",
            "\n",
            "Validation set: Average loss: 1.5103, Accuracy: 4583/10000 (46%)\n",
            "\n",
            "Train Epoch: 2 [50000/50000 (100%)]\tLoss: 1.354597\n",
            "\n",
            "Validation set: Average loss: 1.2697, Accuracy: 5497/10000 (55%)\n",
            "\n",
            "Train Epoch: 3 [50000/50000 (100%)]\tLoss: 1.042386\n",
            "\n",
            "Validation set: Average loss: 1.2647, Accuracy: 5615/10000 (56%)\n",
            "\n",
            "Train Epoch: 4 [50000/50000 (100%)]\tLoss: 0.672963\n",
            "\n",
            "Validation set: Average loss: 1.3810, Accuracy: 5618/10000 (56%)\n",
            "\n",
            "Train Epoch: 5 [50000/50000 (100%)]\tLoss: 0.271060\n",
            "\n",
            "Validation set: Average loss: 1.8611, Accuracy: 5550/10000 (56%)\n",
            "\n",
            "Train Epoch: 6 [50000/50000 (100%)]\tLoss: 0.121320\n",
            "\n",
            "Validation set: Average loss: 2.2932, Accuracy: 5654/10000 (57%)\n",
            "\n",
            "Train Epoch: 7 [50000/50000 (100%)]\tLoss: 0.068582\n",
            "\n",
            "Validation set: Average loss: 2.8480, Accuracy: 5362/10000 (54%)\n",
            "\n",
            "Train Epoch: 8 [50000/50000 (100%)]\tLoss: 0.038305\n",
            "\n",
            "Validation set: Average loss: 3.1458, Accuracy: 5476/10000 (55%)\n",
            "\n",
            "Train Epoch: 9 [50000/50000 (100%)]\tLoss: 0.023365\n",
            "\n",
            "Validation set: Average loss: 3.0905, Accuracy: 5685/10000 (57%)\n",
            "\n",
            "Train Epoch: 10 [50000/50000 (100%)]\tLoss: 0.031893\n",
            "\n",
            "Validation set: Average loss: 3.0798, Accuracy: 5711/10000 (57%)\n",
            "\n",
            "Train Epoch: 11 [50000/50000 (100%)]\tLoss: 0.022495\n",
            "\n",
            "Validation set: Average loss: 3.3198, Accuracy: 5675/10000 (57%)\n",
            "\n",
            "Train Epoch: 12 [50000/50000 (100%)]\tLoss: 0.012274\n",
            "\n",
            "Validation set: Average loss: 3.5318, Accuracy: 5702/10000 (57%)\n",
            "\n",
            "Train Epoch: 13 [50000/50000 (100%)]\tLoss: 0.015828\n",
            "\n",
            "Validation set: Average loss: 3.4970, Accuracy: 5656/10000 (57%)\n",
            "\n",
            "Train Epoch: 14 [50000/50000 (100%)]\tLoss: 0.009049\n",
            "\n",
            "Validation set: Average loss: 3.6898, Accuracy: 5702/10000 (57%)\n",
            "\n",
            "Train Epoch: 15 [50000/50000 (100%)]\tLoss: 0.005396\n",
            "\n",
            "Validation set: Average loss: 3.6772, Accuracy: 5731/10000 (57%)\n",
            "\n",
            "Train Epoch: 16 [50000/50000 (100%)]\tLoss: 0.000644\n",
            "\n",
            "Validation set: Average loss: 3.7286, Accuracy: 5838/10000 (58%)\n",
            "\n",
            "Train Epoch: 17 [50000/50000 (100%)]\tLoss: 0.000101\n",
            "\n",
            "Validation set: Average loss: 3.7684, Accuracy: 5838/10000 (58%)\n",
            "\n",
            "Train Epoch: 18 [50000/50000 (100%)]\tLoss: 0.000062\n",
            "\n",
            "Validation set: Average loss: 3.8110, Accuracy: 5846/10000 (58%)\n",
            "\n",
            "Train Epoch: 19 [50000/50000 (100%)]\tLoss: 0.000050\n",
            "\n",
            "Validation set: Average loss: 3.8460, Accuracy: 5853/10000 (59%)\n",
            "\n",
            "Train Epoch: 20 [50000/50000 (100%)]\tLoss: 0.000043\n",
            "\n",
            "Validation set: Average loss: 3.8763, Accuracy: 5852/10000 (59%)\n",
            "\n",
            "Train Epoch: 21 [50000/50000 (100%)]\tLoss: 0.000037\n",
            "\n",
            "Validation set: Average loss: 3.9031, Accuracy: 5855/10000 (59%)\n",
            "\n",
            "Train Epoch: 22 [50000/50000 (100%)]\tLoss: 0.000033\n",
            "\n",
            "Validation set: Average loss: 3.9273, Accuracy: 5859/10000 (59%)\n",
            "\n",
            "Train Epoch: 23 [50000/50000 (100%)]\tLoss: 0.000030\n",
            "\n",
            "Validation set: Average loss: 3.9494, Accuracy: 5860/10000 (59%)\n",
            "\n",
            "Train Epoch: 24 [50000/50000 (100%)]\tLoss: 0.000027\n",
            "\n",
            "Validation set: Average loss: 3.9702, Accuracy: 5858/10000 (59%)\n",
            "\n",
            "Train Epoch: 25 [50000/50000 (100%)]\tLoss: 0.000025\n",
            "\n",
            "Validation set: Average loss: 3.9895, Accuracy: 5856/10000 (59%)\n",
            "\n",
            "Train Epoch: 26 [50000/50000 (100%)]\tLoss: 0.000023\n",
            "\n",
            "Validation set: Average loss: 4.0073, Accuracy: 5855/10000 (59%)\n",
            "\n",
            "Train Epoch: 27 [50000/50000 (100%)]\tLoss: 0.000022\n",
            "\n",
            "Validation set: Average loss: 4.0238, Accuracy: 5857/10000 (59%)\n",
            "\n",
            "Train Epoch: 28 [50000/50000 (100%)]\tLoss: 0.000020\n",
            "\n",
            "Validation set: Average loss: 4.0397, Accuracy: 5859/10000 (59%)\n",
            "\n",
            "Train Epoch: 29 [50000/50000 (100%)]\tLoss: 0.000019\n",
            "\n",
            "Validation set: Average loss: 4.0547, Accuracy: 5863/10000 (59%)\n",
            "\n",
            "Train Epoch: 30 [50000/50000 (100%)]\tLoss: 0.000018\n",
            "\n",
            "Validation set: Average loss: 4.0691, Accuracy: 5866/10000 (59%)\n",
            "\n",
            "Train Epoch: 31 [50000/50000 (100%)]\tLoss: 0.000017\n",
            "\n",
            "Validation set: Average loss: 4.0826, Accuracy: 5864/10000 (59%)\n",
            "\n",
            "Train Epoch: 32 [50000/50000 (100%)]\tLoss: 0.000016\n",
            "\n",
            "Validation set: Average loss: 4.0955, Accuracy: 5863/10000 (59%)\n",
            "\n",
            "Train Epoch: 33 [50000/50000 (100%)]\tLoss: 0.000015\n",
            "\n",
            "Validation set: Average loss: 4.1079, Accuracy: 5865/10000 (59%)\n",
            "\n",
            "Train Epoch: 34 [50000/50000 (100%)]\tLoss: 0.000015\n",
            "\n",
            "Validation set: Average loss: 4.1198, Accuracy: 5866/10000 (59%)\n",
            "\n",
            "Train Epoch: 35 [50000/50000 (100%)]\tLoss: 0.000014\n",
            "\n",
            "Validation set: Average loss: 4.1312, Accuracy: 5873/10000 (59%)\n",
            "\n",
            "Train Epoch: 36 [50000/50000 (100%)]\tLoss: 0.000013\n",
            "\n",
            "Validation set: Average loss: 4.1422, Accuracy: 5873/10000 (59%)\n",
            "\n",
            "Train Epoch: 37 [50000/50000 (100%)]\tLoss: 0.000013\n",
            "\n",
            "Validation set: Average loss: 4.1529, Accuracy: 5876/10000 (59%)\n",
            "\n",
            "Train Epoch: 38 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 4.1631, Accuracy: 5877/10000 (59%)\n",
            "\n",
            "Train Epoch: 39 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 4.1732, Accuracy: 5878/10000 (59%)\n",
            "\n",
            "Train Epoch: 40 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 4.1827, Accuracy: 5877/10000 (59%)\n",
            "\n",
            "Train Epoch: 41 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 4.1920, Accuracy: 5875/10000 (59%)\n",
            "\n",
            "Train Epoch: 42 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 4.2010, Accuracy: 5874/10000 (59%)\n",
            "\n",
            "Train Epoch: 43 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 4.2097, Accuracy: 5876/10000 (59%)\n",
            "\n",
            "Train Epoch: 44 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 4.2182, Accuracy: 5877/10000 (59%)\n",
            "\n",
            "Train Epoch: 45 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 4.2265, Accuracy: 5879/10000 (59%)\n",
            "\n",
            "Train Epoch: 46 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.2346, Accuracy: 5879/10000 (59%)\n",
            "\n",
            "Train Epoch: 47 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.2424, Accuracy: 5877/10000 (59%)\n",
            "\n",
            "Train Epoch: 48 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.2501, Accuracy: 5876/10000 (59%)\n",
            "\n",
            "Train Epoch: 49 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.2575, Accuracy: 5876/10000 (59%)\n",
            "\n",
            "Train Epoch: 50 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.2648, Accuracy: 5874/10000 (59%)\n",
            "\n",
            "Train Epoch: 51 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.2719, Accuracy: 5875/10000 (59%)\n",
            "\n",
            "Train Epoch: 52 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.2788, Accuracy: 5875/10000 (59%)\n",
            "\n",
            "Train Epoch: 53 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.2856, Accuracy: 5877/10000 (59%)\n",
            "\n",
            "Train Epoch: 54 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.2923, Accuracy: 5877/10000 (59%)\n",
            "\n",
            "Train Epoch: 55 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.2988, Accuracy: 5877/10000 (59%)\n",
            "\n",
            "Train Epoch: 56 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.3052, Accuracy: 5877/10000 (59%)\n",
            "\n",
            "Train Epoch: 57 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.3114, Accuracy: 5878/10000 (59%)\n",
            "\n",
            "Train Epoch: 58 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.3175, Accuracy: 5878/10000 (59%)\n",
            "\n",
            "Train Epoch: 59 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.3235, Accuracy: 5878/10000 (59%)\n",
            "\n",
            "Train Epoch: 60 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.3293, Accuracy: 5878/10000 (59%)\n",
            "\n",
            "Train Epoch: 61 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.3351, Accuracy: 5878/10000 (59%)\n",
            "\n",
            "Train Epoch: 62 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.3408, Accuracy: 5875/10000 (59%)\n",
            "\n",
            "Train Epoch: 63 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.3463, Accuracy: 5875/10000 (59%)\n",
            "\n",
            "Train Epoch: 64 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.3517, Accuracy: 5877/10000 (59%)\n",
            "\n",
            "Train Epoch: 65 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.3571, Accuracy: 5875/10000 (59%)\n",
            "\n",
            "Train Epoch: 66 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.3624, Accuracy: 5871/10000 (59%)\n",
            "\n",
            "Train Epoch: 67 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.3676, Accuracy: 5870/10000 (59%)\n",
            "\n",
            "Train Epoch: 68 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.3727, Accuracy: 5871/10000 (59%)\n",
            "\n",
            "Train Epoch: 69 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.3777, Accuracy: 5871/10000 (59%)\n",
            "\n",
            "Train Epoch: 70 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.3827, Accuracy: 5870/10000 (59%)\n",
            "\n",
            "Train Epoch: 71 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.3875, Accuracy: 5870/10000 (59%)\n",
            "\n",
            "Train Epoch: 72 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.3923, Accuracy: 5870/10000 (59%)\n",
            "\n",
            "Train Epoch: 73 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.3970, Accuracy: 5869/10000 (59%)\n",
            "\n",
            "Train Epoch: 74 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.4016, Accuracy: 5870/10000 (59%)\n",
            "\n",
            "Train Epoch: 75 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.4062, Accuracy: 5870/10000 (59%)\n",
            "\n",
            "Train Epoch: 76 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.4106, Accuracy: 5869/10000 (59%)\n",
            "\n",
            "Train Epoch: 77 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.4151, Accuracy: 5872/10000 (59%)\n",
            "\n",
            "Train Epoch: 78 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.4195, Accuracy: 5872/10000 (59%)\n",
            "\n",
            "Train Epoch: 79 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.4238, Accuracy: 5871/10000 (59%)\n",
            "\n",
            "Train Epoch: 80 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.4280, Accuracy: 5872/10000 (59%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FRNPF(II)"
      ],
      "metadata": {
        "id": "lHFFZR7DMgCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frnpf_ii_linear_model = Conv4GaluLinear(args['image_size'], args['channels'])\n",
        "frnpf_ii_linear_model.to(device)\n",
        "frnpf_ii_linear_model"
      ],
      "metadata": {
        "id": "vUgJqloJMgCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e05e82ec-a1f8-42f9-e848-49242c9da6da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv4GaluLinear(\n",
              "  (NPF_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPF_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPF_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (NPV_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPV_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPV_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (outputs): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in frnpf_ii_linear_model.named_parameters():\n",
        "  if name[0:3]=='NPF':\n",
        "    param.requires_grad = False"
      ],
      "metadata": {
        "id": "zfAbumLEMgCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in frnpf_ii_linear_model.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    print(name)"
      ],
      "metadata": {
        "id": "NGqbl9MxMgCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4c10cd6b-4245-412f-981e-bd6b6a1fb577"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NPV_C1.weight\n",
            "NPV_C1.bias\n",
            "NPV_C2.weight\n",
            "NPV_C2.bias\n",
            "NPV_C3.weight\n",
            "NPV_C3.bias\n",
            "NPV_C4.weight\n",
            "NPV_C4.bias\n",
            "NPV_D1.weight\n",
            "NPV_D1.bias\n",
            "NPV_D2.weight\n",
            "NPV_D2.bias\n",
            "outputs.weight\n",
            "outputs.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(frnpf_ii_linear_model.parameters(), lr=args['lr'])\n",
        "for epoch in range(1, args['epochs']+1):\n",
        "  train(frnpf_ii_linear_model, epoch, train_loader, lossFn, optimizer)\n",
        "  validate(frnpf_ii_linear_model, validation_loader, lossFn)"
      ],
      "metadata": {
        "id": "802UGg8QMgCA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c519dbc8-bafa-4386-d4e6-a246b0e7bcd5"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:70: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [50000/50000 (100%)]\tLoss: 1.921283\n",
            "\n",
            "Validation set: Average loss: 1.5689, Accuracy: 4308/10000 (43%)\n",
            "\n",
            "Train Epoch: 2 [50000/50000 (100%)]\tLoss: 1.370443\n",
            "\n",
            "Validation set: Average loss: 1.2888, Accuracy: 5383/10000 (54%)\n",
            "\n",
            "Train Epoch: 3 [50000/50000 (100%)]\tLoss: 1.080853\n",
            "\n",
            "Validation set: Average loss: 1.2456, Accuracy: 5596/10000 (56%)\n",
            "\n",
            "Train Epoch: 4 [50000/50000 (100%)]\tLoss: 0.746084\n",
            "\n",
            "Validation set: Average loss: 1.4407, Accuracy: 5390/10000 (54%)\n",
            "\n",
            "Train Epoch: 5 [50000/50000 (100%)]\tLoss: 0.351427\n",
            "\n",
            "Validation set: Average loss: 1.6764, Accuracy: 5643/10000 (56%)\n",
            "\n",
            "Train Epoch: 6 [50000/50000 (100%)]\tLoss: 0.134558\n",
            "\n",
            "Validation set: Average loss: 2.0811, Accuracy: 5742/10000 (57%)\n",
            "\n",
            "Train Epoch: 7 [50000/50000 (100%)]\tLoss: 0.071213\n",
            "\n",
            "Validation set: Average loss: 2.6456, Accuracy: 5552/10000 (56%)\n",
            "\n",
            "Train Epoch: 8 [50000/50000 (100%)]\tLoss: 0.038876\n",
            "\n",
            "Validation set: Average loss: 2.6487, Accuracy: 5612/10000 (56%)\n",
            "\n",
            "Train Epoch: 9 [50000/50000 (100%)]\tLoss: 0.032738\n",
            "\n",
            "Validation set: Average loss: 4.5257, Accuracy: 4947/10000 (49%)\n",
            "\n",
            "Train Epoch: 10 [50000/50000 (100%)]\tLoss: 0.026885\n",
            "\n",
            "Validation set: Average loss: 2.9574, Accuracy: 5641/10000 (56%)\n",
            "\n",
            "Train Epoch: 11 [50000/50000 (100%)]\tLoss: 0.013472\n",
            "\n",
            "Validation set: Average loss: 3.2399, Accuracy: 5739/10000 (57%)\n",
            "\n",
            "Train Epoch: 12 [50000/50000 (100%)]\tLoss: 0.003865\n",
            "\n",
            "Validation set: Average loss: 3.4531, Accuracy: 5810/10000 (58%)\n",
            "\n",
            "Train Epoch: 13 [50000/50000 (100%)]\tLoss: 0.000611\n",
            "\n",
            "Validation set: Average loss: 3.4699, Accuracy: 5887/10000 (59%)\n",
            "\n",
            "Train Epoch: 14 [50000/50000 (100%)]\tLoss: 0.000150\n",
            "\n",
            "Validation set: Average loss: 3.5127, Accuracy: 5903/10000 (59%)\n",
            "\n",
            "Train Epoch: 15 [50000/50000 (100%)]\tLoss: 0.000073\n",
            "\n",
            "Validation set: Average loss: 3.5629, Accuracy: 5912/10000 (59%)\n",
            "\n",
            "Train Epoch: 16 [50000/50000 (100%)]\tLoss: 0.000058\n",
            "\n",
            "Validation set: Average loss: 3.6025, Accuracy: 5925/10000 (59%)\n",
            "\n",
            "Train Epoch: 17 [50000/50000 (100%)]\tLoss: 0.000049\n",
            "\n",
            "Validation set: Average loss: 3.6369, Accuracy: 5924/10000 (59%)\n",
            "\n",
            "Train Epoch: 18 [50000/50000 (100%)]\tLoss: 0.000043\n",
            "\n",
            "Validation set: Average loss: 3.6666, Accuracy: 5925/10000 (59%)\n",
            "\n",
            "Train Epoch: 19 [50000/50000 (100%)]\tLoss: 0.000038\n",
            "\n",
            "Validation set: Average loss: 3.6941, Accuracy: 5921/10000 (59%)\n",
            "\n",
            "Train Epoch: 20 [50000/50000 (100%)]\tLoss: 0.000034\n",
            "\n",
            "Validation set: Average loss: 3.7187, Accuracy: 5915/10000 (59%)\n",
            "\n",
            "Train Epoch: 21 [50000/50000 (100%)]\tLoss: 0.000031\n",
            "\n",
            "Validation set: Average loss: 3.7411, Accuracy: 5919/10000 (59%)\n",
            "\n",
            "Train Epoch: 22 [50000/50000 (100%)]\tLoss: 0.000029\n",
            "\n",
            "Validation set: Average loss: 3.7617, Accuracy: 5916/10000 (59%)\n",
            "\n",
            "Train Epoch: 23 [50000/50000 (100%)]\tLoss: 0.000026\n",
            "\n",
            "Validation set: Average loss: 3.7816, Accuracy: 5918/10000 (59%)\n",
            "\n",
            "Train Epoch: 24 [50000/50000 (100%)]\tLoss: 0.000024\n",
            "\n",
            "Validation set: Average loss: 3.7995, Accuracy: 5915/10000 (59%)\n",
            "\n",
            "Train Epoch: 25 [50000/50000 (100%)]\tLoss: 0.000023\n",
            "\n",
            "Validation set: Average loss: 3.8169, Accuracy: 5913/10000 (59%)\n",
            "\n",
            "Train Epoch: 26 [50000/50000 (100%)]\tLoss: 0.000021\n",
            "\n",
            "Validation set: Average loss: 3.8331, Accuracy: 5913/10000 (59%)\n",
            "\n",
            "Train Epoch: 27 [50000/50000 (100%)]\tLoss: 0.000020\n",
            "\n",
            "Validation set: Average loss: 3.8482, Accuracy: 5917/10000 (59%)\n",
            "\n",
            "Train Epoch: 28 [50000/50000 (100%)]\tLoss: 0.000019\n",
            "\n",
            "Validation set: Average loss: 3.8630, Accuracy: 5923/10000 (59%)\n",
            "\n",
            "Train Epoch: 29 [50000/50000 (100%)]\tLoss: 0.000018\n",
            "\n",
            "Validation set: Average loss: 3.8769, Accuracy: 5922/10000 (59%)\n",
            "\n",
            "Train Epoch: 30 [50000/50000 (100%)]\tLoss: 0.000017\n",
            "\n",
            "Validation set: Average loss: 3.8900, Accuracy: 5922/10000 (59%)\n",
            "\n",
            "Train Epoch: 31 [50000/50000 (100%)]\tLoss: 0.000016\n",
            "\n",
            "Validation set: Average loss: 3.9030, Accuracy: 5921/10000 (59%)\n",
            "\n",
            "Train Epoch: 32 [50000/50000 (100%)]\tLoss: 0.000016\n",
            "\n",
            "Validation set: Average loss: 3.9151, Accuracy: 5923/10000 (59%)\n",
            "\n",
            "Train Epoch: 33 [50000/50000 (100%)]\tLoss: 0.000015\n",
            "\n",
            "Validation set: Average loss: 3.9271, Accuracy: 5920/10000 (59%)\n",
            "\n",
            "Train Epoch: 34 [50000/50000 (100%)]\tLoss: 0.000014\n",
            "\n",
            "Validation set: Average loss: 3.9384, Accuracy: 5919/10000 (59%)\n",
            "\n",
            "Train Epoch: 35 [50000/50000 (100%)]\tLoss: 0.000014\n",
            "\n",
            "Validation set: Average loss: 3.9493, Accuracy: 5919/10000 (59%)\n",
            "\n",
            "Train Epoch: 36 [50000/50000 (100%)]\tLoss: 0.000013\n",
            "\n",
            "Validation set: Average loss: 3.9597, Accuracy: 5917/10000 (59%)\n",
            "\n",
            "Train Epoch: 37 [50000/50000 (100%)]\tLoss: 0.000013\n",
            "\n",
            "Validation set: Average loss: 3.9699, Accuracy: 5919/10000 (59%)\n",
            "\n",
            "Train Epoch: 38 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 3.9799, Accuracy: 5921/10000 (59%)\n",
            "\n",
            "Train Epoch: 39 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 3.9895, Accuracy: 5923/10000 (59%)\n",
            "\n",
            "Train Epoch: 40 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 3.9987, Accuracy: 5924/10000 (59%)\n",
            "\n",
            "Train Epoch: 41 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 4.0078, Accuracy: 5923/10000 (59%)\n",
            "\n",
            "Train Epoch: 42 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 4.0165, Accuracy: 5923/10000 (59%)\n",
            "\n",
            "Train Epoch: 43 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 4.0251, Accuracy: 5924/10000 (59%)\n",
            "\n",
            "Train Epoch: 44 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 4.0334, Accuracy: 5923/10000 (59%)\n",
            "\n",
            "Train Epoch: 45 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 4.0415, Accuracy: 5924/10000 (59%)\n",
            "\n",
            "Train Epoch: 46 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 4.0494, Accuracy: 5927/10000 (59%)\n",
            "\n",
            "Train Epoch: 47 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.0571, Accuracy: 5925/10000 (59%)\n",
            "\n",
            "Train Epoch: 48 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.0646, Accuracy: 5925/10000 (59%)\n",
            "\n",
            "Train Epoch: 49 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.0720, Accuracy: 5925/10000 (59%)\n",
            "\n",
            "Train Epoch: 50 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.0791, Accuracy: 5926/10000 (59%)\n",
            "\n",
            "Train Epoch: 51 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.0861, Accuracy: 5926/10000 (59%)\n",
            "\n",
            "Train Epoch: 52 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.0930, Accuracy: 5927/10000 (59%)\n",
            "\n",
            "Train Epoch: 53 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.0997, Accuracy: 5928/10000 (59%)\n",
            "\n",
            "Train Epoch: 54 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.1063, Accuracy: 5928/10000 (59%)\n",
            "\n",
            "Train Epoch: 55 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.1127, Accuracy: 5928/10000 (59%)\n",
            "\n",
            "Train Epoch: 56 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.1190, Accuracy: 5929/10000 (59%)\n",
            "\n",
            "Train Epoch: 57 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.1252, Accuracy: 5929/10000 (59%)\n",
            "\n",
            "Train Epoch: 58 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.1313, Accuracy: 5930/10000 (59%)\n",
            "\n",
            "Train Epoch: 59 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.1372, Accuracy: 5931/10000 (59%)\n",
            "\n",
            "Train Epoch: 60 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.1431, Accuracy: 5930/10000 (59%)\n",
            "\n",
            "Train Epoch: 61 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.1489, Accuracy: 5932/10000 (59%)\n",
            "\n",
            "Train Epoch: 62 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.1544, Accuracy: 5933/10000 (59%)\n",
            "\n",
            "Train Epoch: 63 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.1600, Accuracy: 5933/10000 (59%)\n",
            "\n",
            "Train Epoch: 64 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.1654, Accuracy: 5932/10000 (59%)\n",
            "\n",
            "Train Epoch: 65 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.1708, Accuracy: 5932/10000 (59%)\n",
            "\n",
            "Train Epoch: 66 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.1761, Accuracy: 5932/10000 (59%)\n",
            "\n",
            "Train Epoch: 67 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.1812, Accuracy: 5932/10000 (59%)\n",
            "\n",
            "Train Epoch: 68 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.1863, Accuracy: 5932/10000 (59%)\n",
            "\n",
            "Train Epoch: 69 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.1913, Accuracy: 5932/10000 (59%)\n",
            "\n",
            "Train Epoch: 70 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.1963, Accuracy: 5932/10000 (59%)\n",
            "\n",
            "Train Epoch: 71 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.2011, Accuracy: 5931/10000 (59%)\n",
            "\n",
            "Train Epoch: 72 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.2059, Accuracy: 5931/10000 (59%)\n",
            "\n",
            "Train Epoch: 73 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.2106, Accuracy: 5931/10000 (59%)\n",
            "\n",
            "Train Epoch: 74 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.2152, Accuracy: 5931/10000 (59%)\n",
            "\n",
            "Train Epoch: 75 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.2198, Accuracy: 5932/10000 (59%)\n",
            "\n",
            "Train Epoch: 76 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.2243, Accuracy: 5931/10000 (59%)\n",
            "\n",
            "Train Epoch: 77 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.2288, Accuracy: 5932/10000 (59%)\n",
            "\n",
            "Train Epoch: 78 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.2332, Accuracy: 5932/10000 (59%)\n",
            "\n",
            "Train Epoch: 79 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.2375, Accuracy: 5931/10000 (59%)\n",
            "\n",
            "Train Epoch: 80 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.2418, Accuracy: 5932/10000 (59%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FRNPF(DI)"
      ],
      "metadata": {
        "id": "6eKjcgdUMgCA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "frnpf_di_linear_model = Conv4GaluLinear(args['image_size'], args['channels'])\n",
        "frnpf_di_linear_model.to(device)\n",
        "frnpf_di_linear_model"
      ],
      "metadata": {
        "id": "fnwVpT6_MgCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d03de7fc-da47-4c43-8de1-e017ebeebc45"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv4GaluLinear(\n",
              "  (NPF_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPF_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPF_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (NPV_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPV_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPV_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (outputs): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in frnpf_di_linear_model.named_parameters():\n",
        "  print(name, param)"
      ],
      "metadata": {
        "id": "5mMghcoIMgCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "03ec6bbd-04e4-4573-812c-89eb54066a65"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NPF_C1.weight Parameter containing:\n",
            "tensor([[[[-0.1553,  0.1612, -0.1423],\n",
            "          [ 0.0805,  0.0772, -0.1055],\n",
            "          [-0.1493,  0.1051,  0.1707]],\n",
            "\n",
            "         [[ 0.0159,  0.1586,  0.1776],\n",
            "          [ 0.0674, -0.0341, -0.1590],\n",
            "          [-0.1821,  0.0621,  0.0075]],\n",
            "\n",
            "         [[-0.1605,  0.0590,  0.0632],\n",
            "          [ 0.1709,  0.0633, -0.1144],\n",
            "          [-0.0854, -0.1694,  0.1524]]],\n",
            "\n",
            "\n",
            "        [[[-0.1911,  0.1477,  0.0673],\n",
            "          [ 0.0684, -0.0258, -0.0104],\n",
            "          [ 0.0230,  0.0514,  0.0629]],\n",
            "\n",
            "         [[ 0.0406,  0.1005,  0.0801],\n",
            "          [ 0.0922, -0.0430,  0.1127],\n",
            "          [ 0.0451, -0.1351,  0.1666]],\n",
            "\n",
            "         [[-0.0677, -0.0340, -0.1864],\n",
            "          [ 0.0263,  0.0345, -0.1246],\n",
            "          [ 0.0673, -0.0600, -0.1315]]],\n",
            "\n",
            "\n",
            "        [[[-0.1219,  0.1154, -0.0051],\n",
            "          [-0.0432, -0.0742, -0.1570],\n",
            "          [ 0.0801, -0.1165, -0.1498]],\n",
            "\n",
            "         [[-0.1570, -0.0557, -0.0677],\n",
            "          [ 0.0273, -0.1159, -0.0053],\n",
            "          [-0.0819,  0.1226, -0.0700]],\n",
            "\n",
            "         [[-0.1847, -0.1241, -0.0487],\n",
            "          [-0.0782, -0.0610,  0.1621],\n",
            "          [-0.0858, -0.1311, -0.0140]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0814, -0.1020,  0.0068],\n",
            "          [ 0.1063, -0.0028, -0.1040],\n",
            "          [ 0.1753,  0.1051, -0.1724]],\n",
            "\n",
            "         [[-0.1149, -0.1496,  0.0765],\n",
            "          [ 0.1716, -0.0972,  0.0522],\n",
            "          [ 0.0061,  0.1696, -0.0292]],\n",
            "\n",
            "         [[ 0.1844, -0.1908, -0.0828],\n",
            "          [-0.1648, -0.0213,  0.1090],\n",
            "          [ 0.1819, -0.0112, -0.1252]]],\n",
            "\n",
            "\n",
            "        [[[ 0.1114,  0.1102, -0.0041],\n",
            "          [-0.0739,  0.1055, -0.1062],\n",
            "          [-0.0812,  0.0996,  0.0300]],\n",
            "\n",
            "         [[-0.0045,  0.0129,  0.1254],\n",
            "          [-0.0291,  0.0627,  0.1055],\n",
            "          [ 0.1323, -0.0209,  0.0774]],\n",
            "\n",
            "         [[ 0.0277,  0.1595,  0.1381],\n",
            "          [-0.1019,  0.1715, -0.0057],\n",
            "          [-0.1898, -0.0068,  0.1845]]],\n",
            "\n",
            "\n",
            "        [[[-0.0693,  0.0138, -0.1189],\n",
            "          [-0.1185, -0.0087, -0.0572],\n",
            "          [-0.0825,  0.0892, -0.1097]],\n",
            "\n",
            "         [[ 0.0236,  0.0198,  0.0408],\n",
            "          [-0.1219, -0.0656, -0.1769],\n",
            "          [ 0.1209,  0.1422, -0.0354]],\n",
            "\n",
            "         [[ 0.1736,  0.0553, -0.0148],\n",
            "          [-0.1443, -0.0396,  0.1127],\n",
            "          [ 0.0769, -0.1812, -0.1040]]]], device='cuda:0', requires_grad=True)\n",
            "NPF_C1.bias Parameter containing:\n",
            "tensor([-0.0219, -0.1407, -0.0594, -0.0655,  0.0897, -0.1422,  0.1825, -0.1827,\n",
            "        -0.0969, -0.0057, -0.0223,  0.1364, -0.0485, -0.0428, -0.0666, -0.0739,\n",
            "         0.0617, -0.1062, -0.1751, -0.0568, -0.0226,  0.1704,  0.1581, -0.0136,\n",
            "        -0.1243, -0.0569,  0.0401,  0.1064,  0.0465,  0.1911,  0.0932,  0.0756,\n",
            "         0.1620, -0.0665,  0.0549, -0.1859,  0.0074,  0.1028,  0.0672, -0.1773,\n",
            "        -0.1736,  0.0975,  0.0411, -0.0786,  0.1734,  0.0040,  0.1562, -0.1295,\n",
            "         0.0975, -0.0985, -0.0170, -0.0206,  0.0289, -0.1090,  0.0643, -0.1419,\n",
            "        -0.1054, -0.1210, -0.1254, -0.0234,  0.1256,  0.1162,  0.0077, -0.1083],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPF_C2.weight Parameter containing:\n",
            "tensor([[[[ 1.2305e-02, -1.8484e-02,  6.0620e-03],\n",
            "          [-1.9330e-02,  1.4263e-02,  4.2871e-03],\n",
            "          [ 1.4917e-02,  8.6954e-03,  9.9590e-03]],\n",
            "\n",
            "         [[ 1.5752e-02, -3.3447e-04, -2.6354e-02],\n",
            "          [-3.6045e-03,  1.6882e-02,  3.9498e-02],\n",
            "          [ 2.4544e-02,  1.5408e-02, -7.7768e-03]],\n",
            "\n",
            "         [[ 6.4671e-03, -1.4074e-02, -3.2348e-02],\n",
            "          [-5.0398e-03,  9.8709e-03,  5.2480e-03],\n",
            "          [ 1.9405e-03, -3.6701e-02, -2.8968e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-5.8528e-03, -2.7741e-02, -3.9343e-02],\n",
            "          [ 2.3601e-02,  5.2699e-03, -1.9871e-02],\n",
            "          [-2.2160e-02,  3.7622e-02, -2.8877e-02]],\n",
            "\n",
            "         [[-1.4664e-02,  3.9527e-02, -4.6737e-03],\n",
            "          [ 1.2914e-02,  3.5021e-03, -3.5061e-02],\n",
            "          [ 1.5605e-02, -1.4224e-02, -3.6976e-02]],\n",
            "\n",
            "         [[-9.5450e-03,  3.0968e-02,  2.6091e-02],\n",
            "          [-2.7208e-03,  2.6689e-02,  3.5324e-02],\n",
            "          [-1.5422e-02, -1.0733e-02, -3.2709e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.3383e-02,  1.7837e-02, -2.3235e-02],\n",
            "          [ 3.1452e-02, -2.6931e-02, -3.1706e-02],\n",
            "          [-1.4817e-02, -3.5147e-02,  2.0563e-02]],\n",
            "\n",
            "         [[ 1.7262e-02,  6.6460e-03, -4.1533e-02],\n",
            "          [ 3.8274e-02, -3.1169e-02,  2.5512e-02],\n",
            "          [-4.0262e-02, -2.6912e-02, -1.7949e-02]],\n",
            "\n",
            "         [[ 1.8438e-02,  2.9664e-02,  2.8244e-02],\n",
            "          [-3.0343e-02, -1.8352e-02,  1.8718e-02],\n",
            "          [-1.4564e-02, -1.6524e-02, -2.6952e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1190e-03,  4.1539e-02, -4.1650e-02],\n",
            "          [-3.0919e-03,  1.6209e-02, -1.4792e-02],\n",
            "          [-1.4447e-03,  1.6614e-02,  2.7836e-02]],\n",
            "\n",
            "         [[ 2.8085e-02,  3.2159e-02,  3.4767e-02],\n",
            "          [ 3.4781e-02,  1.6281e-02,  2.4756e-02],\n",
            "          [ 3.7851e-03, -3.8702e-02, -1.7648e-02]],\n",
            "\n",
            "         [[-1.9607e-02,  3.8434e-02,  3.4303e-02],\n",
            "          [ 6.8964e-03,  4.0077e-02,  7.5090e-03],\n",
            "          [ 2.3366e-02,  1.9497e-02, -3.4515e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3533e-04, -2.6212e-02, -2.9006e-02],\n",
            "          [ 1.7448e-02,  1.5547e-02,  2.8247e-02],\n",
            "          [ 7.5453e-03, -3.4134e-02,  1.1381e-02]],\n",
            "\n",
            "         [[-3.8205e-02, -1.6496e-02,  3.4997e-02],\n",
            "          [-7.0620e-03, -3.4518e-02,  8.6728e-03],\n",
            "          [-3.9605e-02,  8.9077e-04,  2.8176e-02]],\n",
            "\n",
            "         [[ 3.4631e-02, -1.0893e-02, -2.4179e-02],\n",
            "          [-1.0118e-02, -2.6780e-02,  2.4653e-02],\n",
            "          [ 1.5561e-02, -8.5767e-03,  2.2157e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4135e-02,  2.8601e-02,  2.3125e-02],\n",
            "          [ 2.3883e-02, -1.6575e-02, -3.7214e-02],\n",
            "          [-3.1343e-02, -3.7732e-02,  1.9654e-02]],\n",
            "\n",
            "         [[ 2.2427e-02,  1.1492e-02,  2.3232e-02],\n",
            "          [-2.5344e-02,  1.4336e-03,  8.8360e-03],\n",
            "          [-2.5704e-02, -3.5029e-02,  3.2764e-02]],\n",
            "\n",
            "         [[-2.3453e-02,  1.0047e-02,  1.2956e-02],\n",
            "          [-5.1163e-03, -2.3016e-02, -2.4578e-03],\n",
            "          [-3.3165e-02, -1.7536e-02, -3.3362e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 1.3156e-02,  5.0893e-03,  1.0971e-02],\n",
            "          [-1.1820e-02, -1.9637e-02, -3.6022e-02],\n",
            "          [-3.5375e-03, -2.7173e-02,  1.7520e-02]],\n",
            "\n",
            "         [[ 6.5058e-05, -7.5558e-03, -1.6839e-02],\n",
            "          [ 1.6371e-02, -1.9443e-02, -4.7751e-03],\n",
            "          [-9.4424e-03, -3.6267e-02, -1.4610e-02]],\n",
            "\n",
            "         [[-3.6849e-02, -6.3213e-04, -1.8234e-02],\n",
            "          [-6.6026e-03, -1.8581e-02, -2.7105e-02],\n",
            "          [ 2.0377e-02, -3.9098e-03,  2.9061e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.0218e-02, -3.8799e-02, -3.8387e-02],\n",
            "          [ 5.3293e-03,  3.4468e-02,  3.9758e-02],\n",
            "          [ 2.8261e-02, -2.0630e-02, -3.8964e-02]],\n",
            "\n",
            "         [[ 6.7398e-03, -1.3412e-02,  8.0092e-03],\n",
            "          [-3.2507e-02, -1.9130e-03,  8.8997e-03],\n",
            "          [ 3.1855e-02, -3.3039e-02,  7.8153e-03]],\n",
            "\n",
            "         [[-1.8967e-02,  1.9361e-02,  3.9852e-02],\n",
            "          [ 3.7042e-02, -1.8348e-02, -1.8116e-02],\n",
            "          [ 9.7539e-03, -3.1921e-02, -3.0874e-02]]],\n",
            "\n",
            "\n",
            "        [[[-3.9957e-03,  6.3324e-04, -1.3234e-02],\n",
            "          [ 2.2945e-02, -4.1719e-03, -1.4061e-02],\n",
            "          [-1.8196e-02,  3.7988e-02,  4.0411e-02]],\n",
            "\n",
            "         [[ 2.1286e-02, -5.5744e-03,  3.4041e-02],\n",
            "          [ 9.2165e-03,  4.5629e-03,  6.2468e-03],\n",
            "          [ 3.7172e-03,  7.6249e-03, -1.4063e-03]],\n",
            "\n",
            "         [[-2.4284e-02, -1.1026e-02,  3.9336e-02],\n",
            "          [ 2.4965e-02, -2.2451e-02, -2.5300e-02],\n",
            "          [ 1.4462e-02,  7.0924e-03, -1.6611e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.4266e-02, -1.4815e-02,  2.1905e-02],\n",
            "          [-2.4200e-02, -3.5973e-02,  1.1224e-02],\n",
            "          [-2.5142e-03,  1.4364e-02,  1.6890e-02]],\n",
            "\n",
            "         [[-1.6382e-03, -2.4064e-03,  3.6102e-02],\n",
            "          [ 2.9133e-03, -2.5540e-02,  1.2139e-04],\n",
            "          [-3.0437e-02, -4.3079e-03, -3.9889e-02]],\n",
            "\n",
            "         [[-1.9388e-02,  1.0284e-02, -3.5444e-02],\n",
            "          [ 2.1515e-02, -3.4313e-02,  2.4795e-02],\n",
            "          [-3.3741e-02,  3.5271e-02,  3.7138e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.0180e-02, -2.9768e-02,  3.9434e-02],\n",
            "          [ 1.8207e-02,  3.1460e-02, -2.8387e-02],\n",
            "          [-1.5291e-03,  1.2847e-02,  2.2772e-02]],\n",
            "\n",
            "         [[ 7.6986e-03, -2.2431e-02, -2.3440e-02],\n",
            "          [ 1.2905e-02, -2.1307e-02,  3.8175e-02],\n",
            "          [ 5.2903e-03,  4.1345e-02,  1.5086e-02]],\n",
            "\n",
            "         [[-2.0217e-02, -9.2522e-03, -3.0857e-02],\n",
            "          [-2.3034e-02, -3.2521e-02,  4.1401e-02],\n",
            "          [ 2.9982e-02, -2.3246e-02, -2.6368e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.0867e-02,  3.7456e-02, -1.1482e-02],\n",
            "          [ 1.0581e-02, -3.8190e-02,  5.1203e-03],\n",
            "          [-1.2664e-02,  1.9929e-02,  2.5227e-02]],\n",
            "\n",
            "         [[ 3.3755e-02,  1.2452e-02,  1.7324e-02],\n",
            "          [ 9.8066e-03, -3.1455e-02,  3.3650e-02],\n",
            "          [-4.0432e-02,  3.3824e-02, -5.5691e-03]],\n",
            "\n",
            "         [[ 1.4541e-03,  1.2459e-02,  4.5509e-04],\n",
            "          [ 1.5166e-02,  3.1444e-02, -3.6638e-02],\n",
            "          [-1.2176e-02,  4.0745e-02,  1.5112e-02]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPF_C2.bias Parameter containing:\n",
            "tensor([ 0.0077,  0.0314,  0.0133,  0.0371,  0.0339, -0.0301,  0.0319, -0.0175,\n",
            "         0.0382, -0.0227, -0.0093,  0.0185, -0.0299,  0.0388,  0.0019, -0.0170,\n",
            "         0.0321,  0.0262,  0.0007,  0.0267, -0.0128,  0.0303, -0.0231,  0.0076,\n",
            "         0.0148, -0.0409, -0.0041,  0.0346,  0.0406,  0.0109, -0.0255, -0.0043,\n",
            "         0.0220, -0.0111,  0.0030,  0.0013, -0.0143,  0.0184, -0.0118,  0.0381,\n",
            "         0.0211, -0.0184, -0.0326, -0.0253, -0.0254,  0.0086, -0.0065,  0.0360,\n",
            "         0.0010, -0.0318, -0.0270,  0.0224, -0.0291, -0.0157, -0.0294, -0.0299,\n",
            "        -0.0053,  0.0013,  0.0363, -0.0243, -0.0297, -0.0225, -0.0194, -0.0356],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPF_C3.weight Parameter containing:\n",
            "tensor([[[[-0.0142,  0.0192,  0.0120],\n",
            "          [-0.0164, -0.0397, -0.0268],\n",
            "          [-0.0061, -0.0091,  0.0247]],\n",
            "\n",
            "         [[-0.0374, -0.0218,  0.0201],\n",
            "          [ 0.0094, -0.0325,  0.0133],\n",
            "          [ 0.0413,  0.0230,  0.0219]],\n",
            "\n",
            "         [[ 0.0399, -0.0176,  0.0413],\n",
            "          [ 0.0230,  0.0044,  0.0218],\n",
            "          [-0.0098, -0.0268, -0.0101]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0219, -0.0341, -0.0172],\n",
            "          [-0.0247, -0.0206,  0.0250],\n",
            "          [-0.0100, -0.0401, -0.0242]],\n",
            "\n",
            "         [[-0.0039,  0.0080, -0.0045],\n",
            "          [ 0.0208,  0.0285,  0.0169],\n",
            "          [-0.0018,  0.0279, -0.0103]],\n",
            "\n",
            "         [[-0.0027, -0.0084,  0.0120],\n",
            "          [ 0.0188, -0.0218, -0.0087],\n",
            "          [ 0.0075, -0.0343,  0.0300]]],\n",
            "\n",
            "\n",
            "        [[[-0.0378,  0.0181, -0.0273],\n",
            "          [ 0.0113,  0.0153,  0.0258],\n",
            "          [ 0.0322,  0.0237, -0.0155]],\n",
            "\n",
            "         [[ 0.0217, -0.0303, -0.0154],\n",
            "          [-0.0392,  0.0092,  0.0018],\n",
            "          [ 0.0214, -0.0384,  0.0312]],\n",
            "\n",
            "         [[ 0.0405,  0.0356, -0.0297],\n",
            "          [ 0.0201, -0.0282,  0.0162],\n",
            "          [-0.0386, -0.0280, -0.0394]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0019,  0.0079, -0.0073],\n",
            "          [ 0.0239, -0.0307, -0.0114],\n",
            "          [-0.0380,  0.0402, -0.0129]],\n",
            "\n",
            "         [[-0.0202,  0.0323, -0.0277],\n",
            "          [-0.0297, -0.0166,  0.0340],\n",
            "          [ 0.0402,  0.0373,  0.0299]],\n",
            "\n",
            "         [[ 0.0375,  0.0197, -0.0081],\n",
            "          [ 0.0279, -0.0128, -0.0392],\n",
            "          [ 0.0007, -0.0296, -0.0177]]],\n",
            "\n",
            "\n",
            "        [[[-0.0297, -0.0173,  0.0345],\n",
            "          [ 0.0229, -0.0182,  0.0033],\n",
            "          [-0.0367,  0.0044, -0.0286]],\n",
            "\n",
            "         [[-0.0250,  0.0199,  0.0350],\n",
            "          [ 0.0232,  0.0063,  0.0313],\n",
            "          [ 0.0237,  0.0184,  0.0150]],\n",
            "\n",
            "         [[ 0.0040,  0.0130, -0.0280],\n",
            "          [-0.0365,  0.0317,  0.0390],\n",
            "          [-0.0239, -0.0203, -0.0080]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0210, -0.0146, -0.0320],\n",
            "          [ 0.0404,  0.0302, -0.0252],\n",
            "          [ 0.0224,  0.0230, -0.0305]],\n",
            "\n",
            "         [[ 0.0373,  0.0312,  0.0040],\n",
            "          [ 0.0354, -0.0035,  0.0005],\n",
            "          [ 0.0408, -0.0040, -0.0015]],\n",
            "\n",
            "         [[-0.0218, -0.0330,  0.0003],\n",
            "          [ 0.0052,  0.0241, -0.0182],\n",
            "          [ 0.0406,  0.0178, -0.0326]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0232,  0.0401, -0.0173],\n",
            "          [ 0.0091, -0.0121, -0.0059],\n",
            "          [-0.0283, -0.0055,  0.0017]],\n",
            "\n",
            "         [[ 0.0140,  0.0299,  0.0109],\n",
            "          [ 0.0298,  0.0018,  0.0377],\n",
            "          [-0.0411, -0.0293,  0.0222]],\n",
            "\n",
            "         [[ 0.0327, -0.0308, -0.0055],\n",
            "          [ 0.0014, -0.0048,  0.0048],\n",
            "          [-0.0298,  0.0173,  0.0367]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0124, -0.0276, -0.0132],\n",
            "          [-0.0133,  0.0040,  0.0216],\n",
            "          [ 0.0410, -0.0304, -0.0098]],\n",
            "\n",
            "         [[-0.0183, -0.0222,  0.0011],\n",
            "          [-0.0240, -0.0307, -0.0104],\n",
            "          [-0.0348,  0.0120, -0.0055]],\n",
            "\n",
            "         [[-0.0138,  0.0185,  0.0314],\n",
            "          [-0.0207, -0.0338,  0.0140],\n",
            "          [-0.0277, -0.0117,  0.0383]]],\n",
            "\n",
            "\n",
            "        [[[-0.0296, -0.0097, -0.0170],\n",
            "          [ 0.0382,  0.0223, -0.0321],\n",
            "          [ 0.0278, -0.0016, -0.0135]],\n",
            "\n",
            "         [[ 0.0403,  0.0290, -0.0225],\n",
            "          [-0.0384, -0.0064,  0.0075],\n",
            "          [-0.0319,  0.0080,  0.0274]],\n",
            "\n",
            "         [[-0.0011,  0.0207,  0.0051],\n",
            "          [-0.0288,  0.0095,  0.0120],\n",
            "          [ 0.0035, -0.0308,  0.0253]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0195, -0.0066, -0.0091],\n",
            "          [ 0.0116, -0.0295, -0.0027],\n",
            "          [-0.0187,  0.0404,  0.0326]],\n",
            "\n",
            "         [[-0.0406,  0.0227,  0.0193],\n",
            "          [ 0.0368,  0.0287, -0.0055],\n",
            "          [ 0.0008, -0.0318,  0.0081]],\n",
            "\n",
            "         [[ 0.0284,  0.0068, -0.0377],\n",
            "          [-0.0280, -0.0119, -0.0384],\n",
            "          [ 0.0025,  0.0311, -0.0031]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0300,  0.0373, -0.0031],\n",
            "          [ 0.0349,  0.0060,  0.0366],\n",
            "          [-0.0031, -0.0035,  0.0152]],\n",
            "\n",
            "         [[-0.0356,  0.0164, -0.0394],\n",
            "          [ 0.0317, -0.0186,  0.0329],\n",
            "          [-0.0226,  0.0178,  0.0410]],\n",
            "\n",
            "         [[-0.0244,  0.0293, -0.0012],\n",
            "          [ 0.0416, -0.0016,  0.0372],\n",
            "          [ 0.0294,  0.0321, -0.0110]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0033,  0.0162, -0.0013],\n",
            "          [ 0.0211,  0.0377, -0.0141],\n",
            "          [-0.0296, -0.0390, -0.0029]],\n",
            "\n",
            "         [[ 0.0217,  0.0337, -0.0002],\n",
            "          [ 0.0038, -0.0084, -0.0146],\n",
            "          [-0.0334, -0.0385,  0.0109]],\n",
            "\n",
            "         [[-0.0232, -0.0305, -0.0244],\n",
            "          [-0.0192,  0.0344,  0.0406],\n",
            "          [ 0.0200,  0.0207,  0.0223]]]], device='cuda:0', requires_grad=True)\n",
            "NPF_C3.bias Parameter containing:\n",
            "tensor([ 0.0060,  0.0416, -0.0320,  0.0072, -0.0264, -0.0052, -0.0055, -0.0054,\n",
            "        -0.0250,  0.0364,  0.0413, -0.0255,  0.0158,  0.0268,  0.0268,  0.0353,\n",
            "        -0.0381,  0.0394, -0.0227,  0.0003,  0.0196,  0.0053, -0.0409,  0.0237,\n",
            "        -0.0044, -0.0053, -0.0247, -0.0347,  0.0236,  0.0347,  0.0308,  0.0008,\n",
            "        -0.0080,  0.0034,  0.0372,  0.0100,  0.0307,  0.0062,  0.0137,  0.0073,\n",
            "        -0.0147, -0.0415, -0.0122, -0.0395,  0.0159, -0.0199,  0.0309, -0.0231,\n",
            "        -0.0147, -0.0373, -0.0159, -0.0065,  0.0003, -0.0227,  0.0056, -0.0233,\n",
            "         0.0045,  0.0415,  0.0408,  0.0177,  0.0354, -0.0269,  0.0094,  0.0348,\n",
            "         0.0019,  0.0250, -0.0318,  0.0095, -0.0224,  0.0197,  0.0102,  0.0098,\n",
            "        -0.0389, -0.0044, -0.0213, -0.0236,  0.0237, -0.0294, -0.0146,  0.0198,\n",
            "        -0.0097, -0.0374,  0.0263, -0.0052, -0.0082,  0.0369, -0.0176, -0.0017,\n",
            "        -0.0200,  0.0011,  0.0118, -0.0221,  0.0261,  0.0145, -0.0027,  0.0075,\n",
            "        -0.0076,  0.0251,  0.0309, -0.0173, -0.0281,  0.0020, -0.0028, -0.0372,\n",
            "         0.0212,  0.0040,  0.0006,  0.0037,  0.0060, -0.0196, -0.0407,  0.0294,\n",
            "         0.0238, -0.0337,  0.0081, -0.0255,  0.0146,  0.0382, -0.0122, -0.0272,\n",
            "        -0.0166, -0.0278, -0.0228, -0.0139, -0.0152, -0.0142,  0.0275, -0.0415],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPF_C4.weight Parameter containing:\n",
            "tensor([[[[-1.4857e-02,  2.4520e-02,  2.4433e-02],\n",
            "          [ 2.0339e-02, -2.0304e-02,  5.5902e-03],\n",
            "          [-2.0558e-02, -3.7597e-03, -4.3953e-03]],\n",
            "\n",
            "         [[ 2.2646e-03,  7.3488e-03,  5.7592e-03],\n",
            "          [ 2.4069e-02, -2.8779e-02, -1.1660e-02],\n",
            "          [ 2.2449e-02, -1.8597e-02, -2.1889e-02]],\n",
            "\n",
            "         [[ 1.0678e-02, -1.3002e-02, -6.3213e-04],\n",
            "          [-1.2563e-02, -2.3752e-02,  2.9031e-02],\n",
            "          [-2.1809e-02,  1.6390e-02, -3.9433e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.8033e-02,  1.0195e-02, -1.7444e-02],\n",
            "          [ 2.8136e-03,  1.0827e-02,  1.8822e-02],\n",
            "          [-2.7937e-02, -2.0059e-03, -9.8946e-03]],\n",
            "\n",
            "         [[ 1.9960e-02,  1.7548e-02,  2.0725e-02],\n",
            "          [-2.6106e-02, -1.0912e-02, -4.7884e-03],\n",
            "          [ 3.5497e-03,  2.6828e-02, -6.1478e-03]],\n",
            "\n",
            "         [[ 6.1134e-03,  1.9914e-02, -2.1106e-03],\n",
            "          [-2.4447e-02,  1.5880e-03,  8.3412e-03],\n",
            "          [ 2.2270e-02, -1.8700e-02, -1.7628e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.3021e-02, -2.8817e-02, -2.4381e-02],\n",
            "          [-4.0420e-03,  1.7213e-02, -2.8558e-02],\n",
            "          [ 1.9117e-03,  3.9683e-03,  2.7176e-03]],\n",
            "\n",
            "         [[ 1.6278e-02, -2.0385e-02,  1.8411e-02],\n",
            "          [ 1.2812e-03,  1.0329e-02,  2.0110e-02],\n",
            "          [ 1.6357e-02, -2.7640e-02,  2.8958e-02]],\n",
            "\n",
            "         [[-4.4554e-03, -1.2015e-02,  1.8781e-02],\n",
            "          [ 6.0240e-03, -3.5127e-03,  1.6022e-02],\n",
            "          [-1.6486e-02, -1.5387e-02, -2.2978e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4807e-02,  9.6127e-03, -2.5068e-02],\n",
            "          [-2.0915e-02, -3.9210e-03,  1.0551e-02],\n",
            "          [-2.6736e-02, -8.1259e-03,  2.7119e-02]],\n",
            "\n",
            "         [[-2.0525e-02, -1.8284e-02,  2.6823e-02],\n",
            "          [-2.0889e-02,  2.3450e-02, -1.1757e-04],\n",
            "          [ 2.5156e-02, -2.7732e-02, -1.4293e-02]],\n",
            "\n",
            "         [[ 2.7941e-02,  1.6992e-02, -1.1480e-02],\n",
            "          [-2.7068e-02, -2.4254e-02,  2.0973e-02],\n",
            "          [ 2.1019e-02,  1.3451e-02, -8.0990e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.5745e-02, -4.2226e-03,  2.3281e-02],\n",
            "          [-1.4885e-02, -1.4593e-02,  1.2478e-02],\n",
            "          [-1.6804e-02, -1.3915e-02, -2.3323e-02]],\n",
            "\n",
            "         [[-1.1459e-02,  1.1504e-02, -8.8727e-03],\n",
            "          [-7.9082e-03,  2.2720e-02,  8.2629e-03],\n",
            "          [-2.2002e-02, -1.0239e-03,  7.2142e-03]],\n",
            "\n",
            "         [[-2.3147e-02,  1.5489e-02,  1.5000e-03],\n",
            "          [ 1.7989e-02, -4.1156e-03,  1.1519e-02],\n",
            "          [ 5.5624e-03, -2.7963e-02, -2.9414e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6973e-02,  3.6069e-03,  1.4189e-02],\n",
            "          [-1.3959e-02, -2.2143e-02,  1.7658e-03],\n",
            "          [ 9.8456e-03, -2.8284e-03,  2.4282e-02]],\n",
            "\n",
            "         [[-2.3082e-02,  2.9278e-02,  2.7103e-02],\n",
            "          [ 9.0364e-03, -2.5105e-02,  2.6104e-02],\n",
            "          [-2.8511e-02, -2.3615e-02,  1.7259e-02]],\n",
            "\n",
            "         [[-6.3106e-03,  1.6599e-02, -2.2246e-02],\n",
            "          [ 2.1028e-02, -1.0879e-02,  1.5793e-02],\n",
            "          [ 1.5510e-02, -2.4076e-02,  2.6424e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-8.6554e-03,  2.3977e-02, -5.4359e-03],\n",
            "          [-2.0787e-02, -1.1849e-02,  1.6561e-02],\n",
            "          [ 1.0622e-02, -2.8419e-02, -1.5057e-02]],\n",
            "\n",
            "         [[ 2.9106e-02, -1.0605e-02,  4.8454e-03],\n",
            "          [ 1.8319e-02,  2.0094e-02, -2.3100e-02],\n",
            "          [-2.0760e-02,  3.5711e-03,  1.5273e-02]],\n",
            "\n",
            "         [[-2.5893e-02, -9.2014e-03, -2.4811e-02],\n",
            "          [ 5.2636e-03,  2.6277e-02, -2.0596e-03],\n",
            "          [ 6.1145e-03, -2.4962e-02, -1.6078e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.5643e-02,  5.1327e-03, -9.2258e-03],\n",
            "          [-4.1718e-03, -1.7103e-02,  1.5814e-02],\n",
            "          [ 2.2507e-02, -2.1283e-02,  9.2135e-03]],\n",
            "\n",
            "         [[ 1.8228e-02,  1.3243e-02,  2.2813e-02],\n",
            "          [ 9.1190e-03,  1.6508e-02,  2.9091e-02],\n",
            "          [-1.4374e-03,  1.5449e-02,  2.5624e-02]],\n",
            "\n",
            "         [[ 2.3977e-02,  1.7692e-02, -1.6368e-02],\n",
            "          [ 1.9420e-02,  5.9950e-03,  2.3949e-03],\n",
            "          [-1.5272e-02,  5.8407e-03,  8.7871e-03]]],\n",
            "\n",
            "\n",
            "        [[[-2.0662e-02,  2.8689e-02,  2.8136e-02],\n",
            "          [ 3.1348e-03,  1.2926e-02, -9.7316e-03],\n",
            "          [-5.0955e-03, -2.5375e-02,  5.2845e-03]],\n",
            "\n",
            "         [[ 1.1793e-03, -3.6164e-03, -1.9155e-02],\n",
            "          [-2.4038e-02, -8.4489e-04,  8.0631e-03],\n",
            "          [-2.2267e-02, -2.0408e-03, -1.6544e-02]],\n",
            "\n",
            "         [[-1.5105e-03, -2.3535e-02,  8.9263e-03],\n",
            "          [-7.2462e-03,  7.2455e-03, -1.3740e-02],\n",
            "          [-2.2400e-02, -2.8517e-02,  1.0034e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8538e-02,  2.5847e-02, -2.7307e-02],\n",
            "          [ 1.3581e-02,  1.0452e-02,  2.2676e-02],\n",
            "          [ 1.8231e-02, -1.7596e-02, -1.8019e-02]],\n",
            "\n",
            "         [[ 1.0351e-03, -3.4067e-03,  2.5231e-02],\n",
            "          [ 1.7977e-02,  1.8054e-02,  2.5055e-02],\n",
            "          [ 8.1348e-03, -2.8718e-02, -8.5852e-03]],\n",
            "\n",
            "         [[-2.7591e-02,  2.1129e-02, -8.5434e-03],\n",
            "          [ 2.9409e-02, -2.6492e-02,  1.0579e-02],\n",
            "          [ 5.0547e-03,  1.6174e-02,  2.3860e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 7.2086e-03, -2.5005e-02,  2.6995e-02],\n",
            "          [-2.1340e-02,  1.0572e-02, -2.0925e-02],\n",
            "          [-5.2923e-03, -7.2567e-03, -2.2113e-02]],\n",
            "\n",
            "         [[-2.6449e-02,  1.4799e-02, -8.9933e-03],\n",
            "          [ 3.4928e-04,  1.5968e-02,  7.4810e-03],\n",
            "          [-1.8699e-02, -1.1230e-02,  4.0624e-03]],\n",
            "\n",
            "         [[ 4.4591e-05, -1.2040e-02, -2.9138e-03],\n",
            "          [ 4.2463e-03,  1.9344e-04,  8.9756e-03],\n",
            "          [ 1.5393e-02,  2.0007e-02, -1.0160e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.5976e-02,  5.0964e-03,  2.3491e-02],\n",
            "          [-1.3357e-03,  2.3932e-02,  1.5497e-02],\n",
            "          [ 2.0496e-03, -2.6019e-02,  3.2779e-03]],\n",
            "\n",
            "         [[ 2.6274e-03,  1.5599e-02,  2.1335e-02],\n",
            "          [ 3.5230e-03,  2.3075e-02,  1.0936e-02],\n",
            "          [-4.0404e-03, -5.9199e-03, -1.1624e-02]],\n",
            "\n",
            "         [[-2.3583e-02, -6.4598e-03,  1.5139e-02],\n",
            "          [ 2.4809e-02,  1.1738e-02,  4.8690e-03],\n",
            "          [-2.7690e-02, -2.4341e-02, -1.4766e-02]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPF_C4.bias Parameter containing:\n",
            "tensor([ 0.0056, -0.0163,  0.0081,  0.0174, -0.0030,  0.0065,  0.0166,  0.0011,\n",
            "         0.0259,  0.0293, -0.0228,  0.0090, -0.0119, -0.0137,  0.0249, -0.0149,\n",
            "        -0.0159,  0.0137, -0.0018, -0.0221,  0.0059, -0.0104, -0.0116,  0.0087,\n",
            "         0.0176,  0.0192,  0.0090,  0.0196, -0.0075, -0.0098, -0.0153, -0.0198,\n",
            "         0.0247,  0.0261, -0.0099, -0.0058, -0.0278,  0.0146,  0.0164, -0.0223,\n",
            "         0.0075,  0.0244,  0.0051,  0.0045, -0.0219,  0.0083, -0.0101,  0.0217,\n",
            "        -0.0044,  0.0257, -0.0293, -0.0153, -0.0035, -0.0180,  0.0017, -0.0203,\n",
            "         0.0005,  0.0223, -0.0071, -0.0155, -0.0102, -0.0174, -0.0078,  0.0275,\n",
            "        -0.0289, -0.0183, -0.0051, -0.0096,  0.0221, -0.0155, -0.0035,  0.0126,\n",
            "        -0.0008, -0.0001,  0.0056, -0.0158, -0.0057, -0.0199, -0.0284, -0.0189,\n",
            "        -0.0229,  0.0008,  0.0151, -0.0255, -0.0034,  0.0107,  0.0268,  0.0100,\n",
            "         0.0021, -0.0150,  0.0291,  0.0074, -0.0191, -0.0037,  0.0005, -0.0035,\n",
            "         0.0150,  0.0246,  0.0230, -0.0226,  0.0115, -0.0204,  0.0164,  0.0090,\n",
            "         0.0023,  0.0150, -0.0193, -0.0149, -0.0120, -0.0258, -0.0253, -0.0149,\n",
            "        -0.0012,  0.0104, -0.0180, -0.0067,  0.0015, -0.0194, -0.0033,  0.0247,\n",
            "         0.0256, -0.0115,  0.0019,  0.0043, -0.0062,  0.0172, -0.0038,  0.0248],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPF_D1.weight Parameter containing:\n",
            "tensor([[ 3.8708e-04,  1.5397e-03, -1.2027e-03,  ..., -8.6393e-04,\n",
            "          2.2675e-03, -1.7601e-03],\n",
            "        [-1.0152e-03,  5.9313e-04,  3.0143e-04,  ..., -5.9247e-04,\n",
            "         -3.0390e-04, -1.7670e-03],\n",
            "        [-4.4040e-04,  2.7326e-04, -1.3259e-03,  ..., -1.1194e-03,\n",
            "         -2.2154e-04, -8.4609e-04],\n",
            "        ...,\n",
            "        [ 2.2057e-03,  9.4155e-04,  2.2917e-03,  ...,  7.1153e-04,\n",
            "         -9.9774e-05, -7.6073e-04],\n",
            "        [ 2.0186e-03, -4.3806e-04, -2.2648e-03,  ..., -5.3644e-04,\n",
            "         -2.6899e-03, -1.1430e-03],\n",
            "        [ 1.7090e-03, -2.4927e-03,  2.4598e-03,  ..., -1.3384e-03,\n",
            "         -1.1971e-03,  4.5468e-04]], device='cuda:0', requires_grad=True)\n",
            "NPF_D1.bias Parameter containing:\n",
            "tensor([ 3.1643e-04,  2.0468e-03,  2.5735e-03,  2.2211e-03,  2.3258e-03,\n",
            "         2.2911e-03, -2.4014e-04, -1.5339e-03,  3.0226e-04,  6.1852e-04,\n",
            "        -2.2724e-03,  1.6684e-03, -2.2896e-03, -2.4125e-03, -2.6172e-03,\n",
            "         1.0851e-04, -1.9079e-03, -9.0138e-04,  1.6079e-03, -2.6173e-03,\n",
            "        -9.4916e-04,  2.2558e-03,  7.8629e-04, -1.1329e-03, -1.8760e-03,\n",
            "        -1.4507e-03,  1.8093e-03, -5.0776e-04,  1.7656e-03, -9.2978e-04,\n",
            "         5.5181e-04, -2.5441e-03,  7.4579e-04,  2.4094e-04,  2.3998e-03,\n",
            "         1.9210e-04,  1.1311e-03,  1.5050e-03,  2.5572e-05, -1.5127e-03,\n",
            "        -1.4884e-04, -2.7042e-03, -1.0729e-03, -1.3482e-04,  1.8473e-03,\n",
            "         2.0022e-03,  8.3235e-04, -1.9340e-03, -4.1893e-04, -1.4977e-03,\n",
            "        -1.9475e-03,  3.8201e-04, -1.7063e-03, -2.1528e-03, -2.1773e-03,\n",
            "         1.5865e-03,  1.7924e-03,  2.6323e-03, -2.9659e-04, -5.5134e-04,\n",
            "         6.7518e-04,  1.0992e-03, -9.9484e-04,  2.1824e-03,  2.4431e-03,\n",
            "         2.8425e-04,  2.6688e-03,  2.5317e-03, -1.2840e-03,  1.9985e-03,\n",
            "        -9.4575e-04, -1.0719e-03, -2.0686e-04,  4.9381e-04, -2.6812e-03,\n",
            "        -9.0865e-04,  1.3890e-03, -4.1808e-04, -2.4926e-03, -1.6354e-03,\n",
            "         2.0638e-03, -2.2709e-03, -1.0597e-03,  2.1539e-03, -1.6401e-04,\n",
            "        -2.2499e-03, -7.1796e-05, -1.7628e-03,  2.3673e-03, -1.5187e-03,\n",
            "        -1.4697e-03,  4.3655e-04, -2.3204e-03, -1.2966e-03, -2.4501e-03,\n",
            "        -1.6106e-03, -3.2404e-05,  2.1368e-03, -8.7794e-04, -5.2068e-04,\n",
            "        -3.6337e-04,  1.7762e-03, -2.2811e-03, -1.5960e-03,  1.4921e-03,\n",
            "         3.5236e-04, -2.3052e-03, -1.7506e-03, -3.0530e-04, -1.1936e-03,\n",
            "         1.6554e-03, -7.5801e-04,  1.4655e-03,  3.7079e-04, -2.1107e-03,\n",
            "        -2.0344e-03, -2.3750e-04,  1.7417e-03, -8.2218e-04, -6.5050e-04,\n",
            "         1.7652e-03,  2.4050e-03, -4.8892e-04, -7.0995e-05,  2.6680e-03,\n",
            "        -1.3711e-03, -7.6254e-04, -1.9431e-03, -6.9262e-04,  2.5605e-03,\n",
            "         1.2950e-03, -5.4267e-04,  2.7590e-04, -2.3061e-03, -1.7835e-04,\n",
            "         1.1255e-03, -1.3731e-03, -1.2949e-03,  1.3520e-03, -2.1839e-03,\n",
            "         6.5235e-04, -2.0228e-03, -2.7450e-03,  2.2422e-03, -2.4451e-03,\n",
            "         2.1513e-03, -2.5085e-03, -3.6417e-04, -1.0900e-03,  9.4325e-05,\n",
            "         1.7512e-03, -7.6012e-04,  6.5279e-04,  1.1379e-03, -1.2719e-03,\n",
            "         7.8671e-04, -6.3236e-04, -1.3746e-04,  5.6345e-04,  2.5017e-03,\n",
            "         5.5869e-04, -9.6531e-04,  1.0854e-03,  9.8771e-04, -2.3123e-03,\n",
            "         1.3475e-03, -1.9724e-03, -2.2600e-03,  1.3859e-03,  1.9805e-03,\n",
            "        -4.8405e-04,  2.1588e-03,  3.3554e-04,  6.6930e-04, -4.5880e-04,\n",
            "         2.4989e-03,  8.5765e-04,  1.1538e-03,  1.6230e-03, -4.8703e-04,\n",
            "         7.8112e-04,  1.3132e-05,  3.0137e-04, -1.3784e-03, -1.4544e-03,\n",
            "        -5.2741e-04, -1.8402e-03, -1.5625e-03, -2.2738e-03,  3.8612e-04,\n",
            "         2.2677e-03, -5.3218e-04,  5.4911e-05,  2.4706e-03,  2.4998e-03,\n",
            "         2.2618e-03,  1.8624e-03, -2.5330e-04,  1.8305e-03, -1.8549e-03,\n",
            "        -2.7169e-03,  9.3133e-04,  2.4379e-03,  1.3090e-03, -1.0152e-03,\n",
            "         8.4190e-05, -1.9869e-03, -9.6177e-05, -1.7655e-04,  8.0438e-04,\n",
            "         6.4729e-04,  5.8401e-04, -1.3096e-03, -2.2929e-03,  1.3037e-03,\n",
            "         2.0154e-03, -7.7762e-04, -2.0418e-03,  2.0039e-03, -2.6189e-03,\n",
            "         2.0915e-03, -2.0183e-03,  8.7145e-04,  2.3424e-03, -1.1179e-04,\n",
            "        -2.3812e-03,  1.0776e-03, -7.3691e-04, -6.2445e-04, -2.0840e-03,\n",
            "        -2.6983e-04, -2.2735e-03, -3.2375e-04,  2.1560e-03,  3.4913e-04,\n",
            "        -9.4118e-04,  1.7069e-03, -8.0000e-04,  2.5294e-03, -2.1021e-04,\n",
            "        -9.1908e-04, -3.8441e-04,  1.2362e-04,  2.5019e-03,  2.0246e-03,\n",
            "         1.5562e-03, -1.0037e-04, -2.1426e-03, -1.5482e-03,  1.3772e-03,\n",
            "        -1.4662e-03, -5.7455e-04,  2.6474e-03,  2.1898e-03,  2.6451e-03,\n",
            "         2.1104e-03], device='cuda:0', requires_grad=True)\n",
            "NPF_D2.weight Parameter containing:\n",
            "tensor([[ 0.0226,  0.0253,  0.0255,  ..., -0.0016, -0.0421, -0.0108],\n",
            "        [-0.0297, -0.0016,  0.0181,  ..., -0.0086, -0.0454, -0.0433],\n",
            "        [ 0.0435,  0.0053, -0.0318,  ...,  0.0247,  0.0059, -0.0624],\n",
            "        ...,\n",
            "        [ 0.0503, -0.0084, -0.0100,  ..., -0.0395, -0.0564, -0.0219],\n",
            "        [-0.0588, -0.0343, -0.0159,  ...,  0.0362, -0.0599,  0.0344],\n",
            "        [-0.0210,  0.0446, -0.0092,  ...,  0.0310,  0.0163,  0.0410]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPF_D2.bias Parameter containing:\n",
            "tensor([ 4.2800e-02, -4.3092e-03, -6.2978e-03, -2.8505e-02, -7.4424e-03,\n",
            "         1.3275e-02,  2.5657e-02, -2.8777e-02, -2.6607e-02,  8.0499e-03,\n",
            "        -3.1067e-02,  3.3679e-02, -2.6727e-03, -4.3679e-02,  8.5959e-03,\n",
            "        -5.3486e-02, -1.5819e-02, -1.2245e-02,  5.6081e-02, -3.9405e-02,\n",
            "         2.3649e-02,  2.0365e-02,  1.0273e-02, -6.1488e-02,  4.2181e-02,\n",
            "         3.8077e-02, -5.2476e-02, -5.8738e-02,  6.4674e-03,  4.5751e-03,\n",
            "         4.6984e-02,  3.7657e-03, -3.3021e-02,  2.2769e-02, -1.8769e-02,\n",
            "        -4.9282e-02, -3.0374e-02, -2.2082e-02, -2.7868e-03,  2.8905e-03,\n",
            "        -1.2718e-02, -1.7982e-02,  2.7873e-03,  6.0139e-02,  3.0708e-02,\n",
            "         6.1973e-02,  3.3093e-02, -1.9884e-02, -4.2857e-02,  5.7772e-02,\n",
            "         2.3433e-04, -5.2528e-02, -3.4056e-02, -1.1307e-02, -1.7174e-02,\n",
            "         1.3986e-02, -1.6949e-02, -3.8208e-02,  5.1287e-02,  4.5456e-02,\n",
            "         3.2084e-02,  3.6367e-02,  3.0858e-02, -4.2917e-02, -5.2346e-02,\n",
            "        -8.8322e-03,  1.9863e-02, -1.4665e-02, -4.9128e-02, -4.2944e-03,\n",
            "        -1.5148e-02, -4.0334e-02, -4.5806e-02,  5.9603e-03,  1.6062e-02,\n",
            "         3.2311e-02,  8.9321e-03,  1.9329e-02,  6.0591e-02, -3.7540e-02,\n",
            "         2.9744e-02, -2.5670e-02,  3.2412e-02,  6.1191e-03,  4.6672e-02,\n",
            "        -6.2543e-03,  2.4540e-03, -2.5525e-02,  5.1066e-02, -4.3589e-02,\n",
            "        -2.4136e-02,  2.5272e-05,  1.2766e-02,  4.0395e-02,  2.5942e-02,\n",
            "         7.8723e-03,  2.9818e-02, -9.6795e-03, -2.3931e-02,  4.2080e-02,\n",
            "         5.9626e-02, -5.9584e-02, -4.7664e-02,  2.3669e-02, -1.5793e-02,\n",
            "         1.0246e-02, -1.3104e-02, -2.7153e-02,  3.2963e-02, -2.7522e-02,\n",
            "         4.0788e-02,  3.6287e-02, -1.9466e-02, -5.6052e-02,  1.4116e-02,\n",
            "         2.3377e-02, -3.0090e-02,  5.1120e-03, -3.5136e-02,  2.4199e-02,\n",
            "         4.9723e-02, -4.6262e-02,  4.5855e-02, -1.8328e-02,  1.5442e-02,\n",
            "         1.9203e-02,  4.7571e-03,  2.7844e-03,  5.0769e-02,  5.9960e-02,\n",
            "        -1.1466e-02, -6.0432e-02,  1.2808e-02,  2.1950e-02, -2.7193e-02,\n",
            "        -5.1358e-02,  5.3069e-02, -3.3407e-02,  3.7827e-03, -4.0993e-02,\n",
            "        -2.7296e-02,  4.1820e-02,  3.6925e-02,  2.5975e-02,  2.6320e-02,\n",
            "         2.5011e-02, -6.1762e-02,  3.1113e-02, -5.1325e-02, -2.6959e-02,\n",
            "        -3.1160e-02,  3.8585e-02,  2.7944e-02,  2.5672e-03, -1.5855e-02,\n",
            "         3.9008e-02, -2.0418e-02,  1.4523e-02, -5.7941e-02, -6.5398e-03,\n",
            "        -1.6154e-02,  4.4858e-02, -2.3848e-02,  5.3910e-02, -5.2435e-03,\n",
            "        -2.7919e-02,  2.1672e-02, -4.2162e-02,  2.4070e-02,  5.5339e-02,\n",
            "         9.6466e-03, -1.6555e-02,  2.9843e-02, -5.2084e-02,  5.7822e-02,\n",
            "         3.9474e-02, -4.7943e-02, -2.8468e-02, -4.2204e-03,  6.9600e-04,\n",
            "         1.5595e-02,  8.9198e-03,  1.5323e-02, -2.0341e-02, -5.0218e-02,\n",
            "        -3.0550e-02,  4.7309e-02, -4.5115e-02, -3.6403e-02,  2.2941e-03,\n",
            "        -3.6866e-02,  1.5713e-02,  4.8251e-02,  3.0561e-02, -5.7094e-02,\n",
            "         2.6231e-02,  2.4206e-02,  8.8430e-03,  3.3270e-02, -5.0306e-02,\n",
            "        -1.2897e-02,  2.2260e-02, -1.2818e-02, -1.6015e-02, -5.7179e-02,\n",
            "        -2.7629e-02, -4.9467e-02, -4.5498e-02,  4.4299e-02,  1.9935e-02,\n",
            "         1.4455e-02,  1.0832e-03, -3.5563e-02,  9.0028e-03, -1.4426e-02,\n",
            "        -2.2047e-02, -3.5411e-02,  1.3181e-02, -4.1169e-02,  4.2671e-03,\n",
            "        -1.4848e-02,  1.1527e-02,  7.8799e-03,  3.1075e-02,  6.0861e-02,\n",
            "        -5.5804e-02,  2.9414e-02, -1.4646e-02, -1.7199e-02,  3.2360e-02,\n",
            "         1.0333e-02,  5.3209e-02,  5.8267e-02, -1.7538e-02,  2.1268e-02,\n",
            "        -4.0636e-02,  1.1377e-02, -1.0893e-02,  1.7886e-02,  3.4469e-02,\n",
            "         5.3115e-02,  4.0215e-02, -1.4792e-02, -2.7106e-02, -3.7962e-02,\n",
            "         3.9214e-03, -3.2006e-03, -2.6415e-03,  4.5538e-02, -1.4577e-02,\n",
            "        -1.7294e-02, -2.8192e-02,  2.0504e-02,  3.5975e-02, -6.0427e-02,\n",
            "        -1.8805e-02], device='cuda:0', requires_grad=True)\n",
            "NPV_C1.weight Parameter containing:\n",
            "tensor([[[[ 0.1397,  0.1195,  0.1305],\n",
            "          [-0.0399, -0.0212,  0.0863],\n",
            "          [ 0.1052, -0.0467, -0.0340]],\n",
            "\n",
            "         [[-0.0456, -0.0650,  0.1604],\n",
            "          [-0.0800, -0.0553, -0.1571],\n",
            "          [ 0.0502,  0.1586,  0.0630]],\n",
            "\n",
            "         [[ 0.0627,  0.0695, -0.1562],\n",
            "          [-0.0733,  0.0070,  0.0283],\n",
            "          [ 0.0936,  0.0916,  0.1129]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0221,  0.0690, -0.1078],\n",
            "          [-0.0679, -0.0322, -0.1376],\n",
            "          [ 0.0458,  0.1631, -0.1905]],\n",
            "\n",
            "         [[ 0.0455, -0.0057, -0.0026],\n",
            "          [-0.0064, -0.0585, -0.0138],\n",
            "          [ 0.0039,  0.1116, -0.1620]],\n",
            "\n",
            "         [[-0.1902,  0.0577, -0.0802],\n",
            "          [-0.1305,  0.0760,  0.1524],\n",
            "          [ 0.0461,  0.0873,  0.1867]]],\n",
            "\n",
            "\n",
            "        [[[-0.1342, -0.0936,  0.1755],\n",
            "          [ 0.0561, -0.0583, -0.0318],\n",
            "          [ 0.0938,  0.1439,  0.1216]],\n",
            "\n",
            "         [[-0.1711, -0.0103, -0.1485],\n",
            "          [-0.0844,  0.0103, -0.1425],\n",
            "          [ 0.0812, -0.1875, -0.0808]],\n",
            "\n",
            "         [[-0.0108,  0.0017, -0.1373],\n",
            "          [ 0.0127, -0.1409, -0.1729],\n",
            "          [-0.1031,  0.0216, -0.1796]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1825, -0.0839,  0.1553],\n",
            "          [ 0.1225, -0.1902,  0.1021],\n",
            "          [ 0.0086, -0.0079, -0.0869]],\n",
            "\n",
            "         [[-0.1163, -0.0005, -0.1880],\n",
            "          [-0.1695, -0.1092, -0.0289],\n",
            "          [ 0.1202,  0.1895, -0.1792]],\n",
            "\n",
            "         [[-0.0916,  0.0500,  0.0272],\n",
            "          [-0.1631, -0.0471, -0.1133],\n",
            "          [-0.1811,  0.0954, -0.1094]]],\n",
            "\n",
            "\n",
            "        [[[-0.0003,  0.0897,  0.0930],\n",
            "          [ 0.0182,  0.0146,  0.0152],\n",
            "          [ 0.0425, -0.1802, -0.0818]],\n",
            "\n",
            "         [[ 0.1188, -0.1829, -0.0368],\n",
            "          [ 0.0825, -0.1435,  0.0541],\n",
            "          [ 0.1812, -0.0301, -0.0365]],\n",
            "\n",
            "         [[-0.0856, -0.0064,  0.1272],\n",
            "          [-0.0808,  0.0998,  0.0959],\n",
            "          [-0.1838, -0.0865, -0.0682]]],\n",
            "\n",
            "\n",
            "        [[[-0.0126, -0.1170,  0.1338],\n",
            "          [-0.1890, -0.0305, -0.1460],\n",
            "          [-0.0961,  0.1789,  0.0605]],\n",
            "\n",
            "         [[ 0.1248, -0.0036,  0.1629],\n",
            "          [ 0.1555, -0.0916,  0.1532],\n",
            "          [ 0.1484, -0.0964, -0.0572]],\n",
            "\n",
            "         [[ 0.1654,  0.1381, -0.0521],\n",
            "          [-0.0630,  0.0016,  0.1834],\n",
            "          [ 0.0865, -0.1030,  0.1264]]]], device='cuda:0', requires_grad=True)\n",
            "NPV_C1.bias Parameter containing:\n",
            "tensor([-7.5618e-02, -2.0373e-02,  1.8304e-01, -2.1611e-02, -1.2243e-01,\n",
            "         1.5610e-01, -1.9741e-04,  8.8301e-02, -1.0414e-01,  8.0709e-05,\n",
            "        -9.6164e-02, -1.4557e-01, -1.0729e-01, -1.0894e-01, -4.2586e-02,\n",
            "         4.6880e-02,  1.8662e-01,  1.4753e-01,  1.2672e-02, -7.7154e-02,\n",
            "         7.9990e-02, -1.0964e-01, -1.8925e-01, -1.2568e-02, -7.8229e-02,\n",
            "        -1.3374e-01,  8.3115e-02,  9.1262e-02, -1.4894e-01, -1.3830e-02,\n",
            "         3.5733e-02, -1.0165e-01,  9.2654e-02,  8.7629e-02,  1.8462e-01,\n",
            "         1.7824e-02, -5.4415e-03,  3.8821e-02, -1.3455e-01, -4.9458e-02,\n",
            "         1.0594e-01,  1.6754e-01, -5.6996e-02, -1.1140e-01,  4.4076e-02,\n",
            "        -4.6056e-03,  1.2403e-01,  8.2572e-02,  1.1036e-01,  6.4899e-02,\n",
            "         7.1810e-02,  5.2053e-02,  6.1288e-02, -5.5573e-02, -1.1473e-02,\n",
            "        -1.8126e-01, -2.5655e-02, -9.7002e-02,  9.8776e-02, -1.3988e-01,\n",
            "         1.7408e-01,  1.7926e-01,  1.0283e-01, -1.6412e-01], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_C2.weight Parameter containing:\n",
            "tensor([[[[ 1.5103e-02,  2.9704e-02, -3.8090e-02],\n",
            "          [ 2.5149e-02,  2.1844e-02, -1.7188e-02],\n",
            "          [-7.3443e-03, -2.2542e-02, -3.3402e-02]],\n",
            "\n",
            "         [[-1.4446e-02, -3.5096e-03, -2.8695e-02],\n",
            "          [ 3.2664e-02,  2.2044e-02,  1.0436e-02],\n",
            "          [-9.0866e-03,  3.6128e-02, -1.5585e-03]],\n",
            "\n",
            "         [[-1.3931e-02, -4.0221e-02,  2.0895e-03],\n",
            "          [ 8.9072e-03,  2.1875e-02,  1.8223e-02],\n",
            "          [-3.8524e-03, -1.9920e-02, -2.9281e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.5132e-04, -2.0359e-02, -3.4813e-02],\n",
            "          [ 2.6408e-02,  2.9757e-02,  6.7718e-03],\n",
            "          [-1.4110e-02,  3.5730e-02, -1.7982e-03]],\n",
            "\n",
            "         [[ 3.3305e-02,  3.9370e-02,  2.3755e-02],\n",
            "          [-2.3260e-02,  2.8692e-02,  4.1187e-02],\n",
            "          [-9.8287e-04, -1.7502e-02,  2.6082e-02]],\n",
            "\n",
            "         [[ 3.7435e-02, -1.9915e-02,  2.4395e-02],\n",
            "          [-1.5445e-02, -3.3038e-02, -3.4764e-02],\n",
            "          [-7.5155e-04, -2.1526e-02,  3.9335e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2589e-02,  1.1960e-02,  4.0104e-02],\n",
            "          [-1.8131e-03, -2.1567e-02, -1.2250e-02],\n",
            "          [-3.8665e-02, -3.0282e-02, -9.7634e-03]],\n",
            "\n",
            "         [[-1.9655e-02, -1.6668e-02, -2.5674e-02],\n",
            "          [ 1.4575e-02, -1.7689e-02,  2.2641e-02],\n",
            "          [ 8.6435e-03, -7.3085e-03,  3.4069e-02]],\n",
            "\n",
            "         [[ 3.2154e-02,  3.3612e-03, -2.8819e-02],\n",
            "          [-3.3646e-03,  2.6050e-02, -3.5905e-02],\n",
            "          [ 3.6797e-02, -1.4488e-02, -4.0826e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7496e-02, -9.1583e-03, -3.6902e-02],\n",
            "          [ 1.2068e-02, -3.1973e-02, -4.5080e-03],\n",
            "          [-3.3742e-02, -3.2313e-02,  2.7683e-02]],\n",
            "\n",
            "         [[ 3.0089e-02,  2.0029e-02,  1.2656e-02],\n",
            "          [ 1.5767e-02,  3.1056e-02,  1.8152e-02],\n",
            "          [ 1.0229e-02, -8.6716e-03, -3.2703e-02]],\n",
            "\n",
            "         [[ 1.4152e-02,  2.8871e-02, -1.2772e-02],\n",
            "          [ 2.6291e-03, -3.2415e-02, -3.2299e-02],\n",
            "          [ 1.8615e-02, -3.9600e-02, -3.2312e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4479e-03,  1.2740e-02, -4.0161e-02],\n",
            "          [ 2.9221e-02,  4.5247e-03, -2.4546e-02],\n",
            "          [ 3.6874e-02,  3.2446e-02, -2.0972e-02]],\n",
            "\n",
            "         [[ 1.3987e-02, -2.3412e-02, -1.9761e-02],\n",
            "          [ 1.2588e-02,  2.0879e-02, -3.7725e-02],\n",
            "          [-2.6674e-02,  4.1480e-02,  9.4362e-03]],\n",
            "\n",
            "         [[-3.8428e-02,  3.6630e-03, -1.7602e-02],\n",
            "          [ 2.5857e-02,  3.3098e-02,  3.0848e-02],\n",
            "          [-1.2142e-02, -1.5178e-02, -4.1672e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.9773e-05,  1.6501e-02, -6.3147e-03],\n",
            "          [-2.1474e-02, -4.9190e-03,  3.9352e-02],\n",
            "          [-9.2543e-03,  2.9354e-02,  8.6049e-03]],\n",
            "\n",
            "         [[-3.2626e-02,  3.1470e-02, -1.8578e-02],\n",
            "          [-1.3097e-02, -1.8886e-02,  3.9942e-02],\n",
            "          [-2.9178e-02,  6.0825e-03, -3.3370e-02]],\n",
            "\n",
            "         [[-1.5172e-02, -2.5937e-02,  1.8562e-02],\n",
            "          [-2.2010e-02,  1.1067e-02, -2.1587e-02],\n",
            "          [ 7.1726e-03,  1.0282e-02,  1.5167e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 5.0240e-03,  6.6737e-03,  3.4744e-02],\n",
            "          [ 1.4027e-02,  3.5884e-02, -2.3025e-02],\n",
            "          [ 2.1495e-02, -1.0652e-02,  3.6764e-02]],\n",
            "\n",
            "         [[ 7.2008e-03, -3.3191e-02,  1.7669e-03],\n",
            "          [-1.9850e-02, -5.9930e-03, -4.9535e-03],\n",
            "          [ 4.1913e-04, -2.4296e-02,  3.0516e-02]],\n",
            "\n",
            "         [[-3.8130e-02, -1.9751e-02, -6.7004e-04],\n",
            "          [-2.8443e-02,  2.6089e-02,  3.1203e-02],\n",
            "          [-2.0108e-02,  1.4846e-02,  1.5329e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2183e-02,  3.5377e-02,  3.8792e-02],\n",
            "          [-5.1794e-04, -4.9221e-03, -1.8558e-02],\n",
            "          [-2.0215e-02,  2.6673e-02, -1.9421e-02]],\n",
            "\n",
            "         [[-2.8709e-02, -3.5574e-02,  2.0479e-02],\n",
            "          [ 2.7200e-02,  1.0205e-03, -3.2720e-02],\n",
            "          [ 2.6169e-02,  3.8491e-02,  3.0745e-02]],\n",
            "\n",
            "         [[-3.8609e-02, -1.6206e-02, -1.0496e-02],\n",
            "          [-3.8901e-02, -3.3373e-02,  2.4763e-03],\n",
            "          [ 2.4792e-02,  3.4783e-02,  3.2995e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9023e-02, -1.7570e-02,  4.0045e-02],\n",
            "          [-1.9843e-02,  1.1494e-02,  9.3193e-03],\n",
            "          [-2.3966e-02, -1.6836e-02, -3.2134e-02]],\n",
            "\n",
            "         [[-3.1831e-02, -3.5493e-02,  1.2249e-02],\n",
            "          [-7.2648e-03, -1.4402e-02, -2.0708e-02],\n",
            "          [-3.8794e-02, -7.6392e-03,  3.6252e-02]],\n",
            "\n",
            "         [[-3.5245e-02,  2.1467e-02, -2.5869e-02],\n",
            "          [-3.1044e-02, -2.7048e-03,  2.1205e-02],\n",
            "          [-3.1879e-02,  2.5301e-02,  2.6311e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.4045e-02,  2.4539e-02, -3.4000e-02],\n",
            "          [ 1.8369e-02, -8.0497e-03,  3.7198e-02],\n",
            "          [-2.2630e-02, -2.5041e-02,  1.6831e-02]],\n",
            "\n",
            "         [[-1.7220e-02, -7.5514e-03,  3.1243e-02],\n",
            "          [-1.8018e-02,  3.5871e-02,  2.5101e-02],\n",
            "          [ 3.1909e-02, -2.3952e-04,  1.2109e-02]],\n",
            "\n",
            "         [[ 1.0008e-02,  3.1892e-02,  1.6287e-02],\n",
            "          [ 3.2663e-02,  1.0426e-03,  1.2819e-02],\n",
            "          [ 2.6255e-02, -5.2062e-04,  2.9484e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.2040e-02,  1.1510e-02,  2.5081e-02],\n",
            "          [-3.2660e-02, -7.6920e-03, -3.0828e-02],\n",
            "          [-1.1586e-02,  2.9833e-02, -2.0006e-02]],\n",
            "\n",
            "         [[ 5.5076e-04, -2.8477e-02,  1.6228e-03],\n",
            "          [-3.5023e-02,  1.1373e-02, -3.0118e-02],\n",
            "          [ 3.3413e-02,  1.4880e-02,  1.4108e-02]],\n",
            "\n",
            "         [[ 2.3838e-02,  3.9022e-02, -4.9853e-03],\n",
            "          [-4.1103e-03, -1.9650e-02,  3.4199e-02],\n",
            "          [ 1.7873e-02,  3.0469e-02,  1.4593e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7736e-02,  2.3017e-02, -3.1640e-02],\n",
            "          [-3.9594e-02,  1.9033e-02,  6.3011e-03],\n",
            "          [-1.2118e-03, -2.2843e-02,  2.2329e-02]],\n",
            "\n",
            "         [[ 2.0127e-02, -1.5998e-02, -1.4322e-02],\n",
            "          [ 1.2743e-02, -2.4873e-02,  3.1725e-03],\n",
            "          [ 1.4726e-02,  3.7864e-02, -4.1027e-02]],\n",
            "\n",
            "         [[ 4.1628e-03, -3.8819e-02,  3.9909e-02],\n",
            "          [-3.0494e-02, -3.3870e-02,  1.6592e-03],\n",
            "          [ 3.9099e-02, -2.9516e-02, -3.0529e-02]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_C2.bias Parameter containing:\n",
            "tensor([-0.0177, -0.0154, -0.0084,  0.0219, -0.0279,  0.0248,  0.0016,  0.0328,\n",
            "         0.0041,  0.0395,  0.0183,  0.0270,  0.0130,  0.0198,  0.0340, -0.0264,\n",
            "        -0.0213, -0.0337, -0.0077, -0.0406,  0.0023, -0.0206, -0.0218,  0.0108,\n",
            "        -0.0166, -0.0043, -0.0244,  0.0065, -0.0128, -0.0366, -0.0349,  0.0171,\n",
            "         0.0324, -0.0299,  0.0117, -0.0097, -0.0255, -0.0255,  0.0183,  0.0414,\n",
            "         0.0230,  0.0124, -0.0026,  0.0354,  0.0296, -0.0295,  0.0338,  0.0335,\n",
            "         0.0112, -0.0382, -0.0412, -0.0043,  0.0043, -0.0024,  0.0056,  0.0163,\n",
            "        -0.0060,  0.0163,  0.0080, -0.0162, -0.0383,  0.0389, -0.0328, -0.0289],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_C3.weight Parameter containing:\n",
            "tensor([[[[ 2.7964e-02, -1.4258e-02,  4.0640e-02],\n",
            "          [-6.4360e-03,  3.4412e-02,  3.0588e-02],\n",
            "          [ 3.5793e-02,  3.7687e-02,  9.4342e-03]],\n",
            "\n",
            "         [[-3.9900e-03, -4.0618e-02,  2.5096e-02],\n",
            "          [-1.3614e-02,  3.4912e-02, -2.6618e-02],\n",
            "          [ 2.2629e-02,  5.6354e-03,  1.1217e-02]],\n",
            "\n",
            "         [[-6.5209e-03,  5.9811e-03, -1.5307e-02],\n",
            "          [-1.0775e-02,  2.3972e-02, -3.9299e-02],\n",
            "          [-3.8561e-02,  2.0907e-02,  4.9464e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.9694e-02,  4.0515e-02,  1.5700e-02],\n",
            "          [ 1.7462e-02, -3.6028e-02,  3.1087e-02],\n",
            "          [ 1.9048e-02,  3.1775e-02,  6.4598e-03]],\n",
            "\n",
            "         [[ 2.7395e-02, -3.8971e-03,  2.9767e-02],\n",
            "          [-6.3219e-03,  2.0025e-02,  1.1343e-02],\n",
            "          [ 3.1056e-02, -1.7743e-02, -3.5663e-02]],\n",
            "\n",
            "         [[-1.3631e-03,  2.5367e-02,  1.9388e-02],\n",
            "          [ 9.2037e-04,  3.1117e-03, -2.8092e-02],\n",
            "          [ 1.0733e-02, -1.5830e-02,  1.8856e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3618e-02,  1.6402e-02,  2.7680e-02],\n",
            "          [-2.9454e-03,  9.0999e-03, -4.0935e-02],\n",
            "          [ 7.2690e-03,  5.7285e-03,  2.2135e-02]],\n",
            "\n",
            "         [[ 8.1404e-04, -1.3830e-02,  2.4567e-02],\n",
            "          [-5.7046e-03,  1.2211e-02, -1.1058e-02],\n",
            "          [ 1.7042e-02, -2.1791e-02, -2.0363e-02]],\n",
            "\n",
            "         [[ 4.0726e-02, -1.6742e-02, -2.7742e-02],\n",
            "          [-2.9966e-02, -3.9999e-02, -9.2839e-03],\n",
            "          [ 2.7488e-02,  4.0374e-02,  3.3610e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.7650e-04,  1.1935e-02, -1.8034e-02],\n",
            "          [ 4.9914e-03,  1.7028e-02, -2.1654e-02],\n",
            "          [-4.2637e-03,  3.5707e-02, -7.2846e-04]],\n",
            "\n",
            "         [[ 3.1115e-02,  1.7409e-02, -1.2101e-02],\n",
            "          [-2.9670e-02, -3.8161e-02, -1.9423e-02],\n",
            "          [ 2.2065e-02, -1.8369e-02,  3.4714e-02]],\n",
            "\n",
            "         [[ 2.9645e-02, -3.8235e-02,  5.5455e-03],\n",
            "          [ 3.1655e-02,  7.9072e-04, -3.1601e-02],\n",
            "          [ 1.2379e-03, -3.9337e-02, -7.9931e-03]]],\n",
            "\n",
            "\n",
            "        [[[-2.1406e-02,  2.3093e-02,  3.1546e-02],\n",
            "          [-2.1994e-02, -4.0008e-02, -3.5435e-03],\n",
            "          [ 2.9838e-02,  2.2146e-02,  2.3794e-02]],\n",
            "\n",
            "         [[ 1.9661e-02,  1.6452e-02,  1.9968e-02],\n",
            "          [ 4.4264e-03, -4.0699e-02, -8.6403e-03],\n",
            "          [ 3.0221e-02, -3.3615e-02,  1.0790e-02]],\n",
            "\n",
            "         [[ 1.9644e-02, -3.7969e-02,  4.3768e-03],\n",
            "          [ 3.4995e-02, -3.0314e-02, -3.7152e-02],\n",
            "          [ 1.9988e-02,  2.9717e-02,  8.5722e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.0374e-02,  4.1600e-02,  2.8022e-02],\n",
            "          [ 3.6694e-02,  1.3379e-02, -2.6019e-02],\n",
            "          [ 5.4211e-03,  4.0412e-02,  1.8356e-02]],\n",
            "\n",
            "         [[-2.3640e-02, -3.9205e-02, -1.1693e-03],\n",
            "          [-6.7535e-03, -4.1143e-02,  1.5097e-02],\n",
            "          [ 2.0514e-02, -1.9466e-02,  1.4203e-02]],\n",
            "\n",
            "         [[-3.3424e-02, -2.1709e-02,  8.0118e-04],\n",
            "          [ 2.7743e-02, -2.7193e-02,  2.0645e-02],\n",
            "          [-3.6155e-02,  4.5968e-03, -3.3871e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-7.3697e-04,  3.8861e-02,  1.2079e-02],\n",
            "          [-6.2368e-03,  3.1688e-03, -3.8680e-02],\n",
            "          [-3.3131e-02, -3.0931e-03,  2.0324e-02]],\n",
            "\n",
            "         [[-3.6622e-02, -5.5431e-03, -1.1966e-02],\n",
            "          [ 1.9755e-02,  3.2430e-02,  1.0582e-03],\n",
            "          [-1.2669e-02,  3.3010e-02, -2.0602e-02]],\n",
            "\n",
            "         [[ 1.8051e-02,  1.7199e-02,  2.3979e-02],\n",
            "          [-7.1250e-03, -3.3461e-02, -2.7502e-02],\n",
            "          [ 2.3725e-02,  4.3231e-03, -2.6217e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1319e-03,  3.5811e-02, -3.8871e-02],\n",
            "          [-1.1978e-02,  1.6480e-02, -2.1538e-03],\n",
            "          [ 7.3885e-03,  2.2238e-02,  1.7665e-02]],\n",
            "\n",
            "         [[-2.4053e-02, -3.0802e-02,  4.1223e-02],\n",
            "          [ 1.5771e-02, -1.2075e-02, -3.2030e-02],\n",
            "          [-2.6104e-02,  3.6451e-02,  5.9892e-03]],\n",
            "\n",
            "         [[ 3.0297e-02, -8.1001e-03,  3.7775e-02],\n",
            "          [-3.8234e-02, -2.3163e-02,  1.9187e-02],\n",
            "          [ 3.6559e-02,  1.4206e-02, -4.0266e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2005e-02,  2.1562e-02,  1.6410e-02],\n",
            "          [-2.3498e-02, -2.8166e-03,  1.7308e-02],\n",
            "          [-2.0041e-02,  4.0335e-02, -2.9493e-02]],\n",
            "\n",
            "         [[ 5.0690e-04,  2.0888e-02, -1.2477e-02],\n",
            "          [-3.4167e-02,  1.1532e-02, -2.4002e-02],\n",
            "          [-2.0033e-03,  4.7282e-03, -3.0495e-02]],\n",
            "\n",
            "         [[ 2.9176e-03, -2.5673e-02,  4.0826e-03],\n",
            "          [ 6.8617e-03, -2.3629e-02, -2.0861e-02],\n",
            "          [-3.3453e-02, -9.5845e-03, -3.8751e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.9466e-02,  3.3056e-02,  1.9936e-02],\n",
            "          [ 5.0624e-03,  3.0220e-02,  1.6363e-02],\n",
            "          [-3.6786e-02, -4.8099e-03,  3.4955e-02]],\n",
            "\n",
            "         [[ 3.3082e-02,  3.7240e-02, -1.7191e-02],\n",
            "          [-4.1342e-02, -1.1075e-02,  3.5222e-02],\n",
            "          [-1.7428e-03,  8.3491e-03,  1.4344e-03]],\n",
            "\n",
            "         [[-8.0141e-03, -2.8263e-02, -1.3644e-03],\n",
            "          [-4.0597e-02,  3.9626e-02,  3.6791e-02],\n",
            "          [-1.3819e-02,  2.4887e-02, -1.0969e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.3566e-02, -6.0411e-03, -1.1267e-02],\n",
            "          [-1.2250e-02,  8.3967e-03,  1.2664e-02],\n",
            "          [-6.0466e-03,  4.0174e-03,  3.5914e-03]],\n",
            "\n",
            "         [[ 1.9744e-02,  1.3591e-03,  2.8004e-02],\n",
            "          [ 2.6026e-02, -3.9161e-02, -1.0894e-02],\n",
            "          [-1.3921e-02, -3.9964e-02, -3.3850e-02]],\n",
            "\n",
            "         [[-2.6803e-02,  5.9273e-03,  2.7128e-02],\n",
            "          [-2.1382e-02, -4.3930e-03, -3.1639e-02],\n",
            "          [-2.9629e-02, -6.7011e-05, -1.7125e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.9256e-02, -1.8403e-02,  2.2623e-02],\n",
            "          [ 1.4056e-04, -3.3285e-02,  2.9321e-03],\n",
            "          [-2.2694e-02, -1.8592e-02,  8.3035e-03]],\n",
            "\n",
            "         [[ 3.9342e-02, -2.5095e-02, -2.9747e-02],\n",
            "          [ 4.1379e-02, -2.1784e-02,  4.1285e-02],\n",
            "          [-3.1189e-02, -3.9926e-02,  5.0639e-03]],\n",
            "\n",
            "         [[-3.1951e-02,  2.6050e-02, -1.8915e-02],\n",
            "          [ 2.7522e-02,  3.9140e-02,  3.2991e-02],\n",
            "          [ 3.2530e-02, -2.9558e-02,  1.7301e-03]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_C3.bias Parameter containing:\n",
            "tensor([ 3.9334e-05,  3.2020e-02,  1.0248e-02,  1.8496e-02,  1.9509e-02,\n",
            "         4.5388e-03,  1.2364e-02,  3.1531e-02,  3.2969e-02,  1.7468e-02,\n",
            "         2.6937e-02, -1.6519e-02, -3.2731e-02, -2.4987e-02, -2.4944e-02,\n",
            "        -7.0629e-03,  3.4070e-02,  9.9553e-03,  1.9015e-03,  2.4769e-02,\n",
            "         1.1476e-02, -2.7237e-02,  1.0295e-03,  1.5450e-02,  1.3191e-02,\n",
            "         4.8306e-03, -3.9031e-02, -4.5210e-03,  1.2507e-02, -1.3457e-02,\n",
            "         8.2698e-03,  1.5339e-02, -1.8239e-02,  5.3797e-03, -3.7862e-02,\n",
            "         2.5797e-02, -1.1372e-02,  2.6838e-02,  1.6744e-02, -1.8637e-02,\n",
            "        -2.2878e-03,  1.4239e-03,  2.9046e-02,  1.2103e-02, -6.1151e-03,\n",
            "         3.1155e-02, -7.9520e-03, -7.0102e-03,  3.5401e-02, -3.4902e-03,\n",
            "         3.0340e-02,  1.3760e-02,  3.9065e-02,  9.4195e-03, -3.2208e-02,\n",
            "        -3.1558e-02,  3.0383e-02,  3.1279e-02, -3.4103e-03,  2.4346e-02,\n",
            "        -1.5568e-02, -1.1867e-02, -8.7517e-03,  2.3896e-02, -1.7156e-02,\n",
            "         2.8070e-02, -3.2973e-02,  2.7324e-02,  3.9937e-02, -4.0962e-02,\n",
            "         1.4773e-02,  3.6188e-02, -2.2469e-02, -2.9435e-02,  1.3103e-02,\n",
            "        -1.6624e-03, -2.9834e-02, -4.0356e-02,  2.1805e-02, -4.6286e-03,\n",
            "        -2.0130e-02, -1.1196e-03,  2.0735e-02, -3.6496e-02,  1.8620e-02,\n",
            "         2.9400e-02, -3.7292e-02,  1.9416e-02,  4.0859e-03,  3.2973e-03,\n",
            "        -3.9134e-02,  2.7848e-02,  1.5195e-02, -1.3676e-02, -9.4028e-03,\n",
            "         2.5965e-02, -2.3699e-02,  3.7911e-02, -1.1878e-02,  8.9494e-03,\n",
            "        -2.6671e-02, -2.2572e-03,  2.1223e-02,  1.9284e-02,  4.1343e-02,\n",
            "        -1.4305e-02,  1.6663e-02, -1.7826e-02, -2.7934e-02,  6.2691e-03,\n",
            "         3.4998e-02, -3.4677e-02,  2.3974e-02, -1.1317e-02,  2.4374e-02,\n",
            "        -6.2491e-03,  3.9319e-02, -2.1692e-02, -7.7318e-03, -1.1863e-02,\n",
            "        -2.2265e-02,  1.6739e-02, -9.3299e-03, -7.1998e-03, -2.6129e-02,\n",
            "        -1.2814e-02, -1.7375e-02, -3.3522e-02], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_C4.weight Parameter containing:\n",
            "tensor([[[[ 2.0371e-02,  2.9366e-02,  5.6723e-04],\n",
            "          [-2.3028e-04,  2.5723e-02,  1.7856e-03],\n",
            "          [-9.5709e-03, -2.2411e-02, -4.9527e-03]],\n",
            "\n",
            "         [[-2.1369e-02,  1.2335e-02, -1.3031e-02],\n",
            "          [ 2.0297e-02,  1.0076e-02, -1.4825e-02],\n",
            "          [-8.7485e-03,  1.9612e-03, -2.0883e-02]],\n",
            "\n",
            "         [[-2.8318e-02,  1.2317e-02, -1.5886e-02],\n",
            "          [-5.4808e-03, -1.9719e-02, -2.3132e-02],\n",
            "          [ 3.0672e-03, -2.2396e-02,  2.2666e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6879e-02, -6.5732e-04, -7.3133e-03],\n",
            "          [ 4.6296e-03,  2.0565e-02,  3.9215e-03],\n",
            "          [-2.2803e-02, -2.4928e-04,  1.6335e-02]],\n",
            "\n",
            "         [[-1.2904e-02,  1.9270e-02,  2.3459e-02],\n",
            "          [ 1.8793e-02, -2.8703e-02, -2.0345e-03],\n",
            "          [-6.2186e-03, -2.8327e-03, -1.5454e-02]],\n",
            "\n",
            "         [[-5.3830e-03,  5.0183e-05, -3.4396e-03],\n",
            "          [-2.0566e-02,  1.4086e-02, -2.2225e-02],\n",
            "          [ 2.3416e-02,  5.7609e-03,  2.9188e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.7112e-02, -2.5985e-03, -2.1115e-02],\n",
            "          [-2.4310e-02, -2.5098e-02,  1.8037e-02],\n",
            "          [ 2.7847e-02, -1.9314e-02,  8.5644e-03]],\n",
            "\n",
            "         [[ 1.0178e-02,  4.8181e-03,  1.9158e-02],\n",
            "          [ 7.4500e-03, -1.0284e-02,  2.2824e-02],\n",
            "          [-6.2708e-03, -2.7865e-02, -2.5806e-02]],\n",
            "\n",
            "         [[ 9.4741e-04,  2.7920e-02, -7.7941e-03],\n",
            "          [-1.9723e-02, -2.2342e-02,  8.3604e-03],\n",
            "          [-8.9683e-03, -1.0408e-02, -1.1677e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7584e-02,  2.8878e-02, -7.6429e-03],\n",
            "          [ 2.6966e-02, -1.0924e-02, -2.5849e-02],\n",
            "          [ 4.9638e-03, -1.8870e-02, -1.3405e-02]],\n",
            "\n",
            "         [[-8.7446e-03,  6.8953e-03, -1.9061e-02],\n",
            "          [-2.0679e-02, -2.4272e-02,  2.5117e-02],\n",
            "          [-2.0867e-02,  6.2490e-03, -7.9333e-03]],\n",
            "\n",
            "         [[ 2.8818e-02, -6.3632e-03,  2.7174e-02],\n",
            "          [ 2.7470e-03, -3.1414e-03, -1.0995e-02],\n",
            "          [ 8.3427e-03, -2.0543e-02,  8.8460e-03]]],\n",
            "\n",
            "\n",
            "        [[[-5.2246e-03, -1.1179e-02, -3.3132e-03],\n",
            "          [ 2.9368e-02, -2.6744e-02, -5.6882e-03],\n",
            "          [ 9.3046e-03, -3.1545e-03, -2.7793e-02]],\n",
            "\n",
            "         [[ 1.7291e-02,  1.5052e-02,  2.1028e-02],\n",
            "          [ 4.4790e-03,  1.6760e-02, -1.0324e-02],\n",
            "          [ 1.1675e-02, -9.9784e-03,  1.6773e-02]],\n",
            "\n",
            "         [[-2.2413e-02, -1.6915e-02,  1.7619e-02],\n",
            "          [-2.7371e-02,  8.9296e-03,  3.8491e-03],\n",
            "          [ 1.3897e-02,  1.5760e-02,  2.1224e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8354e-03,  1.3885e-02,  6.5864e-03],\n",
            "          [ 1.2424e-02, -7.3867e-03,  2.5766e-03],\n",
            "          [-1.5892e-02,  2.4031e-02, -2.8694e-02]],\n",
            "\n",
            "         [[-2.7957e-03, -1.4309e-02,  6.5412e-03],\n",
            "          [-2.1657e-02,  2.4818e-03, -7.9125e-03],\n",
            "          [-2.7373e-02,  7.1716e-03,  4.6227e-03]],\n",
            "\n",
            "         [[ 7.9520e-03, -2.3439e-02, -1.5321e-02],\n",
            "          [ 1.7384e-02,  1.2488e-02, -1.6774e-02],\n",
            "          [ 2.8079e-02,  5.0753e-03, -2.5537e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8584e-02, -2.5551e-02, -1.6184e-02],\n",
            "          [-2.8825e-02, -1.9226e-02, -1.3303e-02],\n",
            "          [ 2.6902e-02, -2.0712e-02, -2.6141e-02]],\n",
            "\n",
            "         [[-2.6779e-02,  2.7673e-02,  1.5814e-02],\n",
            "          [ 4.1666e-04,  4.9395e-03,  2.8764e-02],\n",
            "          [-1.5150e-02,  7.0400e-03, -2.6306e-02]],\n",
            "\n",
            "         [[ 7.3209e-03,  2.2140e-02,  5.7249e-04],\n",
            "          [-2.3913e-02,  5.9633e-03, -1.6602e-02],\n",
            "          [ 2.1585e-02, -2.4239e-02, -1.6952e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7418e-02, -2.4630e-02, -1.0397e-02],\n",
            "          [-1.4418e-02, -2.1527e-02, -5.4219e-03],\n",
            "          [-1.8274e-03, -9.2246e-03,  2.2469e-02]],\n",
            "\n",
            "         [[ 1.7511e-03, -1.2887e-02,  2.4699e-02],\n",
            "          [-8.9034e-03, -7.7052e-03, -2.3588e-02],\n",
            "          [ 1.9349e-02, -1.0436e-02, -1.0437e-03]],\n",
            "\n",
            "         [[ 2.6038e-02, -1.5518e-02,  2.5768e-02],\n",
            "          [-1.8447e-02,  9.6301e-03, -2.8336e-02],\n",
            "          [-9.8251e-05, -6.7263e-03,  7.9410e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9911e-02, -2.4228e-02, -1.3800e-02],\n",
            "          [-1.5150e-02, -1.1877e-02,  3.0183e-03],\n",
            "          [ 7.3772e-03, -7.0166e-03, -2.0739e-02]],\n",
            "\n",
            "         [[-2.4704e-02,  6.5812e-03, -1.6508e-02],\n",
            "          [ 5.4046e-03,  1.9260e-02, -1.3667e-02],\n",
            "          [ 2.1882e-04, -6.9893e-03, -1.0153e-02]],\n",
            "\n",
            "         [[ 1.1859e-02,  2.1625e-02, -1.0004e-02],\n",
            "          [ 2.6110e-02,  2.6414e-02, -1.4471e-02],\n",
            "          [-2.4016e-03,  8.1579e-03,  1.2462e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8600e-02,  2.6413e-02,  7.2234e-03],\n",
            "          [-2.0334e-02, -7.8676e-03,  2.6492e-02],\n",
            "          [ 1.3931e-02, -1.1665e-02, -2.0343e-02]],\n",
            "\n",
            "         [[-5.5493e-03,  1.4370e-02,  1.4061e-02],\n",
            "          [ 2.0525e-02, -1.9774e-02, -1.7299e-02],\n",
            "          [-6.9514e-05, -2.3270e-02,  1.3680e-02]],\n",
            "\n",
            "         [[-1.4865e-02,  2.2148e-02,  8.6107e-03],\n",
            "          [-1.0392e-02, -1.8661e-02,  2.2275e-02],\n",
            "          [ 2.1634e-02,  2.7876e-02, -1.1388e-02]]],\n",
            "\n",
            "\n",
            "        [[[-7.9545e-03, -2.6297e-02,  2.3686e-02],\n",
            "          [-1.6311e-02, -1.0122e-02, -1.8776e-02],\n",
            "          [ 1.1145e-02, -9.1403e-03,  7.7255e-05]],\n",
            "\n",
            "         [[-3.8423e-03, -2.2878e-02, -2.0976e-02],\n",
            "          [-9.6178e-03,  5.0834e-03,  8.2321e-04],\n",
            "          [ 1.8336e-02,  2.8831e-02, -1.2464e-02]],\n",
            "\n",
            "         [[ 2.0929e-02,  1.5928e-02,  2.5535e-02],\n",
            "          [ 2.1138e-03,  2.6109e-02,  1.2691e-02],\n",
            "          [-1.8036e-02, -9.0674e-03,  1.0521e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.3000e-04,  8.5512e-03, -2.6620e-02],\n",
            "          [-1.8205e-02, -1.3702e-02, -2.5862e-02],\n",
            "          [-2.8032e-02, -5.9691e-03, -2.7248e-03]],\n",
            "\n",
            "         [[-2.5383e-02, -1.5387e-02, -8.1234e-03],\n",
            "          [ 1.2977e-02, -2.4731e-02, -2.0188e-02],\n",
            "          [ 1.1842e-02,  1.7818e-02, -1.0922e-02]],\n",
            "\n",
            "         [[-5.4602e-03, -2.5708e-03, -1.1811e-02],\n",
            "          [ 1.0543e-02, -1.6501e-02,  1.5387e-02],\n",
            "          [ 8.6818e-03,  1.7294e-03,  2.9350e-02]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_C4.bias Parameter containing:\n",
            "tensor([ 0.0137, -0.0204, -0.0101, -0.0151,  0.0094, -0.0185,  0.0122, -0.0271,\n",
            "         0.0293,  0.0181, -0.0288, -0.0119,  0.0091,  0.0265, -0.0165, -0.0045,\n",
            "         0.0139, -0.0147, -0.0034,  0.0294, -0.0287,  0.0162, -0.0068, -0.0136,\n",
            "        -0.0033, -0.0008, -0.0013, -0.0058,  0.0005, -0.0115,  0.0103,  0.0061,\n",
            "         0.0011, -0.0180,  0.0002,  0.0090, -0.0087,  0.0015,  0.0237,  0.0077,\n",
            "        -0.0043, -0.0119,  0.0247, -0.0264, -0.0243, -0.0017, -0.0016, -0.0285,\n",
            "         0.0210, -0.0050,  0.0087, -0.0084, -0.0071, -0.0145, -0.0032, -0.0111,\n",
            "         0.0207, -0.0062,  0.0122,  0.0273, -0.0169, -0.0266,  0.0276, -0.0258,\n",
            "        -0.0126,  0.0076,  0.0008,  0.0241, -0.0265, -0.0149,  0.0250, -0.0222,\n",
            "         0.0045, -0.0278, -0.0078, -0.0152,  0.0214,  0.0180,  0.0250, -0.0067,\n",
            "         0.0139, -0.0149, -0.0186, -0.0084, -0.0173,  0.0284, -0.0111, -0.0144,\n",
            "        -0.0169,  0.0230, -0.0067, -0.0052, -0.0242,  0.0277, -0.0127, -0.0236,\n",
            "        -0.0108, -0.0114,  0.0030, -0.0238,  0.0287,  0.0240,  0.0073, -0.0236,\n",
            "        -0.0171,  0.0158,  0.0034,  0.0271, -0.0106, -0.0126, -0.0136, -0.0280,\n",
            "        -0.0137, -0.0210, -0.0213, -0.0256,  0.0253, -0.0180, -0.0215,  0.0198,\n",
            "        -0.0254, -0.0248, -0.0231, -0.0003, -0.0215,  0.0053,  0.0088, -0.0200],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_D1.weight Parameter containing:\n",
            "tensor([[-0.0008, -0.0017,  0.0014,  ...,  0.0025,  0.0022, -0.0017],\n",
            "        [ 0.0024, -0.0001, -0.0024,  ...,  0.0025, -0.0026, -0.0016],\n",
            "        [ 0.0015, -0.0026, -0.0003,  ..., -0.0008, -0.0014,  0.0009],\n",
            "        ...,\n",
            "        [-0.0006, -0.0011,  0.0014,  ...,  0.0011, -0.0025,  0.0009],\n",
            "        [-0.0026,  0.0005,  0.0020,  ...,  0.0012, -0.0015, -0.0011],\n",
            "        [-0.0014, -0.0022,  0.0024,  ...,  0.0016,  0.0024,  0.0021]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_D1.bias Parameter containing:\n",
            "tensor([ 4.2381e-04,  6.3669e-04,  1.6792e-04, -4.7863e-04, -1.8585e-04,\n",
            "         2.6467e-03, -1.0965e-03,  2.3995e-03, -2.1861e-03,  1.2774e-03,\n",
            "        -2.6267e-03,  1.4881e-03, -2.4879e-03, -2.0339e-04, -1.8089e-03,\n",
            "        -2.2518e-03,  1.3348e-03, -5.2184e-04,  2.6268e-04,  6.9110e-05,\n",
            "        -1.8144e-03,  8.9410e-04,  2.0638e-03,  1.5168e-03, -2.6475e-03,\n",
            "         2.5728e-03, -3.0734e-04, -2.3725e-03, -1.1090e-03, -2.2503e-03,\n",
            "         2.2998e-03,  7.8752e-04, -1.7956e-03, -1.0386e-03, -2.4257e-03,\n",
            "         2.2913e-03, -9.8518e-04, -1.3360e-03, -7.6197e-04,  4.4794e-04,\n",
            "         2.4711e-03, -5.5210e-04,  2.0021e-03, -1.2849e-03, -2.5338e-03,\n",
            "        -1.0677e-03, -2.2408e-03, -2.0894e-04,  8.0408e-04,  1.1650e-03,\n",
            "         2.7215e-03,  1.5429e-03, -2.7524e-03, -6.4700e-04, -2.7212e-03,\n",
            "        -1.7297e-03,  1.5433e-03,  3.4041e-04,  2.0696e-03,  1.6445e-03,\n",
            "        -1.6894e-03, -2.1654e-03,  9.3084e-04, -1.6646e-03,  1.9251e-03,\n",
            "        -2.6827e-03, -2.8796e-04, -4.0230e-04, -2.4846e-03, -2.5744e-03,\n",
            "         2.5201e-03,  3.5431e-04,  1.8965e-03, -1.6455e-04,  2.5687e-04,\n",
            "        -1.4282e-03, -1.5757e-03, -9.4774e-04, -1.8050e-03, -2.7233e-03,\n",
            "        -2.7070e-03, -2.1912e-03, -7.9485e-05,  1.0748e-03,  2.0624e-03,\n",
            "         1.1190e-04,  5.2145e-04, -1.3550e-03, -5.7670e-04, -2.2743e-03,\n",
            "         2.6369e-03, -2.3244e-03, -1.7664e-03,  2.7311e-03,  1.6093e-03,\n",
            "        -2.3789e-03,  1.9175e-03, -7.8933e-06, -6.0744e-04,  1.8881e-04,\n",
            "        -6.8827e-04,  2.6160e-03, -1.7735e-04,  1.1211e-03, -1.9872e-03,\n",
            "        -2.3313e-04, -2.2866e-03, -2.1566e-04, -1.1760e-03,  1.2144e-03,\n",
            "         2.0194e-03, -1.2600e-03,  7.7531e-04, -1.5862e-03, -2.5931e-04,\n",
            "         2.6036e-03, -1.5199e-03, -2.2965e-03,  2.0166e-03, -1.1569e-03,\n",
            "         1.7330e-03, -1.9029e-03, -1.0759e-03, -2.1008e-03,  1.5300e-03,\n",
            "         1.5855e-03, -2.6084e-03, -5.7586e-04, -6.4429e-04, -2.3820e-03,\n",
            "        -2.2338e-03,  1.8480e-04, -8.0471e-04, -1.2572e-03,  1.6492e-03,\n",
            "         6.9357e-04,  1.7454e-03,  2.5374e-03, -1.2470e-03, -4.4669e-04,\n",
            "         4.8638e-04, -2.0177e-04, -8.3812e-05,  1.0899e-03, -7.6644e-04,\n",
            "         5.2766e-04,  3.1983e-04, -2.8828e-04, -1.3098e-03,  1.3881e-03,\n",
            "        -1.9326e-03, -1.4517e-03,  1.1955e-03,  2.0040e-03,  6.8689e-04,\n",
            "        -1.2166e-03, -3.4795e-04, -7.8156e-05,  1.2742e-03, -2.4727e-03,\n",
            "        -1.9939e-03,  5.9816e-04, -1.6330e-03,  2.4431e-03,  1.4985e-03,\n",
            "         6.7411e-04,  1.8391e-03, -7.6327e-04,  1.5217e-03, -2.0517e-03,\n",
            "        -1.1564e-03, -1.6793e-03,  2.1213e-03,  1.1693e-03,  1.5846e-03,\n",
            "        -1.0743e-03,  7.7726e-04, -1.1152e-03, -2.5255e-03,  2.3981e-03,\n",
            "         1.3346e-03,  2.1901e-03, -1.6430e-03, -2.3493e-04,  1.5688e-03,\n",
            "         6.0778e-04,  1.0380e-03,  2.2601e-03, -4.4303e-04, -2.1110e-03,\n",
            "        -9.3645e-04, -2.7530e-03, -2.0961e-03, -5.8628e-04,  4.1795e-04,\n",
            "        -2.5625e-03,  2.1970e-03,  8.8361e-04,  1.8522e-03, -1.5451e-03,\n",
            "         2.5454e-03, -2.6268e-03, -2.4506e-03,  1.2301e-03,  1.2361e-03,\n",
            "         1.4738e-03,  1.9664e-03,  2.5124e-03, -1.5915e-03, -9.4372e-05,\n",
            "         1.8074e-03,  2.4719e-03,  5.2893e-04, -7.7887e-04, -2.6860e-04,\n",
            "        -2.5095e-03, -1.0351e-03,  1.9813e-03,  1.0569e-03,  2.4972e-03,\n",
            "         2.6966e-03,  2.4028e-04,  1.0813e-03,  1.5315e-03,  1.6258e-03,\n",
            "        -1.0556e-03, -2.0518e-03,  2.6927e-04, -1.7547e-03,  2.4715e-03,\n",
            "         9.5889e-04,  2.3967e-03,  1.4629e-03,  1.6212e-03,  7.7731e-04,\n",
            "        -1.2734e-03, -1.2658e-03, -2.7010e-03, -2.5887e-03, -1.4514e-03,\n",
            "        -1.7323e-03, -2.5461e-03, -1.7107e-03,  2.4143e-03,  2.0808e-04,\n",
            "         1.0302e-03, -2.3519e-03,  1.4558e-03,  3.9802e-04, -1.6821e-03,\n",
            "        -1.4050e-03, -1.1211e-03,  7.4840e-04, -2.3959e-03, -1.1967e-03,\n",
            "         1.2013e-03], device='cuda:0', requires_grad=True)\n",
            "NPV_D2.weight Parameter containing:\n",
            "tensor([[ 0.0548,  0.0055, -0.0173,  ...,  0.0355,  0.0413, -0.0314],\n",
            "        [-0.0383, -0.0123, -0.0289,  ..., -0.0085, -0.0120, -0.0243],\n",
            "        [ 0.0610,  0.0129, -0.0194,  ..., -0.0605,  0.0478,  0.0328],\n",
            "        ...,\n",
            "        [ 0.0133, -0.0540, -0.0280,  ...,  0.0393, -0.0283, -0.0169],\n",
            "        [ 0.0576, -0.0217,  0.0077,  ..., -0.0422,  0.0159, -0.0040],\n",
            "        [ 0.0408, -0.0072,  0.0035,  ..., -0.0166, -0.0371, -0.0158]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_D2.bias Parameter containing:\n",
            "tensor([-0.0054,  0.0436, -0.0372,  0.0399, -0.0412, -0.0407, -0.0346, -0.0198,\n",
            "         0.0248, -0.0451,  0.0398, -0.0401, -0.0415, -0.0012, -0.0124,  0.0202,\n",
            "        -0.0455,  0.0025, -0.0480, -0.0366, -0.0605, -0.0133, -0.0560,  0.0253,\n",
            "         0.0362, -0.0335, -0.0042, -0.0327,  0.0216,  0.0586,  0.0450, -0.0609,\n",
            "         0.0348,  0.0567, -0.0416, -0.0068, -0.0214, -0.0288,  0.0291, -0.0288,\n",
            "        -0.0228,  0.0094, -0.0417,  0.0507,  0.0305,  0.0190, -0.0134, -0.0237,\n",
            "         0.0267, -0.0351, -0.0405, -0.0085, -0.0452,  0.0361, -0.0002, -0.0017,\n",
            "        -0.0191, -0.0280,  0.0312, -0.0420,  0.0563, -0.0093,  0.0494, -0.0348,\n",
            "        -0.0205,  0.0223,  0.0344,  0.0013, -0.0192, -0.0207,  0.0529, -0.0036,\n",
            "        -0.0080,  0.0267, -0.0541,  0.0483,  0.0572,  0.0506, -0.0059,  0.0355,\n",
            "         0.0238, -0.0340, -0.0443,  0.0096, -0.0479,  0.0205,  0.0404, -0.0611,\n",
            "        -0.0379, -0.0078, -0.0282, -0.0387, -0.0350, -0.0328, -0.0086, -0.0530,\n",
            "         0.0300,  0.0102,  0.0465, -0.0300,  0.0057,  0.0478,  0.0350,  0.0252,\n",
            "        -0.0097, -0.0434,  0.0069, -0.0386,  0.0071, -0.0442, -0.0287, -0.0482,\n",
            "         0.0215, -0.0154,  0.0370, -0.0294, -0.0158, -0.0106, -0.0195,  0.0083,\n",
            "        -0.0482, -0.0442,  0.0549, -0.0336,  0.0104, -0.0251, -0.0074,  0.0509,\n",
            "         0.0455,  0.0343, -0.0322,  0.0248,  0.0011, -0.0500, -0.0516,  0.0551,\n",
            "         0.0310,  0.0070, -0.0512,  0.0206,  0.0226, -0.0088, -0.0022, -0.0607,\n",
            "         0.0195, -0.0266, -0.0248,  0.0561, -0.0356, -0.0392, -0.0256,  0.0311,\n",
            "         0.0475,  0.0565,  0.0365, -0.0190, -0.0072, -0.0391,  0.0094, -0.0346,\n",
            "         0.0392,  0.0129, -0.0118, -0.0316,  0.0455,  0.0108,  0.0489, -0.0218,\n",
            "         0.0317,  0.0152, -0.0542, -0.0532, -0.0208,  0.0338, -0.0377,  0.0178,\n",
            "        -0.0343, -0.0304, -0.0119, -0.0556,  0.0549, -0.0142, -0.0339, -0.0219,\n",
            "         0.0270,  0.0254,  0.0279, -0.0285, -0.0435, -0.0624,  0.0210, -0.0164,\n",
            "        -0.0106, -0.0144, -0.0201, -0.0099,  0.0128,  0.0404,  0.0176, -0.0052,\n",
            "        -0.0574,  0.0240, -0.0339,  0.0285,  0.0616, -0.0188, -0.0533, -0.0526,\n",
            "         0.0101,  0.0582,  0.0477,  0.0560, -0.0205, -0.0323,  0.0323,  0.0064,\n",
            "        -0.0387,  0.0220, -0.0007, -0.0289, -0.0328,  0.0551, -0.0031,  0.0196,\n",
            "        -0.0106, -0.0261, -0.0341,  0.0105,  0.0136, -0.0010, -0.0550, -0.0505,\n",
            "         0.0051,  0.0343,  0.0582,  0.0029, -0.0136, -0.0310,  0.0122,  0.0123,\n",
            "         0.0237, -0.0338, -0.0043, -0.0002,  0.0490,  0.0339, -0.0147, -0.0243,\n",
            "        -0.0569, -0.0419, -0.0522, -0.0211, -0.0138, -0.0091,  0.0220,  0.0110],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "outputs.weight Parameter containing:\n",
            "tensor([[ 0.0573,  0.0027,  0.0226,  ..., -0.0019,  0.0327,  0.0086],\n",
            "        [ 0.0062,  0.0096,  0.0107,  ...,  0.0387,  0.0345,  0.0565],\n",
            "        [-0.0213, -0.0220,  0.0149,  ...,  0.0437,  0.0278,  0.0428],\n",
            "        ...,\n",
            "        [ 0.0019,  0.0030,  0.0243,  ..., -0.0398,  0.0144, -0.0371],\n",
            "        [-0.0079,  0.0156, -0.0154,  ..., -0.0579, -0.0287,  0.0229],\n",
            "        [-0.0401,  0.0051,  0.0425,  ..., -0.0048, -0.0074,  0.0147]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "outputs.bias Parameter containing:\n",
            "tensor([-0.0506, -0.0343,  0.0030,  0.0559, -0.0226, -0.0055, -0.0530,  0.0216,\n",
            "         0.0206,  0.0099], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in frnpf_di_linear_model.named_parameters():\n",
        "  if name[0:3]=='NPF':\n",
        "    paramName = \"NPV\"+name[3:]\n",
        "    param.data = frnpf_di_linear_model.state_dict().get(paramName).data.detach().clone()\n",
        "    param.requires_grad = False\n",
        "  print(name, param)"
      ],
      "metadata": {
        "id": "OrZFUl6kMgCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ac3515d6-300f-4633-bdf6-924d06cab24b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NPF_C1.weight Parameter containing:\n",
            "tensor([[[[ 0.1397,  0.1195,  0.1305],\n",
            "          [-0.0399, -0.0212,  0.0863],\n",
            "          [ 0.1052, -0.0467, -0.0340]],\n",
            "\n",
            "         [[-0.0456, -0.0650,  0.1604],\n",
            "          [-0.0800, -0.0553, -0.1571],\n",
            "          [ 0.0502,  0.1586,  0.0630]],\n",
            "\n",
            "         [[ 0.0627,  0.0695, -0.1562],\n",
            "          [-0.0733,  0.0070,  0.0283],\n",
            "          [ 0.0936,  0.0916,  0.1129]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0221,  0.0690, -0.1078],\n",
            "          [-0.0679, -0.0322, -0.1376],\n",
            "          [ 0.0458,  0.1631, -0.1905]],\n",
            "\n",
            "         [[ 0.0455, -0.0057, -0.0026],\n",
            "          [-0.0064, -0.0585, -0.0138],\n",
            "          [ 0.0039,  0.1116, -0.1620]],\n",
            "\n",
            "         [[-0.1902,  0.0577, -0.0802],\n",
            "          [-0.1305,  0.0760,  0.1524],\n",
            "          [ 0.0461,  0.0873,  0.1867]]],\n",
            "\n",
            "\n",
            "        [[[-0.1342, -0.0936,  0.1755],\n",
            "          [ 0.0561, -0.0583, -0.0318],\n",
            "          [ 0.0938,  0.1439,  0.1216]],\n",
            "\n",
            "         [[-0.1711, -0.0103, -0.1485],\n",
            "          [-0.0844,  0.0103, -0.1425],\n",
            "          [ 0.0812, -0.1875, -0.0808]],\n",
            "\n",
            "         [[-0.0108,  0.0017, -0.1373],\n",
            "          [ 0.0127, -0.1409, -0.1729],\n",
            "          [-0.1031,  0.0216, -0.1796]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1825, -0.0839,  0.1553],\n",
            "          [ 0.1225, -0.1902,  0.1021],\n",
            "          [ 0.0086, -0.0079, -0.0869]],\n",
            "\n",
            "         [[-0.1163, -0.0005, -0.1880],\n",
            "          [-0.1695, -0.1092, -0.0289],\n",
            "          [ 0.1202,  0.1895, -0.1792]],\n",
            "\n",
            "         [[-0.0916,  0.0500,  0.0272],\n",
            "          [-0.1631, -0.0471, -0.1133],\n",
            "          [-0.1811,  0.0954, -0.1094]]],\n",
            "\n",
            "\n",
            "        [[[-0.0003,  0.0897,  0.0930],\n",
            "          [ 0.0182,  0.0146,  0.0152],\n",
            "          [ 0.0425, -0.1802, -0.0818]],\n",
            "\n",
            "         [[ 0.1188, -0.1829, -0.0368],\n",
            "          [ 0.0825, -0.1435,  0.0541],\n",
            "          [ 0.1812, -0.0301, -0.0365]],\n",
            "\n",
            "         [[-0.0856, -0.0064,  0.1272],\n",
            "          [-0.0808,  0.0998,  0.0959],\n",
            "          [-0.1838, -0.0865, -0.0682]]],\n",
            "\n",
            "\n",
            "        [[[-0.0126, -0.1170,  0.1338],\n",
            "          [-0.1890, -0.0305, -0.1460],\n",
            "          [-0.0961,  0.1789,  0.0605]],\n",
            "\n",
            "         [[ 0.1248, -0.0036,  0.1629],\n",
            "          [ 0.1555, -0.0916,  0.1532],\n",
            "          [ 0.1484, -0.0964, -0.0572]],\n",
            "\n",
            "         [[ 0.1654,  0.1381, -0.0521],\n",
            "          [-0.0630,  0.0016,  0.1834],\n",
            "          [ 0.0865, -0.1030,  0.1264]]]], device='cuda:0')\n",
            "NPF_C1.bias Parameter containing:\n",
            "tensor([-7.5618e-02, -2.0373e-02,  1.8304e-01, -2.1611e-02, -1.2243e-01,\n",
            "         1.5610e-01, -1.9741e-04,  8.8301e-02, -1.0414e-01,  8.0709e-05,\n",
            "        -9.6164e-02, -1.4557e-01, -1.0729e-01, -1.0894e-01, -4.2586e-02,\n",
            "         4.6880e-02,  1.8662e-01,  1.4753e-01,  1.2672e-02, -7.7154e-02,\n",
            "         7.9990e-02, -1.0964e-01, -1.8925e-01, -1.2568e-02, -7.8229e-02,\n",
            "        -1.3374e-01,  8.3115e-02,  9.1262e-02, -1.4894e-01, -1.3830e-02,\n",
            "         3.5733e-02, -1.0165e-01,  9.2654e-02,  8.7629e-02,  1.8462e-01,\n",
            "         1.7824e-02, -5.4415e-03,  3.8821e-02, -1.3455e-01, -4.9458e-02,\n",
            "         1.0594e-01,  1.6754e-01, -5.6996e-02, -1.1140e-01,  4.4076e-02,\n",
            "        -4.6056e-03,  1.2403e-01,  8.2572e-02,  1.1036e-01,  6.4899e-02,\n",
            "         7.1810e-02,  5.2053e-02,  6.1288e-02, -5.5573e-02, -1.1473e-02,\n",
            "        -1.8126e-01, -2.5655e-02, -9.7002e-02,  9.8776e-02, -1.3988e-01,\n",
            "         1.7408e-01,  1.7926e-01,  1.0283e-01, -1.6412e-01], device='cuda:0')\n",
            "NPF_C2.weight Parameter containing:\n",
            "tensor([[[[ 1.5103e-02,  2.9704e-02, -3.8090e-02],\n",
            "          [ 2.5149e-02,  2.1844e-02, -1.7188e-02],\n",
            "          [-7.3443e-03, -2.2542e-02, -3.3402e-02]],\n",
            "\n",
            "         [[-1.4446e-02, -3.5096e-03, -2.8695e-02],\n",
            "          [ 3.2664e-02,  2.2044e-02,  1.0436e-02],\n",
            "          [-9.0866e-03,  3.6128e-02, -1.5585e-03]],\n",
            "\n",
            "         [[-1.3931e-02, -4.0221e-02,  2.0895e-03],\n",
            "          [ 8.9072e-03,  2.1875e-02,  1.8223e-02],\n",
            "          [-3.8524e-03, -1.9920e-02, -2.9281e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.5132e-04, -2.0359e-02, -3.4813e-02],\n",
            "          [ 2.6408e-02,  2.9757e-02,  6.7718e-03],\n",
            "          [-1.4110e-02,  3.5730e-02, -1.7982e-03]],\n",
            "\n",
            "         [[ 3.3305e-02,  3.9370e-02,  2.3755e-02],\n",
            "          [-2.3260e-02,  2.8692e-02,  4.1187e-02],\n",
            "          [-9.8287e-04, -1.7502e-02,  2.6082e-02]],\n",
            "\n",
            "         [[ 3.7435e-02, -1.9915e-02,  2.4395e-02],\n",
            "          [-1.5445e-02, -3.3038e-02, -3.4764e-02],\n",
            "          [-7.5155e-04, -2.1526e-02,  3.9335e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2589e-02,  1.1960e-02,  4.0104e-02],\n",
            "          [-1.8131e-03, -2.1567e-02, -1.2250e-02],\n",
            "          [-3.8665e-02, -3.0282e-02, -9.7634e-03]],\n",
            "\n",
            "         [[-1.9655e-02, -1.6668e-02, -2.5674e-02],\n",
            "          [ 1.4575e-02, -1.7689e-02,  2.2641e-02],\n",
            "          [ 8.6435e-03, -7.3085e-03,  3.4069e-02]],\n",
            "\n",
            "         [[ 3.2154e-02,  3.3612e-03, -2.8819e-02],\n",
            "          [-3.3646e-03,  2.6050e-02, -3.5905e-02],\n",
            "          [ 3.6797e-02, -1.4488e-02, -4.0826e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7496e-02, -9.1583e-03, -3.6902e-02],\n",
            "          [ 1.2068e-02, -3.1973e-02, -4.5080e-03],\n",
            "          [-3.3742e-02, -3.2313e-02,  2.7683e-02]],\n",
            "\n",
            "         [[ 3.0089e-02,  2.0029e-02,  1.2656e-02],\n",
            "          [ 1.5767e-02,  3.1056e-02,  1.8152e-02],\n",
            "          [ 1.0229e-02, -8.6716e-03, -3.2703e-02]],\n",
            "\n",
            "         [[ 1.4152e-02,  2.8871e-02, -1.2772e-02],\n",
            "          [ 2.6291e-03, -3.2415e-02, -3.2299e-02],\n",
            "          [ 1.8615e-02, -3.9600e-02, -3.2312e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4479e-03,  1.2740e-02, -4.0161e-02],\n",
            "          [ 2.9221e-02,  4.5247e-03, -2.4546e-02],\n",
            "          [ 3.6874e-02,  3.2446e-02, -2.0972e-02]],\n",
            "\n",
            "         [[ 1.3987e-02, -2.3412e-02, -1.9761e-02],\n",
            "          [ 1.2588e-02,  2.0879e-02, -3.7725e-02],\n",
            "          [-2.6674e-02,  4.1480e-02,  9.4362e-03]],\n",
            "\n",
            "         [[-3.8428e-02,  3.6630e-03, -1.7602e-02],\n",
            "          [ 2.5857e-02,  3.3098e-02,  3.0848e-02],\n",
            "          [-1.2142e-02, -1.5178e-02, -4.1672e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.9773e-05,  1.6501e-02, -6.3147e-03],\n",
            "          [-2.1474e-02, -4.9190e-03,  3.9352e-02],\n",
            "          [-9.2543e-03,  2.9354e-02,  8.6049e-03]],\n",
            "\n",
            "         [[-3.2626e-02,  3.1470e-02, -1.8578e-02],\n",
            "          [-1.3097e-02, -1.8886e-02,  3.9942e-02],\n",
            "          [-2.9178e-02,  6.0825e-03, -3.3370e-02]],\n",
            "\n",
            "         [[-1.5172e-02, -2.5937e-02,  1.8562e-02],\n",
            "          [-2.2010e-02,  1.1067e-02, -2.1587e-02],\n",
            "          [ 7.1726e-03,  1.0282e-02,  1.5167e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 5.0240e-03,  6.6737e-03,  3.4744e-02],\n",
            "          [ 1.4027e-02,  3.5884e-02, -2.3025e-02],\n",
            "          [ 2.1495e-02, -1.0652e-02,  3.6764e-02]],\n",
            "\n",
            "         [[ 7.2008e-03, -3.3191e-02,  1.7669e-03],\n",
            "          [-1.9850e-02, -5.9930e-03, -4.9535e-03],\n",
            "          [ 4.1913e-04, -2.4296e-02,  3.0516e-02]],\n",
            "\n",
            "         [[-3.8130e-02, -1.9751e-02, -6.7004e-04],\n",
            "          [-2.8443e-02,  2.6089e-02,  3.1203e-02],\n",
            "          [-2.0108e-02,  1.4846e-02,  1.5329e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2183e-02,  3.5377e-02,  3.8792e-02],\n",
            "          [-5.1794e-04, -4.9221e-03, -1.8558e-02],\n",
            "          [-2.0215e-02,  2.6673e-02, -1.9421e-02]],\n",
            "\n",
            "         [[-2.8709e-02, -3.5574e-02,  2.0479e-02],\n",
            "          [ 2.7200e-02,  1.0205e-03, -3.2720e-02],\n",
            "          [ 2.6169e-02,  3.8491e-02,  3.0745e-02]],\n",
            "\n",
            "         [[-3.8609e-02, -1.6206e-02, -1.0496e-02],\n",
            "          [-3.8901e-02, -3.3373e-02,  2.4763e-03],\n",
            "          [ 2.4792e-02,  3.4783e-02,  3.2995e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9023e-02, -1.7570e-02,  4.0045e-02],\n",
            "          [-1.9843e-02,  1.1494e-02,  9.3193e-03],\n",
            "          [-2.3966e-02, -1.6836e-02, -3.2134e-02]],\n",
            "\n",
            "         [[-3.1831e-02, -3.5493e-02,  1.2249e-02],\n",
            "          [-7.2648e-03, -1.4402e-02, -2.0708e-02],\n",
            "          [-3.8794e-02, -7.6392e-03,  3.6252e-02]],\n",
            "\n",
            "         [[-3.5245e-02,  2.1467e-02, -2.5869e-02],\n",
            "          [-3.1044e-02, -2.7048e-03,  2.1205e-02],\n",
            "          [-3.1879e-02,  2.5301e-02,  2.6311e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.4045e-02,  2.4539e-02, -3.4000e-02],\n",
            "          [ 1.8369e-02, -8.0497e-03,  3.7198e-02],\n",
            "          [-2.2630e-02, -2.5041e-02,  1.6831e-02]],\n",
            "\n",
            "         [[-1.7220e-02, -7.5514e-03,  3.1243e-02],\n",
            "          [-1.8018e-02,  3.5871e-02,  2.5101e-02],\n",
            "          [ 3.1909e-02, -2.3952e-04,  1.2109e-02]],\n",
            "\n",
            "         [[ 1.0008e-02,  3.1892e-02,  1.6287e-02],\n",
            "          [ 3.2663e-02,  1.0426e-03,  1.2819e-02],\n",
            "          [ 2.6255e-02, -5.2062e-04,  2.9484e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.2040e-02,  1.1510e-02,  2.5081e-02],\n",
            "          [-3.2660e-02, -7.6920e-03, -3.0828e-02],\n",
            "          [-1.1586e-02,  2.9833e-02, -2.0006e-02]],\n",
            "\n",
            "         [[ 5.5076e-04, -2.8477e-02,  1.6228e-03],\n",
            "          [-3.5023e-02,  1.1373e-02, -3.0118e-02],\n",
            "          [ 3.3413e-02,  1.4880e-02,  1.4108e-02]],\n",
            "\n",
            "         [[ 2.3838e-02,  3.9022e-02, -4.9853e-03],\n",
            "          [-4.1103e-03, -1.9650e-02,  3.4199e-02],\n",
            "          [ 1.7873e-02,  3.0469e-02,  1.4593e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7736e-02,  2.3017e-02, -3.1640e-02],\n",
            "          [-3.9594e-02,  1.9033e-02,  6.3011e-03],\n",
            "          [-1.2118e-03, -2.2843e-02,  2.2329e-02]],\n",
            "\n",
            "         [[ 2.0127e-02, -1.5998e-02, -1.4322e-02],\n",
            "          [ 1.2743e-02, -2.4873e-02,  3.1725e-03],\n",
            "          [ 1.4726e-02,  3.7864e-02, -4.1027e-02]],\n",
            "\n",
            "         [[ 4.1628e-03, -3.8819e-02,  3.9909e-02],\n",
            "          [-3.0494e-02, -3.3870e-02,  1.6592e-03],\n",
            "          [ 3.9099e-02, -2.9516e-02, -3.0529e-02]]]], device='cuda:0')\n",
            "NPF_C2.bias Parameter containing:\n",
            "tensor([-0.0177, -0.0154, -0.0084,  0.0219, -0.0279,  0.0248,  0.0016,  0.0328,\n",
            "         0.0041,  0.0395,  0.0183,  0.0270,  0.0130,  0.0198,  0.0340, -0.0264,\n",
            "        -0.0213, -0.0337, -0.0077, -0.0406,  0.0023, -0.0206, -0.0218,  0.0108,\n",
            "        -0.0166, -0.0043, -0.0244,  0.0065, -0.0128, -0.0366, -0.0349,  0.0171,\n",
            "         0.0324, -0.0299,  0.0117, -0.0097, -0.0255, -0.0255,  0.0183,  0.0414,\n",
            "         0.0230,  0.0124, -0.0026,  0.0354,  0.0296, -0.0295,  0.0338,  0.0335,\n",
            "         0.0112, -0.0382, -0.0412, -0.0043,  0.0043, -0.0024,  0.0056,  0.0163,\n",
            "        -0.0060,  0.0163,  0.0080, -0.0162, -0.0383,  0.0389, -0.0328, -0.0289],\n",
            "       device='cuda:0')\n",
            "NPF_C3.weight Parameter containing:\n",
            "tensor([[[[ 2.7964e-02, -1.4258e-02,  4.0640e-02],\n",
            "          [-6.4360e-03,  3.4412e-02,  3.0588e-02],\n",
            "          [ 3.5793e-02,  3.7687e-02,  9.4342e-03]],\n",
            "\n",
            "         [[-3.9900e-03, -4.0618e-02,  2.5096e-02],\n",
            "          [-1.3614e-02,  3.4912e-02, -2.6618e-02],\n",
            "          [ 2.2629e-02,  5.6354e-03,  1.1217e-02]],\n",
            "\n",
            "         [[-6.5209e-03,  5.9811e-03, -1.5307e-02],\n",
            "          [-1.0775e-02,  2.3972e-02, -3.9299e-02],\n",
            "          [-3.8561e-02,  2.0907e-02,  4.9464e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.9694e-02,  4.0515e-02,  1.5700e-02],\n",
            "          [ 1.7462e-02, -3.6028e-02,  3.1087e-02],\n",
            "          [ 1.9048e-02,  3.1775e-02,  6.4598e-03]],\n",
            "\n",
            "         [[ 2.7395e-02, -3.8971e-03,  2.9767e-02],\n",
            "          [-6.3219e-03,  2.0025e-02,  1.1343e-02],\n",
            "          [ 3.1056e-02, -1.7743e-02, -3.5663e-02]],\n",
            "\n",
            "         [[-1.3631e-03,  2.5367e-02,  1.9388e-02],\n",
            "          [ 9.2037e-04,  3.1117e-03, -2.8092e-02],\n",
            "          [ 1.0733e-02, -1.5830e-02,  1.8856e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3618e-02,  1.6402e-02,  2.7680e-02],\n",
            "          [-2.9454e-03,  9.0999e-03, -4.0935e-02],\n",
            "          [ 7.2690e-03,  5.7285e-03,  2.2135e-02]],\n",
            "\n",
            "         [[ 8.1404e-04, -1.3830e-02,  2.4567e-02],\n",
            "          [-5.7046e-03,  1.2211e-02, -1.1058e-02],\n",
            "          [ 1.7042e-02, -2.1791e-02, -2.0363e-02]],\n",
            "\n",
            "         [[ 4.0726e-02, -1.6742e-02, -2.7742e-02],\n",
            "          [-2.9966e-02, -3.9999e-02, -9.2839e-03],\n",
            "          [ 2.7488e-02,  4.0374e-02,  3.3610e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.7650e-04,  1.1935e-02, -1.8034e-02],\n",
            "          [ 4.9914e-03,  1.7028e-02, -2.1654e-02],\n",
            "          [-4.2637e-03,  3.5707e-02, -7.2846e-04]],\n",
            "\n",
            "         [[ 3.1115e-02,  1.7409e-02, -1.2101e-02],\n",
            "          [-2.9670e-02, -3.8161e-02, -1.9423e-02],\n",
            "          [ 2.2065e-02, -1.8369e-02,  3.4714e-02]],\n",
            "\n",
            "         [[ 2.9645e-02, -3.8235e-02,  5.5455e-03],\n",
            "          [ 3.1655e-02,  7.9072e-04, -3.1601e-02],\n",
            "          [ 1.2379e-03, -3.9337e-02, -7.9931e-03]]],\n",
            "\n",
            "\n",
            "        [[[-2.1406e-02,  2.3093e-02,  3.1546e-02],\n",
            "          [-2.1994e-02, -4.0008e-02, -3.5435e-03],\n",
            "          [ 2.9838e-02,  2.2146e-02,  2.3794e-02]],\n",
            "\n",
            "         [[ 1.9661e-02,  1.6452e-02,  1.9968e-02],\n",
            "          [ 4.4264e-03, -4.0699e-02, -8.6403e-03],\n",
            "          [ 3.0221e-02, -3.3615e-02,  1.0790e-02]],\n",
            "\n",
            "         [[ 1.9644e-02, -3.7969e-02,  4.3768e-03],\n",
            "          [ 3.4995e-02, -3.0314e-02, -3.7152e-02],\n",
            "          [ 1.9988e-02,  2.9717e-02,  8.5722e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.0374e-02,  4.1600e-02,  2.8022e-02],\n",
            "          [ 3.6694e-02,  1.3379e-02, -2.6019e-02],\n",
            "          [ 5.4211e-03,  4.0412e-02,  1.8356e-02]],\n",
            "\n",
            "         [[-2.3640e-02, -3.9205e-02, -1.1693e-03],\n",
            "          [-6.7535e-03, -4.1143e-02,  1.5097e-02],\n",
            "          [ 2.0514e-02, -1.9466e-02,  1.4203e-02]],\n",
            "\n",
            "         [[-3.3424e-02, -2.1709e-02,  8.0118e-04],\n",
            "          [ 2.7743e-02, -2.7193e-02,  2.0645e-02],\n",
            "          [-3.6155e-02,  4.5968e-03, -3.3871e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-7.3697e-04,  3.8861e-02,  1.2079e-02],\n",
            "          [-6.2368e-03,  3.1688e-03, -3.8680e-02],\n",
            "          [-3.3131e-02, -3.0931e-03,  2.0324e-02]],\n",
            "\n",
            "         [[-3.6622e-02, -5.5431e-03, -1.1966e-02],\n",
            "          [ 1.9755e-02,  3.2430e-02,  1.0582e-03],\n",
            "          [-1.2669e-02,  3.3010e-02, -2.0602e-02]],\n",
            "\n",
            "         [[ 1.8051e-02,  1.7199e-02,  2.3979e-02],\n",
            "          [-7.1250e-03, -3.3461e-02, -2.7502e-02],\n",
            "          [ 2.3725e-02,  4.3231e-03, -2.6217e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1319e-03,  3.5811e-02, -3.8871e-02],\n",
            "          [-1.1978e-02,  1.6480e-02, -2.1538e-03],\n",
            "          [ 7.3885e-03,  2.2238e-02,  1.7665e-02]],\n",
            "\n",
            "         [[-2.4053e-02, -3.0802e-02,  4.1223e-02],\n",
            "          [ 1.5771e-02, -1.2075e-02, -3.2030e-02],\n",
            "          [-2.6104e-02,  3.6451e-02,  5.9892e-03]],\n",
            "\n",
            "         [[ 3.0297e-02, -8.1001e-03,  3.7775e-02],\n",
            "          [-3.8234e-02, -2.3163e-02,  1.9187e-02],\n",
            "          [ 3.6559e-02,  1.4206e-02, -4.0266e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2005e-02,  2.1562e-02,  1.6410e-02],\n",
            "          [-2.3498e-02, -2.8166e-03,  1.7308e-02],\n",
            "          [-2.0041e-02,  4.0335e-02, -2.9493e-02]],\n",
            "\n",
            "         [[ 5.0690e-04,  2.0888e-02, -1.2477e-02],\n",
            "          [-3.4167e-02,  1.1532e-02, -2.4002e-02],\n",
            "          [-2.0033e-03,  4.7282e-03, -3.0495e-02]],\n",
            "\n",
            "         [[ 2.9176e-03, -2.5673e-02,  4.0826e-03],\n",
            "          [ 6.8617e-03, -2.3629e-02, -2.0861e-02],\n",
            "          [-3.3453e-02, -9.5845e-03, -3.8751e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.9466e-02,  3.3056e-02,  1.9936e-02],\n",
            "          [ 5.0624e-03,  3.0220e-02,  1.6363e-02],\n",
            "          [-3.6786e-02, -4.8099e-03,  3.4955e-02]],\n",
            "\n",
            "         [[ 3.3082e-02,  3.7240e-02, -1.7191e-02],\n",
            "          [-4.1342e-02, -1.1075e-02,  3.5222e-02],\n",
            "          [-1.7428e-03,  8.3491e-03,  1.4344e-03]],\n",
            "\n",
            "         [[-8.0141e-03, -2.8263e-02, -1.3644e-03],\n",
            "          [-4.0597e-02,  3.9626e-02,  3.6791e-02],\n",
            "          [-1.3819e-02,  2.4887e-02, -1.0969e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.3566e-02, -6.0411e-03, -1.1267e-02],\n",
            "          [-1.2250e-02,  8.3967e-03,  1.2664e-02],\n",
            "          [-6.0466e-03,  4.0174e-03,  3.5914e-03]],\n",
            "\n",
            "         [[ 1.9744e-02,  1.3591e-03,  2.8004e-02],\n",
            "          [ 2.6026e-02, -3.9161e-02, -1.0894e-02],\n",
            "          [-1.3921e-02, -3.9964e-02, -3.3850e-02]],\n",
            "\n",
            "         [[-2.6803e-02,  5.9273e-03,  2.7128e-02],\n",
            "          [-2.1382e-02, -4.3930e-03, -3.1639e-02],\n",
            "          [-2.9629e-02, -6.7011e-05, -1.7125e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.9256e-02, -1.8403e-02,  2.2623e-02],\n",
            "          [ 1.4056e-04, -3.3285e-02,  2.9321e-03],\n",
            "          [-2.2694e-02, -1.8592e-02,  8.3035e-03]],\n",
            "\n",
            "         [[ 3.9342e-02, -2.5095e-02, -2.9747e-02],\n",
            "          [ 4.1379e-02, -2.1784e-02,  4.1285e-02],\n",
            "          [-3.1189e-02, -3.9926e-02,  5.0639e-03]],\n",
            "\n",
            "         [[-3.1951e-02,  2.6050e-02, -1.8915e-02],\n",
            "          [ 2.7522e-02,  3.9140e-02,  3.2991e-02],\n",
            "          [ 3.2530e-02, -2.9558e-02,  1.7301e-03]]]], device='cuda:0')\n",
            "NPF_C3.bias Parameter containing:\n",
            "tensor([ 3.9334e-05,  3.2020e-02,  1.0248e-02,  1.8496e-02,  1.9509e-02,\n",
            "         4.5388e-03,  1.2364e-02,  3.1531e-02,  3.2969e-02,  1.7468e-02,\n",
            "         2.6937e-02, -1.6519e-02, -3.2731e-02, -2.4987e-02, -2.4944e-02,\n",
            "        -7.0629e-03,  3.4070e-02,  9.9553e-03,  1.9015e-03,  2.4769e-02,\n",
            "         1.1476e-02, -2.7237e-02,  1.0295e-03,  1.5450e-02,  1.3191e-02,\n",
            "         4.8306e-03, -3.9031e-02, -4.5210e-03,  1.2507e-02, -1.3457e-02,\n",
            "         8.2698e-03,  1.5339e-02, -1.8239e-02,  5.3797e-03, -3.7862e-02,\n",
            "         2.5797e-02, -1.1372e-02,  2.6838e-02,  1.6744e-02, -1.8637e-02,\n",
            "        -2.2878e-03,  1.4239e-03,  2.9046e-02,  1.2103e-02, -6.1151e-03,\n",
            "         3.1155e-02, -7.9520e-03, -7.0102e-03,  3.5401e-02, -3.4902e-03,\n",
            "         3.0340e-02,  1.3760e-02,  3.9065e-02,  9.4195e-03, -3.2208e-02,\n",
            "        -3.1558e-02,  3.0383e-02,  3.1279e-02, -3.4103e-03,  2.4346e-02,\n",
            "        -1.5568e-02, -1.1867e-02, -8.7517e-03,  2.3896e-02, -1.7156e-02,\n",
            "         2.8070e-02, -3.2973e-02,  2.7324e-02,  3.9937e-02, -4.0962e-02,\n",
            "         1.4773e-02,  3.6188e-02, -2.2469e-02, -2.9435e-02,  1.3103e-02,\n",
            "        -1.6624e-03, -2.9834e-02, -4.0356e-02,  2.1805e-02, -4.6286e-03,\n",
            "        -2.0130e-02, -1.1196e-03,  2.0735e-02, -3.6496e-02,  1.8620e-02,\n",
            "         2.9400e-02, -3.7292e-02,  1.9416e-02,  4.0859e-03,  3.2973e-03,\n",
            "        -3.9134e-02,  2.7848e-02,  1.5195e-02, -1.3676e-02, -9.4028e-03,\n",
            "         2.5965e-02, -2.3699e-02,  3.7911e-02, -1.1878e-02,  8.9494e-03,\n",
            "        -2.6671e-02, -2.2572e-03,  2.1223e-02,  1.9284e-02,  4.1343e-02,\n",
            "        -1.4305e-02,  1.6663e-02, -1.7826e-02, -2.7934e-02,  6.2691e-03,\n",
            "         3.4998e-02, -3.4677e-02,  2.3974e-02, -1.1317e-02,  2.4374e-02,\n",
            "        -6.2491e-03,  3.9319e-02, -2.1692e-02, -7.7318e-03, -1.1863e-02,\n",
            "        -2.2265e-02,  1.6739e-02, -9.3299e-03, -7.1998e-03, -2.6129e-02,\n",
            "        -1.2814e-02, -1.7375e-02, -3.3522e-02], device='cuda:0')\n",
            "NPF_C4.weight Parameter containing:\n",
            "tensor([[[[ 2.0371e-02,  2.9366e-02,  5.6723e-04],\n",
            "          [-2.3028e-04,  2.5723e-02,  1.7856e-03],\n",
            "          [-9.5709e-03, -2.2411e-02, -4.9527e-03]],\n",
            "\n",
            "         [[-2.1369e-02,  1.2335e-02, -1.3031e-02],\n",
            "          [ 2.0297e-02,  1.0076e-02, -1.4825e-02],\n",
            "          [-8.7485e-03,  1.9612e-03, -2.0883e-02]],\n",
            "\n",
            "         [[-2.8318e-02,  1.2317e-02, -1.5886e-02],\n",
            "          [-5.4808e-03, -1.9719e-02, -2.3132e-02],\n",
            "          [ 3.0672e-03, -2.2396e-02,  2.2666e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6879e-02, -6.5732e-04, -7.3133e-03],\n",
            "          [ 4.6296e-03,  2.0565e-02,  3.9215e-03],\n",
            "          [-2.2803e-02, -2.4928e-04,  1.6335e-02]],\n",
            "\n",
            "         [[-1.2904e-02,  1.9270e-02,  2.3459e-02],\n",
            "          [ 1.8793e-02, -2.8703e-02, -2.0345e-03],\n",
            "          [-6.2186e-03, -2.8327e-03, -1.5454e-02]],\n",
            "\n",
            "         [[-5.3830e-03,  5.0183e-05, -3.4396e-03],\n",
            "          [-2.0566e-02,  1.4086e-02, -2.2225e-02],\n",
            "          [ 2.3416e-02,  5.7609e-03,  2.9188e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.7112e-02, -2.5985e-03, -2.1115e-02],\n",
            "          [-2.4310e-02, -2.5098e-02,  1.8037e-02],\n",
            "          [ 2.7847e-02, -1.9314e-02,  8.5644e-03]],\n",
            "\n",
            "         [[ 1.0178e-02,  4.8181e-03,  1.9158e-02],\n",
            "          [ 7.4500e-03, -1.0284e-02,  2.2824e-02],\n",
            "          [-6.2708e-03, -2.7865e-02, -2.5806e-02]],\n",
            "\n",
            "         [[ 9.4741e-04,  2.7920e-02, -7.7941e-03],\n",
            "          [-1.9723e-02, -2.2342e-02,  8.3604e-03],\n",
            "          [-8.9683e-03, -1.0408e-02, -1.1677e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7584e-02,  2.8878e-02, -7.6429e-03],\n",
            "          [ 2.6966e-02, -1.0924e-02, -2.5849e-02],\n",
            "          [ 4.9638e-03, -1.8870e-02, -1.3405e-02]],\n",
            "\n",
            "         [[-8.7446e-03,  6.8953e-03, -1.9061e-02],\n",
            "          [-2.0679e-02, -2.4272e-02,  2.5117e-02],\n",
            "          [-2.0867e-02,  6.2490e-03, -7.9333e-03]],\n",
            "\n",
            "         [[ 2.8818e-02, -6.3632e-03,  2.7174e-02],\n",
            "          [ 2.7470e-03, -3.1414e-03, -1.0995e-02],\n",
            "          [ 8.3427e-03, -2.0543e-02,  8.8460e-03]]],\n",
            "\n",
            "\n",
            "        [[[-5.2246e-03, -1.1179e-02, -3.3132e-03],\n",
            "          [ 2.9368e-02, -2.6744e-02, -5.6882e-03],\n",
            "          [ 9.3046e-03, -3.1545e-03, -2.7793e-02]],\n",
            "\n",
            "         [[ 1.7291e-02,  1.5052e-02,  2.1028e-02],\n",
            "          [ 4.4790e-03,  1.6760e-02, -1.0324e-02],\n",
            "          [ 1.1675e-02, -9.9784e-03,  1.6773e-02]],\n",
            "\n",
            "         [[-2.2413e-02, -1.6915e-02,  1.7619e-02],\n",
            "          [-2.7371e-02,  8.9296e-03,  3.8491e-03],\n",
            "          [ 1.3897e-02,  1.5760e-02,  2.1224e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8354e-03,  1.3885e-02,  6.5864e-03],\n",
            "          [ 1.2424e-02, -7.3867e-03,  2.5766e-03],\n",
            "          [-1.5892e-02,  2.4031e-02, -2.8694e-02]],\n",
            "\n",
            "         [[-2.7957e-03, -1.4309e-02,  6.5412e-03],\n",
            "          [-2.1657e-02,  2.4818e-03, -7.9125e-03],\n",
            "          [-2.7373e-02,  7.1716e-03,  4.6227e-03]],\n",
            "\n",
            "         [[ 7.9520e-03, -2.3439e-02, -1.5321e-02],\n",
            "          [ 1.7384e-02,  1.2488e-02, -1.6774e-02],\n",
            "          [ 2.8079e-02,  5.0753e-03, -2.5537e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8584e-02, -2.5551e-02, -1.6184e-02],\n",
            "          [-2.8825e-02, -1.9226e-02, -1.3303e-02],\n",
            "          [ 2.6902e-02, -2.0712e-02, -2.6141e-02]],\n",
            "\n",
            "         [[-2.6779e-02,  2.7673e-02,  1.5814e-02],\n",
            "          [ 4.1666e-04,  4.9395e-03,  2.8764e-02],\n",
            "          [-1.5150e-02,  7.0400e-03, -2.6306e-02]],\n",
            "\n",
            "         [[ 7.3209e-03,  2.2140e-02,  5.7249e-04],\n",
            "          [-2.3913e-02,  5.9633e-03, -1.6602e-02],\n",
            "          [ 2.1585e-02, -2.4239e-02, -1.6952e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7418e-02, -2.4630e-02, -1.0397e-02],\n",
            "          [-1.4418e-02, -2.1527e-02, -5.4219e-03],\n",
            "          [-1.8274e-03, -9.2246e-03,  2.2469e-02]],\n",
            "\n",
            "         [[ 1.7511e-03, -1.2887e-02,  2.4699e-02],\n",
            "          [-8.9034e-03, -7.7052e-03, -2.3588e-02],\n",
            "          [ 1.9349e-02, -1.0436e-02, -1.0437e-03]],\n",
            "\n",
            "         [[ 2.6038e-02, -1.5518e-02,  2.5768e-02],\n",
            "          [-1.8447e-02,  9.6301e-03, -2.8336e-02],\n",
            "          [-9.8251e-05, -6.7263e-03,  7.9410e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9911e-02, -2.4228e-02, -1.3800e-02],\n",
            "          [-1.5150e-02, -1.1877e-02,  3.0183e-03],\n",
            "          [ 7.3772e-03, -7.0166e-03, -2.0739e-02]],\n",
            "\n",
            "         [[-2.4704e-02,  6.5812e-03, -1.6508e-02],\n",
            "          [ 5.4046e-03,  1.9260e-02, -1.3667e-02],\n",
            "          [ 2.1882e-04, -6.9893e-03, -1.0153e-02]],\n",
            "\n",
            "         [[ 1.1859e-02,  2.1625e-02, -1.0004e-02],\n",
            "          [ 2.6110e-02,  2.6414e-02, -1.4471e-02],\n",
            "          [-2.4016e-03,  8.1579e-03,  1.2462e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8600e-02,  2.6413e-02,  7.2234e-03],\n",
            "          [-2.0334e-02, -7.8676e-03,  2.6492e-02],\n",
            "          [ 1.3931e-02, -1.1665e-02, -2.0343e-02]],\n",
            "\n",
            "         [[-5.5493e-03,  1.4370e-02,  1.4061e-02],\n",
            "          [ 2.0525e-02, -1.9774e-02, -1.7299e-02],\n",
            "          [-6.9514e-05, -2.3270e-02,  1.3680e-02]],\n",
            "\n",
            "         [[-1.4865e-02,  2.2148e-02,  8.6107e-03],\n",
            "          [-1.0392e-02, -1.8661e-02,  2.2275e-02],\n",
            "          [ 2.1634e-02,  2.7876e-02, -1.1388e-02]]],\n",
            "\n",
            "\n",
            "        [[[-7.9545e-03, -2.6297e-02,  2.3686e-02],\n",
            "          [-1.6311e-02, -1.0122e-02, -1.8776e-02],\n",
            "          [ 1.1145e-02, -9.1403e-03,  7.7255e-05]],\n",
            "\n",
            "         [[-3.8423e-03, -2.2878e-02, -2.0976e-02],\n",
            "          [-9.6178e-03,  5.0834e-03,  8.2321e-04],\n",
            "          [ 1.8336e-02,  2.8831e-02, -1.2464e-02]],\n",
            "\n",
            "         [[ 2.0929e-02,  1.5928e-02,  2.5535e-02],\n",
            "          [ 2.1138e-03,  2.6109e-02,  1.2691e-02],\n",
            "          [-1.8036e-02, -9.0674e-03,  1.0521e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.3000e-04,  8.5512e-03, -2.6620e-02],\n",
            "          [-1.8205e-02, -1.3702e-02, -2.5862e-02],\n",
            "          [-2.8032e-02, -5.9691e-03, -2.7248e-03]],\n",
            "\n",
            "         [[-2.5383e-02, -1.5387e-02, -8.1234e-03],\n",
            "          [ 1.2977e-02, -2.4731e-02, -2.0188e-02],\n",
            "          [ 1.1842e-02,  1.7818e-02, -1.0922e-02]],\n",
            "\n",
            "         [[-5.4602e-03, -2.5708e-03, -1.1811e-02],\n",
            "          [ 1.0543e-02, -1.6501e-02,  1.5387e-02],\n",
            "          [ 8.6818e-03,  1.7294e-03,  2.9350e-02]]]], device='cuda:0')\n",
            "NPF_C4.bias Parameter containing:\n",
            "tensor([ 0.0137, -0.0204, -0.0101, -0.0151,  0.0094, -0.0185,  0.0122, -0.0271,\n",
            "         0.0293,  0.0181, -0.0288, -0.0119,  0.0091,  0.0265, -0.0165, -0.0045,\n",
            "         0.0139, -0.0147, -0.0034,  0.0294, -0.0287,  0.0162, -0.0068, -0.0136,\n",
            "        -0.0033, -0.0008, -0.0013, -0.0058,  0.0005, -0.0115,  0.0103,  0.0061,\n",
            "         0.0011, -0.0180,  0.0002,  0.0090, -0.0087,  0.0015,  0.0237,  0.0077,\n",
            "        -0.0043, -0.0119,  0.0247, -0.0264, -0.0243, -0.0017, -0.0016, -0.0285,\n",
            "         0.0210, -0.0050,  0.0087, -0.0084, -0.0071, -0.0145, -0.0032, -0.0111,\n",
            "         0.0207, -0.0062,  0.0122,  0.0273, -0.0169, -0.0266,  0.0276, -0.0258,\n",
            "        -0.0126,  0.0076,  0.0008,  0.0241, -0.0265, -0.0149,  0.0250, -0.0222,\n",
            "         0.0045, -0.0278, -0.0078, -0.0152,  0.0214,  0.0180,  0.0250, -0.0067,\n",
            "         0.0139, -0.0149, -0.0186, -0.0084, -0.0173,  0.0284, -0.0111, -0.0144,\n",
            "        -0.0169,  0.0230, -0.0067, -0.0052, -0.0242,  0.0277, -0.0127, -0.0236,\n",
            "        -0.0108, -0.0114,  0.0030, -0.0238,  0.0287,  0.0240,  0.0073, -0.0236,\n",
            "        -0.0171,  0.0158,  0.0034,  0.0271, -0.0106, -0.0126, -0.0136, -0.0280,\n",
            "        -0.0137, -0.0210, -0.0213, -0.0256,  0.0253, -0.0180, -0.0215,  0.0198,\n",
            "        -0.0254, -0.0248, -0.0231, -0.0003, -0.0215,  0.0053,  0.0088, -0.0200],\n",
            "       device='cuda:0')\n",
            "NPF_D1.weight Parameter containing:\n",
            "tensor([[-0.0008, -0.0017,  0.0014,  ...,  0.0025,  0.0022, -0.0017],\n",
            "        [ 0.0024, -0.0001, -0.0024,  ...,  0.0025, -0.0026, -0.0016],\n",
            "        [ 0.0015, -0.0026, -0.0003,  ..., -0.0008, -0.0014,  0.0009],\n",
            "        ...,\n",
            "        [-0.0006, -0.0011,  0.0014,  ...,  0.0011, -0.0025,  0.0009],\n",
            "        [-0.0026,  0.0005,  0.0020,  ...,  0.0012, -0.0015, -0.0011],\n",
            "        [-0.0014, -0.0022,  0.0024,  ...,  0.0016,  0.0024,  0.0021]],\n",
            "       device='cuda:0')\n",
            "NPF_D1.bias Parameter containing:\n",
            "tensor([ 4.2381e-04,  6.3669e-04,  1.6792e-04, -4.7863e-04, -1.8585e-04,\n",
            "         2.6467e-03, -1.0965e-03,  2.3995e-03, -2.1861e-03,  1.2774e-03,\n",
            "        -2.6267e-03,  1.4881e-03, -2.4879e-03, -2.0339e-04, -1.8089e-03,\n",
            "        -2.2518e-03,  1.3348e-03, -5.2184e-04,  2.6268e-04,  6.9110e-05,\n",
            "        -1.8144e-03,  8.9410e-04,  2.0638e-03,  1.5168e-03, -2.6475e-03,\n",
            "         2.5728e-03, -3.0734e-04, -2.3725e-03, -1.1090e-03, -2.2503e-03,\n",
            "         2.2998e-03,  7.8752e-04, -1.7956e-03, -1.0386e-03, -2.4257e-03,\n",
            "         2.2913e-03, -9.8518e-04, -1.3360e-03, -7.6197e-04,  4.4794e-04,\n",
            "         2.4711e-03, -5.5210e-04,  2.0021e-03, -1.2849e-03, -2.5338e-03,\n",
            "        -1.0677e-03, -2.2408e-03, -2.0894e-04,  8.0408e-04,  1.1650e-03,\n",
            "         2.7215e-03,  1.5429e-03, -2.7524e-03, -6.4700e-04, -2.7212e-03,\n",
            "        -1.7297e-03,  1.5433e-03,  3.4041e-04,  2.0696e-03,  1.6445e-03,\n",
            "        -1.6894e-03, -2.1654e-03,  9.3084e-04, -1.6646e-03,  1.9251e-03,\n",
            "        -2.6827e-03, -2.8796e-04, -4.0230e-04, -2.4846e-03, -2.5744e-03,\n",
            "         2.5201e-03,  3.5431e-04,  1.8965e-03, -1.6455e-04,  2.5687e-04,\n",
            "        -1.4282e-03, -1.5757e-03, -9.4774e-04, -1.8050e-03, -2.7233e-03,\n",
            "        -2.7070e-03, -2.1912e-03, -7.9485e-05,  1.0748e-03,  2.0624e-03,\n",
            "         1.1190e-04,  5.2145e-04, -1.3550e-03, -5.7670e-04, -2.2743e-03,\n",
            "         2.6369e-03, -2.3244e-03, -1.7664e-03,  2.7311e-03,  1.6093e-03,\n",
            "        -2.3789e-03,  1.9175e-03, -7.8933e-06, -6.0744e-04,  1.8881e-04,\n",
            "        -6.8827e-04,  2.6160e-03, -1.7735e-04,  1.1211e-03, -1.9872e-03,\n",
            "        -2.3313e-04, -2.2866e-03, -2.1566e-04, -1.1760e-03,  1.2144e-03,\n",
            "         2.0194e-03, -1.2600e-03,  7.7531e-04, -1.5862e-03, -2.5931e-04,\n",
            "         2.6036e-03, -1.5199e-03, -2.2965e-03,  2.0166e-03, -1.1569e-03,\n",
            "         1.7330e-03, -1.9029e-03, -1.0759e-03, -2.1008e-03,  1.5300e-03,\n",
            "         1.5855e-03, -2.6084e-03, -5.7586e-04, -6.4429e-04, -2.3820e-03,\n",
            "        -2.2338e-03,  1.8480e-04, -8.0471e-04, -1.2572e-03,  1.6492e-03,\n",
            "         6.9357e-04,  1.7454e-03,  2.5374e-03, -1.2470e-03, -4.4669e-04,\n",
            "         4.8638e-04, -2.0177e-04, -8.3812e-05,  1.0899e-03, -7.6644e-04,\n",
            "         5.2766e-04,  3.1983e-04, -2.8828e-04, -1.3098e-03,  1.3881e-03,\n",
            "        -1.9326e-03, -1.4517e-03,  1.1955e-03,  2.0040e-03,  6.8689e-04,\n",
            "        -1.2166e-03, -3.4795e-04, -7.8156e-05,  1.2742e-03, -2.4727e-03,\n",
            "        -1.9939e-03,  5.9816e-04, -1.6330e-03,  2.4431e-03,  1.4985e-03,\n",
            "         6.7411e-04,  1.8391e-03, -7.6327e-04,  1.5217e-03, -2.0517e-03,\n",
            "        -1.1564e-03, -1.6793e-03,  2.1213e-03,  1.1693e-03,  1.5846e-03,\n",
            "        -1.0743e-03,  7.7726e-04, -1.1152e-03, -2.5255e-03,  2.3981e-03,\n",
            "         1.3346e-03,  2.1901e-03, -1.6430e-03, -2.3493e-04,  1.5688e-03,\n",
            "         6.0778e-04,  1.0380e-03,  2.2601e-03, -4.4303e-04, -2.1110e-03,\n",
            "        -9.3645e-04, -2.7530e-03, -2.0961e-03, -5.8628e-04,  4.1795e-04,\n",
            "        -2.5625e-03,  2.1970e-03,  8.8361e-04,  1.8522e-03, -1.5451e-03,\n",
            "         2.5454e-03, -2.6268e-03, -2.4506e-03,  1.2301e-03,  1.2361e-03,\n",
            "         1.4738e-03,  1.9664e-03,  2.5124e-03, -1.5915e-03, -9.4372e-05,\n",
            "         1.8074e-03,  2.4719e-03,  5.2893e-04, -7.7887e-04, -2.6860e-04,\n",
            "        -2.5095e-03, -1.0351e-03,  1.9813e-03,  1.0569e-03,  2.4972e-03,\n",
            "         2.6966e-03,  2.4028e-04,  1.0813e-03,  1.5315e-03,  1.6258e-03,\n",
            "        -1.0556e-03, -2.0518e-03,  2.6927e-04, -1.7547e-03,  2.4715e-03,\n",
            "         9.5889e-04,  2.3967e-03,  1.4629e-03,  1.6212e-03,  7.7731e-04,\n",
            "        -1.2734e-03, -1.2658e-03, -2.7010e-03, -2.5887e-03, -1.4514e-03,\n",
            "        -1.7323e-03, -2.5461e-03, -1.7107e-03,  2.4143e-03,  2.0808e-04,\n",
            "         1.0302e-03, -2.3519e-03,  1.4558e-03,  3.9802e-04, -1.6821e-03,\n",
            "        -1.4050e-03, -1.1211e-03,  7.4840e-04, -2.3959e-03, -1.1967e-03,\n",
            "         1.2013e-03], device='cuda:0')\n",
            "NPF_D2.weight Parameter containing:\n",
            "tensor([[ 0.0548,  0.0055, -0.0173,  ...,  0.0355,  0.0413, -0.0314],\n",
            "        [-0.0383, -0.0123, -0.0289,  ..., -0.0085, -0.0120, -0.0243],\n",
            "        [ 0.0610,  0.0129, -0.0194,  ..., -0.0605,  0.0478,  0.0328],\n",
            "        ...,\n",
            "        [ 0.0133, -0.0540, -0.0280,  ...,  0.0393, -0.0283, -0.0169],\n",
            "        [ 0.0576, -0.0217,  0.0077,  ..., -0.0422,  0.0159, -0.0040],\n",
            "        [ 0.0408, -0.0072,  0.0035,  ..., -0.0166, -0.0371, -0.0158]],\n",
            "       device='cuda:0')\n",
            "NPF_D2.bias Parameter containing:\n",
            "tensor([-0.0054,  0.0436, -0.0372,  0.0399, -0.0412, -0.0407, -0.0346, -0.0198,\n",
            "         0.0248, -0.0451,  0.0398, -0.0401, -0.0415, -0.0012, -0.0124,  0.0202,\n",
            "        -0.0455,  0.0025, -0.0480, -0.0366, -0.0605, -0.0133, -0.0560,  0.0253,\n",
            "         0.0362, -0.0335, -0.0042, -0.0327,  0.0216,  0.0586,  0.0450, -0.0609,\n",
            "         0.0348,  0.0567, -0.0416, -0.0068, -0.0214, -0.0288,  0.0291, -0.0288,\n",
            "        -0.0228,  0.0094, -0.0417,  0.0507,  0.0305,  0.0190, -0.0134, -0.0237,\n",
            "         0.0267, -0.0351, -0.0405, -0.0085, -0.0452,  0.0361, -0.0002, -0.0017,\n",
            "        -0.0191, -0.0280,  0.0312, -0.0420,  0.0563, -0.0093,  0.0494, -0.0348,\n",
            "        -0.0205,  0.0223,  0.0344,  0.0013, -0.0192, -0.0207,  0.0529, -0.0036,\n",
            "        -0.0080,  0.0267, -0.0541,  0.0483,  0.0572,  0.0506, -0.0059,  0.0355,\n",
            "         0.0238, -0.0340, -0.0443,  0.0096, -0.0479,  0.0205,  0.0404, -0.0611,\n",
            "        -0.0379, -0.0078, -0.0282, -0.0387, -0.0350, -0.0328, -0.0086, -0.0530,\n",
            "         0.0300,  0.0102,  0.0465, -0.0300,  0.0057,  0.0478,  0.0350,  0.0252,\n",
            "        -0.0097, -0.0434,  0.0069, -0.0386,  0.0071, -0.0442, -0.0287, -0.0482,\n",
            "         0.0215, -0.0154,  0.0370, -0.0294, -0.0158, -0.0106, -0.0195,  0.0083,\n",
            "        -0.0482, -0.0442,  0.0549, -0.0336,  0.0104, -0.0251, -0.0074,  0.0509,\n",
            "         0.0455,  0.0343, -0.0322,  0.0248,  0.0011, -0.0500, -0.0516,  0.0551,\n",
            "         0.0310,  0.0070, -0.0512,  0.0206,  0.0226, -0.0088, -0.0022, -0.0607,\n",
            "         0.0195, -0.0266, -0.0248,  0.0561, -0.0356, -0.0392, -0.0256,  0.0311,\n",
            "         0.0475,  0.0565,  0.0365, -0.0190, -0.0072, -0.0391,  0.0094, -0.0346,\n",
            "         0.0392,  0.0129, -0.0118, -0.0316,  0.0455,  0.0108,  0.0489, -0.0218,\n",
            "         0.0317,  0.0152, -0.0542, -0.0532, -0.0208,  0.0338, -0.0377,  0.0178,\n",
            "        -0.0343, -0.0304, -0.0119, -0.0556,  0.0549, -0.0142, -0.0339, -0.0219,\n",
            "         0.0270,  0.0254,  0.0279, -0.0285, -0.0435, -0.0624,  0.0210, -0.0164,\n",
            "        -0.0106, -0.0144, -0.0201, -0.0099,  0.0128,  0.0404,  0.0176, -0.0052,\n",
            "        -0.0574,  0.0240, -0.0339,  0.0285,  0.0616, -0.0188, -0.0533, -0.0526,\n",
            "         0.0101,  0.0582,  0.0477,  0.0560, -0.0205, -0.0323,  0.0323,  0.0064,\n",
            "        -0.0387,  0.0220, -0.0007, -0.0289, -0.0328,  0.0551, -0.0031,  0.0196,\n",
            "        -0.0106, -0.0261, -0.0341,  0.0105,  0.0136, -0.0010, -0.0550, -0.0505,\n",
            "         0.0051,  0.0343,  0.0582,  0.0029, -0.0136, -0.0310,  0.0122,  0.0123,\n",
            "         0.0237, -0.0338, -0.0043, -0.0002,  0.0490,  0.0339, -0.0147, -0.0243,\n",
            "        -0.0569, -0.0419, -0.0522, -0.0211, -0.0138, -0.0091,  0.0220,  0.0110],\n",
            "       device='cuda:0')\n",
            "NPV_C1.weight Parameter containing:\n",
            "tensor([[[[ 0.1397,  0.1195,  0.1305],\n",
            "          [-0.0399, -0.0212,  0.0863],\n",
            "          [ 0.1052, -0.0467, -0.0340]],\n",
            "\n",
            "         [[-0.0456, -0.0650,  0.1604],\n",
            "          [-0.0800, -0.0553, -0.1571],\n",
            "          [ 0.0502,  0.1586,  0.0630]],\n",
            "\n",
            "         [[ 0.0627,  0.0695, -0.1562],\n",
            "          [-0.0733,  0.0070,  0.0283],\n",
            "          [ 0.0936,  0.0916,  0.1129]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0221,  0.0690, -0.1078],\n",
            "          [-0.0679, -0.0322, -0.1376],\n",
            "          [ 0.0458,  0.1631, -0.1905]],\n",
            "\n",
            "         [[ 0.0455, -0.0057, -0.0026],\n",
            "          [-0.0064, -0.0585, -0.0138],\n",
            "          [ 0.0039,  0.1116, -0.1620]],\n",
            "\n",
            "         [[-0.1902,  0.0577, -0.0802],\n",
            "          [-0.1305,  0.0760,  0.1524],\n",
            "          [ 0.0461,  0.0873,  0.1867]]],\n",
            "\n",
            "\n",
            "        [[[-0.1342, -0.0936,  0.1755],\n",
            "          [ 0.0561, -0.0583, -0.0318],\n",
            "          [ 0.0938,  0.1439,  0.1216]],\n",
            "\n",
            "         [[-0.1711, -0.0103, -0.1485],\n",
            "          [-0.0844,  0.0103, -0.1425],\n",
            "          [ 0.0812, -0.1875, -0.0808]],\n",
            "\n",
            "         [[-0.0108,  0.0017, -0.1373],\n",
            "          [ 0.0127, -0.1409, -0.1729],\n",
            "          [-0.1031,  0.0216, -0.1796]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1825, -0.0839,  0.1553],\n",
            "          [ 0.1225, -0.1902,  0.1021],\n",
            "          [ 0.0086, -0.0079, -0.0869]],\n",
            "\n",
            "         [[-0.1163, -0.0005, -0.1880],\n",
            "          [-0.1695, -0.1092, -0.0289],\n",
            "          [ 0.1202,  0.1895, -0.1792]],\n",
            "\n",
            "         [[-0.0916,  0.0500,  0.0272],\n",
            "          [-0.1631, -0.0471, -0.1133],\n",
            "          [-0.1811,  0.0954, -0.1094]]],\n",
            "\n",
            "\n",
            "        [[[-0.0003,  0.0897,  0.0930],\n",
            "          [ 0.0182,  0.0146,  0.0152],\n",
            "          [ 0.0425, -0.1802, -0.0818]],\n",
            "\n",
            "         [[ 0.1188, -0.1829, -0.0368],\n",
            "          [ 0.0825, -0.1435,  0.0541],\n",
            "          [ 0.1812, -0.0301, -0.0365]],\n",
            "\n",
            "         [[-0.0856, -0.0064,  0.1272],\n",
            "          [-0.0808,  0.0998,  0.0959],\n",
            "          [-0.1838, -0.0865, -0.0682]]],\n",
            "\n",
            "\n",
            "        [[[-0.0126, -0.1170,  0.1338],\n",
            "          [-0.1890, -0.0305, -0.1460],\n",
            "          [-0.0961,  0.1789,  0.0605]],\n",
            "\n",
            "         [[ 0.1248, -0.0036,  0.1629],\n",
            "          [ 0.1555, -0.0916,  0.1532],\n",
            "          [ 0.1484, -0.0964, -0.0572]],\n",
            "\n",
            "         [[ 0.1654,  0.1381, -0.0521],\n",
            "          [-0.0630,  0.0016,  0.1834],\n",
            "          [ 0.0865, -0.1030,  0.1264]]]], device='cuda:0', requires_grad=True)\n",
            "NPV_C1.bias Parameter containing:\n",
            "tensor([-7.5618e-02, -2.0373e-02,  1.8304e-01, -2.1611e-02, -1.2243e-01,\n",
            "         1.5610e-01, -1.9741e-04,  8.8301e-02, -1.0414e-01,  8.0709e-05,\n",
            "        -9.6164e-02, -1.4557e-01, -1.0729e-01, -1.0894e-01, -4.2586e-02,\n",
            "         4.6880e-02,  1.8662e-01,  1.4753e-01,  1.2672e-02, -7.7154e-02,\n",
            "         7.9990e-02, -1.0964e-01, -1.8925e-01, -1.2568e-02, -7.8229e-02,\n",
            "        -1.3374e-01,  8.3115e-02,  9.1262e-02, -1.4894e-01, -1.3830e-02,\n",
            "         3.5733e-02, -1.0165e-01,  9.2654e-02,  8.7629e-02,  1.8462e-01,\n",
            "         1.7824e-02, -5.4415e-03,  3.8821e-02, -1.3455e-01, -4.9458e-02,\n",
            "         1.0594e-01,  1.6754e-01, -5.6996e-02, -1.1140e-01,  4.4076e-02,\n",
            "        -4.6056e-03,  1.2403e-01,  8.2572e-02,  1.1036e-01,  6.4899e-02,\n",
            "         7.1810e-02,  5.2053e-02,  6.1288e-02, -5.5573e-02, -1.1473e-02,\n",
            "        -1.8126e-01, -2.5655e-02, -9.7002e-02,  9.8776e-02, -1.3988e-01,\n",
            "         1.7408e-01,  1.7926e-01,  1.0283e-01, -1.6412e-01], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_C2.weight Parameter containing:\n",
            "tensor([[[[ 1.5103e-02,  2.9704e-02, -3.8090e-02],\n",
            "          [ 2.5149e-02,  2.1844e-02, -1.7188e-02],\n",
            "          [-7.3443e-03, -2.2542e-02, -3.3402e-02]],\n",
            "\n",
            "         [[-1.4446e-02, -3.5096e-03, -2.8695e-02],\n",
            "          [ 3.2664e-02,  2.2044e-02,  1.0436e-02],\n",
            "          [-9.0866e-03,  3.6128e-02, -1.5585e-03]],\n",
            "\n",
            "         [[-1.3931e-02, -4.0221e-02,  2.0895e-03],\n",
            "          [ 8.9072e-03,  2.1875e-02,  1.8223e-02],\n",
            "          [-3.8524e-03, -1.9920e-02, -2.9281e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.5132e-04, -2.0359e-02, -3.4813e-02],\n",
            "          [ 2.6408e-02,  2.9757e-02,  6.7718e-03],\n",
            "          [-1.4110e-02,  3.5730e-02, -1.7982e-03]],\n",
            "\n",
            "         [[ 3.3305e-02,  3.9370e-02,  2.3755e-02],\n",
            "          [-2.3260e-02,  2.8692e-02,  4.1187e-02],\n",
            "          [-9.8287e-04, -1.7502e-02,  2.6082e-02]],\n",
            "\n",
            "         [[ 3.7435e-02, -1.9915e-02,  2.4395e-02],\n",
            "          [-1.5445e-02, -3.3038e-02, -3.4764e-02],\n",
            "          [-7.5155e-04, -2.1526e-02,  3.9335e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2589e-02,  1.1960e-02,  4.0104e-02],\n",
            "          [-1.8131e-03, -2.1567e-02, -1.2250e-02],\n",
            "          [-3.8665e-02, -3.0282e-02, -9.7634e-03]],\n",
            "\n",
            "         [[-1.9655e-02, -1.6668e-02, -2.5674e-02],\n",
            "          [ 1.4575e-02, -1.7689e-02,  2.2641e-02],\n",
            "          [ 8.6435e-03, -7.3085e-03,  3.4069e-02]],\n",
            "\n",
            "         [[ 3.2154e-02,  3.3612e-03, -2.8819e-02],\n",
            "          [-3.3646e-03,  2.6050e-02, -3.5905e-02],\n",
            "          [ 3.6797e-02, -1.4488e-02, -4.0826e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7496e-02, -9.1583e-03, -3.6902e-02],\n",
            "          [ 1.2068e-02, -3.1973e-02, -4.5080e-03],\n",
            "          [-3.3742e-02, -3.2313e-02,  2.7683e-02]],\n",
            "\n",
            "         [[ 3.0089e-02,  2.0029e-02,  1.2656e-02],\n",
            "          [ 1.5767e-02,  3.1056e-02,  1.8152e-02],\n",
            "          [ 1.0229e-02, -8.6716e-03, -3.2703e-02]],\n",
            "\n",
            "         [[ 1.4152e-02,  2.8871e-02, -1.2772e-02],\n",
            "          [ 2.6291e-03, -3.2415e-02, -3.2299e-02],\n",
            "          [ 1.8615e-02, -3.9600e-02, -3.2312e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4479e-03,  1.2740e-02, -4.0161e-02],\n",
            "          [ 2.9221e-02,  4.5247e-03, -2.4546e-02],\n",
            "          [ 3.6874e-02,  3.2446e-02, -2.0972e-02]],\n",
            "\n",
            "         [[ 1.3987e-02, -2.3412e-02, -1.9761e-02],\n",
            "          [ 1.2588e-02,  2.0879e-02, -3.7725e-02],\n",
            "          [-2.6674e-02,  4.1480e-02,  9.4362e-03]],\n",
            "\n",
            "         [[-3.8428e-02,  3.6630e-03, -1.7602e-02],\n",
            "          [ 2.5857e-02,  3.3098e-02,  3.0848e-02],\n",
            "          [-1.2142e-02, -1.5178e-02, -4.1672e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.9773e-05,  1.6501e-02, -6.3147e-03],\n",
            "          [-2.1474e-02, -4.9190e-03,  3.9352e-02],\n",
            "          [-9.2543e-03,  2.9354e-02,  8.6049e-03]],\n",
            "\n",
            "         [[-3.2626e-02,  3.1470e-02, -1.8578e-02],\n",
            "          [-1.3097e-02, -1.8886e-02,  3.9942e-02],\n",
            "          [-2.9178e-02,  6.0825e-03, -3.3370e-02]],\n",
            "\n",
            "         [[-1.5172e-02, -2.5937e-02,  1.8562e-02],\n",
            "          [-2.2010e-02,  1.1067e-02, -2.1587e-02],\n",
            "          [ 7.1726e-03,  1.0282e-02,  1.5167e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 5.0240e-03,  6.6737e-03,  3.4744e-02],\n",
            "          [ 1.4027e-02,  3.5884e-02, -2.3025e-02],\n",
            "          [ 2.1495e-02, -1.0652e-02,  3.6764e-02]],\n",
            "\n",
            "         [[ 7.2008e-03, -3.3191e-02,  1.7669e-03],\n",
            "          [-1.9850e-02, -5.9930e-03, -4.9535e-03],\n",
            "          [ 4.1913e-04, -2.4296e-02,  3.0516e-02]],\n",
            "\n",
            "         [[-3.8130e-02, -1.9751e-02, -6.7004e-04],\n",
            "          [-2.8443e-02,  2.6089e-02,  3.1203e-02],\n",
            "          [-2.0108e-02,  1.4846e-02,  1.5329e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2183e-02,  3.5377e-02,  3.8792e-02],\n",
            "          [-5.1794e-04, -4.9221e-03, -1.8558e-02],\n",
            "          [-2.0215e-02,  2.6673e-02, -1.9421e-02]],\n",
            "\n",
            "         [[-2.8709e-02, -3.5574e-02,  2.0479e-02],\n",
            "          [ 2.7200e-02,  1.0205e-03, -3.2720e-02],\n",
            "          [ 2.6169e-02,  3.8491e-02,  3.0745e-02]],\n",
            "\n",
            "         [[-3.8609e-02, -1.6206e-02, -1.0496e-02],\n",
            "          [-3.8901e-02, -3.3373e-02,  2.4763e-03],\n",
            "          [ 2.4792e-02,  3.4783e-02,  3.2995e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9023e-02, -1.7570e-02,  4.0045e-02],\n",
            "          [-1.9843e-02,  1.1494e-02,  9.3193e-03],\n",
            "          [-2.3966e-02, -1.6836e-02, -3.2134e-02]],\n",
            "\n",
            "         [[-3.1831e-02, -3.5493e-02,  1.2249e-02],\n",
            "          [-7.2648e-03, -1.4402e-02, -2.0708e-02],\n",
            "          [-3.8794e-02, -7.6392e-03,  3.6252e-02]],\n",
            "\n",
            "         [[-3.5245e-02,  2.1467e-02, -2.5869e-02],\n",
            "          [-3.1044e-02, -2.7048e-03,  2.1205e-02],\n",
            "          [-3.1879e-02,  2.5301e-02,  2.6311e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.4045e-02,  2.4539e-02, -3.4000e-02],\n",
            "          [ 1.8369e-02, -8.0497e-03,  3.7198e-02],\n",
            "          [-2.2630e-02, -2.5041e-02,  1.6831e-02]],\n",
            "\n",
            "         [[-1.7220e-02, -7.5514e-03,  3.1243e-02],\n",
            "          [-1.8018e-02,  3.5871e-02,  2.5101e-02],\n",
            "          [ 3.1909e-02, -2.3952e-04,  1.2109e-02]],\n",
            "\n",
            "         [[ 1.0008e-02,  3.1892e-02,  1.6287e-02],\n",
            "          [ 3.2663e-02,  1.0426e-03,  1.2819e-02],\n",
            "          [ 2.6255e-02, -5.2062e-04,  2.9484e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.2040e-02,  1.1510e-02,  2.5081e-02],\n",
            "          [-3.2660e-02, -7.6920e-03, -3.0828e-02],\n",
            "          [-1.1586e-02,  2.9833e-02, -2.0006e-02]],\n",
            "\n",
            "         [[ 5.5076e-04, -2.8477e-02,  1.6228e-03],\n",
            "          [-3.5023e-02,  1.1373e-02, -3.0118e-02],\n",
            "          [ 3.3413e-02,  1.4880e-02,  1.4108e-02]],\n",
            "\n",
            "         [[ 2.3838e-02,  3.9022e-02, -4.9853e-03],\n",
            "          [-4.1103e-03, -1.9650e-02,  3.4199e-02],\n",
            "          [ 1.7873e-02,  3.0469e-02,  1.4593e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7736e-02,  2.3017e-02, -3.1640e-02],\n",
            "          [-3.9594e-02,  1.9033e-02,  6.3011e-03],\n",
            "          [-1.2118e-03, -2.2843e-02,  2.2329e-02]],\n",
            "\n",
            "         [[ 2.0127e-02, -1.5998e-02, -1.4322e-02],\n",
            "          [ 1.2743e-02, -2.4873e-02,  3.1725e-03],\n",
            "          [ 1.4726e-02,  3.7864e-02, -4.1027e-02]],\n",
            "\n",
            "         [[ 4.1628e-03, -3.8819e-02,  3.9909e-02],\n",
            "          [-3.0494e-02, -3.3870e-02,  1.6592e-03],\n",
            "          [ 3.9099e-02, -2.9516e-02, -3.0529e-02]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_C2.bias Parameter containing:\n",
            "tensor([-0.0177, -0.0154, -0.0084,  0.0219, -0.0279,  0.0248,  0.0016,  0.0328,\n",
            "         0.0041,  0.0395,  0.0183,  0.0270,  0.0130,  0.0198,  0.0340, -0.0264,\n",
            "        -0.0213, -0.0337, -0.0077, -0.0406,  0.0023, -0.0206, -0.0218,  0.0108,\n",
            "        -0.0166, -0.0043, -0.0244,  0.0065, -0.0128, -0.0366, -0.0349,  0.0171,\n",
            "         0.0324, -0.0299,  0.0117, -0.0097, -0.0255, -0.0255,  0.0183,  0.0414,\n",
            "         0.0230,  0.0124, -0.0026,  0.0354,  0.0296, -0.0295,  0.0338,  0.0335,\n",
            "         0.0112, -0.0382, -0.0412, -0.0043,  0.0043, -0.0024,  0.0056,  0.0163,\n",
            "        -0.0060,  0.0163,  0.0080, -0.0162, -0.0383,  0.0389, -0.0328, -0.0289],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_C3.weight Parameter containing:\n",
            "tensor([[[[ 2.7964e-02, -1.4258e-02,  4.0640e-02],\n",
            "          [-6.4360e-03,  3.4412e-02,  3.0588e-02],\n",
            "          [ 3.5793e-02,  3.7687e-02,  9.4342e-03]],\n",
            "\n",
            "         [[-3.9900e-03, -4.0618e-02,  2.5096e-02],\n",
            "          [-1.3614e-02,  3.4912e-02, -2.6618e-02],\n",
            "          [ 2.2629e-02,  5.6354e-03,  1.1217e-02]],\n",
            "\n",
            "         [[-6.5209e-03,  5.9811e-03, -1.5307e-02],\n",
            "          [-1.0775e-02,  2.3972e-02, -3.9299e-02],\n",
            "          [-3.8561e-02,  2.0907e-02,  4.9464e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.9694e-02,  4.0515e-02,  1.5700e-02],\n",
            "          [ 1.7462e-02, -3.6028e-02,  3.1087e-02],\n",
            "          [ 1.9048e-02,  3.1775e-02,  6.4598e-03]],\n",
            "\n",
            "         [[ 2.7395e-02, -3.8971e-03,  2.9767e-02],\n",
            "          [-6.3219e-03,  2.0025e-02,  1.1343e-02],\n",
            "          [ 3.1056e-02, -1.7743e-02, -3.5663e-02]],\n",
            "\n",
            "         [[-1.3631e-03,  2.5367e-02,  1.9388e-02],\n",
            "          [ 9.2037e-04,  3.1117e-03, -2.8092e-02],\n",
            "          [ 1.0733e-02, -1.5830e-02,  1.8856e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3618e-02,  1.6402e-02,  2.7680e-02],\n",
            "          [-2.9454e-03,  9.0999e-03, -4.0935e-02],\n",
            "          [ 7.2690e-03,  5.7285e-03,  2.2135e-02]],\n",
            "\n",
            "         [[ 8.1404e-04, -1.3830e-02,  2.4567e-02],\n",
            "          [-5.7046e-03,  1.2211e-02, -1.1058e-02],\n",
            "          [ 1.7042e-02, -2.1791e-02, -2.0363e-02]],\n",
            "\n",
            "         [[ 4.0726e-02, -1.6742e-02, -2.7742e-02],\n",
            "          [-2.9966e-02, -3.9999e-02, -9.2839e-03],\n",
            "          [ 2.7488e-02,  4.0374e-02,  3.3610e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.7650e-04,  1.1935e-02, -1.8034e-02],\n",
            "          [ 4.9914e-03,  1.7028e-02, -2.1654e-02],\n",
            "          [-4.2637e-03,  3.5707e-02, -7.2846e-04]],\n",
            "\n",
            "         [[ 3.1115e-02,  1.7409e-02, -1.2101e-02],\n",
            "          [-2.9670e-02, -3.8161e-02, -1.9423e-02],\n",
            "          [ 2.2065e-02, -1.8369e-02,  3.4714e-02]],\n",
            "\n",
            "         [[ 2.9645e-02, -3.8235e-02,  5.5455e-03],\n",
            "          [ 3.1655e-02,  7.9072e-04, -3.1601e-02],\n",
            "          [ 1.2379e-03, -3.9337e-02, -7.9931e-03]]],\n",
            "\n",
            "\n",
            "        [[[-2.1406e-02,  2.3093e-02,  3.1546e-02],\n",
            "          [-2.1994e-02, -4.0008e-02, -3.5435e-03],\n",
            "          [ 2.9838e-02,  2.2146e-02,  2.3794e-02]],\n",
            "\n",
            "         [[ 1.9661e-02,  1.6452e-02,  1.9968e-02],\n",
            "          [ 4.4264e-03, -4.0699e-02, -8.6403e-03],\n",
            "          [ 3.0221e-02, -3.3615e-02,  1.0790e-02]],\n",
            "\n",
            "         [[ 1.9644e-02, -3.7969e-02,  4.3768e-03],\n",
            "          [ 3.4995e-02, -3.0314e-02, -3.7152e-02],\n",
            "          [ 1.9988e-02,  2.9717e-02,  8.5722e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.0374e-02,  4.1600e-02,  2.8022e-02],\n",
            "          [ 3.6694e-02,  1.3379e-02, -2.6019e-02],\n",
            "          [ 5.4211e-03,  4.0412e-02,  1.8356e-02]],\n",
            "\n",
            "         [[-2.3640e-02, -3.9205e-02, -1.1693e-03],\n",
            "          [-6.7535e-03, -4.1143e-02,  1.5097e-02],\n",
            "          [ 2.0514e-02, -1.9466e-02,  1.4203e-02]],\n",
            "\n",
            "         [[-3.3424e-02, -2.1709e-02,  8.0118e-04],\n",
            "          [ 2.7743e-02, -2.7193e-02,  2.0645e-02],\n",
            "          [-3.6155e-02,  4.5968e-03, -3.3871e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-7.3697e-04,  3.8861e-02,  1.2079e-02],\n",
            "          [-6.2368e-03,  3.1688e-03, -3.8680e-02],\n",
            "          [-3.3131e-02, -3.0931e-03,  2.0324e-02]],\n",
            "\n",
            "         [[-3.6622e-02, -5.5431e-03, -1.1966e-02],\n",
            "          [ 1.9755e-02,  3.2430e-02,  1.0582e-03],\n",
            "          [-1.2669e-02,  3.3010e-02, -2.0602e-02]],\n",
            "\n",
            "         [[ 1.8051e-02,  1.7199e-02,  2.3979e-02],\n",
            "          [-7.1250e-03, -3.3461e-02, -2.7502e-02],\n",
            "          [ 2.3725e-02,  4.3231e-03, -2.6217e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1319e-03,  3.5811e-02, -3.8871e-02],\n",
            "          [-1.1978e-02,  1.6480e-02, -2.1538e-03],\n",
            "          [ 7.3885e-03,  2.2238e-02,  1.7665e-02]],\n",
            "\n",
            "         [[-2.4053e-02, -3.0802e-02,  4.1223e-02],\n",
            "          [ 1.5771e-02, -1.2075e-02, -3.2030e-02],\n",
            "          [-2.6104e-02,  3.6451e-02,  5.9892e-03]],\n",
            "\n",
            "         [[ 3.0297e-02, -8.1001e-03,  3.7775e-02],\n",
            "          [-3.8234e-02, -2.3163e-02,  1.9187e-02],\n",
            "          [ 3.6559e-02,  1.4206e-02, -4.0266e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2005e-02,  2.1562e-02,  1.6410e-02],\n",
            "          [-2.3498e-02, -2.8166e-03,  1.7308e-02],\n",
            "          [-2.0041e-02,  4.0335e-02, -2.9493e-02]],\n",
            "\n",
            "         [[ 5.0690e-04,  2.0888e-02, -1.2477e-02],\n",
            "          [-3.4167e-02,  1.1532e-02, -2.4002e-02],\n",
            "          [-2.0033e-03,  4.7282e-03, -3.0495e-02]],\n",
            "\n",
            "         [[ 2.9176e-03, -2.5673e-02,  4.0826e-03],\n",
            "          [ 6.8617e-03, -2.3629e-02, -2.0861e-02],\n",
            "          [-3.3453e-02, -9.5845e-03, -3.8751e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.9466e-02,  3.3056e-02,  1.9936e-02],\n",
            "          [ 5.0624e-03,  3.0220e-02,  1.6363e-02],\n",
            "          [-3.6786e-02, -4.8099e-03,  3.4955e-02]],\n",
            "\n",
            "         [[ 3.3082e-02,  3.7240e-02, -1.7191e-02],\n",
            "          [-4.1342e-02, -1.1075e-02,  3.5222e-02],\n",
            "          [-1.7428e-03,  8.3491e-03,  1.4344e-03]],\n",
            "\n",
            "         [[-8.0141e-03, -2.8263e-02, -1.3644e-03],\n",
            "          [-4.0597e-02,  3.9626e-02,  3.6791e-02],\n",
            "          [-1.3819e-02,  2.4887e-02, -1.0969e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.3566e-02, -6.0411e-03, -1.1267e-02],\n",
            "          [-1.2250e-02,  8.3967e-03,  1.2664e-02],\n",
            "          [-6.0466e-03,  4.0174e-03,  3.5914e-03]],\n",
            "\n",
            "         [[ 1.9744e-02,  1.3591e-03,  2.8004e-02],\n",
            "          [ 2.6026e-02, -3.9161e-02, -1.0894e-02],\n",
            "          [-1.3921e-02, -3.9964e-02, -3.3850e-02]],\n",
            "\n",
            "         [[-2.6803e-02,  5.9273e-03,  2.7128e-02],\n",
            "          [-2.1382e-02, -4.3930e-03, -3.1639e-02],\n",
            "          [-2.9629e-02, -6.7011e-05, -1.7125e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.9256e-02, -1.8403e-02,  2.2623e-02],\n",
            "          [ 1.4056e-04, -3.3285e-02,  2.9321e-03],\n",
            "          [-2.2694e-02, -1.8592e-02,  8.3035e-03]],\n",
            "\n",
            "         [[ 3.9342e-02, -2.5095e-02, -2.9747e-02],\n",
            "          [ 4.1379e-02, -2.1784e-02,  4.1285e-02],\n",
            "          [-3.1189e-02, -3.9926e-02,  5.0639e-03]],\n",
            "\n",
            "         [[-3.1951e-02,  2.6050e-02, -1.8915e-02],\n",
            "          [ 2.7522e-02,  3.9140e-02,  3.2991e-02],\n",
            "          [ 3.2530e-02, -2.9558e-02,  1.7301e-03]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_C3.bias Parameter containing:\n",
            "tensor([ 3.9334e-05,  3.2020e-02,  1.0248e-02,  1.8496e-02,  1.9509e-02,\n",
            "         4.5388e-03,  1.2364e-02,  3.1531e-02,  3.2969e-02,  1.7468e-02,\n",
            "         2.6937e-02, -1.6519e-02, -3.2731e-02, -2.4987e-02, -2.4944e-02,\n",
            "        -7.0629e-03,  3.4070e-02,  9.9553e-03,  1.9015e-03,  2.4769e-02,\n",
            "         1.1476e-02, -2.7237e-02,  1.0295e-03,  1.5450e-02,  1.3191e-02,\n",
            "         4.8306e-03, -3.9031e-02, -4.5210e-03,  1.2507e-02, -1.3457e-02,\n",
            "         8.2698e-03,  1.5339e-02, -1.8239e-02,  5.3797e-03, -3.7862e-02,\n",
            "         2.5797e-02, -1.1372e-02,  2.6838e-02,  1.6744e-02, -1.8637e-02,\n",
            "        -2.2878e-03,  1.4239e-03,  2.9046e-02,  1.2103e-02, -6.1151e-03,\n",
            "         3.1155e-02, -7.9520e-03, -7.0102e-03,  3.5401e-02, -3.4902e-03,\n",
            "         3.0340e-02,  1.3760e-02,  3.9065e-02,  9.4195e-03, -3.2208e-02,\n",
            "        -3.1558e-02,  3.0383e-02,  3.1279e-02, -3.4103e-03,  2.4346e-02,\n",
            "        -1.5568e-02, -1.1867e-02, -8.7517e-03,  2.3896e-02, -1.7156e-02,\n",
            "         2.8070e-02, -3.2973e-02,  2.7324e-02,  3.9937e-02, -4.0962e-02,\n",
            "         1.4773e-02,  3.6188e-02, -2.2469e-02, -2.9435e-02,  1.3103e-02,\n",
            "        -1.6624e-03, -2.9834e-02, -4.0356e-02,  2.1805e-02, -4.6286e-03,\n",
            "        -2.0130e-02, -1.1196e-03,  2.0735e-02, -3.6496e-02,  1.8620e-02,\n",
            "         2.9400e-02, -3.7292e-02,  1.9416e-02,  4.0859e-03,  3.2973e-03,\n",
            "        -3.9134e-02,  2.7848e-02,  1.5195e-02, -1.3676e-02, -9.4028e-03,\n",
            "         2.5965e-02, -2.3699e-02,  3.7911e-02, -1.1878e-02,  8.9494e-03,\n",
            "        -2.6671e-02, -2.2572e-03,  2.1223e-02,  1.9284e-02,  4.1343e-02,\n",
            "        -1.4305e-02,  1.6663e-02, -1.7826e-02, -2.7934e-02,  6.2691e-03,\n",
            "         3.4998e-02, -3.4677e-02,  2.3974e-02, -1.1317e-02,  2.4374e-02,\n",
            "        -6.2491e-03,  3.9319e-02, -2.1692e-02, -7.7318e-03, -1.1863e-02,\n",
            "        -2.2265e-02,  1.6739e-02, -9.3299e-03, -7.1998e-03, -2.6129e-02,\n",
            "        -1.2814e-02, -1.7375e-02, -3.3522e-02], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_C4.weight Parameter containing:\n",
            "tensor([[[[ 2.0371e-02,  2.9366e-02,  5.6723e-04],\n",
            "          [-2.3028e-04,  2.5723e-02,  1.7856e-03],\n",
            "          [-9.5709e-03, -2.2411e-02, -4.9527e-03]],\n",
            "\n",
            "         [[-2.1369e-02,  1.2335e-02, -1.3031e-02],\n",
            "          [ 2.0297e-02,  1.0076e-02, -1.4825e-02],\n",
            "          [-8.7485e-03,  1.9612e-03, -2.0883e-02]],\n",
            "\n",
            "         [[-2.8318e-02,  1.2317e-02, -1.5886e-02],\n",
            "          [-5.4808e-03, -1.9719e-02, -2.3132e-02],\n",
            "          [ 3.0672e-03, -2.2396e-02,  2.2666e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6879e-02, -6.5732e-04, -7.3133e-03],\n",
            "          [ 4.6296e-03,  2.0565e-02,  3.9215e-03],\n",
            "          [-2.2803e-02, -2.4928e-04,  1.6335e-02]],\n",
            "\n",
            "         [[-1.2904e-02,  1.9270e-02,  2.3459e-02],\n",
            "          [ 1.8793e-02, -2.8703e-02, -2.0345e-03],\n",
            "          [-6.2186e-03, -2.8327e-03, -1.5454e-02]],\n",
            "\n",
            "         [[-5.3830e-03,  5.0183e-05, -3.4396e-03],\n",
            "          [-2.0566e-02,  1.4086e-02, -2.2225e-02],\n",
            "          [ 2.3416e-02,  5.7609e-03,  2.9188e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.7112e-02, -2.5985e-03, -2.1115e-02],\n",
            "          [-2.4310e-02, -2.5098e-02,  1.8037e-02],\n",
            "          [ 2.7847e-02, -1.9314e-02,  8.5644e-03]],\n",
            "\n",
            "         [[ 1.0178e-02,  4.8181e-03,  1.9158e-02],\n",
            "          [ 7.4500e-03, -1.0284e-02,  2.2824e-02],\n",
            "          [-6.2708e-03, -2.7865e-02, -2.5806e-02]],\n",
            "\n",
            "         [[ 9.4741e-04,  2.7920e-02, -7.7941e-03],\n",
            "          [-1.9723e-02, -2.2342e-02,  8.3604e-03],\n",
            "          [-8.9683e-03, -1.0408e-02, -1.1677e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7584e-02,  2.8878e-02, -7.6429e-03],\n",
            "          [ 2.6966e-02, -1.0924e-02, -2.5849e-02],\n",
            "          [ 4.9638e-03, -1.8870e-02, -1.3405e-02]],\n",
            "\n",
            "         [[-8.7446e-03,  6.8953e-03, -1.9061e-02],\n",
            "          [-2.0679e-02, -2.4272e-02,  2.5117e-02],\n",
            "          [-2.0867e-02,  6.2490e-03, -7.9333e-03]],\n",
            "\n",
            "         [[ 2.8818e-02, -6.3632e-03,  2.7174e-02],\n",
            "          [ 2.7470e-03, -3.1414e-03, -1.0995e-02],\n",
            "          [ 8.3427e-03, -2.0543e-02,  8.8460e-03]]],\n",
            "\n",
            "\n",
            "        [[[-5.2246e-03, -1.1179e-02, -3.3132e-03],\n",
            "          [ 2.9368e-02, -2.6744e-02, -5.6882e-03],\n",
            "          [ 9.3046e-03, -3.1545e-03, -2.7793e-02]],\n",
            "\n",
            "         [[ 1.7291e-02,  1.5052e-02,  2.1028e-02],\n",
            "          [ 4.4790e-03,  1.6760e-02, -1.0324e-02],\n",
            "          [ 1.1675e-02, -9.9784e-03,  1.6773e-02]],\n",
            "\n",
            "         [[-2.2413e-02, -1.6915e-02,  1.7619e-02],\n",
            "          [-2.7371e-02,  8.9296e-03,  3.8491e-03],\n",
            "          [ 1.3897e-02,  1.5760e-02,  2.1224e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8354e-03,  1.3885e-02,  6.5864e-03],\n",
            "          [ 1.2424e-02, -7.3867e-03,  2.5766e-03],\n",
            "          [-1.5892e-02,  2.4031e-02, -2.8694e-02]],\n",
            "\n",
            "         [[-2.7957e-03, -1.4309e-02,  6.5412e-03],\n",
            "          [-2.1657e-02,  2.4818e-03, -7.9125e-03],\n",
            "          [-2.7373e-02,  7.1716e-03,  4.6227e-03]],\n",
            "\n",
            "         [[ 7.9520e-03, -2.3439e-02, -1.5321e-02],\n",
            "          [ 1.7384e-02,  1.2488e-02, -1.6774e-02],\n",
            "          [ 2.8079e-02,  5.0753e-03, -2.5537e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8584e-02, -2.5551e-02, -1.6184e-02],\n",
            "          [-2.8825e-02, -1.9226e-02, -1.3303e-02],\n",
            "          [ 2.6902e-02, -2.0712e-02, -2.6141e-02]],\n",
            "\n",
            "         [[-2.6779e-02,  2.7673e-02,  1.5814e-02],\n",
            "          [ 4.1666e-04,  4.9395e-03,  2.8764e-02],\n",
            "          [-1.5150e-02,  7.0400e-03, -2.6306e-02]],\n",
            "\n",
            "         [[ 7.3209e-03,  2.2140e-02,  5.7249e-04],\n",
            "          [-2.3913e-02,  5.9633e-03, -1.6602e-02],\n",
            "          [ 2.1585e-02, -2.4239e-02, -1.6952e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7418e-02, -2.4630e-02, -1.0397e-02],\n",
            "          [-1.4418e-02, -2.1527e-02, -5.4219e-03],\n",
            "          [-1.8274e-03, -9.2246e-03,  2.2469e-02]],\n",
            "\n",
            "         [[ 1.7511e-03, -1.2887e-02,  2.4699e-02],\n",
            "          [-8.9034e-03, -7.7052e-03, -2.3588e-02],\n",
            "          [ 1.9349e-02, -1.0436e-02, -1.0437e-03]],\n",
            "\n",
            "         [[ 2.6038e-02, -1.5518e-02,  2.5768e-02],\n",
            "          [-1.8447e-02,  9.6301e-03, -2.8336e-02],\n",
            "          [-9.8251e-05, -6.7263e-03,  7.9410e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9911e-02, -2.4228e-02, -1.3800e-02],\n",
            "          [-1.5150e-02, -1.1877e-02,  3.0183e-03],\n",
            "          [ 7.3772e-03, -7.0166e-03, -2.0739e-02]],\n",
            "\n",
            "         [[-2.4704e-02,  6.5812e-03, -1.6508e-02],\n",
            "          [ 5.4046e-03,  1.9260e-02, -1.3667e-02],\n",
            "          [ 2.1882e-04, -6.9893e-03, -1.0153e-02]],\n",
            "\n",
            "         [[ 1.1859e-02,  2.1625e-02, -1.0004e-02],\n",
            "          [ 2.6110e-02,  2.6414e-02, -1.4471e-02],\n",
            "          [-2.4016e-03,  8.1579e-03,  1.2462e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8600e-02,  2.6413e-02,  7.2234e-03],\n",
            "          [-2.0334e-02, -7.8676e-03,  2.6492e-02],\n",
            "          [ 1.3931e-02, -1.1665e-02, -2.0343e-02]],\n",
            "\n",
            "         [[-5.5493e-03,  1.4370e-02,  1.4061e-02],\n",
            "          [ 2.0525e-02, -1.9774e-02, -1.7299e-02],\n",
            "          [-6.9514e-05, -2.3270e-02,  1.3680e-02]],\n",
            "\n",
            "         [[-1.4865e-02,  2.2148e-02,  8.6107e-03],\n",
            "          [-1.0392e-02, -1.8661e-02,  2.2275e-02],\n",
            "          [ 2.1634e-02,  2.7876e-02, -1.1388e-02]]],\n",
            "\n",
            "\n",
            "        [[[-7.9545e-03, -2.6297e-02,  2.3686e-02],\n",
            "          [-1.6311e-02, -1.0122e-02, -1.8776e-02],\n",
            "          [ 1.1145e-02, -9.1403e-03,  7.7255e-05]],\n",
            "\n",
            "         [[-3.8423e-03, -2.2878e-02, -2.0976e-02],\n",
            "          [-9.6178e-03,  5.0834e-03,  8.2321e-04],\n",
            "          [ 1.8336e-02,  2.8831e-02, -1.2464e-02]],\n",
            "\n",
            "         [[ 2.0929e-02,  1.5928e-02,  2.5535e-02],\n",
            "          [ 2.1138e-03,  2.6109e-02,  1.2691e-02],\n",
            "          [-1.8036e-02, -9.0674e-03,  1.0521e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.3000e-04,  8.5512e-03, -2.6620e-02],\n",
            "          [-1.8205e-02, -1.3702e-02, -2.5862e-02],\n",
            "          [-2.8032e-02, -5.9691e-03, -2.7248e-03]],\n",
            "\n",
            "         [[-2.5383e-02, -1.5387e-02, -8.1234e-03],\n",
            "          [ 1.2977e-02, -2.4731e-02, -2.0188e-02],\n",
            "          [ 1.1842e-02,  1.7818e-02, -1.0922e-02]],\n",
            "\n",
            "         [[-5.4602e-03, -2.5708e-03, -1.1811e-02],\n",
            "          [ 1.0543e-02, -1.6501e-02,  1.5387e-02],\n",
            "          [ 8.6818e-03,  1.7294e-03,  2.9350e-02]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_C4.bias Parameter containing:\n",
            "tensor([ 0.0137, -0.0204, -0.0101, -0.0151,  0.0094, -0.0185,  0.0122, -0.0271,\n",
            "         0.0293,  0.0181, -0.0288, -0.0119,  0.0091,  0.0265, -0.0165, -0.0045,\n",
            "         0.0139, -0.0147, -0.0034,  0.0294, -0.0287,  0.0162, -0.0068, -0.0136,\n",
            "        -0.0033, -0.0008, -0.0013, -0.0058,  0.0005, -0.0115,  0.0103,  0.0061,\n",
            "         0.0011, -0.0180,  0.0002,  0.0090, -0.0087,  0.0015,  0.0237,  0.0077,\n",
            "        -0.0043, -0.0119,  0.0247, -0.0264, -0.0243, -0.0017, -0.0016, -0.0285,\n",
            "         0.0210, -0.0050,  0.0087, -0.0084, -0.0071, -0.0145, -0.0032, -0.0111,\n",
            "         0.0207, -0.0062,  0.0122,  0.0273, -0.0169, -0.0266,  0.0276, -0.0258,\n",
            "        -0.0126,  0.0076,  0.0008,  0.0241, -0.0265, -0.0149,  0.0250, -0.0222,\n",
            "         0.0045, -0.0278, -0.0078, -0.0152,  0.0214,  0.0180,  0.0250, -0.0067,\n",
            "         0.0139, -0.0149, -0.0186, -0.0084, -0.0173,  0.0284, -0.0111, -0.0144,\n",
            "        -0.0169,  0.0230, -0.0067, -0.0052, -0.0242,  0.0277, -0.0127, -0.0236,\n",
            "        -0.0108, -0.0114,  0.0030, -0.0238,  0.0287,  0.0240,  0.0073, -0.0236,\n",
            "        -0.0171,  0.0158,  0.0034,  0.0271, -0.0106, -0.0126, -0.0136, -0.0280,\n",
            "        -0.0137, -0.0210, -0.0213, -0.0256,  0.0253, -0.0180, -0.0215,  0.0198,\n",
            "        -0.0254, -0.0248, -0.0231, -0.0003, -0.0215,  0.0053,  0.0088, -0.0200],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_D1.weight Parameter containing:\n",
            "tensor([[-0.0008, -0.0017,  0.0014,  ...,  0.0025,  0.0022, -0.0017],\n",
            "        [ 0.0024, -0.0001, -0.0024,  ...,  0.0025, -0.0026, -0.0016],\n",
            "        [ 0.0015, -0.0026, -0.0003,  ..., -0.0008, -0.0014,  0.0009],\n",
            "        ...,\n",
            "        [-0.0006, -0.0011,  0.0014,  ...,  0.0011, -0.0025,  0.0009],\n",
            "        [-0.0026,  0.0005,  0.0020,  ...,  0.0012, -0.0015, -0.0011],\n",
            "        [-0.0014, -0.0022,  0.0024,  ...,  0.0016,  0.0024,  0.0021]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_D1.bias Parameter containing:\n",
            "tensor([ 4.2381e-04,  6.3669e-04,  1.6792e-04, -4.7863e-04, -1.8585e-04,\n",
            "         2.6467e-03, -1.0965e-03,  2.3995e-03, -2.1861e-03,  1.2774e-03,\n",
            "        -2.6267e-03,  1.4881e-03, -2.4879e-03, -2.0339e-04, -1.8089e-03,\n",
            "        -2.2518e-03,  1.3348e-03, -5.2184e-04,  2.6268e-04,  6.9110e-05,\n",
            "        -1.8144e-03,  8.9410e-04,  2.0638e-03,  1.5168e-03, -2.6475e-03,\n",
            "         2.5728e-03, -3.0734e-04, -2.3725e-03, -1.1090e-03, -2.2503e-03,\n",
            "         2.2998e-03,  7.8752e-04, -1.7956e-03, -1.0386e-03, -2.4257e-03,\n",
            "         2.2913e-03, -9.8518e-04, -1.3360e-03, -7.6197e-04,  4.4794e-04,\n",
            "         2.4711e-03, -5.5210e-04,  2.0021e-03, -1.2849e-03, -2.5338e-03,\n",
            "        -1.0677e-03, -2.2408e-03, -2.0894e-04,  8.0408e-04,  1.1650e-03,\n",
            "         2.7215e-03,  1.5429e-03, -2.7524e-03, -6.4700e-04, -2.7212e-03,\n",
            "        -1.7297e-03,  1.5433e-03,  3.4041e-04,  2.0696e-03,  1.6445e-03,\n",
            "        -1.6894e-03, -2.1654e-03,  9.3084e-04, -1.6646e-03,  1.9251e-03,\n",
            "        -2.6827e-03, -2.8796e-04, -4.0230e-04, -2.4846e-03, -2.5744e-03,\n",
            "         2.5201e-03,  3.5431e-04,  1.8965e-03, -1.6455e-04,  2.5687e-04,\n",
            "        -1.4282e-03, -1.5757e-03, -9.4774e-04, -1.8050e-03, -2.7233e-03,\n",
            "        -2.7070e-03, -2.1912e-03, -7.9485e-05,  1.0748e-03,  2.0624e-03,\n",
            "         1.1190e-04,  5.2145e-04, -1.3550e-03, -5.7670e-04, -2.2743e-03,\n",
            "         2.6369e-03, -2.3244e-03, -1.7664e-03,  2.7311e-03,  1.6093e-03,\n",
            "        -2.3789e-03,  1.9175e-03, -7.8933e-06, -6.0744e-04,  1.8881e-04,\n",
            "        -6.8827e-04,  2.6160e-03, -1.7735e-04,  1.1211e-03, -1.9872e-03,\n",
            "        -2.3313e-04, -2.2866e-03, -2.1566e-04, -1.1760e-03,  1.2144e-03,\n",
            "         2.0194e-03, -1.2600e-03,  7.7531e-04, -1.5862e-03, -2.5931e-04,\n",
            "         2.6036e-03, -1.5199e-03, -2.2965e-03,  2.0166e-03, -1.1569e-03,\n",
            "         1.7330e-03, -1.9029e-03, -1.0759e-03, -2.1008e-03,  1.5300e-03,\n",
            "         1.5855e-03, -2.6084e-03, -5.7586e-04, -6.4429e-04, -2.3820e-03,\n",
            "        -2.2338e-03,  1.8480e-04, -8.0471e-04, -1.2572e-03,  1.6492e-03,\n",
            "         6.9357e-04,  1.7454e-03,  2.5374e-03, -1.2470e-03, -4.4669e-04,\n",
            "         4.8638e-04, -2.0177e-04, -8.3812e-05,  1.0899e-03, -7.6644e-04,\n",
            "         5.2766e-04,  3.1983e-04, -2.8828e-04, -1.3098e-03,  1.3881e-03,\n",
            "        -1.9326e-03, -1.4517e-03,  1.1955e-03,  2.0040e-03,  6.8689e-04,\n",
            "        -1.2166e-03, -3.4795e-04, -7.8156e-05,  1.2742e-03, -2.4727e-03,\n",
            "        -1.9939e-03,  5.9816e-04, -1.6330e-03,  2.4431e-03,  1.4985e-03,\n",
            "         6.7411e-04,  1.8391e-03, -7.6327e-04,  1.5217e-03, -2.0517e-03,\n",
            "        -1.1564e-03, -1.6793e-03,  2.1213e-03,  1.1693e-03,  1.5846e-03,\n",
            "        -1.0743e-03,  7.7726e-04, -1.1152e-03, -2.5255e-03,  2.3981e-03,\n",
            "         1.3346e-03,  2.1901e-03, -1.6430e-03, -2.3493e-04,  1.5688e-03,\n",
            "         6.0778e-04,  1.0380e-03,  2.2601e-03, -4.4303e-04, -2.1110e-03,\n",
            "        -9.3645e-04, -2.7530e-03, -2.0961e-03, -5.8628e-04,  4.1795e-04,\n",
            "        -2.5625e-03,  2.1970e-03,  8.8361e-04,  1.8522e-03, -1.5451e-03,\n",
            "         2.5454e-03, -2.6268e-03, -2.4506e-03,  1.2301e-03,  1.2361e-03,\n",
            "         1.4738e-03,  1.9664e-03,  2.5124e-03, -1.5915e-03, -9.4372e-05,\n",
            "         1.8074e-03,  2.4719e-03,  5.2893e-04, -7.7887e-04, -2.6860e-04,\n",
            "        -2.5095e-03, -1.0351e-03,  1.9813e-03,  1.0569e-03,  2.4972e-03,\n",
            "         2.6966e-03,  2.4028e-04,  1.0813e-03,  1.5315e-03,  1.6258e-03,\n",
            "        -1.0556e-03, -2.0518e-03,  2.6927e-04, -1.7547e-03,  2.4715e-03,\n",
            "         9.5889e-04,  2.3967e-03,  1.4629e-03,  1.6212e-03,  7.7731e-04,\n",
            "        -1.2734e-03, -1.2658e-03, -2.7010e-03, -2.5887e-03, -1.4514e-03,\n",
            "        -1.7323e-03, -2.5461e-03, -1.7107e-03,  2.4143e-03,  2.0808e-04,\n",
            "         1.0302e-03, -2.3519e-03,  1.4558e-03,  3.9802e-04, -1.6821e-03,\n",
            "        -1.4050e-03, -1.1211e-03,  7.4840e-04, -2.3959e-03, -1.1967e-03,\n",
            "         1.2013e-03], device='cuda:0', requires_grad=True)\n",
            "NPV_D2.weight Parameter containing:\n",
            "tensor([[ 0.0548,  0.0055, -0.0173,  ...,  0.0355,  0.0413, -0.0314],\n",
            "        [-0.0383, -0.0123, -0.0289,  ..., -0.0085, -0.0120, -0.0243],\n",
            "        [ 0.0610,  0.0129, -0.0194,  ..., -0.0605,  0.0478,  0.0328],\n",
            "        ...,\n",
            "        [ 0.0133, -0.0540, -0.0280,  ...,  0.0393, -0.0283, -0.0169],\n",
            "        [ 0.0576, -0.0217,  0.0077,  ..., -0.0422,  0.0159, -0.0040],\n",
            "        [ 0.0408, -0.0072,  0.0035,  ..., -0.0166, -0.0371, -0.0158]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_D2.bias Parameter containing:\n",
            "tensor([-0.0054,  0.0436, -0.0372,  0.0399, -0.0412, -0.0407, -0.0346, -0.0198,\n",
            "         0.0248, -0.0451,  0.0398, -0.0401, -0.0415, -0.0012, -0.0124,  0.0202,\n",
            "        -0.0455,  0.0025, -0.0480, -0.0366, -0.0605, -0.0133, -0.0560,  0.0253,\n",
            "         0.0362, -0.0335, -0.0042, -0.0327,  0.0216,  0.0586,  0.0450, -0.0609,\n",
            "         0.0348,  0.0567, -0.0416, -0.0068, -0.0214, -0.0288,  0.0291, -0.0288,\n",
            "        -0.0228,  0.0094, -0.0417,  0.0507,  0.0305,  0.0190, -0.0134, -0.0237,\n",
            "         0.0267, -0.0351, -0.0405, -0.0085, -0.0452,  0.0361, -0.0002, -0.0017,\n",
            "        -0.0191, -0.0280,  0.0312, -0.0420,  0.0563, -0.0093,  0.0494, -0.0348,\n",
            "        -0.0205,  0.0223,  0.0344,  0.0013, -0.0192, -0.0207,  0.0529, -0.0036,\n",
            "        -0.0080,  0.0267, -0.0541,  0.0483,  0.0572,  0.0506, -0.0059,  0.0355,\n",
            "         0.0238, -0.0340, -0.0443,  0.0096, -0.0479,  0.0205,  0.0404, -0.0611,\n",
            "        -0.0379, -0.0078, -0.0282, -0.0387, -0.0350, -0.0328, -0.0086, -0.0530,\n",
            "         0.0300,  0.0102,  0.0465, -0.0300,  0.0057,  0.0478,  0.0350,  0.0252,\n",
            "        -0.0097, -0.0434,  0.0069, -0.0386,  0.0071, -0.0442, -0.0287, -0.0482,\n",
            "         0.0215, -0.0154,  0.0370, -0.0294, -0.0158, -0.0106, -0.0195,  0.0083,\n",
            "        -0.0482, -0.0442,  0.0549, -0.0336,  0.0104, -0.0251, -0.0074,  0.0509,\n",
            "         0.0455,  0.0343, -0.0322,  0.0248,  0.0011, -0.0500, -0.0516,  0.0551,\n",
            "         0.0310,  0.0070, -0.0512,  0.0206,  0.0226, -0.0088, -0.0022, -0.0607,\n",
            "         0.0195, -0.0266, -0.0248,  0.0561, -0.0356, -0.0392, -0.0256,  0.0311,\n",
            "         0.0475,  0.0565,  0.0365, -0.0190, -0.0072, -0.0391,  0.0094, -0.0346,\n",
            "         0.0392,  0.0129, -0.0118, -0.0316,  0.0455,  0.0108,  0.0489, -0.0218,\n",
            "         0.0317,  0.0152, -0.0542, -0.0532, -0.0208,  0.0338, -0.0377,  0.0178,\n",
            "        -0.0343, -0.0304, -0.0119, -0.0556,  0.0549, -0.0142, -0.0339, -0.0219,\n",
            "         0.0270,  0.0254,  0.0279, -0.0285, -0.0435, -0.0624,  0.0210, -0.0164,\n",
            "        -0.0106, -0.0144, -0.0201, -0.0099,  0.0128,  0.0404,  0.0176, -0.0052,\n",
            "        -0.0574,  0.0240, -0.0339,  0.0285,  0.0616, -0.0188, -0.0533, -0.0526,\n",
            "         0.0101,  0.0582,  0.0477,  0.0560, -0.0205, -0.0323,  0.0323,  0.0064,\n",
            "        -0.0387,  0.0220, -0.0007, -0.0289, -0.0328,  0.0551, -0.0031,  0.0196,\n",
            "        -0.0106, -0.0261, -0.0341,  0.0105,  0.0136, -0.0010, -0.0550, -0.0505,\n",
            "         0.0051,  0.0343,  0.0582,  0.0029, -0.0136, -0.0310,  0.0122,  0.0123,\n",
            "         0.0237, -0.0338, -0.0043, -0.0002,  0.0490,  0.0339, -0.0147, -0.0243,\n",
            "        -0.0569, -0.0419, -0.0522, -0.0211, -0.0138, -0.0091,  0.0220,  0.0110],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "outputs.weight Parameter containing:\n",
            "tensor([[ 0.0573,  0.0027,  0.0226,  ..., -0.0019,  0.0327,  0.0086],\n",
            "        [ 0.0062,  0.0096,  0.0107,  ...,  0.0387,  0.0345,  0.0565],\n",
            "        [-0.0213, -0.0220,  0.0149,  ...,  0.0437,  0.0278,  0.0428],\n",
            "        ...,\n",
            "        [ 0.0019,  0.0030,  0.0243,  ..., -0.0398,  0.0144, -0.0371],\n",
            "        [-0.0079,  0.0156, -0.0154,  ..., -0.0579, -0.0287,  0.0229],\n",
            "        [-0.0401,  0.0051,  0.0425,  ..., -0.0048, -0.0074,  0.0147]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "outputs.bias Parameter containing:\n",
            "tensor([-0.0506, -0.0343,  0.0030,  0.0559, -0.0226, -0.0055, -0.0530,  0.0216,\n",
            "         0.0206,  0.0099], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frnpf_di_linear_model.state_dict().get(\"NPV_C1.weight\").data"
      ],
      "metadata": {
        "id": "E5iIdQIYMgCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "07c417a7-a22e-4a0b-ed74-1a8df4c69c57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.1397,  0.1195,  0.1305],\n",
              "          [-0.0399, -0.0212,  0.0863],\n",
              "          [ 0.1052, -0.0467, -0.0340]],\n",
              "\n",
              "         [[-0.0456, -0.0650,  0.1604],\n",
              "          [-0.0800, -0.0553, -0.1571],\n",
              "          [ 0.0502,  0.1586,  0.0630]],\n",
              "\n",
              "         [[ 0.0627,  0.0695, -0.1562],\n",
              "          [-0.0733,  0.0070,  0.0283],\n",
              "          [ 0.0936,  0.0916,  0.1129]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0221,  0.0690, -0.1078],\n",
              "          [-0.0679, -0.0322, -0.1376],\n",
              "          [ 0.0458,  0.1631, -0.1905]],\n",
              "\n",
              "         [[ 0.0455, -0.0057, -0.0026],\n",
              "          [-0.0064, -0.0585, -0.0138],\n",
              "          [ 0.0039,  0.1116, -0.1620]],\n",
              "\n",
              "         [[-0.1902,  0.0577, -0.0802],\n",
              "          [-0.1305,  0.0760,  0.1524],\n",
              "          [ 0.0461,  0.0873,  0.1867]]],\n",
              "\n",
              "\n",
              "        [[[-0.1342, -0.0936,  0.1755],\n",
              "          [ 0.0561, -0.0583, -0.0318],\n",
              "          [ 0.0938,  0.1439,  0.1216]],\n",
              "\n",
              "         [[-0.1711, -0.0103, -0.1485],\n",
              "          [-0.0844,  0.0103, -0.1425],\n",
              "          [ 0.0812, -0.1875, -0.0808]],\n",
              "\n",
              "         [[-0.0108,  0.0017, -0.1373],\n",
              "          [ 0.0127, -0.1409, -0.1729],\n",
              "          [-0.1031,  0.0216, -0.1796]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[-0.1825, -0.0839,  0.1553],\n",
              "          [ 0.1225, -0.1902,  0.1021],\n",
              "          [ 0.0086, -0.0079, -0.0869]],\n",
              "\n",
              "         [[-0.1163, -0.0005, -0.1880],\n",
              "          [-0.1695, -0.1092, -0.0289],\n",
              "          [ 0.1202,  0.1895, -0.1792]],\n",
              "\n",
              "         [[-0.0916,  0.0500,  0.0272],\n",
              "          [-0.1631, -0.0471, -0.1133],\n",
              "          [-0.1811,  0.0954, -0.1094]]],\n",
              "\n",
              "\n",
              "        [[[-0.0003,  0.0897,  0.0930],\n",
              "          [ 0.0182,  0.0146,  0.0152],\n",
              "          [ 0.0425, -0.1802, -0.0818]],\n",
              "\n",
              "         [[ 0.1188, -0.1829, -0.0368],\n",
              "          [ 0.0825, -0.1435,  0.0541],\n",
              "          [ 0.1812, -0.0301, -0.0365]],\n",
              "\n",
              "         [[-0.0856, -0.0064,  0.1272],\n",
              "          [-0.0808,  0.0998,  0.0959],\n",
              "          [-0.1838, -0.0865, -0.0682]]],\n",
              "\n",
              "\n",
              "        [[[-0.0126, -0.1170,  0.1338],\n",
              "          [-0.1890, -0.0305, -0.1460],\n",
              "          [-0.0961,  0.1789,  0.0605]],\n",
              "\n",
              "         [[ 0.1248, -0.0036,  0.1629],\n",
              "          [ 0.1555, -0.0916,  0.1532],\n",
              "          [ 0.1484, -0.0964, -0.0572]],\n",
              "\n",
              "         [[ 0.1654,  0.1381, -0.0521],\n",
              "          [-0.0630,  0.0016,  0.1834],\n",
              "          [ 0.0865, -0.1030,  0.1264]]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frnpf_di_linear_model.state_dict().get(\"NPF_C1.weight\").data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k5lr2ClhhYCg",
        "outputId": "bceaae8e-7b42-4326-be02-63ba30e4c9e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.1397,  0.1195,  0.1305],\n",
              "          [-0.0399, -0.0212,  0.0863],\n",
              "          [ 0.1052, -0.0467, -0.0340]],\n",
              "\n",
              "         [[-0.0456, -0.0650,  0.1604],\n",
              "          [-0.0800, -0.0553, -0.1571],\n",
              "          [ 0.0502,  0.1586,  0.0630]],\n",
              "\n",
              "         [[ 0.0627,  0.0695, -0.1562],\n",
              "          [-0.0733,  0.0070,  0.0283],\n",
              "          [ 0.0936,  0.0916,  0.1129]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0221,  0.0690, -0.1078],\n",
              "          [-0.0679, -0.0322, -0.1376],\n",
              "          [ 0.0458,  0.1631, -0.1905]],\n",
              "\n",
              "         [[ 0.0455, -0.0057, -0.0026],\n",
              "          [-0.0064, -0.0585, -0.0138],\n",
              "          [ 0.0039,  0.1116, -0.1620]],\n",
              "\n",
              "         [[-0.1902,  0.0577, -0.0802],\n",
              "          [-0.1305,  0.0760,  0.1524],\n",
              "          [ 0.0461,  0.0873,  0.1867]]],\n",
              "\n",
              "\n",
              "        [[[-0.1342, -0.0936,  0.1755],\n",
              "          [ 0.0561, -0.0583, -0.0318],\n",
              "          [ 0.0938,  0.1439,  0.1216]],\n",
              "\n",
              "         [[-0.1711, -0.0103, -0.1485],\n",
              "          [-0.0844,  0.0103, -0.1425],\n",
              "          [ 0.0812, -0.1875, -0.0808]],\n",
              "\n",
              "         [[-0.0108,  0.0017, -0.1373],\n",
              "          [ 0.0127, -0.1409, -0.1729],\n",
              "          [-0.1031,  0.0216, -0.1796]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[-0.1825, -0.0839,  0.1553],\n",
              "          [ 0.1225, -0.1902,  0.1021],\n",
              "          [ 0.0086, -0.0079, -0.0869]],\n",
              "\n",
              "         [[-0.1163, -0.0005, -0.1880],\n",
              "          [-0.1695, -0.1092, -0.0289],\n",
              "          [ 0.1202,  0.1895, -0.1792]],\n",
              "\n",
              "         [[-0.0916,  0.0500,  0.0272],\n",
              "          [-0.1631, -0.0471, -0.1133],\n",
              "          [-0.1811,  0.0954, -0.1094]]],\n",
              "\n",
              "\n",
              "        [[[-0.0003,  0.0897,  0.0930],\n",
              "          [ 0.0182,  0.0146,  0.0152],\n",
              "          [ 0.0425, -0.1802, -0.0818]],\n",
              "\n",
              "         [[ 0.1188, -0.1829, -0.0368],\n",
              "          [ 0.0825, -0.1435,  0.0541],\n",
              "          [ 0.1812, -0.0301, -0.0365]],\n",
              "\n",
              "         [[-0.0856, -0.0064,  0.1272],\n",
              "          [-0.0808,  0.0998,  0.0959],\n",
              "          [-0.1838, -0.0865, -0.0682]]],\n",
              "\n",
              "\n",
              "        [[[-0.0126, -0.1170,  0.1338],\n",
              "          [-0.1890, -0.0305, -0.1460],\n",
              "          [-0.0961,  0.1789,  0.0605]],\n",
              "\n",
              "         [[ 0.1248, -0.0036,  0.1629],\n",
              "          [ 0.1555, -0.0916,  0.1532],\n",
              "          [ 0.1484, -0.0964, -0.0572]],\n",
              "\n",
              "         [[ 0.1654,  0.1381, -0.0521],\n",
              "          [-0.0630,  0.0016,  0.1834],\n",
              "          [ 0.0865, -0.1030,  0.1264]]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in frnpf_di_linear_model.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    print(name)"
      ],
      "metadata": {
        "id": "IKL7neBHMgCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1ae8a6cd-930e-4a42-987f-496231d94389"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NPV_C1.weight\n",
            "NPV_C1.bias\n",
            "NPV_C2.weight\n",
            "NPV_C2.bias\n",
            "NPV_C3.weight\n",
            "NPV_C3.bias\n",
            "NPV_C4.weight\n",
            "NPV_C4.bias\n",
            "NPV_D1.weight\n",
            "NPV_D1.bias\n",
            "NPV_D2.weight\n",
            "NPV_D2.bias\n",
            "outputs.weight\n",
            "outputs.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(frnpf_di_linear_model.parameters(), lr=args['lr'])\n",
        "for epoch in range(1, args['epochs']+1):\n",
        "  train(frnpf_di_linear_model, epoch, train_loader, lossFn, optimizer)\n",
        "  validate(frnpf_di_linear_model, validation_loader, lossFn)"
      ],
      "metadata": {
        "id": "vZByEnjtMgCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47002aab-e58c-4b97-e878-c89fd5632a22"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:70: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [50000/50000 (100%)]\tLoss: 1.885032\n",
            "\n",
            "Validation set: Average loss: 1.5352, Accuracy: 4478/10000 (45%)\n",
            "\n",
            "Train Epoch: 2 [50000/50000 (100%)]\tLoss: 1.333674\n",
            "\n",
            "Validation set: Average loss: 1.2499, Accuracy: 5542/10000 (55%)\n",
            "\n",
            "Train Epoch: 3 [50000/50000 (100%)]\tLoss: 0.989346\n",
            "\n",
            "Validation set: Average loss: 1.3190, Accuracy: 5454/10000 (55%)\n",
            "\n",
            "Train Epoch: 4 [50000/50000 (100%)]\tLoss: 0.591081\n",
            "\n",
            "Validation set: Average loss: 1.6057, Accuracy: 5269/10000 (53%)\n",
            "\n",
            "Train Epoch: 5 [50000/50000 (100%)]\tLoss: 0.214186\n",
            "\n",
            "Validation set: Average loss: 1.7900, Accuracy: 5575/10000 (56%)\n",
            "\n",
            "Train Epoch: 6 [50000/50000 (100%)]\tLoss: 0.099109\n",
            "\n",
            "Validation set: Average loss: 2.4918, Accuracy: 5549/10000 (55%)\n",
            "\n",
            "Train Epoch: 7 [50000/50000 (100%)]\tLoss: 0.053100\n",
            "\n",
            "Validation set: Average loss: 2.7466, Accuracy: 5578/10000 (56%)\n",
            "\n",
            "Train Epoch: 8 [50000/50000 (100%)]\tLoss: 0.042352\n",
            "\n",
            "Validation set: Average loss: 2.6702, Accuracy: 5794/10000 (58%)\n",
            "\n",
            "Train Epoch: 9 [50000/50000 (100%)]\tLoss: 0.024358\n",
            "\n",
            "Validation set: Average loss: 2.7987, Accuracy: 5811/10000 (58%)\n",
            "\n",
            "Train Epoch: 10 [50000/50000 (100%)]\tLoss: 0.010915\n",
            "\n",
            "Validation set: Average loss: 3.0838, Accuracy: 5814/10000 (58%)\n",
            "\n",
            "Train Epoch: 11 [50000/50000 (100%)]\tLoss: 0.006893\n",
            "\n",
            "Validation set: Average loss: 3.3610, Accuracy: 5873/10000 (59%)\n",
            "\n",
            "Train Epoch: 12 [50000/50000 (100%)]\tLoss: 0.005548\n",
            "\n",
            "Validation set: Average loss: 3.4554, Accuracy: 5844/10000 (58%)\n",
            "\n",
            "Train Epoch: 13 [50000/50000 (100%)]\tLoss: 0.010294\n",
            "\n",
            "Validation set: Average loss: 3.5822, Accuracy: 5772/10000 (58%)\n",
            "\n",
            "Train Epoch: 14 [50000/50000 (100%)]\tLoss: 0.025962\n",
            "\n",
            "Validation set: Average loss: 3.5398, Accuracy: 5653/10000 (57%)\n",
            "\n",
            "Train Epoch: 15 [50000/50000 (100%)]\tLoss: 0.014422\n",
            "\n",
            "Validation set: Average loss: 3.3357, Accuracy: 5787/10000 (58%)\n",
            "\n",
            "Train Epoch: 16 [50000/50000 (100%)]\tLoss: 0.006976\n",
            "\n",
            "Validation set: Average loss: 3.5155, Accuracy: 5722/10000 (57%)\n",
            "\n",
            "Train Epoch: 17 [50000/50000 (100%)]\tLoss: 0.006045\n",
            "\n",
            "Validation set: Average loss: 3.6596, Accuracy: 5761/10000 (58%)\n",
            "\n",
            "Train Epoch: 18 [50000/50000 (100%)]\tLoss: 0.004917\n",
            "\n",
            "Validation set: Average loss: 3.8683, Accuracy: 5756/10000 (58%)\n",
            "\n",
            "Train Epoch: 19 [50000/50000 (100%)]\tLoss: 0.005166\n",
            "\n",
            "Validation set: Average loss: 4.0429, Accuracy: 5699/10000 (57%)\n",
            "\n",
            "Train Epoch: 20 [50000/50000 (100%)]\tLoss: 0.007054\n",
            "\n",
            "Validation set: Average loss: 3.6939, Accuracy: 5745/10000 (57%)\n",
            "\n",
            "Train Epoch: 21 [50000/50000 (100%)]\tLoss: 0.002816\n",
            "\n",
            "Validation set: Average loss: 3.7249, Accuracy: 5869/10000 (59%)\n",
            "\n",
            "Train Epoch: 22 [50000/50000 (100%)]\tLoss: 0.000174\n",
            "\n",
            "Validation set: Average loss: 3.8010, Accuracy: 5895/10000 (59%)\n",
            "\n",
            "Train Epoch: 23 [50000/50000 (100%)]\tLoss: 0.000048\n",
            "\n",
            "Validation set: Average loss: 3.8360, Accuracy: 5899/10000 (59%)\n",
            "\n",
            "Train Epoch: 24 [50000/50000 (100%)]\tLoss: 0.000035\n",
            "\n",
            "Validation set: Average loss: 3.8662, Accuracy: 5903/10000 (59%)\n",
            "\n",
            "Train Epoch: 25 [50000/50000 (100%)]\tLoss: 0.000029\n",
            "\n",
            "Validation set: Average loss: 3.8919, Accuracy: 5907/10000 (59%)\n",
            "\n",
            "Train Epoch: 26 [50000/50000 (100%)]\tLoss: 0.000025\n",
            "\n",
            "Validation set: Average loss: 3.9144, Accuracy: 5905/10000 (59%)\n",
            "\n",
            "Train Epoch: 27 [50000/50000 (100%)]\tLoss: 0.000023\n",
            "\n",
            "Validation set: Average loss: 3.9346, Accuracy: 5904/10000 (59%)\n",
            "\n",
            "Train Epoch: 28 [50000/50000 (100%)]\tLoss: 0.000020\n",
            "\n",
            "Validation set: Average loss: 3.9528, Accuracy: 5902/10000 (59%)\n",
            "\n",
            "Train Epoch: 29 [50000/50000 (100%)]\tLoss: 0.000019\n",
            "\n",
            "Validation set: Average loss: 3.9695, Accuracy: 5900/10000 (59%)\n",
            "\n",
            "Train Epoch: 30 [50000/50000 (100%)]\tLoss: 0.000017\n",
            "\n",
            "Validation set: Average loss: 3.9850, Accuracy: 5903/10000 (59%)\n",
            "\n",
            "Train Epoch: 31 [50000/50000 (100%)]\tLoss: 0.000016\n",
            "\n",
            "Validation set: Average loss: 3.9997, Accuracy: 5905/10000 (59%)\n",
            "\n",
            "Train Epoch: 32 [50000/50000 (100%)]\tLoss: 0.000015\n",
            "\n",
            "Validation set: Average loss: 4.0134, Accuracy: 5905/10000 (59%)\n",
            "\n",
            "Train Epoch: 33 [50000/50000 (100%)]\tLoss: 0.000014\n",
            "\n",
            "Validation set: Average loss: 4.0263, Accuracy: 5905/10000 (59%)\n",
            "\n",
            "Train Epoch: 34 [50000/50000 (100%)]\tLoss: 0.000013\n",
            "\n",
            "Validation set: Average loss: 4.0385, Accuracy: 5906/10000 (59%)\n",
            "\n",
            "Train Epoch: 35 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 4.0501, Accuracy: 5908/10000 (59%)\n",
            "\n",
            "Train Epoch: 36 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 4.0612, Accuracy: 5908/10000 (59%)\n",
            "\n",
            "Train Epoch: 37 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 4.0718, Accuracy: 5909/10000 (59%)\n",
            "\n",
            "Train Epoch: 38 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 4.0819, Accuracy: 5909/10000 (59%)\n",
            "\n",
            "Train Epoch: 39 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 4.0917, Accuracy: 5910/10000 (59%)\n",
            "\n",
            "Train Epoch: 40 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 4.1010, Accuracy: 5908/10000 (59%)\n",
            "\n",
            "Train Epoch: 41 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.1100, Accuracy: 5908/10000 (59%)\n",
            "\n",
            "Train Epoch: 42 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.1187, Accuracy: 5909/10000 (59%)\n",
            "\n",
            "Train Epoch: 43 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 4.1270, Accuracy: 5908/10000 (59%)\n",
            "\n",
            "Train Epoch: 44 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.1351, Accuracy: 5908/10000 (59%)\n",
            "\n",
            "Train Epoch: 45 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.1430, Accuracy: 5907/10000 (59%)\n",
            "\n",
            "Train Epoch: 46 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.1506, Accuracy: 5907/10000 (59%)\n",
            "\n",
            "Train Epoch: 47 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.1580, Accuracy: 5908/10000 (59%)\n",
            "\n",
            "Train Epoch: 48 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.1651, Accuracy: 5910/10000 (59%)\n",
            "\n",
            "Train Epoch: 49 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.1721, Accuracy: 5907/10000 (59%)\n",
            "\n",
            "Train Epoch: 50 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.1789, Accuracy: 5910/10000 (59%)\n",
            "\n",
            "Train Epoch: 51 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.1856, Accuracy: 5912/10000 (59%)\n",
            "\n",
            "Train Epoch: 52 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.1920, Accuracy: 5912/10000 (59%)\n",
            "\n",
            "Train Epoch: 53 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.1983, Accuracy: 5915/10000 (59%)\n",
            "\n",
            "Train Epoch: 54 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.2044, Accuracy: 5915/10000 (59%)\n",
            "\n",
            "Train Epoch: 55 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.2104, Accuracy: 5915/10000 (59%)\n",
            "\n",
            "Train Epoch: 56 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.2163, Accuracy: 5916/10000 (59%)\n",
            "\n",
            "Train Epoch: 57 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.2220, Accuracy: 5917/10000 (59%)\n",
            "\n",
            "Train Epoch: 58 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.2276, Accuracy: 5916/10000 (59%)\n",
            "\n",
            "Train Epoch: 59 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.2331, Accuracy: 5914/10000 (59%)\n",
            "\n",
            "Train Epoch: 60 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.2384, Accuracy: 5916/10000 (59%)\n",
            "\n",
            "Train Epoch: 61 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.2437, Accuracy: 5916/10000 (59%)\n",
            "\n",
            "Train Epoch: 62 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.2488, Accuracy: 5918/10000 (59%)\n",
            "\n",
            "Train Epoch: 63 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.2539, Accuracy: 5918/10000 (59%)\n",
            "\n",
            "Train Epoch: 64 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.2588, Accuracy: 5918/10000 (59%)\n",
            "\n",
            "Train Epoch: 65 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.2637, Accuracy: 5919/10000 (59%)\n",
            "\n",
            "Train Epoch: 66 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.2684, Accuracy: 5919/10000 (59%)\n",
            "\n",
            "Train Epoch: 67 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 4.2731, Accuracy: 5921/10000 (59%)\n",
            "\n",
            "Train Epoch: 68 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 4.2777, Accuracy: 5920/10000 (59%)\n",
            "\n",
            "Train Epoch: 69 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 4.2822, Accuracy: 5919/10000 (59%)\n",
            "\n",
            "Train Epoch: 70 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 4.2866, Accuracy: 5919/10000 (59%)\n",
            "\n",
            "Train Epoch: 71 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 4.2910, Accuracy: 5918/10000 (59%)\n",
            "\n",
            "Train Epoch: 72 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 4.2953, Accuracy: 5918/10000 (59%)\n",
            "\n",
            "Train Epoch: 73 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 4.2995, Accuracy: 5918/10000 (59%)\n",
            "\n",
            "Train Epoch: 74 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 4.3037, Accuracy: 5919/10000 (59%)\n",
            "\n",
            "Train Epoch: 75 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 4.3078, Accuracy: 5918/10000 (59%)\n",
            "\n",
            "Train Epoch: 76 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 4.3118, Accuracy: 5917/10000 (59%)\n",
            "\n",
            "Train Epoch: 77 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 4.3157, Accuracy: 5918/10000 (59%)\n",
            "\n",
            "Train Epoch: 78 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 4.3196, Accuracy: 5918/10000 (59%)\n",
            "\n",
            "Train Epoch: 79 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 4.3235, Accuracy: 5919/10000 (59%)\n",
            "\n",
            "Train Epoch: 80 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 4.3273, Accuracy: 5919/10000 (59%)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in frnpf_di_linear_model.named_parameters():\n",
        "  print(name, param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcZK15qBhH0F",
        "outputId": "93a966a8-8d3d-4d01-fa34-5be637b9ca2c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NPF_C1.weight Parameter containing:\n",
            "tensor([[[[ 0.1397,  0.1195,  0.1305],\n",
            "          [-0.0399, -0.0212,  0.0863],\n",
            "          [ 0.1052, -0.0467, -0.0340]],\n",
            "\n",
            "         [[-0.0456, -0.0650,  0.1604],\n",
            "          [-0.0800, -0.0553, -0.1571],\n",
            "          [ 0.0502,  0.1586,  0.0630]],\n",
            "\n",
            "         [[ 0.0627,  0.0695, -0.1562],\n",
            "          [-0.0733,  0.0070,  0.0283],\n",
            "          [ 0.0936,  0.0916,  0.1129]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0221,  0.0690, -0.1078],\n",
            "          [-0.0679, -0.0322, -0.1376],\n",
            "          [ 0.0458,  0.1631, -0.1905]],\n",
            "\n",
            "         [[ 0.0455, -0.0057, -0.0026],\n",
            "          [-0.0064, -0.0585, -0.0138],\n",
            "          [ 0.0039,  0.1116, -0.1620]],\n",
            "\n",
            "         [[-0.1902,  0.0577, -0.0802],\n",
            "          [-0.1305,  0.0760,  0.1524],\n",
            "          [ 0.0461,  0.0873,  0.1867]]],\n",
            "\n",
            "\n",
            "        [[[-0.1342, -0.0936,  0.1755],\n",
            "          [ 0.0561, -0.0583, -0.0318],\n",
            "          [ 0.0938,  0.1439,  0.1216]],\n",
            "\n",
            "         [[-0.1711, -0.0103, -0.1485],\n",
            "          [-0.0844,  0.0103, -0.1425],\n",
            "          [ 0.0812, -0.1875, -0.0808]],\n",
            "\n",
            "         [[-0.0108,  0.0017, -0.1373],\n",
            "          [ 0.0127, -0.1409, -0.1729],\n",
            "          [-0.1031,  0.0216, -0.1796]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1825, -0.0839,  0.1553],\n",
            "          [ 0.1225, -0.1902,  0.1021],\n",
            "          [ 0.0086, -0.0079, -0.0869]],\n",
            "\n",
            "         [[-0.1163, -0.0005, -0.1880],\n",
            "          [-0.1695, -0.1092, -0.0289],\n",
            "          [ 0.1202,  0.1895, -0.1792]],\n",
            "\n",
            "         [[-0.0916,  0.0500,  0.0272],\n",
            "          [-0.1631, -0.0471, -0.1133],\n",
            "          [-0.1811,  0.0954, -0.1094]]],\n",
            "\n",
            "\n",
            "        [[[-0.0003,  0.0897,  0.0930],\n",
            "          [ 0.0182,  0.0146,  0.0152],\n",
            "          [ 0.0425, -0.1802, -0.0818]],\n",
            "\n",
            "         [[ 0.1188, -0.1829, -0.0368],\n",
            "          [ 0.0825, -0.1435,  0.0541],\n",
            "          [ 0.1812, -0.0301, -0.0365]],\n",
            "\n",
            "         [[-0.0856, -0.0064,  0.1272],\n",
            "          [-0.0808,  0.0998,  0.0959],\n",
            "          [-0.1838, -0.0865, -0.0682]]],\n",
            "\n",
            "\n",
            "        [[[-0.0126, -0.1170,  0.1338],\n",
            "          [-0.1890, -0.0305, -0.1460],\n",
            "          [-0.0961,  0.1789,  0.0605]],\n",
            "\n",
            "         [[ 0.1248, -0.0036,  0.1629],\n",
            "          [ 0.1555, -0.0916,  0.1532],\n",
            "          [ 0.1484, -0.0964, -0.0572]],\n",
            "\n",
            "         [[ 0.1654,  0.1381, -0.0521],\n",
            "          [-0.0630,  0.0016,  0.1834],\n",
            "          [ 0.0865, -0.1030,  0.1264]]]], device='cuda:0')\n",
            "NPF_C1.bias Parameter containing:\n",
            "tensor([-7.5618e-02, -2.0373e-02,  1.8304e-01, -2.1611e-02, -1.2243e-01,\n",
            "         1.5610e-01, -1.9741e-04,  8.8301e-02, -1.0414e-01,  8.0709e-05,\n",
            "        -9.6164e-02, -1.4557e-01, -1.0729e-01, -1.0894e-01, -4.2586e-02,\n",
            "         4.6880e-02,  1.8662e-01,  1.4753e-01,  1.2672e-02, -7.7154e-02,\n",
            "         7.9990e-02, -1.0964e-01, -1.8925e-01, -1.2568e-02, -7.8229e-02,\n",
            "        -1.3374e-01,  8.3115e-02,  9.1262e-02, -1.4894e-01, -1.3830e-02,\n",
            "         3.5733e-02, -1.0165e-01,  9.2654e-02,  8.7629e-02,  1.8462e-01,\n",
            "         1.7824e-02, -5.4415e-03,  3.8821e-02, -1.3455e-01, -4.9458e-02,\n",
            "         1.0594e-01,  1.6754e-01, -5.6996e-02, -1.1140e-01,  4.4076e-02,\n",
            "        -4.6056e-03,  1.2403e-01,  8.2572e-02,  1.1036e-01,  6.4899e-02,\n",
            "         7.1810e-02,  5.2053e-02,  6.1288e-02, -5.5573e-02, -1.1473e-02,\n",
            "        -1.8126e-01, -2.5655e-02, -9.7002e-02,  9.8776e-02, -1.3988e-01,\n",
            "         1.7408e-01,  1.7926e-01,  1.0283e-01, -1.6412e-01], device='cuda:0')\n",
            "NPF_C2.weight Parameter containing:\n",
            "tensor([[[[ 1.5103e-02,  2.9704e-02, -3.8090e-02],\n",
            "          [ 2.5149e-02,  2.1844e-02, -1.7188e-02],\n",
            "          [-7.3443e-03, -2.2542e-02, -3.3402e-02]],\n",
            "\n",
            "         [[-1.4446e-02, -3.5096e-03, -2.8695e-02],\n",
            "          [ 3.2664e-02,  2.2044e-02,  1.0436e-02],\n",
            "          [-9.0866e-03,  3.6128e-02, -1.5585e-03]],\n",
            "\n",
            "         [[-1.3931e-02, -4.0221e-02,  2.0895e-03],\n",
            "          [ 8.9072e-03,  2.1875e-02,  1.8223e-02],\n",
            "          [-3.8524e-03, -1.9920e-02, -2.9281e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-6.5132e-04, -2.0359e-02, -3.4813e-02],\n",
            "          [ 2.6408e-02,  2.9757e-02,  6.7718e-03],\n",
            "          [-1.4110e-02,  3.5730e-02, -1.7982e-03]],\n",
            "\n",
            "         [[ 3.3305e-02,  3.9370e-02,  2.3755e-02],\n",
            "          [-2.3260e-02,  2.8692e-02,  4.1187e-02],\n",
            "          [-9.8287e-04, -1.7502e-02,  2.6082e-02]],\n",
            "\n",
            "         [[ 3.7435e-02, -1.9915e-02,  2.4395e-02],\n",
            "          [-1.5445e-02, -3.3038e-02, -3.4764e-02],\n",
            "          [-7.5155e-04, -2.1526e-02,  3.9335e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2589e-02,  1.1960e-02,  4.0104e-02],\n",
            "          [-1.8131e-03, -2.1567e-02, -1.2250e-02],\n",
            "          [-3.8665e-02, -3.0282e-02, -9.7634e-03]],\n",
            "\n",
            "         [[-1.9655e-02, -1.6668e-02, -2.5674e-02],\n",
            "          [ 1.4575e-02, -1.7689e-02,  2.2641e-02],\n",
            "          [ 8.6435e-03, -7.3085e-03,  3.4069e-02]],\n",
            "\n",
            "         [[ 3.2154e-02,  3.3612e-03, -2.8819e-02],\n",
            "          [-3.3646e-03,  2.6050e-02, -3.5905e-02],\n",
            "          [ 3.6797e-02, -1.4488e-02, -4.0826e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7496e-02, -9.1583e-03, -3.6902e-02],\n",
            "          [ 1.2068e-02, -3.1973e-02, -4.5080e-03],\n",
            "          [-3.3742e-02, -3.2313e-02,  2.7683e-02]],\n",
            "\n",
            "         [[ 3.0089e-02,  2.0029e-02,  1.2656e-02],\n",
            "          [ 1.5767e-02,  3.1056e-02,  1.8152e-02],\n",
            "          [ 1.0229e-02, -8.6716e-03, -3.2703e-02]],\n",
            "\n",
            "         [[ 1.4152e-02,  2.8871e-02, -1.2772e-02],\n",
            "          [ 2.6291e-03, -3.2415e-02, -3.2299e-02],\n",
            "          [ 1.8615e-02, -3.9600e-02, -3.2312e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4479e-03,  1.2740e-02, -4.0161e-02],\n",
            "          [ 2.9221e-02,  4.5247e-03, -2.4546e-02],\n",
            "          [ 3.6874e-02,  3.2446e-02, -2.0972e-02]],\n",
            "\n",
            "         [[ 1.3987e-02, -2.3412e-02, -1.9761e-02],\n",
            "          [ 1.2588e-02,  2.0879e-02, -3.7725e-02],\n",
            "          [-2.6674e-02,  4.1480e-02,  9.4362e-03]],\n",
            "\n",
            "         [[-3.8428e-02,  3.6630e-03, -1.7602e-02],\n",
            "          [ 2.5857e-02,  3.3098e-02,  3.0848e-02],\n",
            "          [-1.2142e-02, -1.5178e-02, -4.1672e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 9.9773e-05,  1.6501e-02, -6.3147e-03],\n",
            "          [-2.1474e-02, -4.9190e-03,  3.9352e-02],\n",
            "          [-9.2543e-03,  2.9354e-02,  8.6049e-03]],\n",
            "\n",
            "         [[-3.2626e-02,  3.1470e-02, -1.8578e-02],\n",
            "          [-1.3097e-02, -1.8886e-02,  3.9942e-02],\n",
            "          [-2.9178e-02,  6.0825e-03, -3.3370e-02]],\n",
            "\n",
            "         [[-1.5172e-02, -2.5937e-02,  1.8562e-02],\n",
            "          [-2.2010e-02,  1.1067e-02, -2.1587e-02],\n",
            "          [ 7.1726e-03,  1.0282e-02,  1.5167e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 5.0240e-03,  6.6737e-03,  3.4744e-02],\n",
            "          [ 1.4027e-02,  3.5884e-02, -2.3025e-02],\n",
            "          [ 2.1495e-02, -1.0652e-02,  3.6764e-02]],\n",
            "\n",
            "         [[ 7.2008e-03, -3.3191e-02,  1.7669e-03],\n",
            "          [-1.9850e-02, -5.9930e-03, -4.9535e-03],\n",
            "          [ 4.1913e-04, -2.4296e-02,  3.0516e-02]],\n",
            "\n",
            "         [[-3.8130e-02, -1.9751e-02, -6.7004e-04],\n",
            "          [-2.8443e-02,  2.6089e-02,  3.1203e-02],\n",
            "          [-2.0108e-02,  1.4846e-02,  1.5329e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.2183e-02,  3.5377e-02,  3.8792e-02],\n",
            "          [-5.1794e-04, -4.9221e-03, -1.8558e-02],\n",
            "          [-2.0215e-02,  2.6673e-02, -1.9421e-02]],\n",
            "\n",
            "         [[-2.8709e-02, -3.5574e-02,  2.0479e-02],\n",
            "          [ 2.7200e-02,  1.0205e-03, -3.2720e-02],\n",
            "          [ 2.6169e-02,  3.8491e-02,  3.0745e-02]],\n",
            "\n",
            "         [[-3.8609e-02, -1.6206e-02, -1.0496e-02],\n",
            "          [-3.8901e-02, -3.3373e-02,  2.4763e-03],\n",
            "          [ 2.4792e-02,  3.4783e-02,  3.2995e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.9023e-02, -1.7570e-02,  4.0045e-02],\n",
            "          [-1.9843e-02,  1.1494e-02,  9.3193e-03],\n",
            "          [-2.3966e-02, -1.6836e-02, -3.2134e-02]],\n",
            "\n",
            "         [[-3.1831e-02, -3.5493e-02,  1.2249e-02],\n",
            "          [-7.2648e-03, -1.4402e-02, -2.0708e-02],\n",
            "          [-3.8794e-02, -7.6392e-03,  3.6252e-02]],\n",
            "\n",
            "         [[-3.5245e-02,  2.1467e-02, -2.5869e-02],\n",
            "          [-3.1044e-02, -2.7048e-03,  2.1205e-02],\n",
            "          [-3.1879e-02,  2.5301e-02,  2.6311e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.4045e-02,  2.4539e-02, -3.4000e-02],\n",
            "          [ 1.8369e-02, -8.0497e-03,  3.7198e-02],\n",
            "          [-2.2630e-02, -2.5041e-02,  1.6831e-02]],\n",
            "\n",
            "         [[-1.7220e-02, -7.5514e-03,  3.1243e-02],\n",
            "          [-1.8018e-02,  3.5871e-02,  2.5101e-02],\n",
            "          [ 3.1909e-02, -2.3952e-04,  1.2109e-02]],\n",
            "\n",
            "         [[ 1.0008e-02,  3.1892e-02,  1.6287e-02],\n",
            "          [ 3.2663e-02,  1.0426e-03,  1.2819e-02],\n",
            "          [ 2.6255e-02, -5.2062e-04,  2.9484e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.2040e-02,  1.1510e-02,  2.5081e-02],\n",
            "          [-3.2660e-02, -7.6920e-03, -3.0828e-02],\n",
            "          [-1.1586e-02,  2.9833e-02, -2.0006e-02]],\n",
            "\n",
            "         [[ 5.5076e-04, -2.8477e-02,  1.6228e-03],\n",
            "          [-3.5023e-02,  1.1373e-02, -3.0118e-02],\n",
            "          [ 3.3413e-02,  1.4880e-02,  1.4108e-02]],\n",
            "\n",
            "         [[ 2.3838e-02,  3.9022e-02, -4.9853e-03],\n",
            "          [-4.1103e-03, -1.9650e-02,  3.4199e-02],\n",
            "          [ 1.7873e-02,  3.0469e-02,  1.4593e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7736e-02,  2.3017e-02, -3.1640e-02],\n",
            "          [-3.9594e-02,  1.9033e-02,  6.3011e-03],\n",
            "          [-1.2118e-03, -2.2843e-02,  2.2329e-02]],\n",
            "\n",
            "         [[ 2.0127e-02, -1.5998e-02, -1.4322e-02],\n",
            "          [ 1.2743e-02, -2.4873e-02,  3.1725e-03],\n",
            "          [ 1.4726e-02,  3.7864e-02, -4.1027e-02]],\n",
            "\n",
            "         [[ 4.1628e-03, -3.8819e-02,  3.9909e-02],\n",
            "          [-3.0494e-02, -3.3870e-02,  1.6592e-03],\n",
            "          [ 3.9099e-02, -2.9516e-02, -3.0529e-02]]]], device='cuda:0')\n",
            "NPF_C2.bias Parameter containing:\n",
            "tensor([-0.0177, -0.0154, -0.0084,  0.0219, -0.0279,  0.0248,  0.0016,  0.0328,\n",
            "         0.0041,  0.0395,  0.0183,  0.0270,  0.0130,  0.0198,  0.0340, -0.0264,\n",
            "        -0.0213, -0.0337, -0.0077, -0.0406,  0.0023, -0.0206, -0.0218,  0.0108,\n",
            "        -0.0166, -0.0043, -0.0244,  0.0065, -0.0128, -0.0366, -0.0349,  0.0171,\n",
            "         0.0324, -0.0299,  0.0117, -0.0097, -0.0255, -0.0255,  0.0183,  0.0414,\n",
            "         0.0230,  0.0124, -0.0026,  0.0354,  0.0296, -0.0295,  0.0338,  0.0335,\n",
            "         0.0112, -0.0382, -0.0412, -0.0043,  0.0043, -0.0024,  0.0056,  0.0163,\n",
            "        -0.0060,  0.0163,  0.0080, -0.0162, -0.0383,  0.0389, -0.0328, -0.0289],\n",
            "       device='cuda:0')\n",
            "NPF_C3.weight Parameter containing:\n",
            "tensor([[[[ 2.7964e-02, -1.4258e-02,  4.0640e-02],\n",
            "          [-6.4360e-03,  3.4412e-02,  3.0588e-02],\n",
            "          [ 3.5793e-02,  3.7687e-02,  9.4342e-03]],\n",
            "\n",
            "         [[-3.9900e-03, -4.0618e-02,  2.5096e-02],\n",
            "          [-1.3614e-02,  3.4912e-02, -2.6618e-02],\n",
            "          [ 2.2629e-02,  5.6354e-03,  1.1217e-02]],\n",
            "\n",
            "         [[-6.5209e-03,  5.9811e-03, -1.5307e-02],\n",
            "          [-1.0775e-02,  2.3972e-02, -3.9299e-02],\n",
            "          [-3.8561e-02,  2.0907e-02,  4.9464e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.9694e-02,  4.0515e-02,  1.5700e-02],\n",
            "          [ 1.7462e-02, -3.6028e-02,  3.1087e-02],\n",
            "          [ 1.9048e-02,  3.1775e-02,  6.4598e-03]],\n",
            "\n",
            "         [[ 2.7395e-02, -3.8971e-03,  2.9767e-02],\n",
            "          [-6.3219e-03,  2.0025e-02,  1.1343e-02],\n",
            "          [ 3.1056e-02, -1.7743e-02, -3.5663e-02]],\n",
            "\n",
            "         [[-1.3631e-03,  2.5367e-02,  1.9388e-02],\n",
            "          [ 9.2037e-04,  3.1117e-03, -2.8092e-02],\n",
            "          [ 1.0733e-02, -1.5830e-02,  1.8856e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 2.3618e-02,  1.6402e-02,  2.7680e-02],\n",
            "          [-2.9454e-03,  9.0999e-03, -4.0935e-02],\n",
            "          [ 7.2690e-03,  5.7285e-03,  2.2135e-02]],\n",
            "\n",
            "         [[ 8.1404e-04, -1.3830e-02,  2.4567e-02],\n",
            "          [-5.7046e-03,  1.2211e-02, -1.1058e-02],\n",
            "          [ 1.7042e-02, -2.1791e-02, -2.0363e-02]],\n",
            "\n",
            "         [[ 4.0726e-02, -1.6742e-02, -2.7742e-02],\n",
            "          [-2.9966e-02, -3.9999e-02, -9.2839e-03],\n",
            "          [ 2.7488e-02,  4.0374e-02,  3.3610e-04]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 5.7650e-04,  1.1935e-02, -1.8034e-02],\n",
            "          [ 4.9914e-03,  1.7028e-02, -2.1654e-02],\n",
            "          [-4.2637e-03,  3.5707e-02, -7.2846e-04]],\n",
            "\n",
            "         [[ 3.1115e-02,  1.7409e-02, -1.2101e-02],\n",
            "          [-2.9670e-02, -3.8161e-02, -1.9423e-02],\n",
            "          [ 2.2065e-02, -1.8369e-02,  3.4714e-02]],\n",
            "\n",
            "         [[ 2.9645e-02, -3.8235e-02,  5.5455e-03],\n",
            "          [ 3.1655e-02,  7.9072e-04, -3.1601e-02],\n",
            "          [ 1.2379e-03, -3.9337e-02, -7.9931e-03]]],\n",
            "\n",
            "\n",
            "        [[[-2.1406e-02,  2.3093e-02,  3.1546e-02],\n",
            "          [-2.1994e-02, -4.0008e-02, -3.5435e-03],\n",
            "          [ 2.9838e-02,  2.2146e-02,  2.3794e-02]],\n",
            "\n",
            "         [[ 1.9661e-02,  1.6452e-02,  1.9968e-02],\n",
            "          [ 4.4264e-03, -4.0699e-02, -8.6403e-03],\n",
            "          [ 3.0221e-02, -3.3615e-02,  1.0790e-02]],\n",
            "\n",
            "         [[ 1.9644e-02, -3.7969e-02,  4.3768e-03],\n",
            "          [ 3.4995e-02, -3.0314e-02, -3.7152e-02],\n",
            "          [ 1.9988e-02,  2.9717e-02,  8.5722e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.0374e-02,  4.1600e-02,  2.8022e-02],\n",
            "          [ 3.6694e-02,  1.3379e-02, -2.6019e-02],\n",
            "          [ 5.4211e-03,  4.0412e-02,  1.8356e-02]],\n",
            "\n",
            "         [[-2.3640e-02, -3.9205e-02, -1.1693e-03],\n",
            "          [-6.7535e-03, -4.1143e-02,  1.5097e-02],\n",
            "          [ 2.0514e-02, -1.9466e-02,  1.4203e-02]],\n",
            "\n",
            "         [[-3.3424e-02, -2.1709e-02,  8.0118e-04],\n",
            "          [ 2.7743e-02, -2.7193e-02,  2.0645e-02],\n",
            "          [-3.6155e-02,  4.5968e-03, -3.3871e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-7.3697e-04,  3.8861e-02,  1.2079e-02],\n",
            "          [-6.2368e-03,  3.1688e-03, -3.8680e-02],\n",
            "          [-3.3131e-02, -3.0931e-03,  2.0324e-02]],\n",
            "\n",
            "         [[-3.6622e-02, -5.5431e-03, -1.1966e-02],\n",
            "          [ 1.9755e-02,  3.2430e-02,  1.0582e-03],\n",
            "          [-1.2669e-02,  3.3010e-02, -2.0602e-02]],\n",
            "\n",
            "         [[ 1.8051e-02,  1.7199e-02,  2.3979e-02],\n",
            "          [-7.1250e-03, -3.3461e-02, -2.7502e-02],\n",
            "          [ 2.3725e-02,  4.3231e-03, -2.6217e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.1319e-03,  3.5811e-02, -3.8871e-02],\n",
            "          [-1.1978e-02,  1.6480e-02, -2.1538e-03],\n",
            "          [ 7.3885e-03,  2.2238e-02,  1.7665e-02]],\n",
            "\n",
            "         [[-2.4053e-02, -3.0802e-02,  4.1223e-02],\n",
            "          [ 1.5771e-02, -1.2075e-02, -3.2030e-02],\n",
            "          [-2.6104e-02,  3.6451e-02,  5.9892e-03]],\n",
            "\n",
            "         [[ 3.0297e-02, -8.1001e-03,  3.7775e-02],\n",
            "          [-3.8234e-02, -2.3163e-02,  1.9187e-02],\n",
            "          [ 3.6559e-02,  1.4206e-02, -4.0266e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.2005e-02,  2.1562e-02,  1.6410e-02],\n",
            "          [-2.3498e-02, -2.8166e-03,  1.7308e-02],\n",
            "          [-2.0041e-02,  4.0335e-02, -2.9493e-02]],\n",
            "\n",
            "         [[ 5.0690e-04,  2.0888e-02, -1.2477e-02],\n",
            "          [-3.4167e-02,  1.1532e-02, -2.4002e-02],\n",
            "          [-2.0033e-03,  4.7282e-03, -3.0495e-02]],\n",
            "\n",
            "         [[ 2.9176e-03, -2.5673e-02,  4.0826e-03],\n",
            "          [ 6.8617e-03, -2.3629e-02, -2.0861e-02],\n",
            "          [-3.3453e-02, -9.5845e-03, -3.8751e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.9466e-02,  3.3056e-02,  1.9936e-02],\n",
            "          [ 5.0624e-03,  3.0220e-02,  1.6363e-02],\n",
            "          [-3.6786e-02, -4.8099e-03,  3.4955e-02]],\n",
            "\n",
            "         [[ 3.3082e-02,  3.7240e-02, -1.7191e-02],\n",
            "          [-4.1342e-02, -1.1075e-02,  3.5222e-02],\n",
            "          [-1.7428e-03,  8.3491e-03,  1.4344e-03]],\n",
            "\n",
            "         [[-8.0141e-03, -2.8263e-02, -1.3644e-03],\n",
            "          [-4.0597e-02,  3.9626e-02,  3.6791e-02],\n",
            "          [-1.3819e-02,  2.4887e-02, -1.0969e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 3.3566e-02, -6.0411e-03, -1.1267e-02],\n",
            "          [-1.2250e-02,  8.3967e-03,  1.2664e-02],\n",
            "          [-6.0466e-03,  4.0174e-03,  3.5914e-03]],\n",
            "\n",
            "         [[ 1.9744e-02,  1.3591e-03,  2.8004e-02],\n",
            "          [ 2.6026e-02, -3.9161e-02, -1.0894e-02],\n",
            "          [-1.3921e-02, -3.9964e-02, -3.3850e-02]],\n",
            "\n",
            "         [[-2.6803e-02,  5.9273e-03,  2.7128e-02],\n",
            "          [-2.1382e-02, -4.3930e-03, -3.1639e-02],\n",
            "          [-2.9629e-02, -6.7011e-05, -1.7125e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.9256e-02, -1.8403e-02,  2.2623e-02],\n",
            "          [ 1.4056e-04, -3.3285e-02,  2.9321e-03],\n",
            "          [-2.2694e-02, -1.8592e-02,  8.3035e-03]],\n",
            "\n",
            "         [[ 3.9342e-02, -2.5095e-02, -2.9747e-02],\n",
            "          [ 4.1379e-02, -2.1784e-02,  4.1285e-02],\n",
            "          [-3.1189e-02, -3.9926e-02,  5.0639e-03]],\n",
            "\n",
            "         [[-3.1951e-02,  2.6050e-02, -1.8915e-02],\n",
            "          [ 2.7522e-02,  3.9140e-02,  3.2991e-02],\n",
            "          [ 3.2530e-02, -2.9558e-02,  1.7301e-03]]]], device='cuda:0')\n",
            "NPF_C3.bias Parameter containing:\n",
            "tensor([ 3.9334e-05,  3.2020e-02,  1.0248e-02,  1.8496e-02,  1.9509e-02,\n",
            "         4.5388e-03,  1.2364e-02,  3.1531e-02,  3.2969e-02,  1.7468e-02,\n",
            "         2.6937e-02, -1.6519e-02, -3.2731e-02, -2.4987e-02, -2.4944e-02,\n",
            "        -7.0629e-03,  3.4070e-02,  9.9553e-03,  1.9015e-03,  2.4769e-02,\n",
            "         1.1476e-02, -2.7237e-02,  1.0295e-03,  1.5450e-02,  1.3191e-02,\n",
            "         4.8306e-03, -3.9031e-02, -4.5210e-03,  1.2507e-02, -1.3457e-02,\n",
            "         8.2698e-03,  1.5339e-02, -1.8239e-02,  5.3797e-03, -3.7862e-02,\n",
            "         2.5797e-02, -1.1372e-02,  2.6838e-02,  1.6744e-02, -1.8637e-02,\n",
            "        -2.2878e-03,  1.4239e-03,  2.9046e-02,  1.2103e-02, -6.1151e-03,\n",
            "         3.1155e-02, -7.9520e-03, -7.0102e-03,  3.5401e-02, -3.4902e-03,\n",
            "         3.0340e-02,  1.3760e-02,  3.9065e-02,  9.4195e-03, -3.2208e-02,\n",
            "        -3.1558e-02,  3.0383e-02,  3.1279e-02, -3.4103e-03,  2.4346e-02,\n",
            "        -1.5568e-02, -1.1867e-02, -8.7517e-03,  2.3896e-02, -1.7156e-02,\n",
            "         2.8070e-02, -3.2973e-02,  2.7324e-02,  3.9937e-02, -4.0962e-02,\n",
            "         1.4773e-02,  3.6188e-02, -2.2469e-02, -2.9435e-02,  1.3103e-02,\n",
            "        -1.6624e-03, -2.9834e-02, -4.0356e-02,  2.1805e-02, -4.6286e-03,\n",
            "        -2.0130e-02, -1.1196e-03,  2.0735e-02, -3.6496e-02,  1.8620e-02,\n",
            "         2.9400e-02, -3.7292e-02,  1.9416e-02,  4.0859e-03,  3.2973e-03,\n",
            "        -3.9134e-02,  2.7848e-02,  1.5195e-02, -1.3676e-02, -9.4028e-03,\n",
            "         2.5965e-02, -2.3699e-02,  3.7911e-02, -1.1878e-02,  8.9494e-03,\n",
            "        -2.6671e-02, -2.2572e-03,  2.1223e-02,  1.9284e-02,  4.1343e-02,\n",
            "        -1.4305e-02,  1.6663e-02, -1.7826e-02, -2.7934e-02,  6.2691e-03,\n",
            "         3.4998e-02, -3.4677e-02,  2.3974e-02, -1.1317e-02,  2.4374e-02,\n",
            "        -6.2491e-03,  3.9319e-02, -2.1692e-02, -7.7318e-03, -1.1863e-02,\n",
            "        -2.2265e-02,  1.6739e-02, -9.3299e-03, -7.1998e-03, -2.6129e-02,\n",
            "        -1.2814e-02, -1.7375e-02, -3.3522e-02], device='cuda:0')\n",
            "NPF_C4.weight Parameter containing:\n",
            "tensor([[[[ 2.0371e-02,  2.9366e-02,  5.6723e-04],\n",
            "          [-2.3028e-04,  2.5723e-02,  1.7856e-03],\n",
            "          [-9.5709e-03, -2.2411e-02, -4.9527e-03]],\n",
            "\n",
            "         [[-2.1369e-02,  1.2335e-02, -1.3031e-02],\n",
            "          [ 2.0297e-02,  1.0076e-02, -1.4825e-02],\n",
            "          [-8.7485e-03,  1.9612e-03, -2.0883e-02]],\n",
            "\n",
            "         [[-2.8318e-02,  1.2317e-02, -1.5886e-02],\n",
            "          [-5.4808e-03, -1.9719e-02, -2.3132e-02],\n",
            "          [ 3.0672e-03, -2.2396e-02,  2.2666e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.6879e-02, -6.5732e-04, -7.3133e-03],\n",
            "          [ 4.6296e-03,  2.0565e-02,  3.9215e-03],\n",
            "          [-2.2803e-02, -2.4928e-04,  1.6335e-02]],\n",
            "\n",
            "         [[-1.2904e-02,  1.9270e-02,  2.3459e-02],\n",
            "          [ 1.8793e-02, -2.8703e-02, -2.0345e-03],\n",
            "          [-6.2186e-03, -2.8327e-03, -1.5454e-02]],\n",
            "\n",
            "         [[-5.3830e-03,  5.0183e-05, -3.4396e-03],\n",
            "          [-2.0566e-02,  1.4086e-02, -2.2225e-02],\n",
            "          [ 2.3416e-02,  5.7609e-03,  2.9188e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.7112e-02, -2.5985e-03, -2.1115e-02],\n",
            "          [-2.4310e-02, -2.5098e-02,  1.8037e-02],\n",
            "          [ 2.7847e-02, -1.9314e-02,  8.5644e-03]],\n",
            "\n",
            "         [[ 1.0178e-02,  4.8181e-03,  1.9158e-02],\n",
            "          [ 7.4500e-03, -1.0284e-02,  2.2824e-02],\n",
            "          [-6.2708e-03, -2.7865e-02, -2.5806e-02]],\n",
            "\n",
            "         [[ 9.4741e-04,  2.7920e-02, -7.7941e-03],\n",
            "          [-1.9723e-02, -2.2342e-02,  8.3604e-03],\n",
            "          [-8.9683e-03, -1.0408e-02, -1.1677e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-2.7584e-02,  2.8878e-02, -7.6429e-03],\n",
            "          [ 2.6966e-02, -1.0924e-02, -2.5849e-02],\n",
            "          [ 4.9638e-03, -1.8870e-02, -1.3405e-02]],\n",
            "\n",
            "         [[-8.7446e-03,  6.8953e-03, -1.9061e-02],\n",
            "          [-2.0679e-02, -2.4272e-02,  2.5117e-02],\n",
            "          [-2.0867e-02,  6.2490e-03, -7.9333e-03]],\n",
            "\n",
            "         [[ 2.8818e-02, -6.3632e-03,  2.7174e-02],\n",
            "          [ 2.7470e-03, -3.1414e-03, -1.0995e-02],\n",
            "          [ 8.3427e-03, -2.0543e-02,  8.8460e-03]]],\n",
            "\n",
            "\n",
            "        [[[-5.2246e-03, -1.1179e-02, -3.3132e-03],\n",
            "          [ 2.9368e-02, -2.6744e-02, -5.6882e-03],\n",
            "          [ 9.3046e-03, -3.1545e-03, -2.7793e-02]],\n",
            "\n",
            "         [[ 1.7291e-02,  1.5052e-02,  2.1028e-02],\n",
            "          [ 4.4790e-03,  1.6760e-02, -1.0324e-02],\n",
            "          [ 1.1675e-02, -9.9784e-03,  1.6773e-02]],\n",
            "\n",
            "         [[-2.2413e-02, -1.6915e-02,  1.7619e-02],\n",
            "          [-2.7371e-02,  8.9296e-03,  3.8491e-03],\n",
            "          [ 1.3897e-02,  1.5760e-02,  2.1224e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8354e-03,  1.3885e-02,  6.5864e-03],\n",
            "          [ 1.2424e-02, -7.3867e-03,  2.5766e-03],\n",
            "          [-1.5892e-02,  2.4031e-02, -2.8694e-02]],\n",
            "\n",
            "         [[-2.7957e-03, -1.4309e-02,  6.5412e-03],\n",
            "          [-2.1657e-02,  2.4818e-03, -7.9125e-03],\n",
            "          [-2.7373e-02,  7.1716e-03,  4.6227e-03]],\n",
            "\n",
            "         [[ 7.9520e-03, -2.3439e-02, -1.5321e-02],\n",
            "          [ 1.7384e-02,  1.2488e-02, -1.6774e-02],\n",
            "          [ 2.8079e-02,  5.0753e-03, -2.5537e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 2.8584e-02, -2.5551e-02, -1.6184e-02],\n",
            "          [-2.8825e-02, -1.9226e-02, -1.3303e-02],\n",
            "          [ 2.6902e-02, -2.0712e-02, -2.6141e-02]],\n",
            "\n",
            "         [[-2.6779e-02,  2.7673e-02,  1.5814e-02],\n",
            "          [ 4.1666e-04,  4.9395e-03,  2.8764e-02],\n",
            "          [-1.5150e-02,  7.0400e-03, -2.6306e-02]],\n",
            "\n",
            "         [[ 7.3209e-03,  2.2140e-02,  5.7249e-04],\n",
            "          [-2.3913e-02,  5.9633e-03, -1.6602e-02],\n",
            "          [ 2.1585e-02, -2.4239e-02, -1.6952e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-1.7418e-02, -2.4630e-02, -1.0397e-02],\n",
            "          [-1.4418e-02, -2.1527e-02, -5.4219e-03],\n",
            "          [-1.8274e-03, -9.2246e-03,  2.2469e-02]],\n",
            "\n",
            "         [[ 1.7511e-03, -1.2887e-02,  2.4699e-02],\n",
            "          [-8.9034e-03, -7.7052e-03, -2.3588e-02],\n",
            "          [ 1.9349e-02, -1.0436e-02, -1.0437e-03]],\n",
            "\n",
            "         [[ 2.6038e-02, -1.5518e-02,  2.5768e-02],\n",
            "          [-1.8447e-02,  9.6301e-03, -2.8336e-02],\n",
            "          [-9.8251e-05, -6.7263e-03,  7.9410e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.9911e-02, -2.4228e-02, -1.3800e-02],\n",
            "          [-1.5150e-02, -1.1877e-02,  3.0183e-03],\n",
            "          [ 7.3772e-03, -7.0166e-03, -2.0739e-02]],\n",
            "\n",
            "         [[-2.4704e-02,  6.5812e-03, -1.6508e-02],\n",
            "          [ 5.4046e-03,  1.9260e-02, -1.3667e-02],\n",
            "          [ 2.1882e-04, -6.9893e-03, -1.0153e-02]],\n",
            "\n",
            "         [[ 1.1859e-02,  2.1625e-02, -1.0004e-02],\n",
            "          [ 2.6110e-02,  2.6414e-02, -1.4471e-02],\n",
            "          [-2.4016e-03,  8.1579e-03,  1.2462e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.8600e-02,  2.6413e-02,  7.2234e-03],\n",
            "          [-2.0334e-02, -7.8676e-03,  2.6492e-02],\n",
            "          [ 1.3931e-02, -1.1665e-02, -2.0343e-02]],\n",
            "\n",
            "         [[-5.5493e-03,  1.4370e-02,  1.4061e-02],\n",
            "          [ 2.0525e-02, -1.9774e-02, -1.7299e-02],\n",
            "          [-6.9514e-05, -2.3270e-02,  1.3680e-02]],\n",
            "\n",
            "         [[-1.4865e-02,  2.2148e-02,  8.6107e-03],\n",
            "          [-1.0392e-02, -1.8661e-02,  2.2275e-02],\n",
            "          [ 2.1634e-02,  2.7876e-02, -1.1388e-02]]],\n",
            "\n",
            "\n",
            "        [[[-7.9545e-03, -2.6297e-02,  2.3686e-02],\n",
            "          [-1.6311e-02, -1.0122e-02, -1.8776e-02],\n",
            "          [ 1.1145e-02, -9.1403e-03,  7.7255e-05]],\n",
            "\n",
            "         [[-3.8423e-03, -2.2878e-02, -2.0976e-02],\n",
            "          [-9.6178e-03,  5.0834e-03,  8.2321e-04],\n",
            "          [ 1.8336e-02,  2.8831e-02, -1.2464e-02]],\n",
            "\n",
            "         [[ 2.0929e-02,  1.5928e-02,  2.5535e-02],\n",
            "          [ 2.1138e-03,  2.6109e-02,  1.2691e-02],\n",
            "          [-1.8036e-02, -9.0674e-03,  1.0521e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.3000e-04,  8.5512e-03, -2.6620e-02],\n",
            "          [-1.8205e-02, -1.3702e-02, -2.5862e-02],\n",
            "          [-2.8032e-02, -5.9691e-03, -2.7248e-03]],\n",
            "\n",
            "         [[-2.5383e-02, -1.5387e-02, -8.1234e-03],\n",
            "          [ 1.2977e-02, -2.4731e-02, -2.0188e-02],\n",
            "          [ 1.1842e-02,  1.7818e-02, -1.0922e-02]],\n",
            "\n",
            "         [[-5.4602e-03, -2.5708e-03, -1.1811e-02],\n",
            "          [ 1.0543e-02, -1.6501e-02,  1.5387e-02],\n",
            "          [ 8.6818e-03,  1.7294e-03,  2.9350e-02]]]], device='cuda:0')\n",
            "NPF_C4.bias Parameter containing:\n",
            "tensor([ 0.0137, -0.0204, -0.0101, -0.0151,  0.0094, -0.0185,  0.0122, -0.0271,\n",
            "         0.0293,  0.0181, -0.0288, -0.0119,  0.0091,  0.0265, -0.0165, -0.0045,\n",
            "         0.0139, -0.0147, -0.0034,  0.0294, -0.0287,  0.0162, -0.0068, -0.0136,\n",
            "        -0.0033, -0.0008, -0.0013, -0.0058,  0.0005, -0.0115,  0.0103,  0.0061,\n",
            "         0.0011, -0.0180,  0.0002,  0.0090, -0.0087,  0.0015,  0.0237,  0.0077,\n",
            "        -0.0043, -0.0119,  0.0247, -0.0264, -0.0243, -0.0017, -0.0016, -0.0285,\n",
            "         0.0210, -0.0050,  0.0087, -0.0084, -0.0071, -0.0145, -0.0032, -0.0111,\n",
            "         0.0207, -0.0062,  0.0122,  0.0273, -0.0169, -0.0266,  0.0276, -0.0258,\n",
            "        -0.0126,  0.0076,  0.0008,  0.0241, -0.0265, -0.0149,  0.0250, -0.0222,\n",
            "         0.0045, -0.0278, -0.0078, -0.0152,  0.0214,  0.0180,  0.0250, -0.0067,\n",
            "         0.0139, -0.0149, -0.0186, -0.0084, -0.0173,  0.0284, -0.0111, -0.0144,\n",
            "        -0.0169,  0.0230, -0.0067, -0.0052, -0.0242,  0.0277, -0.0127, -0.0236,\n",
            "        -0.0108, -0.0114,  0.0030, -0.0238,  0.0287,  0.0240,  0.0073, -0.0236,\n",
            "        -0.0171,  0.0158,  0.0034,  0.0271, -0.0106, -0.0126, -0.0136, -0.0280,\n",
            "        -0.0137, -0.0210, -0.0213, -0.0256,  0.0253, -0.0180, -0.0215,  0.0198,\n",
            "        -0.0254, -0.0248, -0.0231, -0.0003, -0.0215,  0.0053,  0.0088, -0.0200],\n",
            "       device='cuda:0')\n",
            "NPF_D1.weight Parameter containing:\n",
            "tensor([[-0.0008, -0.0017,  0.0014,  ...,  0.0025,  0.0022, -0.0017],\n",
            "        [ 0.0024, -0.0001, -0.0024,  ...,  0.0025, -0.0026, -0.0016],\n",
            "        [ 0.0015, -0.0026, -0.0003,  ..., -0.0008, -0.0014,  0.0009],\n",
            "        ...,\n",
            "        [-0.0006, -0.0011,  0.0014,  ...,  0.0011, -0.0025,  0.0009],\n",
            "        [-0.0026,  0.0005,  0.0020,  ...,  0.0012, -0.0015, -0.0011],\n",
            "        [-0.0014, -0.0022,  0.0024,  ...,  0.0016,  0.0024,  0.0021]],\n",
            "       device='cuda:0')\n",
            "NPF_D1.bias Parameter containing:\n",
            "tensor([ 4.2381e-04,  6.3669e-04,  1.6792e-04, -4.7863e-04, -1.8585e-04,\n",
            "         2.6467e-03, -1.0965e-03,  2.3995e-03, -2.1861e-03,  1.2774e-03,\n",
            "        -2.6267e-03,  1.4881e-03, -2.4879e-03, -2.0339e-04, -1.8089e-03,\n",
            "        -2.2518e-03,  1.3348e-03, -5.2184e-04,  2.6268e-04,  6.9110e-05,\n",
            "        -1.8144e-03,  8.9410e-04,  2.0638e-03,  1.5168e-03, -2.6475e-03,\n",
            "         2.5728e-03, -3.0734e-04, -2.3725e-03, -1.1090e-03, -2.2503e-03,\n",
            "         2.2998e-03,  7.8752e-04, -1.7956e-03, -1.0386e-03, -2.4257e-03,\n",
            "         2.2913e-03, -9.8518e-04, -1.3360e-03, -7.6197e-04,  4.4794e-04,\n",
            "         2.4711e-03, -5.5210e-04,  2.0021e-03, -1.2849e-03, -2.5338e-03,\n",
            "        -1.0677e-03, -2.2408e-03, -2.0894e-04,  8.0408e-04,  1.1650e-03,\n",
            "         2.7215e-03,  1.5429e-03, -2.7524e-03, -6.4700e-04, -2.7212e-03,\n",
            "        -1.7297e-03,  1.5433e-03,  3.4041e-04,  2.0696e-03,  1.6445e-03,\n",
            "        -1.6894e-03, -2.1654e-03,  9.3084e-04, -1.6646e-03,  1.9251e-03,\n",
            "        -2.6827e-03, -2.8796e-04, -4.0230e-04, -2.4846e-03, -2.5744e-03,\n",
            "         2.5201e-03,  3.5431e-04,  1.8965e-03, -1.6455e-04,  2.5687e-04,\n",
            "        -1.4282e-03, -1.5757e-03, -9.4774e-04, -1.8050e-03, -2.7233e-03,\n",
            "        -2.7070e-03, -2.1912e-03, -7.9485e-05,  1.0748e-03,  2.0624e-03,\n",
            "         1.1190e-04,  5.2145e-04, -1.3550e-03, -5.7670e-04, -2.2743e-03,\n",
            "         2.6369e-03, -2.3244e-03, -1.7664e-03,  2.7311e-03,  1.6093e-03,\n",
            "        -2.3789e-03,  1.9175e-03, -7.8933e-06, -6.0744e-04,  1.8881e-04,\n",
            "        -6.8827e-04,  2.6160e-03, -1.7735e-04,  1.1211e-03, -1.9872e-03,\n",
            "        -2.3313e-04, -2.2866e-03, -2.1566e-04, -1.1760e-03,  1.2144e-03,\n",
            "         2.0194e-03, -1.2600e-03,  7.7531e-04, -1.5862e-03, -2.5931e-04,\n",
            "         2.6036e-03, -1.5199e-03, -2.2965e-03,  2.0166e-03, -1.1569e-03,\n",
            "         1.7330e-03, -1.9029e-03, -1.0759e-03, -2.1008e-03,  1.5300e-03,\n",
            "         1.5855e-03, -2.6084e-03, -5.7586e-04, -6.4429e-04, -2.3820e-03,\n",
            "        -2.2338e-03,  1.8480e-04, -8.0471e-04, -1.2572e-03,  1.6492e-03,\n",
            "         6.9357e-04,  1.7454e-03,  2.5374e-03, -1.2470e-03, -4.4669e-04,\n",
            "         4.8638e-04, -2.0177e-04, -8.3812e-05,  1.0899e-03, -7.6644e-04,\n",
            "         5.2766e-04,  3.1983e-04, -2.8828e-04, -1.3098e-03,  1.3881e-03,\n",
            "        -1.9326e-03, -1.4517e-03,  1.1955e-03,  2.0040e-03,  6.8689e-04,\n",
            "        -1.2166e-03, -3.4795e-04, -7.8156e-05,  1.2742e-03, -2.4727e-03,\n",
            "        -1.9939e-03,  5.9816e-04, -1.6330e-03,  2.4431e-03,  1.4985e-03,\n",
            "         6.7411e-04,  1.8391e-03, -7.6327e-04,  1.5217e-03, -2.0517e-03,\n",
            "        -1.1564e-03, -1.6793e-03,  2.1213e-03,  1.1693e-03,  1.5846e-03,\n",
            "        -1.0743e-03,  7.7726e-04, -1.1152e-03, -2.5255e-03,  2.3981e-03,\n",
            "         1.3346e-03,  2.1901e-03, -1.6430e-03, -2.3493e-04,  1.5688e-03,\n",
            "         6.0778e-04,  1.0380e-03,  2.2601e-03, -4.4303e-04, -2.1110e-03,\n",
            "        -9.3645e-04, -2.7530e-03, -2.0961e-03, -5.8628e-04,  4.1795e-04,\n",
            "        -2.5625e-03,  2.1970e-03,  8.8361e-04,  1.8522e-03, -1.5451e-03,\n",
            "         2.5454e-03, -2.6268e-03, -2.4506e-03,  1.2301e-03,  1.2361e-03,\n",
            "         1.4738e-03,  1.9664e-03,  2.5124e-03, -1.5915e-03, -9.4372e-05,\n",
            "         1.8074e-03,  2.4719e-03,  5.2893e-04, -7.7887e-04, -2.6860e-04,\n",
            "        -2.5095e-03, -1.0351e-03,  1.9813e-03,  1.0569e-03,  2.4972e-03,\n",
            "         2.6966e-03,  2.4028e-04,  1.0813e-03,  1.5315e-03,  1.6258e-03,\n",
            "        -1.0556e-03, -2.0518e-03,  2.6927e-04, -1.7547e-03,  2.4715e-03,\n",
            "         9.5889e-04,  2.3967e-03,  1.4629e-03,  1.6212e-03,  7.7731e-04,\n",
            "        -1.2734e-03, -1.2658e-03, -2.7010e-03, -2.5887e-03, -1.4514e-03,\n",
            "        -1.7323e-03, -2.5461e-03, -1.7107e-03,  2.4143e-03,  2.0808e-04,\n",
            "         1.0302e-03, -2.3519e-03,  1.4558e-03,  3.9802e-04, -1.6821e-03,\n",
            "        -1.4050e-03, -1.1211e-03,  7.4840e-04, -2.3959e-03, -1.1967e-03,\n",
            "         1.2013e-03], device='cuda:0')\n",
            "NPF_D2.weight Parameter containing:\n",
            "tensor([[ 0.0548,  0.0055, -0.0173,  ...,  0.0355,  0.0413, -0.0314],\n",
            "        [-0.0383, -0.0123, -0.0289,  ..., -0.0085, -0.0120, -0.0243],\n",
            "        [ 0.0610,  0.0129, -0.0194,  ..., -0.0605,  0.0478,  0.0328],\n",
            "        ...,\n",
            "        [ 0.0133, -0.0540, -0.0280,  ...,  0.0393, -0.0283, -0.0169],\n",
            "        [ 0.0576, -0.0217,  0.0077,  ..., -0.0422,  0.0159, -0.0040],\n",
            "        [ 0.0408, -0.0072,  0.0035,  ..., -0.0166, -0.0371, -0.0158]],\n",
            "       device='cuda:0')\n",
            "NPF_D2.bias Parameter containing:\n",
            "tensor([-0.0054,  0.0436, -0.0372,  0.0399, -0.0412, -0.0407, -0.0346, -0.0198,\n",
            "         0.0248, -0.0451,  0.0398, -0.0401, -0.0415, -0.0012, -0.0124,  0.0202,\n",
            "        -0.0455,  0.0025, -0.0480, -0.0366, -0.0605, -0.0133, -0.0560,  0.0253,\n",
            "         0.0362, -0.0335, -0.0042, -0.0327,  0.0216,  0.0586,  0.0450, -0.0609,\n",
            "         0.0348,  0.0567, -0.0416, -0.0068, -0.0214, -0.0288,  0.0291, -0.0288,\n",
            "        -0.0228,  0.0094, -0.0417,  0.0507,  0.0305,  0.0190, -0.0134, -0.0237,\n",
            "         0.0267, -0.0351, -0.0405, -0.0085, -0.0452,  0.0361, -0.0002, -0.0017,\n",
            "        -0.0191, -0.0280,  0.0312, -0.0420,  0.0563, -0.0093,  0.0494, -0.0348,\n",
            "        -0.0205,  0.0223,  0.0344,  0.0013, -0.0192, -0.0207,  0.0529, -0.0036,\n",
            "        -0.0080,  0.0267, -0.0541,  0.0483,  0.0572,  0.0506, -0.0059,  0.0355,\n",
            "         0.0238, -0.0340, -0.0443,  0.0096, -0.0479,  0.0205,  0.0404, -0.0611,\n",
            "        -0.0379, -0.0078, -0.0282, -0.0387, -0.0350, -0.0328, -0.0086, -0.0530,\n",
            "         0.0300,  0.0102,  0.0465, -0.0300,  0.0057,  0.0478,  0.0350,  0.0252,\n",
            "        -0.0097, -0.0434,  0.0069, -0.0386,  0.0071, -0.0442, -0.0287, -0.0482,\n",
            "         0.0215, -0.0154,  0.0370, -0.0294, -0.0158, -0.0106, -0.0195,  0.0083,\n",
            "        -0.0482, -0.0442,  0.0549, -0.0336,  0.0104, -0.0251, -0.0074,  0.0509,\n",
            "         0.0455,  0.0343, -0.0322,  0.0248,  0.0011, -0.0500, -0.0516,  0.0551,\n",
            "         0.0310,  0.0070, -0.0512,  0.0206,  0.0226, -0.0088, -0.0022, -0.0607,\n",
            "         0.0195, -0.0266, -0.0248,  0.0561, -0.0356, -0.0392, -0.0256,  0.0311,\n",
            "         0.0475,  0.0565,  0.0365, -0.0190, -0.0072, -0.0391,  0.0094, -0.0346,\n",
            "         0.0392,  0.0129, -0.0118, -0.0316,  0.0455,  0.0108,  0.0489, -0.0218,\n",
            "         0.0317,  0.0152, -0.0542, -0.0532, -0.0208,  0.0338, -0.0377,  0.0178,\n",
            "        -0.0343, -0.0304, -0.0119, -0.0556,  0.0549, -0.0142, -0.0339, -0.0219,\n",
            "         0.0270,  0.0254,  0.0279, -0.0285, -0.0435, -0.0624,  0.0210, -0.0164,\n",
            "        -0.0106, -0.0144, -0.0201, -0.0099,  0.0128,  0.0404,  0.0176, -0.0052,\n",
            "        -0.0574,  0.0240, -0.0339,  0.0285,  0.0616, -0.0188, -0.0533, -0.0526,\n",
            "         0.0101,  0.0582,  0.0477,  0.0560, -0.0205, -0.0323,  0.0323,  0.0064,\n",
            "        -0.0387,  0.0220, -0.0007, -0.0289, -0.0328,  0.0551, -0.0031,  0.0196,\n",
            "        -0.0106, -0.0261, -0.0341,  0.0105,  0.0136, -0.0010, -0.0550, -0.0505,\n",
            "         0.0051,  0.0343,  0.0582,  0.0029, -0.0136, -0.0310,  0.0122,  0.0123,\n",
            "         0.0237, -0.0338, -0.0043, -0.0002,  0.0490,  0.0339, -0.0147, -0.0243,\n",
            "        -0.0569, -0.0419, -0.0522, -0.0211, -0.0138, -0.0091,  0.0220,  0.0110],\n",
            "       device='cuda:0')\n",
            "NPV_C1.weight Parameter containing:\n",
            "tensor([[[[ 0.1439,  0.1235,  0.1334],\n",
            "          [-0.0367, -0.0182,  0.0882],\n",
            "          [ 0.1098, -0.0423, -0.0311]],\n",
            "\n",
            "         [[-0.0388, -0.0585,  0.1656],\n",
            "          [-0.0744, -0.0497, -0.1528],\n",
            "          [ 0.0572,  0.1653,  0.0680]],\n",
            "\n",
            "         [[ 0.0709,  0.0773, -0.1499],\n",
            "          [-0.0665,  0.0137,  0.0337],\n",
            "          [ 0.1010,  0.0986,  0.1184]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0253,  0.0712, -0.1079],\n",
            "          [-0.0650, -0.0289, -0.1373],\n",
            "          [ 0.0572,  0.1747, -0.1841]],\n",
            "\n",
            "         [[ 0.0453, -0.0063, -0.0051],\n",
            "          [-0.0063, -0.0573, -0.0153],\n",
            "          [ 0.0129,  0.1215, -0.1573]],\n",
            "\n",
            "         [[-0.1953,  0.0528, -0.0865],\n",
            "          [-0.1359,  0.0722,  0.1463],\n",
            "          [ 0.0488,  0.0912,  0.1857]]],\n",
            "\n",
            "\n",
            "        [[[-0.1279, -0.1052,  0.1603],\n",
            "          [ 0.0498, -0.0874, -0.0633],\n",
            "          [ 0.0945,  0.1263,  0.1028]],\n",
            "\n",
            "         [[-0.1742, -0.0347, -0.1759],\n",
            "          [-0.0940, -0.0251, -0.1792],\n",
            "          [ 0.0867, -0.2025, -0.0961]],\n",
            "\n",
            "         [[-0.0320, -0.0412, -0.1846],\n",
            "          [-0.0172, -0.1976, -0.2326],\n",
            "          [-0.1200, -0.0170, -0.2205]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1927, -0.0999,  0.1469],\n",
            "          [ 0.0989, -0.2207,  0.0821],\n",
            "          [-0.0018, -0.0227, -0.0960]],\n",
            "\n",
            "         [[-0.1364, -0.0267, -0.2045],\n",
            "          [-0.1972, -0.1440, -0.0514],\n",
            "          [ 0.1117,  0.1766, -0.1850]],\n",
            "\n",
            "         [[-0.1257,  0.0096, -0.0052],\n",
            "          [-0.2070, -0.0986, -0.1545],\n",
            "          [-0.2085,  0.0630, -0.1367]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0307,  0.1141,  0.1179],\n",
            "          [ 0.0398,  0.0253,  0.0281],\n",
            "          [ 0.0606, -0.1759, -0.0748]],\n",
            "\n",
            "         [[ 0.1451, -0.1647, -0.0176],\n",
            "          [ 0.0998, -0.1384,  0.0622],\n",
            "          [ 0.1959, -0.0304, -0.0332]],\n",
            "\n",
            "         [[-0.0678,  0.0032,  0.1376],\n",
            "          [-0.0739,  0.0946,  0.0932],\n",
            "          [-0.1803, -0.0980, -0.0770]]],\n",
            "\n",
            "\n",
            "        [[[-0.0095, -0.1140,  0.1357],\n",
            "          [-0.1858, -0.0275, -0.1440],\n",
            "          [-0.0933,  0.1814,  0.0621]],\n",
            "\n",
            "         [[ 0.1295,  0.0009,  0.1660],\n",
            "          [ 0.1603, -0.0872,  0.1564],\n",
            "          [ 0.1525, -0.0928, -0.0549]],\n",
            "\n",
            "         [[ 0.1739,  0.1462, -0.0456],\n",
            "          [-0.0548,  0.0093,  0.1895],\n",
            "          [ 0.0934, -0.0968,  0.1312]]]], device='cuda:0', requires_grad=True)\n",
            "NPV_C1.bias Parameter containing:\n",
            "tensor([-0.0446,  0.0093,  0.5461,  0.0057, -0.0759,  0.4113,  0.0223,  0.2190,\n",
            "        -0.0991,  0.0740, -0.0958, -0.1250, -0.1008, -0.0704, -0.0264,  0.1101,\n",
            "         0.5464,  0.3147,  0.0766, -0.0633,  0.2542, -0.0913, -0.1629, -0.0286,\n",
            "        -0.0353, -0.1056,  0.1998,  0.3070, -0.1471,  0.0557,  0.2006, -0.1050,\n",
            "         0.3071,  0.2212,  0.6027,  0.0678,  0.0353,  0.1260, -0.1186, -0.0246,\n",
            "         0.2098,  0.5526, -0.0226, -0.1075,  0.1004,  0.0108,  0.4818,  0.1757,\n",
            "         0.3602,  0.1588,  0.0724,  0.1225,  0.1930, -0.0645,  0.0440, -0.1789,\n",
            "         0.0153, -0.0929,  0.2628, -0.1262,  0.4667,  0.4513,  0.3030, -0.1423],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_C2.weight Parameter containing:\n",
            "tensor([[[[ 0.0181,  0.0328, -0.0349],\n",
            "          [ 0.0278,  0.0247, -0.0142],\n",
            "          [-0.0052, -0.0203, -0.0310]],\n",
            "\n",
            "         [[-0.0151, -0.0041, -0.0289],\n",
            "          [ 0.0323,  0.0217,  0.0104],\n",
            "          [-0.0090,  0.0360, -0.0015]],\n",
            "\n",
            "         [[-0.0125, -0.0391,  0.0038],\n",
            "          [ 0.0122,  0.0243,  0.0206],\n",
            "          [ 0.0018, -0.0152,  0.0009]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0001, -0.0199, -0.0335],\n",
            "          [ 0.0286,  0.0314,  0.0087],\n",
            "          [-0.0100,  0.0400,  0.0021]],\n",
            "\n",
            "         [[ 0.0364,  0.0427,  0.0259],\n",
            "          [-0.0203,  0.0318,  0.0429],\n",
            "          [ 0.0021, -0.0138,  0.0288]],\n",
            "\n",
            "         [[ 0.0396, -0.0178,  0.0263],\n",
            "          [-0.0142, -0.0318, -0.0336],\n",
            "          [ 0.0005, -0.0203,  0.0407]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0095,  0.0088,  0.0374],\n",
            "          [-0.0040, -0.0240, -0.0145],\n",
            "          [-0.0409, -0.0328, -0.0123]],\n",
            "\n",
            "         [[-0.0218, -0.0188, -0.0274],\n",
            "          [ 0.0127, -0.0197,  0.0211],\n",
            "          [ 0.0072, -0.0087,  0.0330]],\n",
            "\n",
            "         [[ 0.0263, -0.0030, -0.0375],\n",
            "          [-0.0086,  0.0204, -0.0442],\n",
            "          [ 0.0305, -0.0205, -0.0497]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0351, -0.0168, -0.0450],\n",
            "          [ 0.0049, -0.0389, -0.0121],\n",
            "          [-0.0420, -0.0391,  0.0203]],\n",
            "\n",
            "         [[ 0.0252,  0.0159,  0.0075],\n",
            "          [ 0.0108,  0.0272,  0.0130],\n",
            "          [ 0.0054, -0.0122, -0.0367]],\n",
            "\n",
            "         [[ 0.0110,  0.0257, -0.0158],\n",
            "          [-0.0001, -0.0353, -0.0351],\n",
            "          [ 0.0159, -0.0425, -0.0350]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0039,  0.0137, -0.0394],\n",
            "          [ 0.0302,  0.0052, -0.0239],\n",
            "          [ 0.0375,  0.0329, -0.0205]],\n",
            "\n",
            "         [[ 0.0156, -0.0225, -0.0188],\n",
            "          [ 0.0145,  0.0221, -0.0364],\n",
            "          [-0.0227,  0.0452,  0.0131]],\n",
            "\n",
            "         [[-0.0177,  0.0253,  0.0043],\n",
            "          [ 0.0509,  0.0590,  0.0558],\n",
            "          [ 0.0180,  0.0165,  0.0259]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0176,  0.0338,  0.0118],\n",
            "          [ 0.0011,  0.0185,  0.0631],\n",
            "          [ 0.0179,  0.0594,  0.0389]],\n",
            "\n",
            "         [[-0.0207,  0.0439, -0.0072],\n",
            "          [-0.0005, -0.0058,  0.0515],\n",
            "          [-0.0205,  0.0154, -0.0248]],\n",
            "\n",
            "         [[-0.0139, -0.0249,  0.0195],\n",
            "          [-0.0213,  0.0117, -0.0209],\n",
            "          [ 0.0074,  0.0105,  0.0155]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0095,  0.0104,  0.0379],\n",
            "          [ 0.0164,  0.0377, -0.0212],\n",
            "          [ 0.0236, -0.0090,  0.0386]],\n",
            "\n",
            "         [[ 0.0071, -0.0332,  0.0015],\n",
            "          [-0.0202, -0.0062, -0.0054],\n",
            "          [ 0.0009, -0.0237,  0.0309]],\n",
            "\n",
            "         [[-0.0370, -0.0175,  0.0032],\n",
            "          [-0.0234,  0.0317,  0.0371],\n",
            "          [-0.0097,  0.0248,  0.0245]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0142,  0.0378,  0.0415],\n",
            "          [ 0.0050,  0.0012, -0.0129],\n",
            "          [-0.0097,  0.0369, -0.0101]],\n",
            "\n",
            "         [[-0.0189, -0.0261,  0.0308],\n",
            "          [ 0.0378,  0.0108, -0.0225],\n",
            "          [ 0.0362,  0.0473,  0.0395]],\n",
            "\n",
            "         [[-0.0359, -0.0142, -0.0087],\n",
            "          [-0.0379, -0.0332,  0.0027],\n",
            "          [ 0.0250,  0.0343,  0.0327]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0349, -0.0124,  0.0440],\n",
            "          [-0.0160,  0.0146,  0.0120],\n",
            "          [-0.0214, -0.0147, -0.0298]],\n",
            "\n",
            "         [[-0.0287, -0.0336,  0.0133],\n",
            "          [-0.0059, -0.0140, -0.0207],\n",
            "          [-0.0382, -0.0075,  0.0370]],\n",
            "\n",
            "         [[-0.0147,  0.0396, -0.0073],\n",
            "          [-0.0120,  0.0160,  0.0415],\n",
            "          [-0.0083,  0.0488,  0.0509]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0056,  0.0398, -0.0193],\n",
            "          [ 0.0343,  0.0064,  0.0530],\n",
            "          [-0.0037, -0.0064,  0.0377]],\n",
            "\n",
            "         [[-0.0090,  0.0027,  0.0428],\n",
            "          [-0.0059,  0.0485,  0.0371],\n",
            "          [ 0.0445,  0.0102,  0.0203]],\n",
            "\n",
            "         [[ 0.0148,  0.0364,  0.0201],\n",
            "          [ 0.0368,  0.0047,  0.0160],\n",
            "          [ 0.0289,  0.0018,  0.0315]]],\n",
            "\n",
            "\n",
            "        [[[-0.0189,  0.0135,  0.0285],\n",
            "          [-0.0304, -0.0060, -0.0271],\n",
            "          [-0.0096,  0.0317, -0.0159]],\n",
            "\n",
            "         [[ 0.0009, -0.0285,  0.0017],\n",
            "          [-0.0321,  0.0142, -0.0272],\n",
            "          [ 0.0402,  0.0222,  0.0212]],\n",
            "\n",
            "         [[ 0.0796,  0.0976,  0.0448],\n",
            "          [ 0.0610,  0.0483,  0.0913],\n",
            "          [ 0.0837,  0.0976,  0.0701]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0236,  0.0727,  0.0158],\n",
            "          [ 0.0113,  0.0794,  0.0639],\n",
            "          [ 0.0518,  0.0387,  0.0797]],\n",
            "\n",
            "         [[ 0.0531,  0.0175,  0.0189],\n",
            "          [ 0.0416,  0.0034,  0.0319],\n",
            "          [ 0.0356,  0.0586, -0.0189]],\n",
            "\n",
            "         [[ 0.0050, -0.0391,  0.0408],\n",
            "          [-0.0302, -0.0344,  0.0024],\n",
            "          [ 0.0394, -0.0297, -0.0295]]]], device='cuda:0', requires_grad=True)\n",
            "NPV_C2.bias Parameter containing:\n",
            "tensor([-1.6352e-04, -5.7957e-02,  3.1433e-02,  1.8403e-01, -7.9569e-02,\n",
            "         4.3382e-02, -1.8936e-02,  1.2337e-01, -4.2102e-02,  8.5053e-02,\n",
            "         2.2891e-02,  3.5910e-02,  3.6517e-01,  2.7522e-02,  6.0298e-02,\n",
            "        -2.2547e-02,  3.6848e-03,  1.7195e-02, -1.1750e-02, -2.8053e-02,\n",
            "         4.7117e-02, -1.3356e-02, -1.5927e-02,  3.9901e-03, -5.2942e-02,\n",
            "         1.8273e-02,  8.8546e-02,  1.0829e-01, -5.3705e-03, -2.3584e-02,\n",
            "         2.2913e-03,  2.9143e-02,  1.1521e-01, -1.0813e-01,  9.8541e-02,\n",
            "        -4.8499e-02,  1.5164e-02, -1.5129e-02,  1.9249e-02,  8.6712e-02,\n",
            "         1.3239e-01,  4.0995e-02, -7.3385e-02,  1.3167e-01,  9.6092e-02,\n",
            "        -2.6107e-02,  4.8349e-02,  2.8310e-02,  5.4032e-02, -3.1508e-02,\n",
            "        -4.0008e-02,  1.4837e-02,  1.4602e-03,  6.3212e-02,  2.4704e-02,\n",
            "         5.2737e-02, -1.6283e-02,  6.2772e-02,  4.3790e-02, -3.6415e-02,\n",
            "        -1.9420e-02,  9.7299e-02,  9.2249e-03,  1.1532e-01], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_C3.weight Parameter containing:\n",
            "tensor([[[[ 0.0253, -0.0185,  0.0364],\n",
            "          [-0.0095,  0.0302,  0.0269],\n",
            "          [ 0.0335,  0.0347,  0.0069]],\n",
            "\n",
            "         [[-0.0040, -0.0403,  0.0255],\n",
            "          [-0.0135,  0.0353, -0.0264],\n",
            "          [ 0.0220,  0.0052,  0.0105]],\n",
            "\n",
            "         [[-0.0045,  0.0026, -0.0188],\n",
            "          [-0.0117,  0.0173, -0.0474],\n",
            "          [-0.0464,  0.0094, -0.0074]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0293,  0.0420,  0.0186],\n",
            "          [ 0.0180, -0.0342,  0.0351],\n",
            "          [ 0.0209,  0.0347,  0.0117]],\n",
            "\n",
            "         [[ 0.0232, -0.0116,  0.0237],\n",
            "          [-0.0105,  0.0113,  0.0040],\n",
            "          [ 0.0284, -0.0233, -0.0399]],\n",
            "\n",
            "         [[ 0.0179,  0.0456,  0.0419],\n",
            "          [ 0.0164,  0.0175, -0.0140],\n",
            "          [ 0.0189, -0.0101,  0.0064]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0236,  0.0162,  0.0270],\n",
            "          [ 0.0050,  0.0170, -0.0362],\n",
            "          [ 0.0191,  0.0180,  0.0320]],\n",
            "\n",
            "         [[ 0.0065, -0.0123,  0.0245],\n",
            "          [-0.0013,  0.0140, -0.0107],\n",
            "          [ 0.0201, -0.0194, -0.0181]],\n",
            "\n",
            "         [[ 0.0266, -0.0277, -0.0299],\n",
            "          [-0.0391, -0.0461, -0.0118],\n",
            "          [ 0.0358,  0.0526,  0.0143]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0007,  0.0097, -0.0272],\n",
            "          [ 0.0067,  0.0163, -0.0294],\n",
            "          [-0.0027,  0.0349, -0.0079]],\n",
            "\n",
            "         [[ 0.0143,  0.0104, -0.0152],\n",
            "          [-0.0395, -0.0355, -0.0115],\n",
            "          [ 0.0195, -0.0112,  0.0468]],\n",
            "\n",
            "         [[ 0.0057, -0.0687, -0.0204],\n",
            "          [ 0.0060, -0.0336, -0.0638],\n",
            "          [-0.0042, -0.0534, -0.0228]]],\n",
            "\n",
            "\n",
            "        [[[-0.0235,  0.0210,  0.0296],\n",
            "          [-0.0249, -0.0432, -0.0071],\n",
            "          [ 0.0279,  0.0195,  0.0208]],\n",
            "\n",
            "         [[ 0.0195,  0.0174,  0.0211],\n",
            "          [ 0.0050, -0.0386, -0.0078],\n",
            "          [ 0.0303, -0.0318,  0.0125]],\n",
            "\n",
            "         [[ 0.0326, -0.0263,  0.0173],\n",
            "          [ 0.0445, -0.0219, -0.0278],\n",
            "          [ 0.0273,  0.0368,  0.0156]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0294,  0.0404,  0.0258],\n",
            "          [ 0.0353,  0.0117, -0.0281],\n",
            "          [ 0.0039,  0.0379,  0.0157]],\n",
            "\n",
            "         [[-0.0235, -0.0383, -0.0019],\n",
            "          [-0.0088, -0.0409,  0.0163],\n",
            "          [ 0.0192, -0.0218,  0.0128]],\n",
            "\n",
            "         [[-0.0193, -0.0052,  0.0158],\n",
            "          [ 0.0386, -0.0124,  0.0342],\n",
            "          [-0.0348,  0.0109, -0.0280]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0021,  0.0374,  0.0102],\n",
            "          [-0.0078,  0.0017, -0.0405],\n",
            "          [-0.0352, -0.0048,  0.0188]],\n",
            "\n",
            "         [[-0.0326, -0.0018, -0.0086],\n",
            "          [ 0.0235,  0.0360,  0.0045],\n",
            "          [-0.0090,  0.0365, -0.0169]],\n",
            "\n",
            "         [[ 0.0125,  0.0128,  0.0198],\n",
            "          [-0.0110, -0.0365, -0.0305],\n",
            "          [ 0.0212,  0.0030, -0.0282]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0041,  0.0307, -0.0439],\n",
            "          [-0.0176,  0.0109, -0.0078],\n",
            "          [ 0.0016,  0.0163,  0.0116]],\n",
            "\n",
            "         [[-0.0262, -0.0321,  0.0407],\n",
            "          [ 0.0137, -0.0135, -0.0332],\n",
            "          [-0.0279,  0.0350,  0.0044]],\n",
            "\n",
            "         [[ 0.0171, -0.0213,  0.0238],\n",
            "          [-0.0485, -0.0340,  0.0079],\n",
            "          [ 0.0278,  0.0060, -0.0134]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0129,  0.0226,  0.0176],\n",
            "          [-0.0226, -0.0015,  0.0189],\n",
            "          [-0.0196,  0.0413, -0.0280]],\n",
            "\n",
            "         [[ 0.0018,  0.0219, -0.0116],\n",
            "          [-0.0334,  0.0118, -0.0241],\n",
            "          [-0.0013,  0.0050, -0.0305]],\n",
            "\n",
            "         [[ 0.0017, -0.0274,  0.0034],\n",
            "          [ 0.0072, -0.0239, -0.0202],\n",
            "          [-0.0333, -0.0097, -0.0386]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0177,  0.0316,  0.0191],\n",
            "          [ 0.0040,  0.0295,  0.0163],\n",
            "          [-0.0376, -0.0053,  0.0348]],\n",
            "\n",
            "         [[ 0.0298,  0.0342, -0.0188],\n",
            "          [-0.0441, -0.0134,  0.0342],\n",
            "          [-0.0035,  0.0075,  0.0015]],\n",
            "\n",
            "         [[-0.0111, -0.0328, -0.0035],\n",
            "          [-0.0440,  0.0357,  0.0340],\n",
            "          [-0.0163,  0.0209, -0.0149]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0376, -0.0014, -0.0061],\n",
            "          [-0.0100,  0.0111,  0.0164],\n",
            "          [-0.0039,  0.0062,  0.0056]],\n",
            "\n",
            "         [[ 0.0157, -0.0028,  0.0256],\n",
            "          [ 0.0214, -0.0441, -0.0143],\n",
            "          [-0.0180, -0.0445, -0.0378]],\n",
            "\n",
            "         [[-0.0325,  0.0013,  0.0195],\n",
            "          [-0.0277, -0.0100, -0.0395],\n",
            "          [-0.0360, -0.0076, -0.0254]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0145, -0.0139,  0.0293],\n",
            "          [ 0.0065, -0.0284,  0.0092],\n",
            "          [-0.0176, -0.0139,  0.0142]],\n",
            "\n",
            "         [[ 0.0436, -0.0222, -0.0272],\n",
            "          [ 0.0468, -0.0182,  0.0443],\n",
            "          [-0.0281, -0.0359,  0.0102]],\n",
            "\n",
            "         [[-0.0471,  0.0154, -0.0311],\n",
            "          [ 0.0165,  0.0329,  0.0252],\n",
            "          [ 0.0271, -0.0340, -0.0041]]]], device='cuda:0', requires_grad=True)\n",
            "NPV_C3.bias Parameter containing:\n",
            "tensor([ 0.0192,  0.0226,  0.0462, -0.0008,  0.0277, -0.0061,  0.0201,  0.0232,\n",
            "         0.0366,  0.0065,  0.0394, -0.0565,  0.0067, -0.0391, -0.0279, -0.0018,\n",
            "         0.0473,  0.0122,  0.0399,  0.0460, -0.0574, -0.0039, -0.0279, -0.0002,\n",
            "        -0.0327, -0.0059, -0.0357,  0.0097,  0.0144, -0.0092,  0.0239,  0.0315,\n",
            "        -0.0227,  0.0510, -0.0603,  0.0514,  0.0026,  0.0475,  0.0594, -0.0323,\n",
            "        -0.0317, -0.0006,  0.0312,  0.0274,  0.0074,  0.0472, -0.0138,  0.0140,\n",
            "         0.0432,  0.0207,  0.0289,  0.0302,  0.0550, -0.0048, -0.0212, -0.0127,\n",
            "         0.0478,  0.0831, -0.0261,  0.0740, -0.0105, -0.0356,  0.0240,  0.0468,\n",
            "        -0.0530,  0.0086, -0.0219,  0.0237,  0.0641, -0.0429,  0.0207,  0.0436,\n",
            "        -0.0410, -0.0352, -0.0367,  0.0345, -0.0620, -0.0235,  0.0357,  0.0115,\n",
            "        -0.0280, -0.0015,  0.0241, -0.0452, -0.0166,  0.0524, -0.0034,  0.0467,\n",
            "        -0.0176,  0.0154, -0.0089,  0.0354,  0.0780,  0.0261,  0.0084,  0.1061,\n",
            "        -0.0196,  0.0554, -0.0007,  0.0361, -0.0360,  0.0281,  0.0506,  0.0227,\n",
            "         0.0969, -0.0324,  0.0212, -0.0543, -0.0214, -0.0088,  0.0479, -0.0300,\n",
            "         0.0456, -0.0260,  0.0630,  0.0006,  0.0782, -0.0084, -0.0223, -0.0384,\n",
            "        -0.0225,  0.0349,  0.0113, -0.0097, -0.0453, -0.0249, -0.0248, -0.0026],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_C4.weight Parameter containing:\n",
            "tensor([[[[ 0.0207,  0.0219, -0.0097],\n",
            "          [-0.0002,  0.0172, -0.0147],\n",
            "          [-0.0185, -0.0365, -0.0215]],\n",
            "\n",
            "         [[-0.0280,  0.0121, -0.0120],\n",
            "          [ 0.0318,  0.0101, -0.0190],\n",
            "          [ 0.0115,  0.0135, -0.0267]],\n",
            "\n",
            "         [[-0.0282,  0.0131, -0.0164],\n",
            "          [-0.0067, -0.0189, -0.0235],\n",
            "          [ 0.0008, -0.0166,  0.0270]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0241,  0.0034, -0.0032],\n",
            "          [ 0.0203,  0.0354,  0.0166],\n",
            "          [-0.0071,  0.0110,  0.0257]],\n",
            "\n",
            "         [[-0.0153,  0.0172,  0.0209],\n",
            "          [ 0.0143, -0.0331, -0.0055],\n",
            "          [-0.0095, -0.0070, -0.0188]],\n",
            "\n",
            "         [[-0.0101,  0.0008, -0.0018],\n",
            "          [-0.0288,  0.0108, -0.0226],\n",
            "          [ 0.0173, -0.0008,  0.0270]]],\n",
            "\n",
            "\n",
            "        [[[-0.0210, -0.0080, -0.0303],\n",
            "          [-0.0318, -0.0342,  0.0096],\n",
            "          [ 0.0081, -0.0449, -0.0191]],\n",
            "\n",
            "         [[ 0.0224,  0.0075,  0.0386],\n",
            "          [ 0.0478,  0.0184,  0.0566],\n",
            "          [ 0.0314,  0.0051,  0.0065]],\n",
            "\n",
            "         [[-0.0202,  0.0112, -0.0294],\n",
            "          [-0.0460, -0.0373, -0.0077],\n",
            "          [-0.0324, -0.0228, -0.0216]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0463,  0.0201, -0.0056],\n",
            "          [ 0.0214, -0.0195, -0.0191],\n",
            "          [-0.0023, -0.0252, -0.0081]],\n",
            "\n",
            "         [[-0.0095,  0.0043, -0.0227],\n",
            "          [-0.0250, -0.0281,  0.0199],\n",
            "          [-0.0231,  0.0037, -0.0111]],\n",
            "\n",
            "         [[ 0.0286, -0.0103,  0.0232],\n",
            "          [-0.0024, -0.0123, -0.0184],\n",
            "          [ 0.0015, -0.0273,  0.0045]]],\n",
            "\n",
            "\n",
            "        [[[-0.0067, -0.0174, -0.0123],\n",
            "          [ 0.0258, -0.0345, -0.0175],\n",
            "          [ 0.0079, -0.0032, -0.0333]],\n",
            "\n",
            "         [[ 0.0129,  0.0106,  0.0228],\n",
            "          [-0.0089,  0.0085, -0.0159],\n",
            "          [-0.0012, -0.0216,  0.0185]],\n",
            "\n",
            "         [[-0.0355, -0.0324,  0.0049],\n",
            "          [-0.0315,  0.0066,  0.0059],\n",
            "          [ 0.0190,  0.0185,  0.0258]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0005,  0.0067, -0.0043],\n",
            "          [ 0.0075, -0.0148, -0.0088],\n",
            "          [-0.0113,  0.0242, -0.0332]],\n",
            "\n",
            "         [[-0.0030, -0.0144,  0.0075],\n",
            "          [-0.0209,  0.0030, -0.0073],\n",
            "          [-0.0266,  0.0085,  0.0062]],\n",
            "\n",
            "         [[ 0.0111, -0.0203, -0.0095],\n",
            "          [ 0.0170,  0.0129, -0.0158],\n",
            "          [ 0.0245, -0.0014, -0.0308]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0371, -0.0246, -0.0182],\n",
            "          [-0.0247, -0.0172, -0.0166],\n",
            "          [ 0.0332, -0.0172, -0.0272]],\n",
            "\n",
            "         [[-0.0291,  0.0373,  0.0269],\n",
            "          [ 0.0034,  0.0180,  0.0440],\n",
            "          [-0.0107,  0.0147, -0.0253]],\n",
            "\n",
            "         [[ 0.0055,  0.0264,  0.0002],\n",
            "          [-0.0311,  0.0042, -0.0173],\n",
            "          [ 0.0214, -0.0240, -0.0140]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0190, -0.0271, -0.0106],\n",
            "          [-0.0131, -0.0177, -0.0041],\n",
            "          [-0.0021, -0.0059,  0.0248]],\n",
            "\n",
            "         [[ 0.0016, -0.0133,  0.0235],\n",
            "          [-0.0083, -0.0074, -0.0237],\n",
            "          [ 0.0212, -0.0092,  0.0003]],\n",
            "\n",
            "         [[ 0.0332, -0.0094,  0.0298],\n",
            "          [-0.0170,  0.0116, -0.0316],\n",
            "          [ 0.0004, -0.0070,  0.0044]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0201, -0.0237, -0.0116],\n",
            "          [-0.0155, -0.0088,  0.0120],\n",
            "          [ 0.0113, -0.0024, -0.0117]],\n",
            "\n",
            "         [[-0.0601, -0.0358, -0.0653],\n",
            "          [-0.0205, -0.0200, -0.0624],\n",
            "          [-0.0100, -0.0376, -0.0407]],\n",
            "\n",
            "         [[ 0.0201,  0.0315, -0.0018],\n",
            "          [ 0.0334,  0.0386, -0.0072],\n",
            "          [-0.0033,  0.0087,  0.0181]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0346,  0.0301,  0.0145],\n",
            "          [-0.0246, -0.0124,  0.0347],\n",
            "          [ 0.0148, -0.0113, -0.0092]],\n",
            "\n",
            "         [[-0.0094,  0.0101,  0.0093],\n",
            "          [ 0.0178, -0.0230, -0.0211],\n",
            "          [-0.0018, -0.0256,  0.0124]],\n",
            "\n",
            "         [[-0.0258,  0.0143,  0.0068],\n",
            "          [-0.0155, -0.0236,  0.0195],\n",
            "          [ 0.0213,  0.0280, -0.0127]]],\n",
            "\n",
            "\n",
            "        [[[-0.0123, -0.0342,  0.0157],\n",
            "          [-0.0194, -0.0168, -0.0263],\n",
            "          [ 0.0116, -0.0111, -0.0023]],\n",
            "\n",
            "         [[-0.0007, -0.0183, -0.0198],\n",
            "          [-0.0045,  0.0120,  0.0034],\n",
            "          [ 0.0274,  0.0374, -0.0070]],\n",
            "\n",
            "         [[ 0.0185,  0.0140,  0.0230],\n",
            "          [-0.0002,  0.0238,  0.0117],\n",
            "          [-0.0198, -0.0083,  0.0032]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0021,  0.0107, -0.0249],\n",
            "          [-0.0157, -0.0103, -0.0239],\n",
            "          [-0.0236, -0.0003,  0.0002]],\n",
            "\n",
            "         [[-0.0258, -0.0155, -0.0075],\n",
            "          [ 0.0118, -0.0265, -0.0208],\n",
            "          [ 0.0109,  0.0164, -0.0120]],\n",
            "\n",
            "         [[-0.0063, -0.0023, -0.0112],\n",
            "          [ 0.0069, -0.0180,  0.0153],\n",
            "          [ 0.0044, -0.0026,  0.0261]]]], device='cuda:0', requires_grad=True)\n",
            "NPV_C4.bias Parameter containing:\n",
            "tensor([ 0.0195, -0.0393, -0.0038, -0.0560,  0.0110, -0.0263,  0.0317, -0.0534,\n",
            "         0.0616,  0.0164, -0.0314, -0.0109,  0.0213,  0.0463, -0.0258, -0.0249,\n",
            "         0.0220,  0.0001,  0.0030,  0.0489, -0.0331,  0.0285, -0.0152, -0.0477,\n",
            "        -0.0224,  0.0014, -0.0037,  0.0017,  0.0104, -0.0086,  0.0380,  0.0274,\n",
            "         0.0040, -0.0188, -0.0001,  0.0152, -0.0043,  0.0064,  0.0552,  0.0098,\n",
            "        -0.0265, -0.0071,  0.0256, -0.0294, -0.0301,  0.0037,  0.0103, -0.0323,\n",
            "         0.0196, -0.0061, -0.0032, -0.0131,  0.0192, -0.0203,  0.0108,  0.0114,\n",
            "         0.0464, -0.0752,  0.0237,  0.0367, -0.0383, -0.0247,  0.0487, -0.0395,\n",
            "        -0.0120,  0.0118,  0.0077,  0.0549, -0.0475, -0.0366,  0.0438, -0.0313,\n",
            "         0.0116, -0.0290,  0.0233, -0.0221,  0.0327,  0.0495,  0.0386, -0.0061,\n",
            "         0.0328, -0.0199, -0.0162,  0.0023, -0.0240,  0.0427,  0.0143, -0.0220,\n",
            "        -0.0108,  0.0569, -0.0084, -0.0114, -0.0307,  0.0437, -0.0139, -0.0276,\n",
            "        -0.0091, -0.0071, -0.0261, -0.0168,  0.0520,  0.0556,  0.0075, -0.0154,\n",
            "        -0.0045,  0.0534,  0.0089,  0.0725, -0.0265, -0.0359, -0.0289, -0.0350,\n",
            "        -0.0150, -0.0297, -0.0184, -0.0417,  0.0863, -0.0292, -0.0257,  0.0239,\n",
            "        -0.0372, -0.0326, -0.0128, -0.0053, -0.0338,  0.0199,  0.0229, -0.0145],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_D1.weight Parameter containing:\n",
            "tensor([[-6.7692e-04, -1.0449e-03,  1.0428e-03,  ...,  2.7275e-03,\n",
            "          2.0155e-03, -1.5908e-03],\n",
            "        [ 1.9175e-03,  3.7635e-04, -2.2487e-03,  ...,  1.7689e-03,\n",
            "         -3.1942e-03, -1.7018e-03],\n",
            "        [ 1.1209e-03, -2.2546e-03,  5.8433e-05,  ..., -5.1267e-04,\n",
            "         -1.5297e-03,  1.0066e-03],\n",
            "        ...,\n",
            "        [-1.0792e-03, -1.3467e-03,  8.8318e-04,  ...,  9.1685e-04,\n",
            "         -1.6770e-03,  9.0052e-04],\n",
            "        [-2.4132e-03,  9.8461e-05,  2.2434e-03,  ..., -1.2529e-04,\n",
            "         -2.1967e-03, -1.2057e-03],\n",
            "        [-9.2513e-04, -1.3274e-03,  3.8641e-03,  ...,  2.1772e-03,\n",
            "          3.5826e-03,  2.2008e-03]], device='cuda:0', requires_grad=True)\n",
            "NPV_D1.bias Parameter containing:\n",
            "tensor([ 5.0527e-03,  2.4298e-03, -2.4658e-04, -1.7930e-03,  5.6529e-04,\n",
            "         7.4645e-03,  2.6270e-03,  7.2969e-03, -5.3213e-03,  2.6641e-03,\n",
            "        -6.2710e-03,  2.4358e-03, -1.9574e-03, -1.7564e-05,  1.8841e-03,\n",
            "        -4.0740e-03,  5.2741e-04, -1.9550e-03,  1.6735e-05,  2.6515e-03,\n",
            "         2.6779e-03,  9.2055e-03,  3.4541e-03,  7.7773e-04, -2.4442e-03,\n",
            "        -3.1051e-03,  1.4305e-03, -2.8238e-03, -2.8265e-03, -2.6071e-03,\n",
            "         1.3081e-03,  5.1065e-03, -1.4197e-03, -5.3238e-04, -3.9257e-04,\n",
            "         3.5229e-03, -1.6816e-03, -4.7189e-03,  1.1219e-03,  2.2541e-03,\n",
            "         5.2332e-03,  1.3312e-03,  6.8576e-03, -8.6358e-04, -4.7492e-03,\n",
            "        -1.8822e-04, -2.3759e-03,  2.0733e-03,  2.4130e-03,  2.7084e-03,\n",
            "         4.5596e-03, -5.0619e-04, -3.9603e-03,  1.2512e-03, -2.7604e-03,\n",
            "        -9.6975e-04,  5.2716e-03, -2.3283e-03,  3.4928e-03,  1.3289e-03,\n",
            "        -6.3847e-03, -2.3348e-03,  1.1665e-03,  8.6915e-04,  9.4170e-03,\n",
            "        -3.8167e-04,  5.7119e-03, -3.4278e-03, -7.1278e-03, -4.0058e-03,\n",
            "         2.5615e-03, -1.1754e-03, -1.7602e-03, -8.5320e-04, -2.2375e-03,\n",
            "        -9.1785e-04, -7.7837e-03, -2.5716e-03, -7.3647e-03, -5.1040e-04,\n",
            "        -2.3086e-03, -1.8880e-03, -4.7354e-04,  3.3616e-03, -7.1720e-04,\n",
            "        -8.8932e-05, -3.1084e-03, -1.3076e-03, -3.8327e-03, -2.8070e-03,\n",
            "         5.4988e-03, -2.5099e-03,  5.1228e-03,  3.6391e-03, -1.3582e-03,\n",
            "        -1.1876e-03, -5.5103e-03,  3.9155e-03,  1.0391e-03,  2.4814e-03,\n",
            "        -5.6004e-03,  4.2852e-03,  1.2558e-03,  3.9883e-03, -2.0387e-03,\n",
            "        -1.7692e-03, -6.2712e-03,  1.0297e-03, -1.0054e-03,  3.1681e-04,\n",
            "         4.2946e-03,  1.5722e-03, -3.0172e-03, -3.0487e-03, -5.5607e-04,\n",
            "         1.7074e-03,  1.5669e-03, -1.8393e-03,  2.0542e-03,  3.3257e-04,\n",
            "         4.8175e-03, -6.5761e-04,  9.2573e-04, -4.9023e-03, -1.3105e-03,\n",
            "         1.6962e-03, -2.5704e-03,  2.0190e-03, -5.3224e-03, -3.3748e-03,\n",
            "         4.5583e-03,  8.0348e-04, -4.1526e-03, -4.0413e-04,  6.3886e-03,\n",
            "         7.7929e-04,  4.1175e-04,  8.2113e-04,  2.4740e-03, -3.9139e-03,\n",
            "        -2.8252e-03,  4.8896e-03, -1.7100e-03, -1.3936e-03, -3.7146e-04,\n",
            "         8.1892e-03, -1.1921e-03, -1.9242e-03, -1.1946e-03, -8.8002e-07,\n",
            "        -2.9630e-03,  1.2169e-03,  1.9584e-03, -2.0318e-04, -1.5559e-03,\n",
            "        -5.2539e-03,  3.2017e-03, -3.1463e-03,  4.1716e-04, -1.5811e-03,\n",
            "        -5.6489e-04, -3.5867e-03,  4.1567e-03,  7.4680e-04, -1.1995e-03,\n",
            "        -2.5358e-04,  3.6465e-03,  1.1688e-03,  3.4316e-03, -1.2658e-03,\n",
            "        -2.4799e-03, -2.1269e-03,  2.0965e-03,  3.8391e-04, -3.1803e-03,\n",
            "        -7.4929e-04, -7.1984e-05,  4.5931e-04,  9.7438e-04,  7.6365e-04,\n",
            "         2.8551e-05,  5.6402e-03,  1.1403e-03,  3.1633e-04,  2.5077e-03,\n",
            "        -1.9645e-03,  2.4089e-03,  5.1048e-03, -2.9856e-03, -3.0185e-03,\n",
            "        -3.2117e-03, -4.0773e-03,  3.3862e-04,  2.6820e-03, -2.6291e-04,\n",
            "        -1.9163e-03,  5.8405e-03, -1.0113e-03,  4.9111e-03, -6.1617e-04,\n",
            "         3.7640e-03,  1.1391e-04, -3.0970e-03,  3.3822e-04,  2.2263e-03,\n",
            "         1.6279e-03,  2.7110e-03, -3.5725e-03, -4.2233e-03, -1.4284e-03,\n",
            "         6.8862e-04,  1.5666e-03, -6.3787e-03, -1.6066e-03,  1.2963e-03,\n",
            "        -2.2659e-03, -2.4784e-03, -1.3346e-03,  3.0489e-03,  7.9715e-04,\n",
            "         4.4968e-03,  5.6768e-03,  5.3405e-03,  4.5718e-03, -3.7027e-05,\n",
            "        -3.8524e-03,  2.4213e-04,  3.6077e-04,  2.4143e-03, -2.4599e-03,\n",
            "        -9.3515e-04,  3.9905e-03,  4.6537e-03, -3.5650e-03,  3.6976e-03,\n",
            "        -3.0901e-03, -1.0890e-02,  4.3430e-03, -4.1415e-03, -3.5180e-03,\n",
            "        -2.3009e-03,  2.3034e-03, -5.5972e-03,  1.5868e-03, -3.2424e-03,\n",
            "        -8.8222e-04, -3.0376e-03,  2.0520e-03,  7.6077e-04, -4.3922e-03,\n",
            "        -2.0804e-03, -4.3301e-04,  2.8558e-03, -4.8234e-03,  3.6685e-03,\n",
            "         6.3923e-03], device='cuda:0', requires_grad=True)\n",
            "NPV_D2.weight Parameter containing:\n",
            "tensor([[ 0.0765, -0.0019, -0.0198,  ...,  0.0431,  0.0412, -0.0121],\n",
            "        [-0.0343, -0.0082, -0.0351,  ...,  0.0069, -0.0108, -0.0216],\n",
            "        [ 0.0622,  0.0097, -0.0183,  ..., -0.0599,  0.0485,  0.0327],\n",
            "        ...,\n",
            "        [ 0.0072, -0.0624, -0.0228,  ...,  0.0424, -0.0366, -0.0163],\n",
            "        [ 0.0748, -0.0478,  0.0023,  ..., -0.0483,  0.0144, -0.0069],\n",
            "        [ 0.0119, -0.0209,  0.0090,  ..., -0.0162, -0.0434, -0.0092]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_D2.bias Parameter containing:\n",
            "tensor([ 2.4919e-03,  4.4366e-02, -3.8675e-02,  4.7188e-02, -4.0903e-02,\n",
            "        -4.0596e-02, -3.4668e-02, -2.0314e-02,  3.3390e-02, -4.4966e-02,\n",
            "         4.4220e-02, -3.9737e-02, -4.0181e-02, -7.8427e-06, -1.1680e-02,\n",
            "         6.6547e-03, -4.5538e-02,  5.6779e-03, -4.7976e-02, -3.6062e-02,\n",
            "        -6.0503e-02, -1.4173e-02, -5.6073e-02,  3.3042e-02,  3.7955e-02,\n",
            "        -3.4677e-02, -8.8219e-03, -3.3863e-02,  1.5301e-02,  5.6979e-02,\n",
            "         5.4064e-02, -6.0629e-02,  2.0600e-02,  6.2461e-02, -4.1719e-02,\n",
            "        -9.3702e-03, -2.1659e-02, -2.6449e-02,  2.8996e-02, -2.8503e-02,\n",
            "        -1.8502e-02,  3.4063e-03, -4.2938e-02,  5.4853e-02,  3.6239e-02,\n",
            "         5.4162e-03, -1.0082e-02, -2.0185e-02,  2.5269e-02, -3.5451e-02,\n",
            "        -4.0105e-02,  4.5458e-03, -4.5130e-02,  3.7682e-02, -3.7924e-04,\n",
            "        -2.4140e-03, -7.2407e-03, -3.6180e-02,  1.5837e-02, -4.2501e-02,\n",
            "         6.3612e-02, -5.4390e-03,  4.8685e-02, -3.5899e-02, -2.1144e-02,\n",
            "         1.9156e-02,  4.2483e-02,  8.4084e-03, -1.9001e-02, -2.1566e-02,\n",
            "         4.5573e-02, -6.1486e-03, -1.5185e-02,  2.7124e-02, -5.4347e-02,\n",
            "         4.6465e-02,  5.4721e-02,  5.8267e-02, -9.4012e-03,  5.0791e-02,\n",
            "         2.4693e-02, -2.8537e-02, -4.4469e-02,  3.1128e-03, -4.8371e-02,\n",
            "         2.1725e-02,  3.1066e-02, -6.1069e-02, -3.7544e-02, -4.0667e-03,\n",
            "        -3.2712e-02, -3.8841e-02, -3.3987e-02, -3.1550e-02, -3.8630e-03,\n",
            "        -5.3117e-02,  2.3842e-02,  1.9898e-03,  4.4445e-02, -2.8646e-02,\n",
            "         9.3895e-04,  4.9084e-02,  2.7369e-02,  2.1271e-02, -2.3808e-02,\n",
            "        -4.1300e-02,  2.7549e-02, -3.9295e-02,  8.5315e-03, -4.4188e-02,\n",
            "        -3.0592e-02, -4.8589e-02,  2.1111e-02, -2.3817e-02,  3.1953e-02,\n",
            "        -2.8770e-02, -1.2824e-02, -6.7276e-03, -1.7323e-02,  9.0767e-03,\n",
            "        -4.8325e-02, -4.4310e-02,  5.5553e-02, -3.0175e-02,  8.0673e-03,\n",
            "        -2.5624e-02, -6.5028e-03,  4.2075e-02,  4.6290e-02,  3.3169e-02,\n",
            "        -3.3203e-02,  3.4218e-02,  1.8569e-04, -5.0053e-02, -5.1682e-02,\n",
            "         5.6106e-02,  3.1158e-02,  1.5651e-03, -5.0640e-02,  2.0130e-02,\n",
            "         2.4816e-02, -1.0896e-02, -1.9429e-03, -6.0906e-02,  1.8137e-02,\n",
            "        -2.6652e-02, -2.7819e-02,  5.7968e-02, -3.5936e-02, -3.9990e-02,\n",
            "        -2.4763e-02,  2.7777e-02,  5.2516e-02,  5.6760e-02,  4.1650e-02,\n",
            "        -1.7606e-02, -3.5855e-03, -3.9766e-02, -1.2657e-02, -3.5329e-02,\n",
            "         4.0002e-02,  1.4215e-02, -1.9710e-02, -3.2290e-02,  5.1131e-02,\n",
            "         1.9510e-02,  5.0236e-02, -1.4030e-02,  3.3173e-02,  1.9266e-02,\n",
            "        -5.3925e-02, -5.3054e-02, -1.8541e-02,  3.9635e-02, -3.5383e-02,\n",
            "         1.6033e-02, -3.3121e-02, -3.4647e-02, -2.3149e-02, -5.5628e-02,\n",
            "         4.8612e-02, -1.9694e-02, -3.1284e-02, -3.0729e-02,  1.9119e-02,\n",
            "         2.2080e-02,  2.7527e-02, -2.7591e-02, -4.2359e-02, -6.2430e-02,\n",
            "         2.9621e-02, -1.9552e-02, -2.5156e-02, -2.0197e-02, -2.4117e-02,\n",
            "        -1.4146e-02,  2.1048e-02,  4.1420e-02,  1.9935e-02,  1.4222e-02,\n",
            "        -5.7438e-02,  1.7754e-02, -4.0311e-02,  1.4100e-02,  5.1037e-02,\n",
            "        -2.1035e-02, -5.3631e-02, -5.2682e-02,  6.4767e-03,  5.4977e-02,\n",
            "         3.7551e-02,  5.2373e-02, -1.7833e-02, -3.2622e-02,  3.5040e-02,\n",
            "         2.6882e-03, -3.4860e-02,  2.0287e-02,  9.5434e-03, -2.7975e-02,\n",
            "        -3.2224e-02,  4.4047e-02, -1.4040e-03,  6.1894e-03, -6.6746e-03,\n",
            "        -2.8096e-02, -3.4058e-02,  4.9212e-03,  1.5661e-02, -5.3754e-03,\n",
            "        -5.4796e-02, -5.0062e-02, -1.3438e-03,  2.4619e-02,  5.9665e-02,\n",
            "         1.3568e-03, -6.5000e-03, -3.1164e-02,  1.3329e-02,  1.8968e-02,\n",
            "         2.9461e-02, -3.2918e-02, -4.0667e-03, -5.8180e-03,  4.1228e-02,\n",
            "         3.1160e-02, -1.7268e-02, -2.4342e-02, -5.6807e-02, -3.7421e-02,\n",
            "        -5.2228e-02, -2.0972e-02, -1.6852e-02, -8.0439e-03,  2.6574e-02,\n",
            "         1.8912e-02], device='cuda:0', requires_grad=True)\n",
            "outputs.weight Parameter containing:\n",
            "tensor([[ 0.1040, -0.0059,  0.0242,  ..., -0.0193,  0.1097, -0.0372],\n",
            "        [ 0.0077,  0.0018, -0.0003,  ...,  0.0252,  0.0707,  0.1603],\n",
            "        [-0.1252, -0.0464,  0.0303,  ...,  0.0567,  0.0851, -0.0205],\n",
            "        ...,\n",
            "        [ 0.0641, -0.0034,  0.0371,  ..., -0.0443,  0.0329, -0.0913],\n",
            "        [ 0.0329,  0.0350, -0.0006,  ..., -0.0713, -0.0741,  0.1305],\n",
            "        [-0.1294,  0.0057,  0.0579,  ...,  0.0462,  0.0053, -0.0280]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "outputs.bias Parameter containing:\n",
            "tensor([ 0.0136, -0.0798,  0.0420,  0.0730,  0.0265, -0.0291, -0.0980, -0.0133,\n",
            "         0.0191, -0.0092], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frnpf_di_linear_model.state_dict().get(\"NPV_C1.weight\").data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oz3jKxj4hIIn",
        "outputId": "2b95cb7f-8ec2-47e9-e4a7-050ec486a61f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.1439,  0.1235,  0.1334],\n",
              "          [-0.0367, -0.0182,  0.0882],\n",
              "          [ 0.1098, -0.0423, -0.0311]],\n",
              "\n",
              "         [[-0.0388, -0.0585,  0.1656],\n",
              "          [-0.0744, -0.0497, -0.1528],\n",
              "          [ 0.0572,  0.1653,  0.0680]],\n",
              "\n",
              "         [[ 0.0709,  0.0773, -0.1499],\n",
              "          [-0.0665,  0.0137,  0.0337],\n",
              "          [ 0.1010,  0.0986,  0.1184]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0253,  0.0712, -0.1079],\n",
              "          [-0.0650, -0.0289, -0.1373],\n",
              "          [ 0.0572,  0.1747, -0.1841]],\n",
              "\n",
              "         [[ 0.0453, -0.0063, -0.0051],\n",
              "          [-0.0063, -0.0573, -0.0153],\n",
              "          [ 0.0129,  0.1215, -0.1573]],\n",
              "\n",
              "         [[-0.1953,  0.0528, -0.0865],\n",
              "          [-0.1359,  0.0722,  0.1463],\n",
              "          [ 0.0488,  0.0912,  0.1857]]],\n",
              "\n",
              "\n",
              "        [[[-0.1279, -0.1052,  0.1603],\n",
              "          [ 0.0498, -0.0874, -0.0633],\n",
              "          [ 0.0945,  0.1263,  0.1028]],\n",
              "\n",
              "         [[-0.1742, -0.0347, -0.1759],\n",
              "          [-0.0940, -0.0251, -0.1792],\n",
              "          [ 0.0867, -0.2025, -0.0961]],\n",
              "\n",
              "         [[-0.0320, -0.0412, -0.1846],\n",
              "          [-0.0172, -0.1976, -0.2326],\n",
              "          [-0.1200, -0.0170, -0.2205]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[-0.1927, -0.0999,  0.1469],\n",
              "          [ 0.0989, -0.2207,  0.0821],\n",
              "          [-0.0018, -0.0227, -0.0960]],\n",
              "\n",
              "         [[-0.1364, -0.0267, -0.2045],\n",
              "          [-0.1972, -0.1440, -0.0514],\n",
              "          [ 0.1117,  0.1766, -0.1850]],\n",
              "\n",
              "         [[-0.1257,  0.0096, -0.0052],\n",
              "          [-0.2070, -0.0986, -0.1545],\n",
              "          [-0.2085,  0.0630, -0.1367]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0307,  0.1141,  0.1179],\n",
              "          [ 0.0398,  0.0253,  0.0281],\n",
              "          [ 0.0606, -0.1759, -0.0748]],\n",
              "\n",
              "         [[ 0.1451, -0.1647, -0.0176],\n",
              "          [ 0.0998, -0.1384,  0.0622],\n",
              "          [ 0.1959, -0.0304, -0.0332]],\n",
              "\n",
              "         [[-0.0678,  0.0032,  0.1376],\n",
              "          [-0.0739,  0.0946,  0.0932],\n",
              "          [-0.1803, -0.0980, -0.0770]]],\n",
              "\n",
              "\n",
              "        [[[-0.0095, -0.1140,  0.1357],\n",
              "          [-0.1858, -0.0275, -0.1440],\n",
              "          [-0.0933,  0.1814,  0.0621]],\n",
              "\n",
              "         [[ 0.1295,  0.0009,  0.1660],\n",
              "          [ 0.1603, -0.0872,  0.1564],\n",
              "          [ 0.1525, -0.0928, -0.0549]],\n",
              "\n",
              "         [[ 0.1739,  0.1462, -0.0456],\n",
              "          [-0.0548,  0.0093,  0.1895],\n",
              "          [ 0.0934, -0.0968,  0.1312]]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "frnpf_di_linear_model.state_dict().get(\"NPF_C1.weight\").data"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "liXbUBt1hIXS",
        "outputId": "95e9f863-e17e-4874-e8df-8c1bd46514fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[[ 0.1397,  0.1195,  0.1305],\n",
              "          [-0.0399, -0.0212,  0.0863],\n",
              "          [ 0.1052, -0.0467, -0.0340]],\n",
              "\n",
              "         [[-0.0456, -0.0650,  0.1604],\n",
              "          [-0.0800, -0.0553, -0.1571],\n",
              "          [ 0.0502,  0.1586,  0.0630]],\n",
              "\n",
              "         [[ 0.0627,  0.0695, -0.1562],\n",
              "          [-0.0733,  0.0070,  0.0283],\n",
              "          [ 0.0936,  0.0916,  0.1129]]],\n",
              "\n",
              "\n",
              "        [[[ 0.0221,  0.0690, -0.1078],\n",
              "          [-0.0679, -0.0322, -0.1376],\n",
              "          [ 0.0458,  0.1631, -0.1905]],\n",
              "\n",
              "         [[ 0.0455, -0.0057, -0.0026],\n",
              "          [-0.0064, -0.0585, -0.0138],\n",
              "          [ 0.0039,  0.1116, -0.1620]],\n",
              "\n",
              "         [[-0.1902,  0.0577, -0.0802],\n",
              "          [-0.1305,  0.0760,  0.1524],\n",
              "          [ 0.0461,  0.0873,  0.1867]]],\n",
              "\n",
              "\n",
              "        [[[-0.1342, -0.0936,  0.1755],\n",
              "          [ 0.0561, -0.0583, -0.0318],\n",
              "          [ 0.0938,  0.1439,  0.1216]],\n",
              "\n",
              "         [[-0.1711, -0.0103, -0.1485],\n",
              "          [-0.0844,  0.0103, -0.1425],\n",
              "          [ 0.0812, -0.1875, -0.0808]],\n",
              "\n",
              "         [[-0.0108,  0.0017, -0.1373],\n",
              "          [ 0.0127, -0.1409, -0.1729],\n",
              "          [-0.1031,  0.0216, -0.1796]]],\n",
              "\n",
              "\n",
              "        ...,\n",
              "\n",
              "\n",
              "        [[[-0.1825, -0.0839,  0.1553],\n",
              "          [ 0.1225, -0.1902,  0.1021],\n",
              "          [ 0.0086, -0.0079, -0.0869]],\n",
              "\n",
              "         [[-0.1163, -0.0005, -0.1880],\n",
              "          [-0.1695, -0.1092, -0.0289],\n",
              "          [ 0.1202,  0.1895, -0.1792]],\n",
              "\n",
              "         [[-0.0916,  0.0500,  0.0272],\n",
              "          [-0.1631, -0.0471, -0.1133],\n",
              "          [-0.1811,  0.0954, -0.1094]]],\n",
              "\n",
              "\n",
              "        [[[-0.0003,  0.0897,  0.0930],\n",
              "          [ 0.0182,  0.0146,  0.0152],\n",
              "          [ 0.0425, -0.1802, -0.0818]],\n",
              "\n",
              "         [[ 0.1188, -0.1829, -0.0368],\n",
              "          [ 0.0825, -0.1435,  0.0541],\n",
              "          [ 0.1812, -0.0301, -0.0365]],\n",
              "\n",
              "         [[-0.0856, -0.0064,  0.1272],\n",
              "          [-0.0808,  0.0998,  0.0959],\n",
              "          [-0.1838, -0.0865, -0.0682]]],\n",
              "\n",
              "\n",
              "        [[[-0.0126, -0.1170,  0.1338],\n",
              "          [-0.1890, -0.0305, -0.1460],\n",
              "          [-0.0961,  0.1789,  0.0605]],\n",
              "\n",
              "         [[ 0.1248, -0.0036,  0.1629],\n",
              "          [ 0.1555, -0.0916,  0.1532],\n",
              "          [ 0.1484, -0.0964, -0.0572]],\n",
              "\n",
              "         [[ 0.1654,  0.1381, -0.0521],\n",
              "          [-0.0630,  0.0016,  0.1834],\n",
              "          [ 0.0865, -0.1030,  0.1264]]]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "FLNPF"
      ],
      "metadata": {
        "id": "Nwn-8ewJMgCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "flnpf_linear_model = Conv4GaluLinear(args['image_size'], args['channels'])\n",
        "flnpf_linear_model.to(device)\n",
        "flnpf_linear_model"
      ],
      "metadata": {
        "id": "T1VTi5RgMgCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cb8dc74e-f991-4fd4-b3bf-7e8e28f3dcbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Conv4GaluLinear(\n",
              "  (NPF_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPF_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPF_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPF_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (NPV_C1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C3): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_C4): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
              "  (NPV_F): Flatten(start_dim=1, end_dim=-1)\n",
              "  (NPV_D1): Linear(in_features=131072, out_features=256, bias=True)\n",
              "  (NPV_D2): Linear(in_features=256, out_features=256, bias=True)\n",
              "  (outputs): Linear(in_features=256, out_features=10, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for p in relu_model.parameters():\n",
        "  print(p)"
      ],
      "metadata": {
        "id": "l_0lEne7MgCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dbf4692e-1fd0-4b38-c9b3-e8945675ccf9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Parameter containing:\n",
            "tensor([[[[ 0.1783,  0.1678,  0.0707],\n",
            "          [-0.2148,  0.0080, -0.1329],\n",
            "          [-0.0768, -0.0828,  0.1414]],\n",
            "\n",
            "         [[ 0.1201,  0.1692, -0.0584],\n",
            "          [ 0.1144, -0.0063,  0.0048],\n",
            "          [ 0.0877, -0.2433, -0.2285]],\n",
            "\n",
            "         [[ 0.1040,  0.0727,  0.2162],\n",
            "          [-0.1520, -0.1024,  0.1551],\n",
            "          [ 0.0867, -0.1389, -0.1641]]],\n",
            "\n",
            "\n",
            "        [[[-0.1793, -0.1019, -0.0161],\n",
            "          [-0.0146, -0.1024, -0.1758],\n",
            "          [-0.1873, -0.0495, -0.2175]],\n",
            "\n",
            "         [[-0.0260, -0.0427, -0.0657],\n",
            "          [ 0.1340,  0.1662,  0.0424],\n",
            "          [ 0.0282, -0.2293, -0.1476]],\n",
            "\n",
            "         [[-0.0764,  0.1406,  0.2345],\n",
            "          [-0.1003,  0.0475,  0.0635],\n",
            "          [ 0.0049,  0.0302, -0.1059]]],\n",
            "\n",
            "\n",
            "        [[[-0.0955, -0.0208, -0.1790],\n",
            "          [ 0.0309, -0.1191, -0.1719],\n",
            "          [ 0.2915, -0.0676, -0.0349]],\n",
            "\n",
            "         [[-0.1897,  0.1271, -0.0343],\n",
            "          [ 0.1399,  0.0184,  0.1888],\n",
            "          [ 0.1491, -0.0418,  0.1892]],\n",
            "\n",
            "         [[-0.1733, -0.2329, -0.1357],\n",
            "          [-0.1382,  0.1079,  0.1240],\n",
            "          [-0.0594,  0.2394,  0.1112]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1990, -0.0096, -0.0576],\n",
            "          [ 0.0097,  0.0260, -0.0029],\n",
            "          [ 0.0082, -0.0942, -0.0978]],\n",
            "\n",
            "         [[ 0.0348, -0.1271,  0.1993],\n",
            "          [ 0.1334, -0.1001,  0.0583],\n",
            "          [-0.1213,  0.1562, -0.1089]],\n",
            "\n",
            "         [[ 0.1338,  0.1800,  0.0372],\n",
            "          [ 0.0039,  0.2208,  0.1513],\n",
            "          [-0.0640,  0.1286,  0.0668]]],\n",
            "\n",
            "\n",
            "        [[[-0.0437,  0.0585, -0.0300],\n",
            "          [-0.1077, -0.1139,  0.2140],\n",
            "          [-0.2148, -0.3558, -0.2091]],\n",
            "\n",
            "         [[ 0.2795,  0.3531,  0.2870],\n",
            "          [-0.0597,  0.3122,  0.2711],\n",
            "          [-0.0950, -0.0614, -0.2974]],\n",
            "\n",
            "         [[ 0.1576,  0.0207, -0.0846],\n",
            "          [ 0.0213,  0.2274,  0.0105],\n",
            "          [-0.0890, -0.3062, -0.2418]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2872,  0.1812, -0.0491],\n",
            "          [ 0.1627, -0.0591,  0.0814],\n",
            "          [-0.3145, -0.2374,  0.2393]],\n",
            "\n",
            "         [[-0.0208,  0.0911, -0.0378],\n",
            "          [ 0.1538, -0.1809, -0.0119],\n",
            "          [-0.2223, -0.1330,  0.0278]],\n",
            "\n",
            "         [[ 0.1490, -0.0319, -0.1459],\n",
            "          [ 0.2538, -0.2243, -0.1458],\n",
            "          [-0.1564, -0.1006,  0.1436]]]], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0173, -0.1624,  0.2160,  0.2229, -0.1069,  0.0854,  0.0301, -0.0217,\n",
            "         0.0910, -0.2613,  0.2520, -0.0846,  0.0088, -0.0380, -0.0387, -0.0367,\n",
            "        -0.1031, -0.0308,  0.2666, -0.0407, -0.2653,  0.2456, -0.0370,  0.1910,\n",
            "         0.2658,  0.1928,  0.1449, -0.2143, -0.0110,  0.2867, -0.0604,  0.2145,\n",
            "         0.0058,  0.1568, -0.0267,  0.1595,  0.0323, -0.0777,  0.0054,  0.1436,\n",
            "        -0.1524,  0.0468,  0.0366,  0.1173, -0.0892,  0.2186, -0.0229,  0.3434,\n",
            "         0.2675,  0.0024, -0.0183, -0.1151, -0.0957,  0.0141, -0.0619, -0.1340,\n",
            "         0.2070,  0.0188,  0.2372, -0.1457, -0.0481, -0.1605,  0.0187, -0.2085],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[[[ 3.2001e-02,  9.1168e-03,  2.8330e-02],\n",
            "          [-3.0332e-02,  9.6452e-03, -2.4690e-02],\n",
            "          [-3.4668e-02,  1.8335e-02, -2.8662e-02]],\n",
            "\n",
            "         [[-2.1238e-02,  2.7825e-02, -3.0030e-02],\n",
            "          [-2.1330e-02,  4.5230e-02,  3.3289e-02],\n",
            "          [ 4.1187e-02,  2.0557e-03,  3.1419e-02]],\n",
            "\n",
            "         [[-3.8820e-03, -4.7527e-02, -1.4905e-02],\n",
            "          [-4.8554e-02, -4.8428e-02,  2.5625e-02],\n",
            "          [-3.4557e-02,  4.1444e-03,  1.4335e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4257e-02,  2.4394e-02,  3.9946e-03],\n",
            "          [ 1.8668e-02, -3.1637e-02,  9.5560e-03],\n",
            "          [ 3.2598e-02, -1.7549e-02,  2.0341e-03]],\n",
            "\n",
            "         [[-7.5345e-03, -2.7743e-02,  2.1741e-03],\n",
            "          [-1.6420e-02, -5.6036e-02, -3.7136e-02],\n",
            "          [-4.0715e-02, -8.0570e-02, -6.5032e-02]],\n",
            "\n",
            "         [[ 2.8545e-02,  1.0203e-02,  5.5409e-03],\n",
            "          [ 1.7573e-02,  4.9532e-03,  2.6139e-02],\n",
            "          [ 6.5156e-02,  3.5886e-02,  1.8216e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1881e-02, -6.9828e-03,  4.0112e-02],\n",
            "          [ 2.3973e-02, -3.1583e-03, -2.6041e-02],\n",
            "          [-4.4420e-02, -1.0565e-02, -3.7871e-02]],\n",
            "\n",
            "         [[-3.4038e-02,  5.5332e-02,  3.3835e-02],\n",
            "          [ 1.8912e-02, -1.1744e-02,  4.3739e-02],\n",
            "          [-1.9880e-02, -1.7229e-02,  2.2020e-02]],\n",
            "\n",
            "         [[-4.0655e-02,  6.4909e-03, -3.5098e-03],\n",
            "          [-1.9571e-04,  3.0176e-02,  4.1301e-02],\n",
            "          [-3.1335e-02, -3.0740e-02,  1.7581e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4689e-02,  1.5225e-04,  2.8799e-02],\n",
            "          [-4.5992e-02, -2.8588e-02, -3.2966e-03],\n",
            "          [-1.5035e-02,  1.0694e-02, -4.3348e-02]],\n",
            "\n",
            "         [[-3.9046e-02, -1.0756e-02, -6.4772e-03],\n",
            "          [-4.6365e-02, -2.6837e-02, -1.1921e-02],\n",
            "          [-9.1780e-03, -3.3564e-02, -2.7085e-02]],\n",
            "\n",
            "         [[-3.5399e-02, -5.1048e-03, -1.8076e-02],\n",
            "          [-1.2935e-02, -3.1997e-02, -4.3831e-02],\n",
            "          [-2.2916e-02, -5.1055e-03,  6.1727e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7974e-02,  4.2229e-02, -5.2652e-03],\n",
            "          [-5.9138e-03, -2.6785e-02,  2.0459e-02],\n",
            "          [ 9.5431e-03, -3.0225e-05,  1.6665e-02]],\n",
            "\n",
            "         [[ 1.6059e-02,  1.9674e-02, -3.6834e-02],\n",
            "          [-8.0846e-03,  3.6968e-02,  3.3175e-02],\n",
            "          [-3.4880e-02,  6.7107e-03,  7.4166e-03]],\n",
            "\n",
            "         [[-5.7282e-04,  3.8921e-02, -2.0561e-02],\n",
            "          [-2.9580e-02, -4.2997e-03,  4.3143e-03],\n",
            "          [-5.4409e-03, -3.2837e-02, -1.5609e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.1140e-02,  2.1459e-02,  2.7394e-02],\n",
            "          [ 3.3537e-02,  9.7760e-03, -3.4729e-02],\n",
            "          [-2.8220e-02,  2.9653e-02,  1.3969e-02]],\n",
            "\n",
            "         [[-2.6242e-02,  1.4204e-02,  5.7703e-02],\n",
            "          [ 2.1306e-02,  1.7519e-02, -2.0617e-02],\n",
            "          [ 4.2496e-02,  8.1717e-03,  1.2701e-02]],\n",
            "\n",
            "         [[-2.4732e-02, -1.8880e-02, -1.8417e-02],\n",
            "          [-3.2196e-03, -2.8812e-02,  4.6357e-02],\n",
            "          [-4.1272e-04, -1.3013e-02, -1.7801e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.8105e-02, -1.4650e-02, -2.2165e-02],\n",
            "          [-1.2866e-02, -4.2084e-02,  2.1669e-02],\n",
            "          [-3.1966e-02,  2.1298e-03,  2.7938e-02]],\n",
            "\n",
            "         [[-2.2418e-03,  1.4748e-02,  4.4557e-02],\n",
            "          [ 5.5673e-02,  5.0982e-02, -1.8368e-02],\n",
            "          [ 4.6846e-02,  4.8603e-02,  1.0509e-04]],\n",
            "\n",
            "         [[-1.7109e-02,  1.2698e-02, -2.2443e-02],\n",
            "          [ 4.7169e-03,  3.3432e-02,  5.8487e-02],\n",
            "          [-7.2413e-03, -3.8845e-03,  4.4474e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.6513e-02, -1.2442e-02, -3.1260e-02],\n",
            "          [-1.1502e-02,  2.7639e-02,  1.1707e-02],\n",
            "          [ 1.9617e-03,  2.6097e-02, -8.5746e-04]],\n",
            "\n",
            "         [[ 3.1042e-02, -2.4324e-02, -1.4685e-02],\n",
            "          [-6.1672e-03, -2.3776e-02,  4.5197e-02],\n",
            "          [ 3.4812e-02,  4.1110e-03,  1.1130e-02]],\n",
            "\n",
            "         [[-3.5614e-02,  2.0783e-02,  2.8210e-03],\n",
            "          [ 2.3428e-02,  3.2879e-02, -1.7972e-02],\n",
            "          [-1.4736e-02,  2.2192e-02, -1.6626e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.3972e-02, -4.6845e-02, -4.4742e-02],\n",
            "          [ 4.0569e-03,  9.4357e-03, -4.3139e-02],\n",
            "          [-4.0127e-02,  4.5356e-03,  6.6380e-03]],\n",
            "\n",
            "         [[-1.8611e-04, -3.1868e-02, -2.1324e-02],\n",
            "          [-1.1394e-02, -6.3253e-04, -4.1593e-02],\n",
            "          [-2.6143e-02, -4.3754e-03, -1.6207e-02]],\n",
            "\n",
            "         [[-2.2294e-02, -2.7121e-02,  2.4063e-02],\n",
            "          [ 3.9785e-02,  4.9655e-03,  1.5862e-02],\n",
            "          [ 5.2054e-02,  8.5450e-02,  1.2709e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.5123e-02, -5.2380e-02, -4.7986e-02],\n",
            "          [-5.8383e-02, -1.2068e-03, -4.2647e-02],\n",
            "          [ 1.5634e-02, -1.2871e-02, -5.3748e-02]],\n",
            "\n",
            "         [[-3.1711e-02,  2.9711e-02, -2.0116e-02],\n",
            "          [ 2.9453e-02,  1.0416e-02,  9.7745e-03],\n",
            "          [ 1.3039e-02,  1.4789e-02,  5.0820e-03]],\n",
            "\n",
            "         [[-1.1513e-02, -1.5585e-02,  1.1944e-02],\n",
            "          [ 1.7842e-02, -3.0042e-02, -3.6803e-02],\n",
            "          [-1.0287e-02, -2.5526e-03, -3.8143e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.8189e-02, -1.9792e-02,  5.1994e-03],\n",
            "          [ 1.1544e-02, -1.8797e-02, -4.6066e-02],\n",
            "          [-1.3080e-02,  1.7157e-02,  2.2549e-02]],\n",
            "\n",
            "         [[-8.3771e-03, -5.0764e-02, -1.1878e-02],\n",
            "          [-5.1156e-02, -5.7552e-02, -3.2062e-02],\n",
            "          [-5.7209e-02, -2.0481e-03, -1.5820e-02]],\n",
            "\n",
            "         [[-5.9426e-02, -5.8591e-02,  9.7092e-03],\n",
            "          [-3.8548e-02,  6.3683e-03,  1.5035e-02],\n",
            "          [-3.7046e-02, -1.4111e-02, -1.6597e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.4269e-03,  1.8713e-02,  2.5267e-02],\n",
            "          [ 6.9802e-03,  1.7929e-02,  9.9811e-03],\n",
            "          [ 2.1969e-02,  1.8796e-02, -4.0721e-02]],\n",
            "\n",
            "         [[-3.5862e-03, -1.5231e-02, -7.7869e-02],\n",
            "          [-6.1249e-02, -4.0560e-02, -3.8124e-02],\n",
            "          [-7.2436e-02, -4.5243e-02, -8.9422e-05]],\n",
            "\n",
            "         [[-2.7227e-02,  5.8149e-02, -2.4128e-02],\n",
            "          [ 4.1856e-02,  3.3249e-02, -1.6890e-02],\n",
            "          [ 2.0971e-04,  3.7346e-02,  2.9470e-02]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 0.0513,  0.1535, -0.0500, -0.0670, -0.0056,  0.0797,  0.1203,  0.1337,\n",
            "         0.0065, -0.0164, -0.0487,  0.0189,  0.1697, -0.1225, -0.0371, -0.0333,\n",
            "         0.3465,  0.0618, -0.0519,  0.0535,  0.0104,  0.1288, -0.1057, -0.0359,\n",
            "         0.0989, -0.0550,  0.1212, -0.3112, -0.0255,  0.0673, -0.0111, -0.0319,\n",
            "        -0.0385,  0.0808, -0.0369,  0.1016,  0.0967, -0.0092, -0.0390,  0.0191,\n",
            "         0.1409, -0.2105,  0.0366,  0.1235,  0.1686, -0.0280, -0.0220,  0.0293,\n",
            "         0.0387, -0.0150,  0.1441, -0.0105,  0.5572,  0.1637, -0.0016,  0.0868,\n",
            "         0.3200,  0.0243, -0.0474, -0.1277, -0.0394, -0.0703,  0.2334,  0.1057],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[[[ 0.0038, -0.0008,  0.0508],\n",
            "          [ 0.0168,  0.0423,  0.0392],\n",
            "          [ 0.0407, -0.0038,  0.0352]],\n",
            "\n",
            "         [[-0.0319, -0.0002, -0.0060],\n",
            "          [ 0.0047,  0.0075, -0.0131],\n",
            "          [-0.0096, -0.0327,  0.0157]],\n",
            "\n",
            "         [[-0.0192,  0.0251,  0.0009],\n",
            "          [-0.0218,  0.0263, -0.0248],\n",
            "          [ 0.0215,  0.0052,  0.0027]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0507, -0.0072,  0.0174],\n",
            "          [-0.0440, -0.0113, -0.0009],\n",
            "          [-0.0481,  0.0016, -0.0349]],\n",
            "\n",
            "         [[ 0.0293,  0.0314, -0.0086],\n",
            "          [ 0.0106,  0.0263,  0.0413],\n",
            "          [ 0.0470,  0.0267,  0.0330]],\n",
            "\n",
            "         [[ 0.0391,  0.0027,  0.0342],\n",
            "          [ 0.0122,  0.0629,  0.0038],\n",
            "          [ 0.0525,  0.0482, -0.0169]]],\n",
            "\n",
            "\n",
            "        [[[-0.0642, -0.0480, -0.0610],\n",
            "          [-0.0868, -0.0750, -0.0684],\n",
            "          [-0.0534, -0.0071, -0.0138]],\n",
            "\n",
            "         [[-0.0403, -0.0365, -0.0642],\n",
            "          [-0.0269, -0.0226, -0.0300],\n",
            "          [-0.0122,  0.0104, -0.0338]],\n",
            "\n",
            "         [[-0.0157, -0.0203, -0.0651],\n",
            "          [-0.0421, -0.0165, -0.0508],\n",
            "          [-0.0243, -0.0468, -0.0066]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0010, -0.0435, -0.0458],\n",
            "          [-0.0358, -0.0759, -0.0710],\n",
            "          [-0.0241, -0.0372, -0.0103]],\n",
            "\n",
            "         [[ 0.0449,  0.0889,  0.0706],\n",
            "          [ 0.0257,  0.0189, -0.0361],\n",
            "          [-0.0170, -0.0326,  0.0117]],\n",
            "\n",
            "         [[ 0.0339,  0.0005, -0.0232],\n",
            "          [ 0.0145,  0.0238,  0.0163],\n",
            "          [ 0.0018,  0.0273,  0.0014]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0264,  0.0414,  0.0268],\n",
            "          [ 0.0384, -0.0001, -0.0064],\n",
            "          [ 0.0162,  0.0620,  0.0486]],\n",
            "\n",
            "         [[ 0.0519,  0.0159,  0.0168],\n",
            "          [-0.0063,  0.0371,  0.0379],\n",
            "          [ 0.0150,  0.0194, -0.0243]],\n",
            "\n",
            "         [[ 0.0107,  0.0371,  0.0363],\n",
            "          [ 0.0200,  0.0336, -0.0259],\n",
            "          [ 0.0596, -0.0240, -0.0362]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0026,  0.0085, -0.0062],\n",
            "          [-0.0016,  0.0411, -0.0315],\n",
            "          [ 0.0523, -0.0075, -0.0178]],\n",
            "\n",
            "         [[-0.0539,  0.0013, -0.0077],\n",
            "          [ 0.0119, -0.0064, -0.0017],\n",
            "          [-0.0195, -0.0388, -0.0058]],\n",
            "\n",
            "         [[ 0.0243,  0.0161,  0.0141],\n",
            "          [ 0.0409, -0.0236,  0.0061],\n",
            "          [ 0.0045,  0.0162,  0.0014]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0316, -0.0288, -0.0363],\n",
            "          [-0.0521, -0.0665, -0.0617],\n",
            "          [ 0.0208, -0.0204, -0.0576]],\n",
            "\n",
            "         [[-0.0295, -0.0019, -0.0506],\n",
            "          [-0.0202,  0.0010,  0.0053],\n",
            "          [-0.0107, -0.0131, -0.0208]],\n",
            "\n",
            "         [[-0.0193,  0.0100,  0.0283],\n",
            "          [-0.0555,  0.0251,  0.0402],\n",
            "          [-0.0535, -0.0299,  0.0371]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0043,  0.0103, -0.0006],\n",
            "          [ 0.0112, -0.0071,  0.0060],\n",
            "          [ 0.0075, -0.0386, -0.0151]],\n",
            "\n",
            "         [[ 0.0724,  0.0413,  0.0597],\n",
            "          [-0.0003, -0.0045, -0.0417],\n",
            "          [ 0.0045, -0.0164, -0.0140]],\n",
            "\n",
            "         [[ 0.0206, -0.0335, -0.0177],\n",
            "          [ 0.0250,  0.0098, -0.0381],\n",
            "          [-0.0305,  0.0383,  0.0066]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0435, -0.0119, -0.0281],\n",
            "          [ 0.0087, -0.0417, -0.0329],\n",
            "          [ 0.0158,  0.0215, -0.0297]],\n",
            "\n",
            "         [[-0.0333,  0.0367,  0.0243],\n",
            "          [-0.0221,  0.0039, -0.0113],\n",
            "          [-0.0013, -0.0327, -0.0056]],\n",
            "\n",
            "         [[-0.0412, -0.0220, -0.0129],\n",
            "          [-0.0039,  0.0199,  0.0363],\n",
            "          [ 0.0029, -0.0168,  0.0290]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0297,  0.0179,  0.0060],\n",
            "          [ 0.0306,  0.0010,  0.0305],\n",
            "          [ 0.0147,  0.0211, -0.0027]],\n",
            "\n",
            "         [[-0.0247, -0.0284, -0.0333],\n",
            "          [ 0.0013,  0.0187, -0.0341],\n",
            "          [ 0.0102, -0.0037, -0.0029]],\n",
            "\n",
            "         [[ 0.0431, -0.0087, -0.0194],\n",
            "          [ 0.0117, -0.0048, -0.0355],\n",
            "          [-0.0075,  0.0331,  0.0027]]],\n",
            "\n",
            "\n",
            "        [[[-0.0352,  0.0125,  0.0424],\n",
            "          [ 0.0268,  0.0453,  0.0072],\n",
            "          [-0.0214, -0.0282, -0.0308]],\n",
            "\n",
            "         [[ 0.0434, -0.0404, -0.0251],\n",
            "          [-0.0013, -0.0089,  0.0359],\n",
            "          [ 0.0265,  0.0263, -0.0254]],\n",
            "\n",
            "         [[ 0.0338,  0.0337,  0.0316],\n",
            "          [ 0.0104,  0.0468,  0.0248],\n",
            "          [-0.0093, -0.0360,  0.0327]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0104, -0.0166,  0.0110],\n",
            "          [-0.0195,  0.0175, -0.0340],\n",
            "          [-0.0409,  0.0113,  0.0176]],\n",
            "\n",
            "         [[-0.0230, -0.0244, -0.0029],\n",
            "          [ 0.0283,  0.0362,  0.0301],\n",
            "          [-0.0107, -0.0198,  0.0206]],\n",
            "\n",
            "         [[ 0.0071,  0.0315, -0.0397],\n",
            "          [-0.0112,  0.0164, -0.0011],\n",
            "          [ 0.0258, -0.0162,  0.0020]]]], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-3.4846e-02,  8.7000e-02,  1.2875e-03,  1.0487e-01,  6.1114e-02,\n",
            "         9.1184e-03, -2.5402e-02,  2.4087e-02, -1.6373e-02, -1.4174e-01,\n",
            "         2.0500e-02, -4.9308e-02, -1.5768e-02, -4.8209e-02, -6.1082e-02,\n",
            "         2.6656e-01, -1.9494e-02, -2.5979e-02,  3.3295e-03,  8.3524e-02,\n",
            "        -7.2036e-03,  2.7407e-02, -4.9092e-02,  1.9464e-02, -6.8575e-03,\n",
            "        -6.2067e-03,  4.8491e-02,  2.2992e-02, -5.5147e-02, -7.2407e-03,\n",
            "        -3.9937e-02,  2.6763e-02,  5.1784e-02, -4.0574e-02, -1.2482e-02,\n",
            "        -1.8976e-02,  8.0504e-02,  7.1739e-02, -6.8780e-02, -8.4659e-02,\n",
            "        -3.1103e-02,  6.8865e-03,  1.4577e-01, -1.3227e-02,  3.8724e-02,\n",
            "         1.6883e-01,  3.4541e-03, -3.4003e-02,  7.6403e-02,  1.5786e-01,\n",
            "        -3.8834e-02, -6.2189e-03, -1.6126e-01, -9.8288e-03, -3.7811e-02,\n",
            "        -3.9008e-02, -1.7036e-01, -3.9662e-02,  4.8990e-02,  2.5706e-02,\n",
            "        -9.7746e-02,  2.1794e-02,  1.0118e-01,  7.2068e-02,  6.1512e-02,\n",
            "         9.0474e-02,  1.0820e-01,  8.5050e-02, -3.7102e-02, -2.2940e-02,\n",
            "        -2.1355e-02,  3.2596e-02,  7.5985e-02, -3.4479e-02,  1.2275e-03,\n",
            "         5.2317e-03, -1.0651e-02, -1.0496e-02, -7.2905e-02,  5.7056e-02,\n",
            "         2.7545e-02,  2.1627e-02, -6.5842e-02,  3.8661e-02, -3.6719e-02,\n",
            "         9.4928e-02,  9.9031e-02,  2.0302e-02,  6.7619e-02,  8.0499e-03,\n",
            "        -1.8535e-02,  2.5151e-02,  2.0655e-02,  4.6369e-02,  5.3830e-02,\n",
            "        -1.6531e-02, -4.0587e-02,  9.9635e-02,  1.3885e-02,  1.6713e-01,\n",
            "        -2.6902e-02, -7.2300e-02,  2.9541e-02,  1.7817e-01,  3.9239e-02,\n",
            "        -4.9265e-02,  1.0279e-01,  2.0496e-01,  8.9500e-03,  5.0590e-02,\n",
            "        -3.2406e-02, -1.9809e-02,  1.4841e-03,  5.7404e-02,  3.7612e-02,\n",
            "         1.4807e-05,  4.8456e-02,  1.8840e-02,  1.5774e-01, -3.7525e-03,\n",
            "         2.1047e-01,  3.0878e-02, -5.3492e-02,  1.3687e-01, -2.7422e-02,\n",
            "        -2.6537e-02, -3.0793e-02, -3.1854e-02], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[[[ 0.0063, -0.0148, -0.0130],\n",
            "          [ 0.0212, -0.0012, -0.0180],\n",
            "          [ 0.0028, -0.0088, -0.0351]],\n",
            "\n",
            "         [[-0.0722, -0.0543, -0.0475],\n",
            "          [-0.0847, -0.0972, -0.0528],\n",
            "          [-0.0687, -0.0514, -0.0130]],\n",
            "\n",
            "         [[ 0.0420,  0.0182,  0.0171],\n",
            "          [-0.0090, -0.0116,  0.0199],\n",
            "          [ 0.0050, -0.0255, -0.0031]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0482, -0.0613, -0.0080],\n",
            "          [-0.0435, -0.0555, -0.0807],\n",
            "          [-0.0389, -0.0641, -0.0621]],\n",
            "\n",
            "         [[-0.0423, -0.0102, -0.0246],\n",
            "          [-0.0322, -0.0291,  0.0018],\n",
            "          [-0.0208,  0.0125, -0.0127]],\n",
            "\n",
            "         [[ 0.0155,  0.0236,  0.0291],\n",
            "          [ 0.0292,  0.0259,  0.0031],\n",
            "          [ 0.0021,  0.0204, -0.0319]]],\n",
            "\n",
            "\n",
            "        [[[-0.0068,  0.0043, -0.0148],\n",
            "          [-0.0023,  0.0313, -0.0076],\n",
            "          [-0.0079,  0.0234, -0.0130]],\n",
            "\n",
            "         [[-0.0197, -0.0332, -0.0155],\n",
            "          [-0.0314, -0.0398, -0.0526],\n",
            "          [-0.0179, -0.0310, -0.0265]],\n",
            "\n",
            "         [[ 0.0088,  0.0193, -0.0098],\n",
            "          [ 0.0213,  0.0135, -0.0216],\n",
            "          [ 0.0005,  0.0218,  0.0197]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0148, -0.0429, -0.0013],\n",
            "          [-0.0445, -0.0561, -0.0304],\n",
            "          [-0.0147, -0.0222, -0.0531]],\n",
            "\n",
            "         [[-0.0220, -0.0242, -0.0159],\n",
            "          [-0.0262,  0.0134, -0.0128],\n",
            "          [ 0.0149,  0.0200,  0.0043]],\n",
            "\n",
            "         [[ 0.0038, -0.0018, -0.0204],\n",
            "          [-0.0195, -0.0262,  0.0148],\n",
            "          [-0.0184,  0.0227, -0.0212]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0129,  0.0145, -0.0318],\n",
            "          [ 0.0058, -0.0124,  0.0231],\n",
            "          [-0.0173, -0.0126,  0.0170]],\n",
            "\n",
            "         [[ 0.0217,  0.0168,  0.0398],\n",
            "          [ 0.0198, -0.0134,  0.0239],\n",
            "          [-0.0192,  0.0274,  0.0036]],\n",
            "\n",
            "         [[-0.0273, -0.0141, -0.0011],\n",
            "          [ 0.0224,  0.0268, -0.0097],\n",
            "          [-0.0217,  0.0116, -0.0073]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0183, -0.0021,  0.0091],\n",
            "          [-0.0204, -0.0149,  0.0266],\n",
            "          [-0.0062,  0.0156,  0.0228]],\n",
            "\n",
            "         [[-0.0140,  0.0026, -0.0243],\n",
            "          [-0.0010, -0.0038, -0.0138],\n",
            "          [-0.0115, -0.0283,  0.0284]],\n",
            "\n",
            "         [[ 0.0069, -0.0302,  0.0189],\n",
            "          [ 0.0189, -0.0256,  0.0199],\n",
            "          [-0.0164,  0.0134, -0.0080]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0106, -0.0144, -0.0298],\n",
            "          [ 0.0018,  0.0014, -0.0438],\n",
            "          [-0.0345,  0.0035,  0.0013]],\n",
            "\n",
            "         [[-0.0156, -0.0374,  0.0241],\n",
            "          [-0.0127,  0.0293,  0.0346],\n",
            "          [ 0.0122,  0.0374,  0.0060]],\n",
            "\n",
            "         [[-0.0175, -0.0196,  0.0007],\n",
            "          [-0.0062, -0.0320, -0.0274],\n",
            "          [-0.0152,  0.0031, -0.0131]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0089,  0.0060,  0.0193],\n",
            "          [-0.0054,  0.0373,  0.0264],\n",
            "          [ 0.0198,  0.0370,  0.0314]],\n",
            "\n",
            "         [[ 0.0157,  0.0315,  0.0184],\n",
            "          [ 0.0208,  0.0270, -0.0044],\n",
            "          [-0.0101,  0.0137, -0.0322]],\n",
            "\n",
            "         [[-0.0140,  0.0098,  0.0052],\n",
            "          [-0.0103, -0.0058,  0.0143],\n",
            "          [-0.0018, -0.0211,  0.0313]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0465,  0.0063,  0.0023],\n",
            "          [ 0.0443,  0.0386, -0.0153],\n",
            "          [ 0.0343,  0.0270, -0.0005]],\n",
            "\n",
            "         [[-0.0187, -0.0725, -0.0504],\n",
            "          [-0.0369, -0.0830, -0.0373],\n",
            "          [-0.0329, -0.0646, -0.0497]],\n",
            "\n",
            "         [[ 0.0274, -0.0050, -0.0347],\n",
            "          [ 0.0060,  0.0183,  0.0176],\n",
            "          [-0.0101,  0.0096, -0.0086]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0450, -0.0410, -0.0585],\n",
            "          [-0.0579, -0.0172, -0.0219],\n",
            "          [-0.0122, -0.0703, -0.0188]],\n",
            "\n",
            "         [[-0.0137,  0.0158,  0.0351],\n",
            "          [ 0.0214,  0.0099, -0.0159],\n",
            "          [-0.0013, -0.0071, -0.0230]],\n",
            "\n",
            "         [[ 0.0018, -0.0108, -0.0035],\n",
            "          [-0.0131, -0.0126, -0.0175],\n",
            "          [ 0.0178,  0.0218,  0.0205]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0196,  0.0130,  0.0085],\n",
            "          [-0.0094,  0.0191, -0.0256],\n",
            "          [ 0.0140,  0.0177, -0.0193]],\n",
            "\n",
            "         [[ 0.0061,  0.0086, -0.0433],\n",
            "          [-0.0181, -0.0306, -0.0008],\n",
            "          [-0.0101, -0.0173, -0.0079]],\n",
            "\n",
            "         [[ 0.0179,  0.0190, -0.0217],\n",
            "          [-0.0171,  0.0095,  0.0158],\n",
            "          [ 0.0091, -0.0212, -0.0051]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0281, -0.0009,  0.0011],\n",
            "          [-0.0098, -0.0089, -0.0246],\n",
            "          [ 0.0117,  0.0045, -0.0149]],\n",
            "\n",
            "         [[ 0.0072,  0.0080,  0.0079],\n",
            "          [-0.0187,  0.0110,  0.0170],\n",
            "          [-0.0276, -0.0231,  0.0197]],\n",
            "\n",
            "         [[ 0.0241,  0.0112,  0.0028],\n",
            "          [ 0.0185, -0.0046, -0.0206],\n",
            "          [-0.0146,  0.0094, -0.0102]]]], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-1.4048e-01,  9.6191e-02, -4.3294e-02,  4.7014e-02, -3.4280e-02,\n",
            "        -2.8041e-02,  5.6957e-07,  2.8087e-02,  8.3634e-02, -1.8796e-02,\n",
            "        -4.9327e-02, -2.1622e-03, -3.7975e-02, -3.7822e-02,  6.0118e-02,\n",
            "         1.0793e-02, -1.1519e-02,  4.3799e-02, -1.2171e-03, -7.3191e-02,\n",
            "         5.1215e-02, -5.1821e-03,  7.8735e-02,  3.9522e-02, -5.1520e-02,\n",
            "         8.4217e-02,  9.3058e-03,  4.5134e-02, -1.4854e-02,  8.7456e-02,\n",
            "        -9.0380e-04,  2.0084e-02, -6.6906e-02, -3.9386e-02,  3.4063e-02,\n",
            "        -5.4559e-02, -4.4674e-02, -2.1013e-02, -4.3287e-02,  2.2981e-03,\n",
            "        -4.9960e-02,  9.4194e-02,  1.5854e-02,  8.3217e-02, -2.8836e-02,\n",
            "         2.5868e-02,  9.3305e-02, -9.8918e-02,  1.4203e-02, -3.8131e-02,\n",
            "        -5.2342e-02,  1.1077e-01, -2.8311e-02,  1.1419e-01, -4.8486e-02,\n",
            "        -1.5246e-02,  9.6932e-02, -1.8698e-02, -2.1852e-02,  2.9802e-02,\n",
            "        -3.2811e-02, -1.3624e-02,  2.2592e-02,  9.4108e-04,  1.0353e-01,\n",
            "         2.8279e-02,  4.7596e-03, -1.4128e-02, -1.8498e-02,  8.6116e-03,\n",
            "         6.0759e-02, -6.2951e-02,  2.3466e-02, -4.2819e-02, -6.6455e-02,\n",
            "         8.2387e-03, -7.6491e-02, -3.2411e-02, -3.5737e-02,  1.1969e-01,\n",
            "        -7.3236e-03,  7.2396e-02,  1.1388e-02, -3.2076e-02,  4.7530e-02,\n",
            "        -8.0964e-03,  2.0620e-02,  5.2809e-03, -1.4564e-02, -2.1585e-02,\n",
            "        -2.5384e-05,  1.1295e-01,  6.8178e-02,  4.8905e-02, -2.4907e-04,\n",
            "         8.9701e-02, -5.7080e-02, -2.1874e-02, -6.6997e-02, -1.9928e-02,\n",
            "         6.2555e-02, -2.7426e-02,  3.1241e-02, -5.5984e-02, -4.2995e-02,\n",
            "        -8.7601e-02,  2.7590e-02,  1.4413e-02,  4.1093e-02,  2.8078e-02,\n",
            "         9.1632e-02,  6.6610e-02,  2.3909e-02,  2.0334e-01,  2.4000e-03,\n",
            "        -6.1719e-02,  9.3815e-03, -4.2662e-02,  3.7205e-02,  1.5065e-03,\n",
            "        -6.7008e-02,  2.2681e-02,  7.1174e-02,  3.4144e-02,  8.1765e-02,\n",
            "        -9.4480e-02,  3.7726e-02,  2.1621e-02], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[ 6.7449e-03,  6.1731e-03,  4.8530e-03,  ...,  5.2381e-04,\n",
            "          1.1130e-03, -1.6672e-03],\n",
            "        [ 4.8801e-03,  1.5872e-03, -7.7500e-04,  ...,  9.6313e-04,\n",
            "          8.4391e-04, -2.7619e-03],\n",
            "        [-3.7731e-03,  1.0738e-03,  2.6014e-03,  ..., -2.3517e-03,\n",
            "          9.1521e-04,  1.2799e-03],\n",
            "        ...,\n",
            "        [ 1.4176e-03, -1.1536e-03, -2.7435e-03,  ..., -2.3350e-03,\n",
            "          1.4809e-03,  2.4409e-05],\n",
            "        [-6.1190e-03, -6.0081e-03, -5.5994e-03,  ..., -6.2548e-07,\n",
            "         -1.5353e-03, -2.5109e-03],\n",
            "        [-1.5325e-03, -6.8287e-04,  2.9356e-03,  ...,  1.5325e-03,\n",
            "          1.2744e-03, -9.9538e-04]], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-3.0915e-03,  7.0009e-03,  7.0303e-03,  9.4845e-03,  3.9633e-03,\n",
            "        -8.0749e-03, -4.1135e-03, -1.5254e-02, -1.6902e-03, -1.5214e-03,\n",
            "        -2.5312e-03, -3.9826e-03, -9.4153e-03, -1.5733e-02,  1.6684e-02,\n",
            "         1.0345e-02,  1.4854e-02,  7.1318e-03,  1.2992e-03, -2.2155e-04,\n",
            "        -6.1878e-03, -1.2607e-02, -1.1307e-02, -1.6547e-03, -1.7876e-04,\n",
            "        -8.0982e-06,  5.5304e-03,  2.2679e-02, -3.1908e-03, -9.7886e-04,\n",
            "         1.2088e-02,  1.8609e-03, -7.1207e-04, -4.5546e-03,  1.2510e-02,\n",
            "        -8.4185e-03, -6.0673e-03,  5.6303e-03,  5.9940e-03, -2.9022e-03,\n",
            "         2.9085e-03, -2.8603e-03, -1.3797e-02,  3.1808e-03,  1.4519e-03,\n",
            "        -1.7068e-03, -9.5413e-03, -1.0355e-04, -2.6459e-03, -1.9908e-03,\n",
            "         7.3725e-04, -6.0261e-03, -4.3008e-03, -9.9383e-04, -7.2133e-03,\n",
            "        -2.5354e-03,  1.9866e-03,  3.3992e-04, -5.7449e-04, -5.9058e-03,\n",
            "        -1.4717e-02, -6.0643e-03,  6.5032e-03,  2.0901e-03,  1.0524e-03,\n",
            "        -1.3056e-03, -4.3813e-03,  3.7003e-04,  9.1302e-04,  8.5404e-03,\n",
            "         8.4802e-04,  3.6423e-03,  1.3719e-03,  1.0192e-03, -1.0547e-03,\n",
            "         1.9940e-03, -2.0427e-03, -4.6941e-03, -4.7571e-04,  7.4905e-03,\n",
            "         4.6411e-03, -3.6499e-03, -4.2417e-03, -2.1899e-03,  2.5620e-03,\n",
            "        -1.0117e-03,  3.5433e-03, -5.3203e-03,  2.0155e-03,  4.5279e-04,\n",
            "        -5.1749e-03, -3.8822e-04,  2.0121e-03, -6.2089e-03,  7.4697e-03,\n",
            "        -1.1007e-02,  2.6627e-03, -4.4507e-04,  3.8131e-03, -1.0979e-03,\n",
            "         9.0132e-03,  3.4430e-03,  1.4222e-02, -2.1734e-03, -6.0811e-04,\n",
            "         8.9175e-03, -8.1742e-05,  1.3188e-02,  9.4976e-03,  1.8648e-02,\n",
            "         2.4595e-03, -2.2414e-04,  3.4034e-03,  1.4558e-02, -2.9319e-03,\n",
            "         5.2252e-03, -5.6529e-03,  2.2380e-03,  2.5314e-03,  8.5799e-03,\n",
            "         1.5914e-02, -2.3840e-03, -6.1985e-03,  1.2094e-02,  9.2096e-03,\n",
            "         3.2088e-04, -3.1514e-03,  9.6105e-03, -1.3118e-03,  1.1295e-03,\n",
            "        -1.0864e-02, -2.8191e-03,  2.6089e-03, -1.2218e-02,  8.0490e-03,\n",
            "         1.5359e-02, -8.2282e-03, -8.2814e-03,  3.4456e-03, -4.3062e-03,\n",
            "        -7.8290e-03,  6.8536e-03, -7.2861e-04, -6.5191e-03, -1.5222e-02,\n",
            "         7.8873e-03,  5.2406e-03,  7.9274e-04, -1.0236e-03, -5.6191e-03,\n",
            "        -6.3615e-03,  5.0162e-03, -4.6353e-03, -3.7864e-03, -3.6407e-03,\n",
            "        -1.6264e-03,  2.7726e-03,  9.7290e-03,  4.7300e-03, -1.4370e-03,\n",
            "         1.1758e-02, -8.0294e-04, -9.2608e-03, -1.1416e-02,  6.8734e-03,\n",
            "        -6.0536e-04, -5.8020e-04, -9.7040e-04,  6.8940e-03,  8.8368e-03,\n",
            "         4.7202e-04,  3.7066e-03,  1.3898e-02,  7.7289e-03, -1.1926e-03,\n",
            "        -7.5731e-03, -5.4208e-03,  1.9885e-02, -7.6324e-04,  3.6520e-04,\n",
            "         9.6962e-03,  9.7695e-03,  3.0466e-02, -3.7861e-03,  2.5986e-03,\n",
            "         4.6441e-03, -8.5641e-03, -4.5385e-03, -4.6865e-04,  9.4331e-03,\n",
            "        -3.7152e-03,  9.2867e-03,  1.5283e-02,  7.1120e-03, -6.8776e-03,\n",
            "        -2.0699e-03,  4.9396e-03, -1.2593e-03,  1.0136e-02,  4.4243e-04,\n",
            "        -1.6393e-03,  4.4133e-03, -4.9833e-05,  6.4461e-04,  5.5527e-03,\n",
            "         7.7580e-03,  1.5224e-03,  2.0735e-03,  5.4495e-03, -2.0216e-03,\n",
            "         1.9098e-04, -4.2264e-03,  9.5848e-04,  2.8455e-03,  3.1706e-03,\n",
            "        -9.1583e-04,  1.2265e-02, -1.6689e-02,  1.8296e-02, -8.3061e-04,\n",
            "         6.4869e-03,  3.4647e-03,  1.8250e-02, -1.0599e-02,  1.3780e-02,\n",
            "         2.2303e-03, -7.3938e-03, -2.8179e-03, -5.7437e-04,  1.1052e-03,\n",
            "        -1.5825e-03,  1.1565e-03,  9.9466e-04,  5.1443e-03, -2.4445e-03,\n",
            "         1.0103e-03, -3.2024e-04,  1.7139e-02, -3.1749e-03,  2.4549e-03,\n",
            "        -2.5718e-03,  6.0574e-03,  1.8967e-02,  1.4457e-02,  9.4804e-03,\n",
            "         1.6462e-03, -1.1233e-03,  2.6835e-02, -1.6480e-03,  4.4640e-04,\n",
            "        -1.0330e-03,  7.6867e-03,  1.4860e-02,  2.0030e-02,  1.3012e-02,\n",
            "         7.9192e-03], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0465, -0.0347,  0.0314,  ...,  0.0773, -0.0112, -0.0381],\n",
            "        [-0.0333,  0.0111,  0.0345,  ...,  0.0514, -0.0576, -0.0164],\n",
            "        [-0.0381,  0.0283,  0.0575,  ...,  0.0580, -0.0330,  0.0078],\n",
            "        ...,\n",
            "        [-0.0491,  0.0670, -0.0389,  ..., -0.0117,  0.0869,  0.0140],\n",
            "        [ 0.0139, -0.0937,  0.0108,  ..., -0.0434,  0.0237,  0.0219],\n",
            "        [ 0.0571, -0.0282, -0.0208,  ...,  0.0279,  0.0637, -0.0374]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([ 4.5473e-02, -5.7139e-02, -2.9093e-02, -5.0247e-02,  4.2335e-02,\n",
            "        -1.6718e-02, -3.5878e-02, -5.3695e-02,  5.6157e-02,  6.6721e-03,\n",
            "         1.5898e-03,  4.6791e-02, -8.6835e-03, -1.6502e-02,  2.0300e-02,\n",
            "        -4.3535e-02, -6.2531e-02,  5.2724e-02,  5.7026e-02, -1.3874e-03,\n",
            "         8.2331e-02, -1.0039e-02,  1.1745e-02, -4.9126e-02,  5.2308e-02,\n",
            "         3.6910e-02,  7.4297e-02, -2.7946e-03,  8.7575e-03, -3.1718e-02,\n",
            "         3.4552e-02,  3.5587e-02,  3.7751e-03, -1.8720e-02, -3.5325e-02,\n",
            "         7.8075e-02,  5.1705e-02, -3.1460e-02, -7.0226e-02, -5.3672e-02,\n",
            "        -9.0174e-03, -3.1423e-02,  6.3338e-02, -2.4389e-02,  4.9373e-02,\n",
            "        -3.7016e-02, -2.5443e-02, -2.5748e-02, -2.5363e-02,  1.1471e-02,\n",
            "        -2.7745e-02, -5.0331e-02, -3.5288e-02, -1.3219e-02, -5.2088e-02,\n",
            "         4.3271e-02,  7.4937e-05, -3.7170e-02, -2.3296e-03,  2.6841e-02,\n",
            "        -3.8704e-02, -2.1582e-02, -2.0754e-02, -8.7166e-03,  6.7588e-02,\n",
            "        -2.6501e-02,  1.0619e-02, -1.2561e-02,  2.6602e-02,  1.9597e-02,\n",
            "        -4.0196e-02,  4.0825e-02,  2.7750e-02, -1.3544e-03,  5.5286e-02,\n",
            "         4.2390e-02, -2.6353e-02,  1.6179e-02,  5.2938e-02, -1.0193e-02,\n",
            "         5.1481e-03, -1.8962e-02,  4.9291e-02,  1.4843e-03, -3.9726e-03,\n",
            "        -2.8083e-02, -3.1004e-02,  1.0442e-02, -9.6342e-03, -2.7878e-02,\n",
            "         5.1296e-02,  4.2423e-02, -1.4784e-02,  2.2083e-02, -8.6445e-03,\n",
            "         1.1230e-02, -3.2027e-02,  1.0807e-01,  4.6524e-02, -8.4898e-02,\n",
            "         1.0180e-02,  2.1943e-02,  5.3770e-02,  5.0490e-02,  3.0643e-02,\n",
            "        -2.5971e-02,  1.2850e-04, -8.4604e-03, -2.3737e-02, -1.7258e-02,\n",
            "         1.1791e-03,  7.1117e-02,  6.3593e-02,  4.5163e-02,  2.8635e-02,\n",
            "        -4.7197e-02, -1.7831e-02, -6.6808e-02, -4.1405e-02,  1.3712e-02,\n",
            "         3.1863e-02, -2.3927e-02, -1.7907e-02, -1.4008e-03,  3.0950e-02,\n",
            "        -4.0003e-02, -3.4667e-02, -1.2824e-02, -6.7120e-03,  1.0405e-03,\n",
            "         6.6542e-02, -1.6147e-02, -2.3056e-02,  8.2906e-02,  6.0791e-02,\n",
            "         3.9900e-03,  2.8331e-02, -6.1703e-02,  3.5911e-02, -2.4963e-02,\n",
            "        -2.1127e-02, -1.4459e-02,  2.7395e-02,  8.6956e-02,  3.6084e-02,\n",
            "         3.7619e-02,  5.2293e-02, -8.2965e-03,  3.0467e-02, -9.0976e-03,\n",
            "         8.5941e-02, -1.6776e-03,  3.0691e-02, -3.5836e-02,  2.5440e-02,\n",
            "         2.4193e-02,  3.9853e-03,  5.6605e-02,  1.5860e-02, -5.1976e-03,\n",
            "        -1.7930e-02,  1.6676e-02, -6.3776e-02,  1.4769e-02,  3.3682e-02,\n",
            "         2.9574e-03, -5.8169e-03,  7.5095e-02,  6.5779e-03, -2.3813e-02,\n",
            "         5.5482e-02,  2.2832e-02, -4.1213e-02,  3.0200e-02,  1.2985e-02,\n",
            "         4.7857e-02, -5.1859e-02,  1.3278e-02,  3.2736e-03, -4.3618e-02,\n",
            "         5.3195e-02, -5.4649e-02, -2.5899e-02,  5.7355e-02,  1.0069e-02,\n",
            "        -4.9136e-02,  3.9379e-02,  5.6972e-02,  2.8310e-03, -4.5423e-02,\n",
            "        -1.5912e-02,  6.0484e-02,  6.7017e-02, -3.5506e-02,  6.4443e-02,\n",
            "        -4.9948e-02,  8.2845e-02, -1.5741e-02,  1.8897e-02, -1.6098e-02,\n",
            "         5.1434e-02,  1.1333e-02, -3.9169e-02, -2.8337e-02,  4.5283e-02,\n",
            "        -3.2605e-02,  3.3899e-02,  6.8907e-03, -4.5377e-04,  2.1536e-02,\n",
            "         5.2908e-02,  6.3469e-02,  8.1366e-04, -3.6495e-02, -1.7760e-02,\n",
            "        -3.5620e-02,  9.1117e-02,  5.6486e-02, -3.0464e-02, -5.3003e-02,\n",
            "         1.4814e-03,  6.2014e-03,  1.9019e-02,  1.3726e-02, -4.6079e-02,\n",
            "         7.0234e-02, -5.0221e-02,  2.5273e-03, -3.1132e-02,  5.5686e-02,\n",
            "         4.1419e-02,  1.6330e-02,  9.7150e-02, -3.1393e-02,  6.4006e-02,\n",
            "        -7.0758e-02,  7.9557e-02, -6.7301e-02,  7.4336e-02,  5.2423e-02,\n",
            "         1.1303e-02, -4.0421e-02,  3.0251e-03,  5.1646e-02, -2.3781e-02,\n",
            "         2.1432e-02, -5.9478e-02,  1.5478e-02,  1.1718e-02,  5.7684e-03,\n",
            "         1.2809e-02,  4.3602e-03, -7.0166e-02,  4.7890e-02,  1.3361e-02,\n",
            "         4.9955e-02], device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([[-0.0368, -0.0939, -0.0909,  ...,  0.0624, -0.0122,  0.1053],\n",
            "        [-0.1097, -0.0640,  0.2392,  ..., -0.0897,  0.0734, -0.0440],\n",
            "        [ 0.2167, -0.0087,  0.0375,  ...,  0.1732, -0.1245, -0.0437],\n",
            "        ...,\n",
            "        [-0.1829, -0.0624, -0.0535,  ...,  0.0543, -0.0097,  0.1216],\n",
            "        [ 0.0258,  0.0657, -0.0883,  ..., -0.0939, -0.0732, -0.1364],\n",
            "        [-0.0651,  0.0535,  0.1306,  ..., -0.0683, -0.0752, -0.0946]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "Parameter containing:\n",
            "tensor([-0.0699, -0.2069, -0.0076, -0.0199,  0.1698, -0.0917,  0.1441, -0.0824,\n",
            "         0.0624, -0.0235], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trained_params = [x.data for x in relu_model.parameters()]\n",
        "\n",
        "i=0\n",
        "for (name, params) in flnpf_linear_model.named_parameters():\n",
        "  if name[0:3]=='NPF':\n",
        "    params.data = trained_params[i]\n",
        "    params.requires_grad = False\n",
        "    i+=1\n",
        "  print(name, params)"
      ],
      "metadata": {
        "id": "ZqVSrDh2MgCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a87d7270-eda6-4955-c34b-ed6cf102c1b3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NPF_C1.weight Parameter containing:\n",
            "tensor([[[[ 0.1783,  0.1678,  0.0707],\n",
            "          [-0.2148,  0.0080, -0.1329],\n",
            "          [-0.0768, -0.0828,  0.1414]],\n",
            "\n",
            "         [[ 0.1201,  0.1692, -0.0584],\n",
            "          [ 0.1144, -0.0063,  0.0048],\n",
            "          [ 0.0877, -0.2433, -0.2285]],\n",
            "\n",
            "         [[ 0.1040,  0.0727,  0.2162],\n",
            "          [-0.1520, -0.1024,  0.1551],\n",
            "          [ 0.0867, -0.1389, -0.1641]]],\n",
            "\n",
            "\n",
            "        [[[-0.1793, -0.1019, -0.0161],\n",
            "          [-0.0146, -0.1024, -0.1758],\n",
            "          [-0.1873, -0.0495, -0.2175]],\n",
            "\n",
            "         [[-0.0260, -0.0427, -0.0657],\n",
            "          [ 0.1340,  0.1662,  0.0424],\n",
            "          [ 0.0282, -0.2293, -0.1476]],\n",
            "\n",
            "         [[-0.0764,  0.1406,  0.2345],\n",
            "          [-0.1003,  0.0475,  0.0635],\n",
            "          [ 0.0049,  0.0302, -0.1059]]],\n",
            "\n",
            "\n",
            "        [[[-0.0955, -0.0208, -0.1790],\n",
            "          [ 0.0309, -0.1191, -0.1719],\n",
            "          [ 0.2915, -0.0676, -0.0349]],\n",
            "\n",
            "         [[-0.1897,  0.1271, -0.0343],\n",
            "          [ 0.1399,  0.0184,  0.1888],\n",
            "          [ 0.1491, -0.0418,  0.1892]],\n",
            "\n",
            "         [[-0.1733, -0.2329, -0.1357],\n",
            "          [-0.1382,  0.1079,  0.1240],\n",
            "          [-0.0594,  0.2394,  0.1112]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1990, -0.0096, -0.0576],\n",
            "          [ 0.0097,  0.0260, -0.0029],\n",
            "          [ 0.0082, -0.0942, -0.0978]],\n",
            "\n",
            "         [[ 0.0348, -0.1271,  0.1993],\n",
            "          [ 0.1334, -0.1001,  0.0583],\n",
            "          [-0.1213,  0.1562, -0.1089]],\n",
            "\n",
            "         [[ 0.1338,  0.1800,  0.0372],\n",
            "          [ 0.0039,  0.2208,  0.1513],\n",
            "          [-0.0640,  0.1286,  0.0668]]],\n",
            "\n",
            "\n",
            "        [[[-0.0437,  0.0585, -0.0300],\n",
            "          [-0.1077, -0.1139,  0.2140],\n",
            "          [-0.2148, -0.3558, -0.2091]],\n",
            "\n",
            "         [[ 0.2795,  0.3531,  0.2870],\n",
            "          [-0.0597,  0.3122,  0.2711],\n",
            "          [-0.0950, -0.0614, -0.2974]],\n",
            "\n",
            "         [[ 0.1576,  0.0207, -0.0846],\n",
            "          [ 0.0213,  0.2274,  0.0105],\n",
            "          [-0.0890, -0.3062, -0.2418]]],\n",
            "\n",
            "\n",
            "        [[[ 0.2872,  0.1812, -0.0491],\n",
            "          [ 0.1627, -0.0591,  0.0814],\n",
            "          [-0.3145, -0.2374,  0.2393]],\n",
            "\n",
            "         [[-0.0208,  0.0911, -0.0378],\n",
            "          [ 0.1538, -0.1809, -0.0119],\n",
            "          [-0.2223, -0.1330,  0.0278]],\n",
            "\n",
            "         [[ 0.1490, -0.0319, -0.1459],\n",
            "          [ 0.2538, -0.2243, -0.1458],\n",
            "          [-0.1564, -0.1006,  0.1436]]]], device='cuda:0')\n",
            "NPF_C1.bias Parameter containing:\n",
            "tensor([ 0.0173, -0.1624,  0.2160,  0.2229, -0.1069,  0.0854,  0.0301, -0.0217,\n",
            "         0.0910, -0.2613,  0.2520, -0.0846,  0.0088, -0.0380, -0.0387, -0.0367,\n",
            "        -0.1031, -0.0308,  0.2666, -0.0407, -0.2653,  0.2456, -0.0370,  0.1910,\n",
            "         0.2658,  0.1928,  0.1449, -0.2143, -0.0110,  0.2867, -0.0604,  0.2145,\n",
            "         0.0058,  0.1568, -0.0267,  0.1595,  0.0323, -0.0777,  0.0054,  0.1436,\n",
            "        -0.1524,  0.0468,  0.0366,  0.1173, -0.0892,  0.2186, -0.0229,  0.3434,\n",
            "         0.2675,  0.0024, -0.0183, -0.1151, -0.0957,  0.0141, -0.0619, -0.1340,\n",
            "         0.2070,  0.0188,  0.2372, -0.1457, -0.0481, -0.1605,  0.0187, -0.2085],\n",
            "       device='cuda:0')\n",
            "NPF_C2.weight Parameter containing:\n",
            "tensor([[[[ 3.2001e-02,  9.1168e-03,  2.8330e-02],\n",
            "          [-3.0332e-02,  9.6452e-03, -2.4690e-02],\n",
            "          [-3.4668e-02,  1.8335e-02, -2.8662e-02]],\n",
            "\n",
            "         [[-2.1238e-02,  2.7825e-02, -3.0030e-02],\n",
            "          [-2.1330e-02,  4.5230e-02,  3.3289e-02],\n",
            "          [ 4.1187e-02,  2.0557e-03,  3.1419e-02]],\n",
            "\n",
            "         [[-3.8820e-03, -4.7527e-02, -1.4905e-02],\n",
            "          [-4.8554e-02, -4.8428e-02,  2.5625e-02],\n",
            "          [-3.4557e-02,  4.1444e-03,  1.4335e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4257e-02,  2.4394e-02,  3.9946e-03],\n",
            "          [ 1.8668e-02, -3.1637e-02,  9.5560e-03],\n",
            "          [ 3.2598e-02, -1.7549e-02,  2.0341e-03]],\n",
            "\n",
            "         [[-7.5345e-03, -2.7743e-02,  2.1741e-03],\n",
            "          [-1.6420e-02, -5.6036e-02, -3.7136e-02],\n",
            "          [-4.0715e-02, -8.0570e-02, -6.5032e-02]],\n",
            "\n",
            "         [[ 2.8545e-02,  1.0203e-02,  5.5409e-03],\n",
            "          [ 1.7573e-02,  4.9532e-03,  2.6139e-02],\n",
            "          [ 6.5156e-02,  3.5886e-02,  1.8216e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 1.1881e-02, -6.9828e-03,  4.0112e-02],\n",
            "          [ 2.3973e-02, -3.1583e-03, -2.6041e-02],\n",
            "          [-4.4420e-02, -1.0565e-02, -3.7871e-02]],\n",
            "\n",
            "         [[-3.4038e-02,  5.5332e-02,  3.3835e-02],\n",
            "          [ 1.8912e-02, -1.1744e-02,  4.3739e-02],\n",
            "          [-1.9880e-02, -1.7229e-02,  2.2020e-02]],\n",
            "\n",
            "         [[-4.0655e-02,  6.4909e-03, -3.5098e-03],\n",
            "          [-1.9571e-04,  3.0176e-02,  4.1301e-02],\n",
            "          [-3.1335e-02, -3.0740e-02,  1.7581e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.4689e-02,  1.5225e-04,  2.8799e-02],\n",
            "          [-4.5992e-02, -2.8588e-02, -3.2966e-03],\n",
            "          [-1.5035e-02,  1.0694e-02, -4.3348e-02]],\n",
            "\n",
            "         [[-3.9046e-02, -1.0756e-02, -6.4772e-03],\n",
            "          [-4.6365e-02, -2.6837e-02, -1.1921e-02],\n",
            "          [-9.1780e-03, -3.3564e-02, -2.7085e-02]],\n",
            "\n",
            "         [[-3.5399e-02, -5.1048e-03, -1.8076e-02],\n",
            "          [-1.2935e-02, -3.1997e-02, -4.3831e-02],\n",
            "          [-2.2916e-02, -5.1055e-03,  6.1727e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.7974e-02,  4.2229e-02, -5.2652e-03],\n",
            "          [-5.9138e-03, -2.6785e-02,  2.0459e-02],\n",
            "          [ 9.5431e-03, -3.0225e-05,  1.6665e-02]],\n",
            "\n",
            "         [[ 1.6059e-02,  1.9674e-02, -3.6834e-02],\n",
            "          [-8.0846e-03,  3.6968e-02,  3.3175e-02],\n",
            "          [-3.4880e-02,  6.7107e-03,  7.4166e-03]],\n",
            "\n",
            "         [[-5.7282e-04,  3.8921e-02, -2.0561e-02],\n",
            "          [-2.9580e-02, -4.2997e-03,  4.3143e-03],\n",
            "          [-5.4409e-03, -3.2837e-02, -1.5609e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.1140e-02,  2.1459e-02,  2.7394e-02],\n",
            "          [ 3.3537e-02,  9.7760e-03, -3.4729e-02],\n",
            "          [-2.8220e-02,  2.9653e-02,  1.3969e-02]],\n",
            "\n",
            "         [[-2.6242e-02,  1.4204e-02,  5.7703e-02],\n",
            "          [ 2.1306e-02,  1.7519e-02, -2.0617e-02],\n",
            "          [ 4.2496e-02,  8.1717e-03,  1.2701e-02]],\n",
            "\n",
            "         [[-2.4732e-02, -1.8880e-02, -1.8417e-02],\n",
            "          [-3.2196e-03, -2.8812e-02,  4.6357e-02],\n",
            "          [-4.1272e-04, -1.3013e-02, -1.7801e-03]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.8105e-02, -1.4650e-02, -2.2165e-02],\n",
            "          [-1.2866e-02, -4.2084e-02,  2.1669e-02],\n",
            "          [-3.1966e-02,  2.1298e-03,  2.7938e-02]],\n",
            "\n",
            "         [[-2.2418e-03,  1.4748e-02,  4.4557e-02],\n",
            "          [ 5.5673e-02,  5.0982e-02, -1.8368e-02],\n",
            "          [ 4.6846e-02,  4.8603e-02,  1.0509e-04]],\n",
            "\n",
            "         [[-1.7109e-02,  1.2698e-02, -2.2443e-02],\n",
            "          [ 4.7169e-03,  3.3432e-02,  5.8487e-02],\n",
            "          [-7.2413e-03, -3.8845e-03,  4.4474e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.6513e-02, -1.2442e-02, -3.1260e-02],\n",
            "          [-1.1502e-02,  2.7639e-02,  1.1707e-02],\n",
            "          [ 1.9617e-03,  2.6097e-02, -8.5746e-04]],\n",
            "\n",
            "         [[ 3.1042e-02, -2.4324e-02, -1.4685e-02],\n",
            "          [-6.1672e-03, -2.3776e-02,  4.5197e-02],\n",
            "          [ 3.4812e-02,  4.1110e-03,  1.1130e-02]],\n",
            "\n",
            "         [[-3.5614e-02,  2.0783e-02,  2.8210e-03],\n",
            "          [ 2.3428e-02,  3.2879e-02, -1.7972e-02],\n",
            "          [-1.4736e-02,  2.2192e-02, -1.6626e-02]]],\n",
            "\n",
            "\n",
            "        [[[-1.3972e-02, -4.6845e-02, -4.4742e-02],\n",
            "          [ 4.0569e-03,  9.4357e-03, -4.3139e-02],\n",
            "          [-4.0127e-02,  4.5356e-03,  6.6380e-03]],\n",
            "\n",
            "         [[-1.8611e-04, -3.1868e-02, -2.1324e-02],\n",
            "          [-1.1394e-02, -6.3253e-04, -4.1593e-02],\n",
            "          [-2.6143e-02, -4.3754e-03, -1.6207e-02]],\n",
            "\n",
            "         [[-2.2294e-02, -2.7121e-02,  2.4063e-02],\n",
            "          [ 3.9785e-02,  4.9655e-03,  1.5862e-02],\n",
            "          [ 5.2054e-02,  8.5450e-02,  1.2709e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-4.5123e-02, -5.2380e-02, -4.7986e-02],\n",
            "          [-5.8383e-02, -1.2068e-03, -4.2647e-02],\n",
            "          [ 1.5634e-02, -1.2871e-02, -5.3748e-02]],\n",
            "\n",
            "         [[-3.1711e-02,  2.9711e-02, -2.0116e-02],\n",
            "          [ 2.9453e-02,  1.0416e-02,  9.7745e-03],\n",
            "          [ 1.3039e-02,  1.4789e-02,  5.0820e-03]],\n",
            "\n",
            "         [[-1.1513e-02, -1.5585e-02,  1.1944e-02],\n",
            "          [ 1.7842e-02, -3.0042e-02, -3.6803e-02],\n",
            "          [-1.0287e-02, -2.5526e-03, -3.8143e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 4.8189e-02, -1.9792e-02,  5.1994e-03],\n",
            "          [ 1.1544e-02, -1.8797e-02, -4.6066e-02],\n",
            "          [-1.3080e-02,  1.7157e-02,  2.2549e-02]],\n",
            "\n",
            "         [[-8.3771e-03, -5.0764e-02, -1.1878e-02],\n",
            "          [-5.1156e-02, -5.7552e-02, -3.2062e-02],\n",
            "          [-5.7209e-02, -2.0481e-03, -1.5820e-02]],\n",
            "\n",
            "         [[-5.9426e-02, -5.8591e-02,  9.7092e-03],\n",
            "          [-3.8548e-02,  6.3683e-03,  1.5035e-02],\n",
            "          [-3.7046e-02, -1.4111e-02, -1.6597e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-7.4269e-03,  1.8713e-02,  2.5267e-02],\n",
            "          [ 6.9802e-03,  1.7929e-02,  9.9811e-03],\n",
            "          [ 2.1969e-02,  1.8796e-02, -4.0721e-02]],\n",
            "\n",
            "         [[-3.5862e-03, -1.5231e-02, -7.7869e-02],\n",
            "          [-6.1249e-02, -4.0560e-02, -3.8124e-02],\n",
            "          [-7.2436e-02, -4.5243e-02, -8.9422e-05]],\n",
            "\n",
            "         [[-2.7227e-02,  5.8149e-02, -2.4128e-02],\n",
            "          [ 4.1856e-02,  3.3249e-02, -1.6890e-02],\n",
            "          [ 2.0971e-04,  3.7346e-02,  2.9470e-02]]]], device='cuda:0')\n",
            "NPF_C2.bias Parameter containing:\n",
            "tensor([ 0.0513,  0.1535, -0.0500, -0.0670, -0.0056,  0.0797,  0.1203,  0.1337,\n",
            "         0.0065, -0.0164, -0.0487,  0.0189,  0.1697, -0.1225, -0.0371, -0.0333,\n",
            "         0.3465,  0.0618, -0.0519,  0.0535,  0.0104,  0.1288, -0.1057, -0.0359,\n",
            "         0.0989, -0.0550,  0.1212, -0.3112, -0.0255,  0.0673, -0.0111, -0.0319,\n",
            "        -0.0385,  0.0808, -0.0369,  0.1016,  0.0967, -0.0092, -0.0390,  0.0191,\n",
            "         0.1409, -0.2105,  0.0366,  0.1235,  0.1686, -0.0280, -0.0220,  0.0293,\n",
            "         0.0387, -0.0150,  0.1441, -0.0105,  0.5572,  0.1637, -0.0016,  0.0868,\n",
            "         0.3200,  0.0243, -0.0474, -0.1277, -0.0394, -0.0703,  0.2334,  0.1057],\n",
            "       device='cuda:0')\n",
            "NPF_C3.weight Parameter containing:\n",
            "tensor([[[[ 0.0038, -0.0008,  0.0508],\n",
            "          [ 0.0168,  0.0423,  0.0392],\n",
            "          [ 0.0407, -0.0038,  0.0352]],\n",
            "\n",
            "         [[-0.0319, -0.0002, -0.0060],\n",
            "          [ 0.0047,  0.0075, -0.0131],\n",
            "          [-0.0096, -0.0327,  0.0157]],\n",
            "\n",
            "         [[-0.0192,  0.0251,  0.0009],\n",
            "          [-0.0218,  0.0263, -0.0248],\n",
            "          [ 0.0215,  0.0052,  0.0027]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0507, -0.0072,  0.0174],\n",
            "          [-0.0440, -0.0113, -0.0009],\n",
            "          [-0.0481,  0.0016, -0.0349]],\n",
            "\n",
            "         [[ 0.0293,  0.0314, -0.0086],\n",
            "          [ 0.0106,  0.0263,  0.0413],\n",
            "          [ 0.0470,  0.0267,  0.0330]],\n",
            "\n",
            "         [[ 0.0391,  0.0027,  0.0342],\n",
            "          [ 0.0122,  0.0629,  0.0038],\n",
            "          [ 0.0525,  0.0482, -0.0169]]],\n",
            "\n",
            "\n",
            "        [[[-0.0642, -0.0480, -0.0610],\n",
            "          [-0.0868, -0.0750, -0.0684],\n",
            "          [-0.0534, -0.0071, -0.0138]],\n",
            "\n",
            "         [[-0.0403, -0.0365, -0.0642],\n",
            "          [-0.0269, -0.0226, -0.0300],\n",
            "          [-0.0122,  0.0104, -0.0338]],\n",
            "\n",
            "         [[-0.0157, -0.0203, -0.0651],\n",
            "          [-0.0421, -0.0165, -0.0508],\n",
            "          [-0.0243, -0.0468, -0.0066]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0010, -0.0435, -0.0458],\n",
            "          [-0.0358, -0.0759, -0.0710],\n",
            "          [-0.0241, -0.0372, -0.0103]],\n",
            "\n",
            "         [[ 0.0449,  0.0889,  0.0706],\n",
            "          [ 0.0257,  0.0189, -0.0361],\n",
            "          [-0.0170, -0.0326,  0.0117]],\n",
            "\n",
            "         [[ 0.0339,  0.0005, -0.0232],\n",
            "          [ 0.0145,  0.0238,  0.0163],\n",
            "          [ 0.0018,  0.0273,  0.0014]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0264,  0.0414,  0.0268],\n",
            "          [ 0.0384, -0.0001, -0.0064],\n",
            "          [ 0.0162,  0.0620,  0.0486]],\n",
            "\n",
            "         [[ 0.0519,  0.0159,  0.0168],\n",
            "          [-0.0063,  0.0371,  0.0379],\n",
            "          [ 0.0150,  0.0194, -0.0243]],\n",
            "\n",
            "         [[ 0.0107,  0.0371,  0.0363],\n",
            "          [ 0.0200,  0.0336, -0.0259],\n",
            "          [ 0.0596, -0.0240, -0.0362]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0026,  0.0085, -0.0062],\n",
            "          [-0.0016,  0.0411, -0.0315],\n",
            "          [ 0.0523, -0.0075, -0.0178]],\n",
            "\n",
            "         [[-0.0539,  0.0013, -0.0077],\n",
            "          [ 0.0119, -0.0064, -0.0017],\n",
            "          [-0.0195, -0.0388, -0.0058]],\n",
            "\n",
            "         [[ 0.0243,  0.0161,  0.0141],\n",
            "          [ 0.0409, -0.0236,  0.0061],\n",
            "          [ 0.0045,  0.0162,  0.0014]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.0316, -0.0288, -0.0363],\n",
            "          [-0.0521, -0.0665, -0.0617],\n",
            "          [ 0.0208, -0.0204, -0.0576]],\n",
            "\n",
            "         [[-0.0295, -0.0019, -0.0506],\n",
            "          [-0.0202,  0.0010,  0.0053],\n",
            "          [-0.0107, -0.0131, -0.0208]],\n",
            "\n",
            "         [[-0.0193,  0.0100,  0.0283],\n",
            "          [-0.0555,  0.0251,  0.0402],\n",
            "          [-0.0535, -0.0299,  0.0371]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0043,  0.0103, -0.0006],\n",
            "          [ 0.0112, -0.0071,  0.0060],\n",
            "          [ 0.0075, -0.0386, -0.0151]],\n",
            "\n",
            "         [[ 0.0724,  0.0413,  0.0597],\n",
            "          [-0.0003, -0.0045, -0.0417],\n",
            "          [ 0.0045, -0.0164, -0.0140]],\n",
            "\n",
            "         [[ 0.0206, -0.0335, -0.0177],\n",
            "          [ 0.0250,  0.0098, -0.0381],\n",
            "          [-0.0305,  0.0383,  0.0066]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0435, -0.0119, -0.0281],\n",
            "          [ 0.0087, -0.0417, -0.0329],\n",
            "          [ 0.0158,  0.0215, -0.0297]],\n",
            "\n",
            "         [[-0.0333,  0.0367,  0.0243],\n",
            "          [-0.0221,  0.0039, -0.0113],\n",
            "          [-0.0013, -0.0327, -0.0056]],\n",
            "\n",
            "         [[-0.0412, -0.0220, -0.0129],\n",
            "          [-0.0039,  0.0199,  0.0363],\n",
            "          [ 0.0029, -0.0168,  0.0290]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0297,  0.0179,  0.0060],\n",
            "          [ 0.0306,  0.0010,  0.0305],\n",
            "          [ 0.0147,  0.0211, -0.0027]],\n",
            "\n",
            "         [[-0.0247, -0.0284, -0.0333],\n",
            "          [ 0.0013,  0.0187, -0.0341],\n",
            "          [ 0.0102, -0.0037, -0.0029]],\n",
            "\n",
            "         [[ 0.0431, -0.0087, -0.0194],\n",
            "          [ 0.0117, -0.0048, -0.0355],\n",
            "          [-0.0075,  0.0331,  0.0027]]],\n",
            "\n",
            "\n",
            "        [[[-0.0352,  0.0125,  0.0424],\n",
            "          [ 0.0268,  0.0453,  0.0072],\n",
            "          [-0.0214, -0.0282, -0.0308]],\n",
            "\n",
            "         [[ 0.0434, -0.0404, -0.0251],\n",
            "          [-0.0013, -0.0089,  0.0359],\n",
            "          [ 0.0265,  0.0263, -0.0254]],\n",
            "\n",
            "         [[ 0.0338,  0.0337,  0.0316],\n",
            "          [ 0.0104,  0.0468,  0.0248],\n",
            "          [-0.0093, -0.0360,  0.0327]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0104, -0.0166,  0.0110],\n",
            "          [-0.0195,  0.0175, -0.0340],\n",
            "          [-0.0409,  0.0113,  0.0176]],\n",
            "\n",
            "         [[-0.0230, -0.0244, -0.0029],\n",
            "          [ 0.0283,  0.0362,  0.0301],\n",
            "          [-0.0107, -0.0198,  0.0206]],\n",
            "\n",
            "         [[ 0.0071,  0.0315, -0.0397],\n",
            "          [-0.0112,  0.0164, -0.0011],\n",
            "          [ 0.0258, -0.0162,  0.0020]]]], device='cuda:0')\n",
            "NPF_C3.bias Parameter containing:\n",
            "tensor([-3.4846e-02,  8.7000e-02,  1.2875e-03,  1.0487e-01,  6.1114e-02,\n",
            "         9.1184e-03, -2.5402e-02,  2.4087e-02, -1.6373e-02, -1.4174e-01,\n",
            "         2.0500e-02, -4.9308e-02, -1.5768e-02, -4.8209e-02, -6.1082e-02,\n",
            "         2.6656e-01, -1.9494e-02, -2.5979e-02,  3.3295e-03,  8.3524e-02,\n",
            "        -7.2036e-03,  2.7407e-02, -4.9092e-02,  1.9464e-02, -6.8575e-03,\n",
            "        -6.2067e-03,  4.8491e-02,  2.2992e-02, -5.5147e-02, -7.2407e-03,\n",
            "        -3.9937e-02,  2.6763e-02,  5.1784e-02, -4.0574e-02, -1.2482e-02,\n",
            "        -1.8976e-02,  8.0504e-02,  7.1739e-02, -6.8780e-02, -8.4659e-02,\n",
            "        -3.1103e-02,  6.8865e-03,  1.4577e-01, -1.3227e-02,  3.8724e-02,\n",
            "         1.6883e-01,  3.4541e-03, -3.4003e-02,  7.6403e-02,  1.5786e-01,\n",
            "        -3.8834e-02, -6.2189e-03, -1.6126e-01, -9.8288e-03, -3.7811e-02,\n",
            "        -3.9008e-02, -1.7036e-01, -3.9662e-02,  4.8990e-02,  2.5706e-02,\n",
            "        -9.7746e-02,  2.1794e-02,  1.0118e-01,  7.2068e-02,  6.1512e-02,\n",
            "         9.0474e-02,  1.0820e-01,  8.5050e-02, -3.7102e-02, -2.2940e-02,\n",
            "        -2.1355e-02,  3.2596e-02,  7.5985e-02, -3.4479e-02,  1.2275e-03,\n",
            "         5.2317e-03, -1.0651e-02, -1.0496e-02, -7.2905e-02,  5.7056e-02,\n",
            "         2.7545e-02,  2.1627e-02, -6.5842e-02,  3.8661e-02, -3.6719e-02,\n",
            "         9.4928e-02,  9.9031e-02,  2.0302e-02,  6.7619e-02,  8.0499e-03,\n",
            "        -1.8535e-02,  2.5151e-02,  2.0655e-02,  4.6369e-02,  5.3830e-02,\n",
            "        -1.6531e-02, -4.0587e-02,  9.9635e-02,  1.3885e-02,  1.6713e-01,\n",
            "        -2.6902e-02, -7.2300e-02,  2.9541e-02,  1.7817e-01,  3.9239e-02,\n",
            "        -4.9265e-02,  1.0279e-01,  2.0496e-01,  8.9500e-03,  5.0590e-02,\n",
            "        -3.2406e-02, -1.9809e-02,  1.4841e-03,  5.7404e-02,  3.7612e-02,\n",
            "         1.4807e-05,  4.8456e-02,  1.8840e-02,  1.5774e-01, -3.7525e-03,\n",
            "         2.1047e-01,  3.0878e-02, -5.3492e-02,  1.3687e-01, -2.7422e-02,\n",
            "        -2.6537e-02, -3.0793e-02, -3.1854e-02], device='cuda:0')\n",
            "NPF_C4.weight Parameter containing:\n",
            "tensor([[[[ 0.0063, -0.0148, -0.0130],\n",
            "          [ 0.0212, -0.0012, -0.0180],\n",
            "          [ 0.0028, -0.0088, -0.0351]],\n",
            "\n",
            "         [[-0.0722, -0.0543, -0.0475],\n",
            "          [-0.0847, -0.0972, -0.0528],\n",
            "          [-0.0687, -0.0514, -0.0130]],\n",
            "\n",
            "         [[ 0.0420,  0.0182,  0.0171],\n",
            "          [-0.0090, -0.0116,  0.0199],\n",
            "          [ 0.0050, -0.0255, -0.0031]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0482, -0.0613, -0.0080],\n",
            "          [-0.0435, -0.0555, -0.0807],\n",
            "          [-0.0389, -0.0641, -0.0621]],\n",
            "\n",
            "         [[-0.0423, -0.0102, -0.0246],\n",
            "          [-0.0322, -0.0291,  0.0018],\n",
            "          [-0.0208,  0.0125, -0.0127]],\n",
            "\n",
            "         [[ 0.0155,  0.0236,  0.0291],\n",
            "          [ 0.0292,  0.0259,  0.0031],\n",
            "          [ 0.0021,  0.0204, -0.0319]]],\n",
            "\n",
            "\n",
            "        [[[-0.0068,  0.0043, -0.0148],\n",
            "          [-0.0023,  0.0313, -0.0076],\n",
            "          [-0.0079,  0.0234, -0.0130]],\n",
            "\n",
            "         [[-0.0197, -0.0332, -0.0155],\n",
            "          [-0.0314, -0.0398, -0.0526],\n",
            "          [-0.0179, -0.0310, -0.0265]],\n",
            "\n",
            "         [[ 0.0088,  0.0193, -0.0098],\n",
            "          [ 0.0213,  0.0135, -0.0216],\n",
            "          [ 0.0005,  0.0218,  0.0197]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0148, -0.0429, -0.0013],\n",
            "          [-0.0445, -0.0561, -0.0304],\n",
            "          [-0.0147, -0.0222, -0.0531]],\n",
            "\n",
            "         [[-0.0220, -0.0242, -0.0159],\n",
            "          [-0.0262,  0.0134, -0.0128],\n",
            "          [ 0.0149,  0.0200,  0.0043]],\n",
            "\n",
            "         [[ 0.0038, -0.0018, -0.0204],\n",
            "          [-0.0195, -0.0262,  0.0148],\n",
            "          [-0.0184,  0.0227, -0.0212]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0129,  0.0145, -0.0318],\n",
            "          [ 0.0058, -0.0124,  0.0231],\n",
            "          [-0.0173, -0.0126,  0.0170]],\n",
            "\n",
            "         [[ 0.0217,  0.0168,  0.0398],\n",
            "          [ 0.0198, -0.0134,  0.0239],\n",
            "          [-0.0192,  0.0274,  0.0036]],\n",
            "\n",
            "         [[-0.0273, -0.0141, -0.0011],\n",
            "          [ 0.0224,  0.0268, -0.0097],\n",
            "          [-0.0217,  0.0116, -0.0073]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0183, -0.0021,  0.0091],\n",
            "          [-0.0204, -0.0149,  0.0266],\n",
            "          [-0.0062,  0.0156,  0.0228]],\n",
            "\n",
            "         [[-0.0140,  0.0026, -0.0243],\n",
            "          [-0.0010, -0.0038, -0.0138],\n",
            "          [-0.0115, -0.0283,  0.0284]],\n",
            "\n",
            "         [[ 0.0069, -0.0302,  0.0189],\n",
            "          [ 0.0189, -0.0256,  0.0199],\n",
            "          [-0.0164,  0.0134, -0.0080]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0106, -0.0144, -0.0298],\n",
            "          [ 0.0018,  0.0014, -0.0438],\n",
            "          [-0.0345,  0.0035,  0.0013]],\n",
            "\n",
            "         [[-0.0156, -0.0374,  0.0241],\n",
            "          [-0.0127,  0.0293,  0.0346],\n",
            "          [ 0.0122,  0.0374,  0.0060]],\n",
            "\n",
            "         [[-0.0175, -0.0196,  0.0007],\n",
            "          [-0.0062, -0.0320, -0.0274],\n",
            "          [-0.0152,  0.0031, -0.0131]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0089,  0.0060,  0.0193],\n",
            "          [-0.0054,  0.0373,  0.0264],\n",
            "          [ 0.0198,  0.0370,  0.0314]],\n",
            "\n",
            "         [[ 0.0157,  0.0315,  0.0184],\n",
            "          [ 0.0208,  0.0270, -0.0044],\n",
            "          [-0.0101,  0.0137, -0.0322]],\n",
            "\n",
            "         [[-0.0140,  0.0098,  0.0052],\n",
            "          [-0.0103, -0.0058,  0.0143],\n",
            "          [-0.0018, -0.0211,  0.0313]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0465,  0.0063,  0.0023],\n",
            "          [ 0.0443,  0.0386, -0.0153],\n",
            "          [ 0.0343,  0.0270, -0.0005]],\n",
            "\n",
            "         [[-0.0187, -0.0725, -0.0504],\n",
            "          [-0.0369, -0.0830, -0.0373],\n",
            "          [-0.0329, -0.0646, -0.0497]],\n",
            "\n",
            "         [[ 0.0274, -0.0050, -0.0347],\n",
            "          [ 0.0060,  0.0183,  0.0176],\n",
            "          [-0.0101,  0.0096, -0.0086]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0450, -0.0410, -0.0585],\n",
            "          [-0.0579, -0.0172, -0.0219],\n",
            "          [-0.0122, -0.0703, -0.0188]],\n",
            "\n",
            "         [[-0.0137,  0.0158,  0.0351],\n",
            "          [ 0.0214,  0.0099, -0.0159],\n",
            "          [-0.0013, -0.0071, -0.0230]],\n",
            "\n",
            "         [[ 0.0018, -0.0108, -0.0035],\n",
            "          [-0.0131, -0.0126, -0.0175],\n",
            "          [ 0.0178,  0.0218,  0.0205]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0196,  0.0130,  0.0085],\n",
            "          [-0.0094,  0.0191, -0.0256],\n",
            "          [ 0.0140,  0.0177, -0.0193]],\n",
            "\n",
            "         [[ 0.0061,  0.0086, -0.0433],\n",
            "          [-0.0181, -0.0306, -0.0008],\n",
            "          [-0.0101, -0.0173, -0.0079]],\n",
            "\n",
            "         [[ 0.0179,  0.0190, -0.0217],\n",
            "          [-0.0171,  0.0095,  0.0158],\n",
            "          [ 0.0091, -0.0212, -0.0051]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0281, -0.0009,  0.0011],\n",
            "          [-0.0098, -0.0089, -0.0246],\n",
            "          [ 0.0117,  0.0045, -0.0149]],\n",
            "\n",
            "         [[ 0.0072,  0.0080,  0.0079],\n",
            "          [-0.0187,  0.0110,  0.0170],\n",
            "          [-0.0276, -0.0231,  0.0197]],\n",
            "\n",
            "         [[ 0.0241,  0.0112,  0.0028],\n",
            "          [ 0.0185, -0.0046, -0.0206],\n",
            "          [-0.0146,  0.0094, -0.0102]]]], device='cuda:0')\n",
            "NPF_C4.bias Parameter containing:\n",
            "tensor([-1.4048e-01,  9.6191e-02, -4.3294e-02,  4.7014e-02, -3.4280e-02,\n",
            "        -2.8041e-02,  5.6957e-07,  2.8087e-02,  8.3634e-02, -1.8796e-02,\n",
            "        -4.9327e-02, -2.1622e-03, -3.7975e-02, -3.7822e-02,  6.0118e-02,\n",
            "         1.0793e-02, -1.1519e-02,  4.3799e-02, -1.2171e-03, -7.3191e-02,\n",
            "         5.1215e-02, -5.1821e-03,  7.8735e-02,  3.9522e-02, -5.1520e-02,\n",
            "         8.4217e-02,  9.3058e-03,  4.5134e-02, -1.4854e-02,  8.7456e-02,\n",
            "        -9.0380e-04,  2.0084e-02, -6.6906e-02, -3.9386e-02,  3.4063e-02,\n",
            "        -5.4559e-02, -4.4674e-02, -2.1013e-02, -4.3287e-02,  2.2981e-03,\n",
            "        -4.9960e-02,  9.4194e-02,  1.5854e-02,  8.3217e-02, -2.8836e-02,\n",
            "         2.5868e-02,  9.3305e-02, -9.8918e-02,  1.4203e-02, -3.8131e-02,\n",
            "        -5.2342e-02,  1.1077e-01, -2.8311e-02,  1.1419e-01, -4.8486e-02,\n",
            "        -1.5246e-02,  9.6932e-02, -1.8698e-02, -2.1852e-02,  2.9802e-02,\n",
            "        -3.2811e-02, -1.3624e-02,  2.2592e-02,  9.4108e-04,  1.0353e-01,\n",
            "         2.8279e-02,  4.7596e-03, -1.4128e-02, -1.8498e-02,  8.6116e-03,\n",
            "         6.0759e-02, -6.2951e-02,  2.3466e-02, -4.2819e-02, -6.6455e-02,\n",
            "         8.2387e-03, -7.6491e-02, -3.2411e-02, -3.5737e-02,  1.1969e-01,\n",
            "        -7.3236e-03,  7.2396e-02,  1.1388e-02, -3.2076e-02,  4.7530e-02,\n",
            "        -8.0964e-03,  2.0620e-02,  5.2809e-03, -1.4564e-02, -2.1585e-02,\n",
            "        -2.5384e-05,  1.1295e-01,  6.8178e-02,  4.8905e-02, -2.4907e-04,\n",
            "         8.9701e-02, -5.7080e-02, -2.1874e-02, -6.6997e-02, -1.9928e-02,\n",
            "         6.2555e-02, -2.7426e-02,  3.1241e-02, -5.5984e-02, -4.2995e-02,\n",
            "        -8.7601e-02,  2.7590e-02,  1.4413e-02,  4.1093e-02,  2.8078e-02,\n",
            "         9.1632e-02,  6.6610e-02,  2.3909e-02,  2.0334e-01,  2.4000e-03,\n",
            "        -6.1719e-02,  9.3815e-03, -4.2662e-02,  3.7205e-02,  1.5065e-03,\n",
            "        -6.7008e-02,  2.2681e-02,  7.1174e-02,  3.4144e-02,  8.1765e-02,\n",
            "        -9.4480e-02,  3.7726e-02,  2.1621e-02], device='cuda:0')\n",
            "NPF_D1.weight Parameter containing:\n",
            "tensor([[ 6.7449e-03,  6.1731e-03,  4.8530e-03,  ...,  5.2381e-04,\n",
            "          1.1130e-03, -1.6672e-03],\n",
            "        [ 4.8801e-03,  1.5872e-03, -7.7500e-04,  ...,  9.6313e-04,\n",
            "          8.4391e-04, -2.7619e-03],\n",
            "        [-3.7731e-03,  1.0738e-03,  2.6014e-03,  ..., -2.3517e-03,\n",
            "          9.1521e-04,  1.2799e-03],\n",
            "        ...,\n",
            "        [ 1.4176e-03, -1.1536e-03, -2.7435e-03,  ..., -2.3350e-03,\n",
            "          1.4809e-03,  2.4409e-05],\n",
            "        [-6.1190e-03, -6.0081e-03, -5.5994e-03,  ..., -6.2548e-07,\n",
            "         -1.5353e-03, -2.5109e-03],\n",
            "        [-1.5325e-03, -6.8287e-04,  2.9356e-03,  ...,  1.5325e-03,\n",
            "          1.2744e-03, -9.9538e-04]], device='cuda:0')\n",
            "NPF_D1.bias Parameter containing:\n",
            "tensor([-3.0915e-03,  7.0009e-03,  7.0303e-03,  9.4845e-03,  3.9633e-03,\n",
            "        -8.0749e-03, -4.1135e-03, -1.5254e-02, -1.6902e-03, -1.5214e-03,\n",
            "        -2.5312e-03, -3.9826e-03, -9.4153e-03, -1.5733e-02,  1.6684e-02,\n",
            "         1.0345e-02,  1.4854e-02,  7.1318e-03,  1.2992e-03, -2.2155e-04,\n",
            "        -6.1878e-03, -1.2607e-02, -1.1307e-02, -1.6547e-03, -1.7876e-04,\n",
            "        -8.0982e-06,  5.5304e-03,  2.2679e-02, -3.1908e-03, -9.7886e-04,\n",
            "         1.2088e-02,  1.8609e-03, -7.1207e-04, -4.5546e-03,  1.2510e-02,\n",
            "        -8.4185e-03, -6.0673e-03,  5.6303e-03,  5.9940e-03, -2.9022e-03,\n",
            "         2.9085e-03, -2.8603e-03, -1.3797e-02,  3.1808e-03,  1.4519e-03,\n",
            "        -1.7068e-03, -9.5413e-03, -1.0355e-04, -2.6459e-03, -1.9908e-03,\n",
            "         7.3725e-04, -6.0261e-03, -4.3008e-03, -9.9383e-04, -7.2133e-03,\n",
            "        -2.5354e-03,  1.9866e-03,  3.3992e-04, -5.7449e-04, -5.9058e-03,\n",
            "        -1.4717e-02, -6.0643e-03,  6.5032e-03,  2.0901e-03,  1.0524e-03,\n",
            "        -1.3056e-03, -4.3813e-03,  3.7003e-04,  9.1302e-04,  8.5404e-03,\n",
            "         8.4802e-04,  3.6423e-03,  1.3719e-03,  1.0192e-03, -1.0547e-03,\n",
            "         1.9940e-03, -2.0427e-03, -4.6941e-03, -4.7571e-04,  7.4905e-03,\n",
            "         4.6411e-03, -3.6499e-03, -4.2417e-03, -2.1899e-03,  2.5620e-03,\n",
            "        -1.0117e-03,  3.5433e-03, -5.3203e-03,  2.0155e-03,  4.5279e-04,\n",
            "        -5.1749e-03, -3.8822e-04,  2.0121e-03, -6.2089e-03,  7.4697e-03,\n",
            "        -1.1007e-02,  2.6627e-03, -4.4507e-04,  3.8131e-03, -1.0979e-03,\n",
            "         9.0132e-03,  3.4430e-03,  1.4222e-02, -2.1734e-03, -6.0811e-04,\n",
            "         8.9175e-03, -8.1742e-05,  1.3188e-02,  9.4976e-03,  1.8648e-02,\n",
            "         2.4595e-03, -2.2414e-04,  3.4034e-03,  1.4558e-02, -2.9319e-03,\n",
            "         5.2252e-03, -5.6529e-03,  2.2380e-03,  2.5314e-03,  8.5799e-03,\n",
            "         1.5914e-02, -2.3840e-03, -6.1985e-03,  1.2094e-02,  9.2096e-03,\n",
            "         3.2088e-04, -3.1514e-03,  9.6105e-03, -1.3118e-03,  1.1295e-03,\n",
            "        -1.0864e-02, -2.8191e-03,  2.6089e-03, -1.2218e-02,  8.0490e-03,\n",
            "         1.5359e-02, -8.2282e-03, -8.2814e-03,  3.4456e-03, -4.3062e-03,\n",
            "        -7.8290e-03,  6.8536e-03, -7.2861e-04, -6.5191e-03, -1.5222e-02,\n",
            "         7.8873e-03,  5.2406e-03,  7.9274e-04, -1.0236e-03, -5.6191e-03,\n",
            "        -6.3615e-03,  5.0162e-03, -4.6353e-03, -3.7864e-03, -3.6407e-03,\n",
            "        -1.6264e-03,  2.7726e-03,  9.7290e-03,  4.7300e-03, -1.4370e-03,\n",
            "         1.1758e-02, -8.0294e-04, -9.2608e-03, -1.1416e-02,  6.8734e-03,\n",
            "        -6.0536e-04, -5.8020e-04, -9.7040e-04,  6.8940e-03,  8.8368e-03,\n",
            "         4.7202e-04,  3.7066e-03,  1.3898e-02,  7.7289e-03, -1.1926e-03,\n",
            "        -7.5731e-03, -5.4208e-03,  1.9885e-02, -7.6324e-04,  3.6520e-04,\n",
            "         9.6962e-03,  9.7695e-03,  3.0466e-02, -3.7861e-03,  2.5986e-03,\n",
            "         4.6441e-03, -8.5641e-03, -4.5385e-03, -4.6865e-04,  9.4331e-03,\n",
            "        -3.7152e-03,  9.2867e-03,  1.5283e-02,  7.1120e-03, -6.8776e-03,\n",
            "        -2.0699e-03,  4.9396e-03, -1.2593e-03,  1.0136e-02,  4.4243e-04,\n",
            "        -1.6393e-03,  4.4133e-03, -4.9833e-05,  6.4461e-04,  5.5527e-03,\n",
            "         7.7580e-03,  1.5224e-03,  2.0735e-03,  5.4495e-03, -2.0216e-03,\n",
            "         1.9098e-04, -4.2264e-03,  9.5848e-04,  2.8455e-03,  3.1706e-03,\n",
            "        -9.1583e-04,  1.2265e-02, -1.6689e-02,  1.8296e-02, -8.3061e-04,\n",
            "         6.4869e-03,  3.4647e-03,  1.8250e-02, -1.0599e-02,  1.3780e-02,\n",
            "         2.2303e-03, -7.3938e-03, -2.8179e-03, -5.7437e-04,  1.1052e-03,\n",
            "        -1.5825e-03,  1.1565e-03,  9.9466e-04,  5.1443e-03, -2.4445e-03,\n",
            "         1.0103e-03, -3.2024e-04,  1.7139e-02, -3.1749e-03,  2.4549e-03,\n",
            "        -2.5718e-03,  6.0574e-03,  1.8967e-02,  1.4457e-02,  9.4804e-03,\n",
            "         1.6462e-03, -1.1233e-03,  2.6835e-02, -1.6480e-03,  4.4640e-04,\n",
            "        -1.0330e-03,  7.6867e-03,  1.4860e-02,  2.0030e-02,  1.3012e-02,\n",
            "         7.9192e-03], device='cuda:0')\n",
            "NPF_D2.weight Parameter containing:\n",
            "tensor([[-0.0465, -0.0347,  0.0314,  ...,  0.0773, -0.0112, -0.0381],\n",
            "        [-0.0333,  0.0111,  0.0345,  ...,  0.0514, -0.0576, -0.0164],\n",
            "        [-0.0381,  0.0283,  0.0575,  ...,  0.0580, -0.0330,  0.0078],\n",
            "        ...,\n",
            "        [-0.0491,  0.0670, -0.0389,  ..., -0.0117,  0.0869,  0.0140],\n",
            "        [ 0.0139, -0.0937,  0.0108,  ..., -0.0434,  0.0237,  0.0219],\n",
            "        [ 0.0571, -0.0282, -0.0208,  ...,  0.0279,  0.0637, -0.0374]],\n",
            "       device='cuda:0')\n",
            "NPF_D2.bias Parameter containing:\n",
            "tensor([ 4.5473e-02, -5.7139e-02, -2.9093e-02, -5.0247e-02,  4.2335e-02,\n",
            "        -1.6718e-02, -3.5878e-02, -5.3695e-02,  5.6157e-02,  6.6721e-03,\n",
            "         1.5898e-03,  4.6791e-02, -8.6835e-03, -1.6502e-02,  2.0300e-02,\n",
            "        -4.3535e-02, -6.2531e-02,  5.2724e-02,  5.7026e-02, -1.3874e-03,\n",
            "         8.2331e-02, -1.0039e-02,  1.1745e-02, -4.9126e-02,  5.2308e-02,\n",
            "         3.6910e-02,  7.4297e-02, -2.7946e-03,  8.7575e-03, -3.1718e-02,\n",
            "         3.4552e-02,  3.5587e-02,  3.7751e-03, -1.8720e-02, -3.5325e-02,\n",
            "         7.8075e-02,  5.1705e-02, -3.1460e-02, -7.0226e-02, -5.3672e-02,\n",
            "        -9.0174e-03, -3.1423e-02,  6.3338e-02, -2.4389e-02,  4.9373e-02,\n",
            "        -3.7016e-02, -2.5443e-02, -2.5748e-02, -2.5363e-02,  1.1471e-02,\n",
            "        -2.7745e-02, -5.0331e-02, -3.5288e-02, -1.3219e-02, -5.2088e-02,\n",
            "         4.3271e-02,  7.4937e-05, -3.7170e-02, -2.3296e-03,  2.6841e-02,\n",
            "        -3.8704e-02, -2.1582e-02, -2.0754e-02, -8.7166e-03,  6.7588e-02,\n",
            "        -2.6501e-02,  1.0619e-02, -1.2561e-02,  2.6602e-02,  1.9597e-02,\n",
            "        -4.0196e-02,  4.0825e-02,  2.7750e-02, -1.3544e-03,  5.5286e-02,\n",
            "         4.2390e-02, -2.6353e-02,  1.6179e-02,  5.2938e-02, -1.0193e-02,\n",
            "         5.1481e-03, -1.8962e-02,  4.9291e-02,  1.4843e-03, -3.9726e-03,\n",
            "        -2.8083e-02, -3.1004e-02,  1.0442e-02, -9.6342e-03, -2.7878e-02,\n",
            "         5.1296e-02,  4.2423e-02, -1.4784e-02,  2.2083e-02, -8.6445e-03,\n",
            "         1.1230e-02, -3.2027e-02,  1.0807e-01,  4.6524e-02, -8.4898e-02,\n",
            "         1.0180e-02,  2.1943e-02,  5.3770e-02,  5.0490e-02,  3.0643e-02,\n",
            "        -2.5971e-02,  1.2850e-04, -8.4604e-03, -2.3737e-02, -1.7258e-02,\n",
            "         1.1791e-03,  7.1117e-02,  6.3593e-02,  4.5163e-02,  2.8635e-02,\n",
            "        -4.7197e-02, -1.7831e-02, -6.6808e-02, -4.1405e-02,  1.3712e-02,\n",
            "         3.1863e-02, -2.3927e-02, -1.7907e-02, -1.4008e-03,  3.0950e-02,\n",
            "        -4.0003e-02, -3.4667e-02, -1.2824e-02, -6.7120e-03,  1.0405e-03,\n",
            "         6.6542e-02, -1.6147e-02, -2.3056e-02,  8.2906e-02,  6.0791e-02,\n",
            "         3.9900e-03,  2.8331e-02, -6.1703e-02,  3.5911e-02, -2.4963e-02,\n",
            "        -2.1127e-02, -1.4459e-02,  2.7395e-02,  8.6956e-02,  3.6084e-02,\n",
            "         3.7619e-02,  5.2293e-02, -8.2965e-03,  3.0467e-02, -9.0976e-03,\n",
            "         8.5941e-02, -1.6776e-03,  3.0691e-02, -3.5836e-02,  2.5440e-02,\n",
            "         2.4193e-02,  3.9853e-03,  5.6605e-02,  1.5860e-02, -5.1976e-03,\n",
            "        -1.7930e-02,  1.6676e-02, -6.3776e-02,  1.4769e-02,  3.3682e-02,\n",
            "         2.9574e-03, -5.8169e-03,  7.5095e-02,  6.5779e-03, -2.3813e-02,\n",
            "         5.5482e-02,  2.2832e-02, -4.1213e-02,  3.0200e-02,  1.2985e-02,\n",
            "         4.7857e-02, -5.1859e-02,  1.3278e-02,  3.2736e-03, -4.3618e-02,\n",
            "         5.3195e-02, -5.4649e-02, -2.5899e-02,  5.7355e-02,  1.0069e-02,\n",
            "        -4.9136e-02,  3.9379e-02,  5.6972e-02,  2.8310e-03, -4.5423e-02,\n",
            "        -1.5912e-02,  6.0484e-02,  6.7017e-02, -3.5506e-02,  6.4443e-02,\n",
            "        -4.9948e-02,  8.2845e-02, -1.5741e-02,  1.8897e-02, -1.6098e-02,\n",
            "         5.1434e-02,  1.1333e-02, -3.9169e-02, -2.8337e-02,  4.5283e-02,\n",
            "        -3.2605e-02,  3.3899e-02,  6.8907e-03, -4.5377e-04,  2.1536e-02,\n",
            "         5.2908e-02,  6.3469e-02,  8.1366e-04, -3.6495e-02, -1.7760e-02,\n",
            "        -3.5620e-02,  9.1117e-02,  5.6486e-02, -3.0464e-02, -5.3003e-02,\n",
            "         1.4814e-03,  6.2014e-03,  1.9019e-02,  1.3726e-02, -4.6079e-02,\n",
            "         7.0234e-02, -5.0221e-02,  2.5273e-03, -3.1132e-02,  5.5686e-02,\n",
            "         4.1419e-02,  1.6330e-02,  9.7150e-02, -3.1393e-02,  6.4006e-02,\n",
            "        -7.0758e-02,  7.9557e-02, -6.7301e-02,  7.4336e-02,  5.2423e-02,\n",
            "         1.1303e-02, -4.0421e-02,  3.0251e-03,  5.1646e-02, -2.3781e-02,\n",
            "         2.1432e-02, -5.9478e-02,  1.5478e-02,  1.1718e-02,  5.7684e-03,\n",
            "         1.2809e-02,  4.3602e-03, -7.0166e-02,  4.7890e-02,  1.3361e-02,\n",
            "         4.9955e-02], device='cuda:0')\n",
            "NPV_C1.weight Parameter containing:\n",
            "tensor([[[[ 0.1778,  0.0128,  0.1679],\n",
            "          [-0.0871, -0.1735, -0.0433],\n",
            "          [-0.0195,  0.0608, -0.1079]],\n",
            "\n",
            "         [[-0.0826, -0.0897,  0.1800],\n",
            "          [-0.1181, -0.1640,  0.0918],\n",
            "          [-0.1492,  0.1673, -0.1072]],\n",
            "\n",
            "         [[-0.0698, -0.1231, -0.0780],\n",
            "          [ 0.0232, -0.0379, -0.0385],\n",
            "          [ 0.1519,  0.1188,  0.1498]]],\n",
            "\n",
            "\n",
            "        [[[-0.1239, -0.1314,  0.0775],\n",
            "          [ 0.0793,  0.1594,  0.0667],\n",
            "          [-0.1275,  0.1172,  0.1679]],\n",
            "\n",
            "         [[ 0.1496, -0.0440,  0.1035],\n",
            "          [ 0.0496,  0.1330,  0.0733],\n",
            "          [-0.1677,  0.1277,  0.0782]],\n",
            "\n",
            "         [[-0.1844,  0.0888, -0.1897],\n",
            "          [ 0.1859,  0.1563,  0.1354],\n",
            "          [-0.1560,  0.0302,  0.1145]]],\n",
            "\n",
            "\n",
            "        [[[-0.0755,  0.1683, -0.0802],\n",
            "          [ 0.1646, -0.1100,  0.1108],\n",
            "          [-0.1372,  0.1356,  0.0436]],\n",
            "\n",
            "         [[ 0.0483,  0.0695,  0.0011],\n",
            "          [-0.0537,  0.0032,  0.0099],\n",
            "          [-0.1751,  0.1396,  0.0798]],\n",
            "\n",
            "         [[ 0.1276, -0.1281, -0.1407],\n",
            "          [-0.0343, -0.1246,  0.1191],\n",
            "          [-0.0369,  0.0600,  0.1135]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-0.1709,  0.0462, -0.0874],\n",
            "          [ 0.0194, -0.1724,  0.0801],\n",
            "          [ 0.1329,  0.0256, -0.0856]],\n",
            "\n",
            "         [[ 0.1324, -0.1483,  0.1294],\n",
            "          [-0.0217, -0.1403, -0.1847],\n",
            "          [ 0.1139, -0.0753,  0.1704]],\n",
            "\n",
            "         [[-0.0720,  0.0688, -0.1594],\n",
            "          [ 0.0313, -0.1448, -0.1330],\n",
            "          [ 0.0518, -0.1104, -0.1011]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0297, -0.0047,  0.0709],\n",
            "          [-0.0622,  0.1465,  0.0316],\n",
            "          [-0.1456,  0.0663,  0.0618]],\n",
            "\n",
            "         [[-0.1882,  0.1773,  0.0404],\n",
            "          [-0.0730, -0.0151,  0.0720],\n",
            "          [-0.1228,  0.0372,  0.1524]],\n",
            "\n",
            "         [[ 0.1381, -0.1638,  0.1076],\n",
            "          [-0.0546,  0.0096, -0.0260],\n",
            "          [-0.0630, -0.1412,  0.0218]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0878, -0.1757, -0.1502],\n",
            "          [-0.0040,  0.0181, -0.1694],\n",
            "          [ 0.1852,  0.1344, -0.0171]],\n",
            "\n",
            "         [[ 0.0315, -0.1702, -0.1189],\n",
            "          [ 0.1825,  0.1614,  0.0051],\n",
            "          [ 0.1454, -0.0247,  0.0436]],\n",
            "\n",
            "         [[ 0.0307, -0.1865,  0.1639],\n",
            "          [ 0.1157,  0.1322, -0.0506],\n",
            "          [ 0.1320, -0.0113,  0.0102]]]], device='cuda:0', requires_grad=True)\n",
            "NPV_C1.bias Parameter containing:\n",
            "tensor([ 0.1025, -0.0083, -0.0964, -0.0746, -0.0983,  0.0744, -0.0287,  0.0873,\n",
            "        -0.0460,  0.0152, -0.1420,  0.1827, -0.1745,  0.1445, -0.1512, -0.0782,\n",
            "         0.0478, -0.0083, -0.0562,  0.0911, -0.1249, -0.1091, -0.0632,  0.0404,\n",
            "        -0.1161, -0.0594, -0.1107, -0.1595,  0.0170,  0.1792,  0.0881, -0.0779,\n",
            "        -0.0314,  0.0856, -0.1635, -0.0265,  0.1080, -0.1921,  0.1459,  0.1893,\n",
            "         0.0377,  0.0118, -0.0407,  0.0047, -0.0617, -0.1267,  0.1191,  0.0042,\n",
            "        -0.0798, -0.0425, -0.1233,  0.1394,  0.1250,  0.0373, -0.0278, -0.0195,\n",
            "         0.0821, -0.0290,  0.0109, -0.1654,  0.1807,  0.0576,  0.0546,  0.0628],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_C2.weight Parameter containing:\n",
            "tensor([[[[-4.2847e-03, -2.5944e-02,  1.7309e-02],\n",
            "          [ 3.1451e-02, -2.8468e-02, -3.4692e-02],\n",
            "          [ 3.7695e-02,  1.6569e-02,  2.9985e-02]],\n",
            "\n",
            "         [[-3.3970e-02,  2.9210e-03, -6.4157e-03],\n",
            "          [ 1.5202e-02,  6.2889e-04, -9.9893e-03],\n",
            "          [ 3.8551e-02,  2.8838e-02,  2.2614e-02]],\n",
            "\n",
            "         [[ 3.5059e-02,  2.0806e-02,  2.1574e-02],\n",
            "          [-7.7338e-03,  4.9909e-03,  2.5451e-02],\n",
            "          [ 1.8523e-02, -1.8684e-02, -1.6201e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.9207e-03,  3.9204e-02,  2.5630e-02],\n",
            "          [-3.4301e-02, -3.6790e-02,  3.3343e-02],\n",
            "          [-2.8310e-02, -3.2224e-02, -3.7685e-02]],\n",
            "\n",
            "         [[-1.7877e-02, -2.1620e-02,  1.8730e-02],\n",
            "          [-4.7899e-03, -3.1127e-02,  3.0097e-02],\n",
            "          [-2.8483e-02,  7.4868e-03,  6.1965e-03]],\n",
            "\n",
            "         [[ 1.9177e-02,  5.4160e-04, -3.5774e-02],\n",
            "          [-3.5896e-03, -3.2238e-02,  3.3079e-03],\n",
            "          [-3.8442e-02, -1.6601e-02,  3.2488e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.1579e-02,  1.0569e-02, -3.6887e-02],\n",
            "          [ 2.3266e-02,  3.6505e-02,  2.0101e-02],\n",
            "          [-2.1082e-03, -3.1224e-02, -2.1953e-03]],\n",
            "\n",
            "         [[-1.5420e-02, -1.1610e-02, -3.5908e-02],\n",
            "          [ 3.0697e-02,  3.6306e-02, -1.6947e-02],\n",
            "          [ 2.3644e-02,  2.2924e-02, -2.7937e-03]],\n",
            "\n",
            "         [[-1.7372e-02, -2.1680e-02,  3.1856e-02],\n",
            "          [ 8.4491e-03, -3.9068e-02, -3.3231e-02],\n",
            "          [ 3.1711e-02,  3.0475e-02, -2.3376e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 3.9307e-02,  3.1646e-02,  1.3188e-02],\n",
            "          [ 4.1654e-02, -2.6984e-02, -2.0563e-02],\n",
            "          [ 2.7164e-02,  1.3820e-02, -9.9138e-03]],\n",
            "\n",
            "         [[-1.6821e-02, -1.3196e-03, -1.4809e-02],\n",
            "          [ 3.9117e-03,  2.7847e-02, -1.9583e-02],\n",
            "          [ 3.1420e-02,  1.1573e-02, -2.6286e-02]],\n",
            "\n",
            "         [[-1.4594e-02, -2.0139e-02, -2.8845e-02],\n",
            "          [-3.5173e-02, -1.8674e-02,  1.8092e-02],\n",
            "          [-3.0772e-02, -1.5892e-02, -1.1684e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 2.4749e-02,  2.9747e-02, -9.2798e-03],\n",
            "          [ 4.1196e-02, -3.7991e-03, -3.7688e-02],\n",
            "          [-2.5616e-02, -3.5090e-02, -3.7956e-02]],\n",
            "\n",
            "         [[ 2.9159e-02,  2.1464e-02,  1.8552e-02],\n",
            "          [-3.3053e-02,  3.2608e-04, -1.2081e-02],\n",
            "          [-7.0181e-04,  1.0089e-02, -3.0756e-02]],\n",
            "\n",
            "         [[-3.1744e-02, -2.3019e-03,  1.2704e-02],\n",
            "          [-1.8780e-02, -1.9896e-02,  3.4598e-02],\n",
            "          [ 3.9880e-02,  1.4410e-02, -2.3750e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.5554e-02,  3.0088e-02, -9.5614e-03],\n",
            "          [-1.1563e-02,  2.8307e-02, -1.1022e-02],\n",
            "          [ 1.1720e-02,  2.1658e-02,  6.4490e-03]],\n",
            "\n",
            "         [[ 3.3345e-02,  1.9256e-02,  1.6531e-02],\n",
            "          [ 1.5005e-02,  1.4388e-02, -7.0005e-03],\n",
            "          [ 2.5566e-02, -3.7483e-02,  3.8937e-03]],\n",
            "\n",
            "         [[ 3.0856e-02, -8.7513e-03, -5.9075e-03],\n",
            "          [-1.2645e-02, -2.2372e-02, -2.3732e-03],\n",
            "          [-4.0644e-02, -3.8491e-02,  2.4724e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-3.3697e-02,  1.7100e-02,  9.2399e-03],\n",
            "          [-3.6991e-02, -2.0131e-02, -7.1689e-03],\n",
            "          [ 1.8627e-02, -1.7871e-02, -5.1520e-03]],\n",
            "\n",
            "         [[ 2.4673e-02, -3.2488e-02, -1.8826e-02],\n",
            "          [-2.1127e-02, -2.5570e-03, -9.3398e-03],\n",
            "          [-8.3827e-03,  5.5756e-03, -3.5510e-02]],\n",
            "\n",
            "         [[ 3.4639e-02,  8.7137e-03,  3.9714e-02],\n",
            "          [ 1.1330e-02,  9.9257e-03, -3.4454e-02],\n",
            "          [-5.4924e-03,  3.1033e-02, -2.6759e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 1.3971e-02,  1.0340e-02, -3.7517e-02],\n",
            "          [-3.1490e-02, -2.1836e-02,  3.3404e-02],\n",
            "          [-2.3930e-02, -2.3191e-02,  2.7839e-02]],\n",
            "\n",
            "         [[-2.4203e-02, -2.4327e-02,  1.2756e-02],\n",
            "          [ 5.1063e-03,  3.1996e-02, -2.4713e-02],\n",
            "          [ 3.9713e-02, -2.1347e-03, -8.1387e-03]],\n",
            "\n",
            "         [[-2.5164e-02, -2.4884e-02,  2.9242e-02],\n",
            "          [-9.9620e-03, -3.3550e-02,  6.9603e-03],\n",
            "          [-3.6185e-02, -2.4977e-02,  1.9436e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 5.0232e-03, -5.5108e-03, -2.6284e-03],\n",
            "          [ 3.7679e-03, -4.3480e-03, -5.0074e-03],\n",
            "          [-1.0662e-02, -1.5837e-02, -3.7930e-02]],\n",
            "\n",
            "         [[ 1.8283e-02, -3.5601e-02, -2.1664e-02],\n",
            "          [-8.5333e-03,  3.7742e-02,  1.2427e-02],\n",
            "          [ 1.9758e-02, -2.2686e-02, -1.0595e-02]],\n",
            "\n",
            "         [[-9.2135e-03, -2.8669e-02,  3.3969e-02],\n",
            "          [ 4.0544e-02,  1.6163e-02,  2.3921e-02],\n",
            "          [ 1.2747e-02, -2.0006e-02, -1.1757e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 8.3061e-03, -1.5240e-02, -1.0007e-02],\n",
            "          [ 6.8923e-05,  2.2750e-02,  1.5417e-03],\n",
            "          [-1.7950e-02, -2.6767e-02,  1.3783e-02]],\n",
            "\n",
            "         [[-8.0728e-03,  2.1026e-02,  2.3278e-03],\n",
            "          [ 3.2780e-02,  2.6681e-02, -5.5565e-03],\n",
            "          [ 3.2027e-02, -2.7358e-02,  2.4779e-02]],\n",
            "\n",
            "         [[ 1.5621e-02,  2.0104e-02, -2.1971e-02],\n",
            "          [-3.8046e-02,  3.4253e-02,  2.0540e-02],\n",
            "          [-3.8861e-02,  3.2657e-02, -2.2493e-02]]],\n",
            "\n",
            "\n",
            "        [[[-4.6662e-03,  1.1725e-02, -1.7919e-02],\n",
            "          [-2.9003e-02, -2.7024e-02,  1.7578e-02],\n",
            "          [ 1.0437e-02, -2.3824e-02,  3.6631e-02]],\n",
            "\n",
            "         [[ 2.1332e-02,  1.9472e-02, -7.7526e-03],\n",
            "          [-2.7974e-02,  3.1200e-03, -3.3514e-02],\n",
            "          [ 4.5456e-04,  2.8574e-02, -1.2189e-02]],\n",
            "\n",
            "         [[ 1.0876e-02, -2.4448e-02, -3.8510e-02],\n",
            "          [ 1.9550e-03, -1.5318e-02,  1.5483e-02],\n",
            "          [-3.8008e-02,  8.4060e-03, -2.6048e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.1589e-02, -2.5658e-02, -2.9865e-02],\n",
            "          [-4.0270e-02,  1.3504e-02,  3.6314e-02],\n",
            "          [ 4.7979e-03,  2.2821e-02,  2.0056e-02]],\n",
            "\n",
            "         [[-7.0959e-03, -2.7958e-02,  2.4071e-02],\n",
            "          [-2.8099e-02, -3.3409e-03, -2.7384e-02],\n",
            "          [-4.0236e-02,  7.9574e-03,  1.1421e-02]],\n",
            "\n",
            "         [[ 1.6088e-02,  2.9062e-03, -1.6562e-02],\n",
            "          [ 3.6965e-02,  4.1430e-02, -1.3344e-02],\n",
            "          [ 1.3650e-02,  3.6135e-02,  3.0510e-02]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_C2.bias Parameter containing:\n",
            "tensor([ 0.0371, -0.0188,  0.0135, -0.0347,  0.0237,  0.0195, -0.0128, -0.0338,\n",
            "        -0.0105,  0.0409, -0.0199, -0.0057,  0.0080, -0.0293,  0.0009, -0.0412,\n",
            "         0.0205, -0.0277,  0.0171,  0.0274, -0.0277,  0.0220,  0.0224,  0.0317,\n",
            "        -0.0203,  0.0065,  0.0372,  0.0094, -0.0301,  0.0245, -0.0305,  0.0326,\n",
            "        -0.0116, -0.0233,  0.0176, -0.0395,  0.0234, -0.0326,  0.0139,  0.0403,\n",
            "        -0.0343, -0.0196, -0.0072,  0.0345, -0.0182,  0.0005,  0.0403,  0.0282,\n",
            "         0.0254, -0.0009, -0.0355,  0.0058, -0.0096,  0.0241,  0.0405,  0.0161,\n",
            "         0.0320,  0.0286,  0.0221,  0.0028, -0.0398, -0.0058, -0.0090, -0.0364],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_C3.weight Parameter containing:\n",
            "tensor([[[[-0.0034, -0.0111,  0.0038],\n",
            "          [-0.0231,  0.0128,  0.0376],\n",
            "          [ 0.0073,  0.0167,  0.0325]],\n",
            "\n",
            "         [[-0.0111,  0.0153,  0.0174],\n",
            "          [ 0.0255,  0.0348,  0.0067],\n",
            "          [ 0.0190,  0.0325,  0.0150]],\n",
            "\n",
            "         [[-0.0129,  0.0298, -0.0287],\n",
            "          [ 0.0235, -0.0272, -0.0136],\n",
            "          [-0.0250,  0.0134, -0.0366]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0078, -0.0181,  0.0097],\n",
            "          [ 0.0141, -0.0291,  0.0411],\n",
            "          [ 0.0006,  0.0360,  0.0046]],\n",
            "\n",
            "         [[ 0.0179, -0.0249, -0.0012],\n",
            "          [ 0.0067,  0.0163,  0.0074],\n",
            "          [-0.0103, -0.0130, -0.0166]],\n",
            "\n",
            "         [[-0.0130, -0.0165, -0.0142],\n",
            "          [ 0.0004, -0.0360,  0.0068],\n",
            "          [ 0.0183, -0.0127,  0.0227]]],\n",
            "\n",
            "\n",
            "        [[[ 0.0032,  0.0366,  0.0231],\n",
            "          [ 0.0202, -0.0233, -0.0210],\n",
            "          [ 0.0387, -0.0311, -0.0239]],\n",
            "\n",
            "         [[ 0.0138, -0.0278,  0.0215],\n",
            "          [-0.0008, -0.0409, -0.0233],\n",
            "          [-0.0071, -0.0340, -0.0397]],\n",
            "\n",
            "         [[ 0.0330,  0.0332, -0.0073],\n",
            "          [-0.0083,  0.0197,  0.0057],\n",
            "          [ 0.0225, -0.0172, -0.0260]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0375, -0.0089,  0.0350],\n",
            "          [-0.0290,  0.0101, -0.0123],\n",
            "          [-0.0301, -0.0152, -0.0060]],\n",
            "\n",
            "         [[ 0.0385, -0.0131, -0.0373],\n",
            "          [-0.0048, -0.0095, -0.0044],\n",
            "          [ 0.0226, -0.0065,  0.0380]],\n",
            "\n",
            "         [[-0.0172,  0.0341,  0.0369],\n",
            "          [ 0.0233,  0.0025, -0.0359],\n",
            "          [ 0.0303, -0.0277, -0.0042]]],\n",
            "\n",
            "\n",
            "        [[[-0.0387, -0.0218, -0.0289],\n",
            "          [ 0.0022, -0.0238,  0.0216],\n",
            "          [-0.0325,  0.0114,  0.0027]],\n",
            "\n",
            "         [[ 0.0026, -0.0122,  0.0026],\n",
            "          [ 0.0294, -0.0349,  0.0261],\n",
            "          [ 0.0390, -0.0037, -0.0190]],\n",
            "\n",
            "         [[ 0.0042, -0.0339,  0.0192],\n",
            "          [ 0.0126,  0.0137,  0.0113],\n",
            "          [ 0.0140, -0.0182,  0.0043]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0341,  0.0230,  0.0267],\n",
            "          [-0.0355, -0.0121,  0.0167],\n",
            "          [ 0.0145, -0.0181, -0.0049]],\n",
            "\n",
            "         [[-0.0080,  0.0101, -0.0086],\n",
            "          [ 0.0151, -0.0411, -0.0314],\n",
            "          [ 0.0206,  0.0398, -0.0214]],\n",
            "\n",
            "         [[ 0.0237,  0.0090, -0.0292],\n",
            "          [ 0.0282, -0.0079,  0.0341],\n",
            "          [ 0.0268,  0.0101,  0.0411]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[ 0.0178, -0.0408,  0.0044],\n",
            "          [ 0.0311, -0.0230, -0.0089],\n",
            "          [ 0.0361, -0.0214, -0.0395]],\n",
            "\n",
            "         [[-0.0282,  0.0098, -0.0098],\n",
            "          [ 0.0047, -0.0293,  0.0309],\n",
            "          [-0.0119, -0.0197, -0.0254]],\n",
            "\n",
            "         [[-0.0358,  0.0313, -0.0128],\n",
            "          [-0.0209, -0.0113,  0.0036],\n",
            "          [ 0.0040,  0.0341, -0.0052]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 0.0089, -0.0333,  0.0255],\n",
            "          [-0.0178, -0.0244,  0.0149],\n",
            "          [ 0.0177, -0.0211, -0.0231]],\n",
            "\n",
            "         [[-0.0032,  0.0174,  0.0162],\n",
            "          [-0.0069, -0.0342,  0.0379],\n",
            "          [ 0.0044, -0.0243,  0.0381]],\n",
            "\n",
            "         [[ 0.0236,  0.0270, -0.0087],\n",
            "          [ 0.0215,  0.0184, -0.0202],\n",
            "          [-0.0010,  0.0202,  0.0313]]],\n",
            "\n",
            "\n",
            "        [[[-0.0047,  0.0304,  0.0282],\n",
            "          [-0.0287,  0.0388, -0.0131],\n",
            "          [-0.0337,  0.0131, -0.0327]],\n",
            "\n",
            "         [[-0.0089,  0.0266,  0.0280],\n",
            "          [ 0.0412,  0.0111, -0.0417],\n",
            "          [ 0.0307,  0.0063,  0.0025]],\n",
            "\n",
            "         [[ 0.0342,  0.0361, -0.0079],\n",
            "          [ 0.0353, -0.0222, -0.0100],\n",
            "          [-0.0217, -0.0103,  0.0262]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0043,  0.0172, -0.0380],\n",
            "          [-0.0097, -0.0103, -0.0269],\n",
            "          [ 0.0412,  0.0212, -0.0086]],\n",
            "\n",
            "         [[-0.0150,  0.0279, -0.0180],\n",
            "          [-0.0003, -0.0294,  0.0266],\n",
            "          [-0.0154, -0.0300,  0.0321]],\n",
            "\n",
            "         [[ 0.0354, -0.0352,  0.0255],\n",
            "          [-0.0367, -0.0107, -0.0302],\n",
            "          [-0.0245, -0.0170,  0.0246]]],\n",
            "\n",
            "\n",
            "        [[[-0.0161,  0.0046,  0.0179],\n",
            "          [ 0.0188,  0.0087, -0.0319],\n",
            "          [-0.0176, -0.0362,  0.0275]],\n",
            "\n",
            "         [[-0.0349,  0.0406, -0.0321],\n",
            "          [-0.0238, -0.0340, -0.0351],\n",
            "          [ 0.0012, -0.0262,  0.0400]],\n",
            "\n",
            "         [[-0.0108, -0.0074,  0.0042],\n",
            "          [-0.0102,  0.0135,  0.0109],\n",
            "          [-0.0044, -0.0285, -0.0220]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[-0.0119,  0.0031,  0.0044],\n",
            "          [-0.0315, -0.0035, -0.0154],\n",
            "          [-0.0367,  0.0205,  0.0158]],\n",
            "\n",
            "         [[-0.0263, -0.0204,  0.0217],\n",
            "          [ 0.0083,  0.0070, -0.0197],\n",
            "          [-0.0051,  0.0197, -0.0163]],\n",
            "\n",
            "         [[ 0.0411, -0.0257,  0.0204],\n",
            "          [-0.0214, -0.0323, -0.0114],\n",
            "          [-0.0322,  0.0212,  0.0366]]]], device='cuda:0', requires_grad=True)\n",
            "NPV_C3.bias Parameter containing:\n",
            "tensor([ 0.0251,  0.0412,  0.0189, -0.0158, -0.0062,  0.0019,  0.0211,  0.0228,\n",
            "        -0.0108, -0.0355, -0.0194, -0.0279,  0.0215, -0.0086, -0.0081,  0.0119,\n",
            "         0.0087,  0.0250,  0.0146,  0.0229, -0.0165, -0.0009, -0.0075,  0.0334,\n",
            "         0.0060,  0.0184, -0.0308, -0.0036,  0.0107, -0.0229,  0.0149,  0.0189,\n",
            "        -0.0370, -0.0028, -0.0368,  0.0243,  0.0200, -0.0219, -0.0329, -0.0103,\n",
            "         0.0164, -0.0021, -0.0058, -0.0336, -0.0048,  0.0161, -0.0385, -0.0332,\n",
            "         0.0028, -0.0212,  0.0173, -0.0075, -0.0171,  0.0330, -0.0287,  0.0376,\n",
            "        -0.0077,  0.0152, -0.0029,  0.0337, -0.0253,  0.0024, -0.0085,  0.0051,\n",
            "        -0.0298,  0.0079, -0.0301,  0.0306, -0.0364, -0.0364, -0.0368,  0.0266,\n",
            "        -0.0265, -0.0369,  0.0292,  0.0357,  0.0277,  0.0365, -0.0020,  0.0159,\n",
            "        -0.0331,  0.0415,  0.0083, -0.0116, -0.0074, -0.0332, -0.0329, -0.0212,\n",
            "         0.0367,  0.0063,  0.0406,  0.0099, -0.0145,  0.0189, -0.0352, -0.0216,\n",
            "        -0.0164, -0.0182,  0.0096,  0.0211,  0.0156, -0.0256, -0.0378,  0.0186,\n",
            "        -0.0284,  0.0303,  0.0279,  0.0352,  0.0365, -0.0328,  0.0360,  0.0415,\n",
            "        -0.0276,  0.0183, -0.0250, -0.0200,  0.0233,  0.0401,  0.0350, -0.0212,\n",
            "        -0.0370, -0.0086,  0.0305, -0.0129, -0.0280,  0.0287, -0.0125,  0.0281],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_C4.weight Parameter containing:\n",
            "tensor([[[[ 1.8547e-02, -2.5560e-02,  2.7901e-02],\n",
            "          [ 2.6662e-02, -1.3741e-02, -2.5135e-02],\n",
            "          [ 2.1099e-02, -7.7050e-03,  2.6357e-02]],\n",
            "\n",
            "         [[-1.1221e-03,  4.2975e-03, -1.5433e-03],\n",
            "          [-5.8772e-03, -1.1894e-02,  2.0187e-02],\n",
            "          [-4.2308e-03,  1.7861e-02,  2.1509e-02]],\n",
            "\n",
            "         [[-1.5515e-02, -4.4448e-03,  2.7863e-02],\n",
            "          [-2.4853e-02,  1.1110e-02,  7.5147e-03],\n",
            "          [-8.2277e-03, -1.8365e-02,  1.6102e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.6049e-02, -1.3853e-02,  1.4366e-02],\n",
            "          [-1.9216e-02, -8.6931e-03, -1.2399e-02],\n",
            "          [-9.6457e-03, -2.3747e-03,  7.9544e-03]],\n",
            "\n",
            "         [[ 2.0802e-02,  2.1545e-02,  8.6930e-03],\n",
            "          [ 2.4062e-02, -2.1345e-02,  7.6487e-03],\n",
            "          [ 2.8455e-02, -5.8696e-03,  4.2505e-03]],\n",
            "\n",
            "         [[ 2.0200e-03,  1.1953e-02, -2.6009e-02],\n",
            "          [-8.9402e-03, -1.5453e-02, -2.6909e-03],\n",
            "          [-3.4822e-03, -1.2013e-02,  2.8915e-02]]],\n",
            "\n",
            "\n",
            "        [[[ 9.9335e-03,  1.5138e-02,  1.8524e-02],\n",
            "          [ 1.1680e-02,  8.7692e-04,  1.1865e-02],\n",
            "          [ 1.6412e-02, -2.6634e-02, -2.6997e-02]],\n",
            "\n",
            "         [[ 1.2825e-02,  4.7145e-03,  2.7711e-02],\n",
            "          [ 2.3124e-03,  1.8865e-02, -2.2584e-03],\n",
            "          [-2.6276e-02, -8.4672e-04, -7.1188e-03]],\n",
            "\n",
            "         [[-5.6164e-03, -5.4858e-03,  2.5175e-02],\n",
            "          [-3.2166e-03,  3.2054e-03,  2.7843e-02],\n",
            "          [ 4.9885e-03, -8.6341e-04, -1.2402e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.6404e-02,  1.2483e-02, -1.0252e-02],\n",
            "          [ 2.9257e-02,  6.9699e-04,  1.7973e-02],\n",
            "          [ 5.9282e-03,  1.2037e-02,  6.6220e-03]],\n",
            "\n",
            "         [[-1.2238e-02,  5.4102e-03, -7.5757e-03],\n",
            "          [ 9.7785e-04, -1.7176e-02, -1.8293e-02],\n",
            "          [ 2.7187e-02,  7.1037e-03,  2.8183e-02]],\n",
            "\n",
            "         [[ 1.0141e-02, -7.2595e-03,  1.2024e-02],\n",
            "          [ 1.4648e-02,  2.8141e-02, -1.6464e-02],\n",
            "          [-5.6109e-03,  2.8029e-02, -2.7142e-02]]],\n",
            "\n",
            "\n",
            "        [[[-2.7441e-03, -2.1184e-02, -5.2326e-03],\n",
            "          [ 1.7715e-02, -2.7127e-02,  2.0267e-02],\n",
            "          [-1.5180e-02, -1.1591e-02, -1.6512e-02]],\n",
            "\n",
            "         [[-1.0961e-03, -2.3102e-02,  2.7686e-02],\n",
            "          [-2.7964e-02,  2.8466e-02,  1.2443e-02],\n",
            "          [-2.2951e-03,  4.2725e-04,  2.6366e-02]],\n",
            "\n",
            "         [[ 2.2846e-02, -2.6554e-02,  3.1655e-04],\n",
            "          [-1.3473e-02,  3.6214e-03,  2.6605e-02],\n",
            "          [-2.5853e-02,  2.1306e-02,  6.6371e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 7.1370e-03, -2.9110e-02, -4.6803e-03],\n",
            "          [ 7.8221e-03,  2.3999e-02,  1.9790e-03],\n",
            "          [-2.7707e-02, -2.0211e-03, -1.7226e-02]],\n",
            "\n",
            "         [[ 8.6065e-03, -1.1801e-02, -2.4871e-02],\n",
            "          [ 1.9454e-02,  2.9128e-02, -2.6209e-02],\n",
            "          [-1.9582e-02, -4.4405e-03,  2.4269e-02]],\n",
            "\n",
            "         [[ 6.9338e-04,  2.7026e-02,  1.6004e-02],\n",
            "          [-5.1979e-03, -6.8585e-03,  2.3670e-02],\n",
            "          [ 6.7176e-03,  2.0709e-02, -1.7795e-02]]],\n",
            "\n",
            "\n",
            "        ...,\n",
            "\n",
            "\n",
            "        [[[-2.9438e-02, -2.6797e-02, -2.8662e-02],\n",
            "          [-8.3774e-04, -1.6151e-02, -1.5690e-02],\n",
            "          [-2.5351e-03, -4.7705e-03,  1.9657e-02]],\n",
            "\n",
            "         [[ 8.4716e-04, -1.8302e-02,  1.7641e-02],\n",
            "          [-2.3969e-03, -8.5136e-03, -9.7407e-03],\n",
            "          [ 1.6985e-02,  6.2068e-03,  3.8944e-03]],\n",
            "\n",
            "         [[-1.7281e-02, -1.7267e-02, -4.8513e-03],\n",
            "          [-1.2995e-02,  2.8919e-02, -2.4618e-03],\n",
            "          [ 1.8350e-02, -5.5502e-04, -9.7419e-03]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 2.3555e-02, -2.0635e-02,  2.1347e-02],\n",
            "          [-1.5004e-02, -1.5949e-03, -2.2799e-03],\n",
            "          [ 1.4768e-02,  1.7583e-02,  1.7823e-02]],\n",
            "\n",
            "         [[ 1.3865e-02, -9.2809e-03,  1.2621e-02],\n",
            "          [-3.3316e-03, -2.8142e-02, -2.3077e-02],\n",
            "          [ 6.8082e-03,  1.6964e-02,  2.6318e-02]],\n",
            "\n",
            "         [[-2.4937e-06,  1.9748e-02,  2.1456e-02],\n",
            "          [-6.0093e-03,  2.0804e-02,  8.1895e-03],\n",
            "          [ 1.5051e-02,  2.8388e-02, -6.7704e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 1.0225e-02, -2.1930e-02,  1.6251e-02],\n",
            "          [-2.8889e-02, -2.8999e-02, -2.0172e-02],\n",
            "          [-2.9454e-02, -1.7223e-02, -1.4882e-02]],\n",
            "\n",
            "         [[-2.3062e-02,  2.2952e-02, -2.4384e-02],\n",
            "          [ 1.4760e-02, -1.3173e-02,  1.4922e-02],\n",
            "          [-1.3056e-02,  2.8262e-02,  2.8419e-02]],\n",
            "\n",
            "         [[ 9.6457e-03,  1.3938e-02, -3.3275e-04],\n",
            "          [-1.0336e-02, -9.9067e-03, -4.7636e-03],\n",
            "          [ 1.6801e-02,  8.9782e-03,  1.8836e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.6673e-03,  1.9174e-02,  2.7351e-02],\n",
            "          [ 1.1162e-02,  2.4850e-03,  1.2936e-02],\n",
            "          [-2.6243e-02,  1.8634e-02,  2.8729e-02]],\n",
            "\n",
            "         [[-2.5799e-02, -1.1588e-02, -2.8326e-02],\n",
            "          [-1.1454e-02,  2.5598e-02,  2.5784e-02],\n",
            "          [-5.8341e-04, -2.3068e-02, -2.2342e-02]],\n",
            "\n",
            "         [[ 1.0763e-02,  1.1719e-02,  6.8478e-03],\n",
            "          [ 1.1783e-02, -2.9400e-02,  7.8208e-03],\n",
            "          [ 1.1646e-02, -6.0014e-03,  4.0814e-03]]],\n",
            "\n",
            "\n",
            "        [[[ 4.8612e-03, -4.2903e-04,  6.2463e-03],\n",
            "          [ 9.8827e-03,  1.2396e-02, -8.3966e-03],\n",
            "          [ 1.2972e-02,  1.8804e-02,  2.7096e-02]],\n",
            "\n",
            "         [[ 2.0468e-03,  1.6091e-02, -1.2142e-02],\n",
            "          [ 5.3405e-04,  1.8808e-02, -2.3685e-02],\n",
            "          [-1.0943e-02,  2.0159e-02,  2.2524e-02]],\n",
            "\n",
            "         [[ 4.7737e-03, -3.8733e-03, -2.0508e-02],\n",
            "          [ 2.6969e-02,  7.6279e-03,  5.7198e-03],\n",
            "          [ 1.9303e-02, -2.6259e-02,  1.4673e-02]],\n",
            "\n",
            "         ...,\n",
            "\n",
            "         [[ 4.7801e-03, -1.6427e-02, -8.9633e-03],\n",
            "          [ 1.7075e-02,  1.1106e-02, -2.4079e-02],\n",
            "          [-2.0180e-02,  1.6747e-02,  3.5819e-03]],\n",
            "\n",
            "         [[ 1.1290e-02, -2.0374e-02,  2.5160e-02],\n",
            "          [ 2.9366e-02, -1.7133e-02, -1.0462e-02],\n",
            "          [-2.5380e-02,  2.5374e-02,  1.1679e-02]],\n",
            "\n",
            "         [[-2.1870e-02,  2.6703e-03, -3.1049e-03],\n",
            "          [ 2.1699e-02,  1.5988e-02,  1.9027e-02],\n",
            "          [ 1.0664e-02,  1.5961e-02, -1.5497e-02]]]], device='cuda:0',\n",
            "       requires_grad=True)\n",
            "NPV_C4.bias Parameter containing:\n",
            "tensor([-0.0056,  0.0135, -0.0150,  0.0107, -0.0147,  0.0063,  0.0207,  0.0132,\n",
            "        -0.0284,  0.0110,  0.0252,  0.0065,  0.0092,  0.0220, -0.0031, -0.0048,\n",
            "        -0.0115,  0.0161, -0.0012,  0.0278,  0.0236,  0.0116, -0.0130, -0.0261,\n",
            "        -0.0171,  0.0257, -0.0082,  0.0114, -0.0271,  0.0205, -0.0016, -0.0131,\n",
            "         0.0003,  0.0020,  0.0263,  0.0258, -0.0229,  0.0021,  0.0033,  0.0027,\n",
            "         0.0062, -0.0034,  0.0093, -0.0009,  0.0151, -0.0133, -0.0167, -0.0256,\n",
            "        -0.0258,  0.0107,  0.0288, -0.0004, -0.0013, -0.0195,  0.0020,  0.0001,\n",
            "        -0.0021,  0.0232, -0.0264,  0.0047,  0.0128, -0.0269, -0.0289,  0.0147,\n",
            "         0.0121, -0.0234, -0.0199, -0.0042, -0.0193, -0.0154,  0.0166,  0.0273,\n",
            "        -0.0164, -0.0184, -0.0020, -0.0217,  0.0245,  0.0116,  0.0279,  0.0218,\n",
            "         0.0119,  0.0232, -0.0198,  0.0024, -0.0209,  0.0287,  0.0192,  0.0049,\n",
            "        -0.0145, -0.0164,  0.0028, -0.0007, -0.0180, -0.0041, -0.0268,  0.0114,\n",
            "        -0.0051,  0.0261, -0.0009,  0.0265, -0.0226, -0.0093,  0.0242,  0.0042,\n",
            "        -0.0089,  0.0130, -0.0007,  0.0092, -0.0199,  0.0136,  0.0280, -0.0111,\n",
            "         0.0267, -0.0082, -0.0260,  0.0060,  0.0240,  0.0119, -0.0111,  0.0013,\n",
            "         0.0283,  0.0082, -0.0141, -0.0092,  0.0185,  0.0091,  0.0109,  0.0039],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_D1.weight Parameter containing:\n",
            "tensor([[-0.0013, -0.0021,  0.0013,  ...,  0.0015,  0.0014,  0.0002],\n",
            "        [-0.0005,  0.0024,  0.0017,  ..., -0.0022,  0.0020,  0.0019],\n",
            "        [ 0.0005, -0.0027, -0.0024,  ...,  0.0004, -0.0015,  0.0027],\n",
            "        ...,\n",
            "        [ 0.0020,  0.0018, -0.0003,  ..., -0.0014,  0.0016,  0.0020],\n",
            "        [-0.0022, -0.0009,  0.0006,  ...,  0.0025, -0.0013, -0.0027],\n",
            "        [ 0.0001, -0.0019, -0.0001,  ...,  0.0024, -0.0002, -0.0020]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_D1.bias Parameter containing:\n",
            "tensor([-4.1384e-04, -1.0738e-03, -3.9989e-04,  1.8989e-03, -7.3267e-04,\n",
            "         1.8078e-03, -1.4925e-03, -1.8753e-03,  2.8884e-04, -5.9429e-04,\n",
            "        -2.2780e-03, -6.1660e-04,  2.6611e-03, -2.3226e-03,  2.7339e-03,\n",
            "        -8.6587e-04, -1.7221e-03, -1.3927e-03,  1.0094e-03,  2.6458e-03,\n",
            "         1.6272e-03, -1.4196e-04, -2.4869e-03, -3.0160e-04,  9.2237e-05,\n",
            "        -6.6595e-04, -1.4047e-04,  1.1011e-03,  4.8976e-04, -2.1280e-03,\n",
            "         2.6215e-03, -2.4352e-03,  2.1192e-03,  1.4688e-03,  5.4750e-05,\n",
            "         2.1195e-03,  1.1754e-03, -1.6902e-04,  1.3187e-03, -2.5843e-03,\n",
            "        -2.5860e-03,  2.4320e-03,  2.3231e-04, -1.2277e-03,  1.2351e-03,\n",
            "         2.3183e-03, -2.1269e-04, -1.3373e-04,  1.2696e-05, -8.8607e-04,\n",
            "        -1.3307e-03,  1.0189e-03,  3.2031e-04, -1.9148e-03,  1.9085e-03,\n",
            "        -3.1937e-04, -1.0270e-03, -4.3079e-05,  2.6409e-05, -1.9233e-03,\n",
            "         1.7765e-03,  7.1654e-04,  1.9622e-04,  2.2668e-04, -1.5567e-03,\n",
            "        -1.2953e-03, -4.2565e-04,  1.4677e-04,  9.6539e-04, -1.3649e-04,\n",
            "        -1.5099e-03, -2.5443e-04,  1.1356e-03,  2.5933e-03,  2.8024e-05,\n",
            "         1.9936e-03, -2.1555e-03,  1.5932e-03,  2.6165e-03,  2.7190e-05,\n",
            "         1.9097e-03,  2.9164e-05,  2.3115e-03, -7.1524e-04, -7.5080e-04,\n",
            "        -1.1367e-03, -5.3456e-04, -2.5369e-03,  3.1001e-05, -1.0638e-04,\n",
            "        -2.1188e-03,  1.6220e-03, -4.4891e-04, -2.1179e-03,  6.6457e-04,\n",
            "         1.8765e-03, -4.3621e-04, -2.0483e-03, -2.6705e-03,  9.5321e-04,\n",
            "        -1.0956e-03,  2.5556e-03, -2.6456e-03,  1.1538e-03,  2.2131e-03,\n",
            "         1.3228e-03, -2.3158e-03, -2.2547e-03, -2.7083e-03, -1.9790e-04,\n",
            "         9.1698e-04, -1.9535e-03,  2.2420e-03,  1.9626e-03, -8.8746e-04,\n",
            "         1.8249e-03,  1.6661e-03,  3.4375e-04, -2.1479e-03,  1.9391e-03,\n",
            "         1.4510e-03,  1.8275e-03,  7.6839e-04, -3.6183e-04, -8.4572e-04,\n",
            "         2.5884e-03, -2.6515e-03, -2.0279e-03, -1.3368e-03, -2.3529e-03,\n",
            "        -2.2336e-03, -1.8140e-03,  1.9664e-03, -1.1903e-03, -2.0383e-03,\n",
            "        -5.5501e-04,  1.2805e-03,  1.2288e-03, -2.1721e-03, -2.6898e-03,\n",
            "         2.4605e-03,  2.1607e-03,  3.5855e-04,  1.1235e-03,  1.4407e-03,\n",
            "         1.9458e-03, -1.3276e-03, -1.3623e-03,  2.6739e-03, -2.6933e-03,\n",
            "        -2.2199e-03,  8.7995e-04, -4.5598e-04,  1.0855e-03,  1.7859e-03,\n",
            "         2.6374e-03,  1.5598e-03,  1.5535e-03, -1.5259e-03, -2.0964e-03,\n",
            "         1.7102e-03,  2.6205e-03,  7.4783e-04, -9.1155e-04,  1.7671e-03,\n",
            "        -6.3164e-04, -2.4441e-03,  1.2537e-03,  2.2623e-03, -4.4254e-04,\n",
            "        -1.3406e-03, -5.2329e-04,  3.4630e-04,  1.2714e-03,  2.6960e-03,\n",
            "         1.7744e-03,  2.4454e-03, -2.6768e-03,  2.6465e-03, -2.3019e-04,\n",
            "        -9.2419e-04, -1.4838e-03, -2.5337e-03,  6.4903e-04,  2.0928e-03,\n",
            "         1.3986e-03,  2.8568e-04, -2.2695e-03,  2.3626e-03,  1.0240e-03,\n",
            "        -5.0970e-04,  1.7523e-03, -2.6457e-03,  2.5607e-03, -2.0905e-03,\n",
            "        -1.4426e-03, -9.8503e-04,  2.3083e-03, -2.1219e-04, -2.3740e-03,\n",
            "        -1.0958e-03, -1.9475e-03, -1.0756e-03, -2.5889e-04,  1.7586e-03,\n",
            "        -1.6205e-03,  2.5872e-03, -2.4051e-03,  9.0938e-04, -1.0316e-06,\n",
            "        -1.3849e-04,  1.7000e-03,  1.7999e-03, -2.0845e-04, -8.0787e-04,\n",
            "         1.7902e-03, -3.9683e-04, -2.1924e-03,  1.6272e-03,  2.2098e-03,\n",
            "        -1.7826e-03, -1.4174e-03, -1.3312e-03,  1.4647e-03, -2.7536e-04,\n",
            "         4.0342e-06, -9.0189e-04,  1.4448e-04, -6.0202e-04,  2.3892e-03,\n",
            "         2.0357e-03,  5.7639e-04, -2.1735e-03, -2.6652e-03,  6.2228e-04,\n",
            "        -2.6638e-03, -1.4721e-03, -1.9672e-03, -1.2559e-03,  1.1948e-03,\n",
            "         2.6072e-03,  1.9213e-03,  1.3809e-03,  1.0799e-03, -1.7860e-03,\n",
            "        -2.6538e-04,  2.2230e-03, -7.7239e-04,  1.4155e-03, -1.3319e-03,\n",
            "        -1.6126e-03,  1.1060e-03, -1.4397e-03, -1.0832e-03, -1.5709e-03,\n",
            "        -2.5035e-03], device='cuda:0', requires_grad=True)\n",
            "NPV_D2.weight Parameter containing:\n",
            "tensor([[ 0.0078,  0.0359, -0.0523,  ...,  0.0363,  0.0073,  0.0139],\n",
            "        [-0.0412, -0.0252,  0.0347,  ...,  0.0289,  0.0056,  0.0428],\n",
            "        [ 0.0461, -0.0216,  0.0004,  ..., -0.0574, -0.0037,  0.0543],\n",
            "        ...,\n",
            "        [ 0.0609, -0.0291, -0.0598,  ...,  0.0150, -0.0602,  0.0104],\n",
            "        [-0.0109, -0.0581, -0.0391,  ...,  0.0467,  0.0350, -0.0120],\n",
            "        [-0.0615,  0.0021, -0.0185,  ...,  0.0610, -0.0457, -0.0423]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "NPV_D2.bias Parameter containing:\n",
            "tensor([-0.0624, -0.0491, -0.0104, -0.0518, -0.0450,  0.0253,  0.0189,  0.0088,\n",
            "        -0.0043,  0.0449, -0.0328, -0.0254,  0.0256,  0.0169,  0.0576,  0.0610,\n",
            "        -0.0454,  0.0487, -0.0595,  0.0364, -0.0578,  0.0352, -0.0076, -0.0598,\n",
            "         0.0089, -0.0089,  0.0388, -0.0006,  0.0493, -0.0394,  0.0185, -0.0379,\n",
            "        -0.0308, -0.0580,  0.0301,  0.0239, -0.0399, -0.0617, -0.0541,  0.0181,\n",
            "         0.0283, -0.0617,  0.0285,  0.0433,  0.0257, -0.0353,  0.0457, -0.0401,\n",
            "        -0.0554,  0.0252,  0.0525,  0.0228,  0.0032, -0.0105,  0.0411, -0.0018,\n",
            "        -0.0385, -0.0198,  0.0333,  0.0102, -0.0511, -0.0600, -0.0215, -0.0263,\n",
            "         0.0486,  0.0017, -0.0552, -0.0322,  0.0046,  0.0287, -0.0490, -0.0024,\n",
            "         0.0118, -0.0525, -0.0375,  0.0178,  0.0139, -0.0361,  0.0501, -0.0028,\n",
            "        -0.0156,  0.0569,  0.0320, -0.0101, -0.0241,  0.0421,  0.0116, -0.0287,\n",
            "        -0.0219,  0.0401, -0.0433,  0.0382, -0.0165,  0.0624,  0.0113, -0.0571,\n",
            "        -0.0507,  0.0058, -0.0057, -0.0062, -0.0214, -0.0060,  0.0280, -0.0245,\n",
            "        -0.0523,  0.0319, -0.0351, -0.0368,  0.0270, -0.0416,  0.0475, -0.0248,\n",
            "         0.0115,  0.0347, -0.0068,  0.0329,  0.0262, -0.0297,  0.0268, -0.0572,\n",
            "        -0.0587, -0.0110,  0.0533, -0.0075, -0.0190, -0.0197, -0.0437, -0.0008,\n",
            "         0.0597, -0.0341,  0.0395, -0.0432,  0.0482, -0.0616,  0.0280, -0.0610,\n",
            "        -0.0329,  0.0077,  0.0388,  0.0413,  0.0386, -0.0252,  0.0476,  0.0549,\n",
            "         0.0010, -0.0448,  0.0197, -0.0066, -0.0380, -0.0420,  0.0234, -0.0305,\n",
            "        -0.0240,  0.0058, -0.0222, -0.0618,  0.0338,  0.0148, -0.0228, -0.0473,\n",
            "         0.0579, -0.0269,  0.0441,  0.0086,  0.0128, -0.0045,  0.0486,  0.0050,\n",
            "         0.0380, -0.0197, -0.0292, -0.0460,  0.0105, -0.0351, -0.0555,  0.0467,\n",
            "         0.0045, -0.0036,  0.0419, -0.0345,  0.0595,  0.0131,  0.0556, -0.0468,\n",
            "        -0.0139, -0.0545, -0.0068, -0.0448,  0.0382, -0.0428, -0.0591, -0.0571,\n",
            "         0.0034,  0.0023, -0.0480,  0.0218, -0.0160,  0.0265, -0.0035, -0.0100,\n",
            "        -0.0062,  0.0313, -0.0121,  0.0498, -0.0415,  0.0428,  0.0144,  0.0445,\n",
            "        -0.0144, -0.0336, -0.0123, -0.0097, -0.0251,  0.0142, -0.0208,  0.0285,\n",
            "         0.0057,  0.0136, -0.0265,  0.0133,  0.0038, -0.0054,  0.0307,  0.0077,\n",
            "        -0.0552, -0.0164, -0.0227,  0.0301,  0.0092, -0.0301,  0.0566, -0.0371,\n",
            "        -0.0008, -0.0405, -0.0548, -0.0059, -0.0535,  0.0247, -0.0562, -0.0495,\n",
            "        -0.0170,  0.0118, -0.0149, -0.0375,  0.0076, -0.0143, -0.0375,  0.0253,\n",
            "         0.0298, -0.0339,  0.0584,  0.0584, -0.0588,  0.0578,  0.0070,  0.0050],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "outputs.weight Parameter containing:\n",
            "tensor([[ 0.0343, -0.0499, -0.0540,  ..., -0.0426,  0.0288, -0.0183],\n",
            "        [-0.0240,  0.0257, -0.0623,  ...,  0.0148,  0.0014, -0.0594],\n",
            "        [ 0.0029,  0.0302,  0.0486,  ..., -0.0442,  0.0029,  0.0101],\n",
            "        ...,\n",
            "        [ 0.0097,  0.0373,  0.0091,  ...,  0.0226,  0.0458, -0.0256],\n",
            "        [-0.0167, -0.0053,  0.0563,  ...,  0.0622, -0.0512,  0.0277],\n",
            "        [-0.0213,  0.0414,  0.0194,  ..., -0.0155, -0.0592,  0.0369]],\n",
            "       device='cuda:0', requires_grad=True)\n",
            "outputs.bias Parameter containing:\n",
            "tensor([ 0.0458,  0.0382, -0.0524, -0.0228, -0.0135,  0.0372, -0.0526,  0.0281,\n",
            "        -0.0004,  0.0427], device='cuda:0', requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in flnpf_linear_model.named_parameters():\n",
        "  if param.requires_grad:\n",
        "    print(name)"
      ],
      "metadata": {
        "id": "UcIj_YlsMgCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "188becdb-dbc5-44ff-e500-a94e49673550"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "NPV_C1.weight\n",
            "NPV_C1.bias\n",
            "NPV_C2.weight\n",
            "NPV_C2.bias\n",
            "NPV_C3.weight\n",
            "NPV_C3.bias\n",
            "NPV_C4.weight\n",
            "NPV_C4.bias\n",
            "NPV_D1.weight\n",
            "NPV_D1.bias\n",
            "NPV_D2.weight\n",
            "NPV_D2.bias\n",
            "outputs.weight\n",
            "outputs.bias\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = optim.SGD(flnpf_linear_model.parameters(), lr=args['lr'])\n",
        "for epoch in range(1, args['epochs']+1):\n",
        "  train(flnpf_linear_model, epoch, train_loader, lossFn, optimizer)\n",
        "  validate(flnpf_linear_model, validation_loader, lossFn)"
      ],
      "metadata": {
        "id": "eweiWlndMgCB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "71e60e07-2783-4303-df01-16dac4c16a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:70: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Epoch: 1 [50000/50000 (100%)]\tLoss: 1.866728\n",
            "\n",
            "Validation set: Average loss: 1.4675, Accuracy: 4684/10000 (47%)\n",
            "\n",
            "Train Epoch: 2 [50000/50000 (100%)]\tLoss: 1.260146\n",
            "\n",
            "Validation set: Average loss: 1.2232, Accuracy: 5583/10000 (56%)\n",
            "\n",
            "Train Epoch: 3 [50000/50000 (100%)]\tLoss: 0.934243\n",
            "\n",
            "Validation set: Average loss: 1.1796, Accuracy: 5821/10000 (58%)\n",
            "\n",
            "Train Epoch: 4 [50000/50000 (100%)]\tLoss: 0.569756\n",
            "\n",
            "Validation set: Average loss: 1.2849, Accuracy: 5996/10000 (60%)\n",
            "\n",
            "Train Epoch: 5 [50000/50000 (100%)]\tLoss: 0.220961\n",
            "\n",
            "Validation set: Average loss: 1.8084, Accuracy: 5863/10000 (59%)\n",
            "\n",
            "Train Epoch: 6 [50000/50000 (100%)]\tLoss: 0.097999\n",
            "\n",
            "Validation set: Average loss: 2.1656, Accuracy: 5773/10000 (58%)\n",
            "\n",
            "Train Epoch: 7 [50000/50000 (100%)]\tLoss: 0.056938\n",
            "\n",
            "Validation set: Average loss: 2.4876, Accuracy: 5890/10000 (59%)\n",
            "\n",
            "Train Epoch: 8 [50000/50000 (100%)]\tLoss: 0.039705\n",
            "\n",
            "Validation set: Average loss: 2.5050, Accuracy: 6083/10000 (61%)\n",
            "\n",
            "Train Epoch: 9 [50000/50000 (100%)]\tLoss: 0.019216\n",
            "\n",
            "Validation set: Average loss: 2.8003, Accuracy: 5972/10000 (60%)\n",
            "\n",
            "Train Epoch: 10 [50000/50000 (100%)]\tLoss: 0.013108\n",
            "\n",
            "Validation set: Average loss: 2.9850, Accuracy: 6065/10000 (61%)\n",
            "\n",
            "Train Epoch: 11 [50000/50000 (100%)]\tLoss: 0.011848\n",
            "\n",
            "Validation set: Average loss: 3.4540, Accuracy: 5921/10000 (59%)\n",
            "\n",
            "Train Epoch: 12 [50000/50000 (100%)]\tLoss: 0.014531\n",
            "\n",
            "Validation set: Average loss: 3.3561, Accuracy: 5939/10000 (59%)\n",
            "\n",
            "Train Epoch: 13 [50000/50000 (100%)]\tLoss: 0.012699\n",
            "\n",
            "Validation set: Average loss: 3.2354, Accuracy: 6053/10000 (61%)\n",
            "\n",
            "Train Epoch: 14 [50000/50000 (100%)]\tLoss: 0.006346\n",
            "\n",
            "Validation set: Average loss: 3.4430, Accuracy: 6058/10000 (61%)\n",
            "\n",
            "Train Epoch: 15 [50000/50000 (100%)]\tLoss: 0.001159\n",
            "\n",
            "Validation set: Average loss: 3.5177, Accuracy: 6075/10000 (61%)\n",
            "\n",
            "Train Epoch: 16 [50000/50000 (100%)]\tLoss: 0.000340\n",
            "\n",
            "Validation set: Average loss: 3.5117, Accuracy: 6091/10000 (61%)\n",
            "\n",
            "Train Epoch: 17 [50000/50000 (100%)]\tLoss: 0.000077\n",
            "\n",
            "Validation set: Average loss: 3.5592, Accuracy: 6120/10000 (61%)\n",
            "\n",
            "Train Epoch: 18 [50000/50000 (100%)]\tLoss: 0.000055\n",
            "\n",
            "Validation set: Average loss: 3.5976, Accuracy: 6114/10000 (61%)\n",
            "\n",
            "Train Epoch: 19 [50000/50000 (100%)]\tLoss: 0.000045\n",
            "\n",
            "Validation set: Average loss: 3.6289, Accuracy: 6115/10000 (61%)\n",
            "\n",
            "Train Epoch: 20 [50000/50000 (100%)]\tLoss: 0.000039\n",
            "\n",
            "Validation set: Average loss: 3.6563, Accuracy: 6117/10000 (61%)\n",
            "\n",
            "Train Epoch: 21 [50000/50000 (100%)]\tLoss: 0.000034\n",
            "\n",
            "Validation set: Average loss: 3.6809, Accuracy: 6118/10000 (61%)\n",
            "\n",
            "Train Epoch: 22 [50000/50000 (100%)]\tLoss: 0.000031\n",
            "\n",
            "Validation set: Average loss: 3.7036, Accuracy: 6121/10000 (61%)\n",
            "\n",
            "Train Epoch: 23 [50000/50000 (100%)]\tLoss: 0.000028\n",
            "\n",
            "Validation set: Average loss: 3.7243, Accuracy: 6123/10000 (61%)\n",
            "\n",
            "Train Epoch: 24 [50000/50000 (100%)]\tLoss: 0.000025\n",
            "\n",
            "Validation set: Average loss: 3.7434, Accuracy: 6126/10000 (61%)\n",
            "\n",
            "Train Epoch: 25 [50000/50000 (100%)]\tLoss: 0.000023\n",
            "\n",
            "Validation set: Average loss: 3.7609, Accuracy: 6125/10000 (61%)\n",
            "\n",
            "Train Epoch: 26 [50000/50000 (100%)]\tLoss: 0.000022\n",
            "\n",
            "Validation set: Average loss: 3.7772, Accuracy: 6123/10000 (61%)\n",
            "\n",
            "Train Epoch: 27 [50000/50000 (100%)]\tLoss: 0.000020\n",
            "\n",
            "Validation set: Average loss: 3.7927, Accuracy: 6124/10000 (61%)\n",
            "\n",
            "Train Epoch: 28 [50000/50000 (100%)]\tLoss: 0.000019\n",
            "\n",
            "Validation set: Average loss: 3.8071, Accuracy: 6124/10000 (61%)\n",
            "\n",
            "Train Epoch: 29 [50000/50000 (100%)]\tLoss: 0.000018\n",
            "\n",
            "Validation set: Average loss: 3.8210, Accuracy: 6124/10000 (61%)\n",
            "\n",
            "Train Epoch: 30 [50000/50000 (100%)]\tLoss: 0.000017\n",
            "\n",
            "Validation set: Average loss: 3.8341, Accuracy: 6128/10000 (61%)\n",
            "\n",
            "Train Epoch: 31 [50000/50000 (100%)]\tLoss: 0.000016\n",
            "\n",
            "Validation set: Average loss: 3.8467, Accuracy: 6127/10000 (61%)\n",
            "\n",
            "Train Epoch: 32 [50000/50000 (100%)]\tLoss: 0.000015\n",
            "\n",
            "Validation set: Average loss: 3.8586, Accuracy: 6128/10000 (61%)\n",
            "\n",
            "Train Epoch: 33 [50000/50000 (100%)]\tLoss: 0.000015\n",
            "\n",
            "Validation set: Average loss: 3.8701, Accuracy: 6130/10000 (61%)\n",
            "\n",
            "Train Epoch: 34 [50000/50000 (100%)]\tLoss: 0.000014\n",
            "\n",
            "Validation set: Average loss: 3.8813, Accuracy: 6128/10000 (61%)\n",
            "\n",
            "Train Epoch: 35 [50000/50000 (100%)]\tLoss: 0.000013\n",
            "\n",
            "Validation set: Average loss: 3.8918, Accuracy: 6127/10000 (61%)\n",
            "\n",
            "Train Epoch: 36 [50000/50000 (100%)]\tLoss: 0.000013\n",
            "\n",
            "Validation set: Average loss: 3.9019, Accuracy: 6125/10000 (61%)\n",
            "\n",
            "Train Epoch: 37 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 3.9118, Accuracy: 6128/10000 (61%)\n",
            "\n",
            "Train Epoch: 38 [50000/50000 (100%)]\tLoss: 0.000012\n",
            "\n",
            "Validation set: Average loss: 3.9214, Accuracy: 6130/10000 (61%)\n",
            "\n",
            "Train Epoch: 39 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 3.9306, Accuracy: 6130/10000 (61%)\n",
            "\n",
            "Train Epoch: 40 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 3.9396, Accuracy: 6132/10000 (61%)\n",
            "\n",
            "Train Epoch: 41 [50000/50000 (100%)]\tLoss: 0.000011\n",
            "\n",
            "Validation set: Average loss: 3.9482, Accuracy: 6134/10000 (61%)\n",
            "\n",
            "Train Epoch: 42 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 3.9566, Accuracy: 6136/10000 (61%)\n",
            "\n",
            "Train Epoch: 43 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 3.9647, Accuracy: 6140/10000 (61%)\n",
            "\n",
            "Train Epoch: 44 [50000/50000 (100%)]\tLoss: 0.000010\n",
            "\n",
            "Validation set: Average loss: 3.9726, Accuracy: 6141/10000 (61%)\n",
            "\n",
            "Train Epoch: 45 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 3.9803, Accuracy: 6142/10000 (61%)\n",
            "\n",
            "Train Epoch: 46 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 3.9877, Accuracy: 6143/10000 (61%)\n",
            "\n",
            "Train Epoch: 47 [50000/50000 (100%)]\tLoss: 0.000009\n",
            "\n",
            "Validation set: Average loss: 3.9951, Accuracy: 6144/10000 (61%)\n",
            "\n",
            "Train Epoch: 48 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.0023, Accuracy: 6144/10000 (61%)\n",
            "\n",
            "Train Epoch: 49 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.0092, Accuracy: 6145/10000 (61%)\n",
            "\n",
            "Train Epoch: 50 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.0160, Accuracy: 6145/10000 (61%)\n",
            "\n",
            "Train Epoch: 51 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.0226, Accuracy: 6144/10000 (61%)\n",
            "\n",
            "Train Epoch: 52 [50000/50000 (100%)]\tLoss: 0.000008\n",
            "\n",
            "Validation set: Average loss: 4.0291, Accuracy: 6144/10000 (61%)\n",
            "\n",
            "Train Epoch: 53 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.0354, Accuracy: 6142/10000 (61%)\n",
            "\n",
            "Train Epoch: 54 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.0416, Accuracy: 6143/10000 (61%)\n",
            "\n",
            "Train Epoch: 55 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.0476, Accuracy: 6144/10000 (61%)\n",
            "\n",
            "Train Epoch: 56 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.0536, Accuracy: 6143/10000 (61%)\n",
            "\n",
            "Train Epoch: 57 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.0594, Accuracy: 6143/10000 (61%)\n",
            "\n",
            "Train Epoch: 58 [50000/50000 (100%)]\tLoss: 0.000007\n",
            "\n",
            "Validation set: Average loss: 4.0651, Accuracy: 6141/10000 (61%)\n",
            "\n",
            "Train Epoch: 59 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.0707, Accuracy: 6144/10000 (61%)\n",
            "\n",
            "Train Epoch: 60 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.0761, Accuracy: 6144/10000 (61%)\n",
            "\n",
            "Train Epoch: 61 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.0815, Accuracy: 6144/10000 (61%)\n",
            "\n",
            "Train Epoch: 62 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.0868, Accuracy: 6144/10000 (61%)\n",
            "\n",
            "Train Epoch: 63 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.0920, Accuracy: 6144/10000 (61%)\n",
            "\n",
            "Train Epoch: 64 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.0970, Accuracy: 6144/10000 (61%)\n",
            "\n",
            "Train Epoch: 65 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.1020, Accuracy: 6144/10000 (61%)\n",
            "\n",
            "Train Epoch: 66 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.1070, Accuracy: 6143/10000 (61%)\n",
            "\n",
            "Train Epoch: 67 [50000/50000 (100%)]\tLoss: 0.000006\n",
            "\n",
            "Validation set: Average loss: 4.1118, Accuracy: 6144/10000 (61%)\n",
            "\n",
            "Train Epoch: 68 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.1165, Accuracy: 6144/10000 (61%)\n",
            "\n",
            "Train Epoch: 69 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.1212, Accuracy: 6145/10000 (61%)\n",
            "\n",
            "Train Epoch: 70 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.1259, Accuracy: 6144/10000 (61%)\n",
            "\n",
            "Train Epoch: 71 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.1304, Accuracy: 6145/10000 (61%)\n",
            "\n",
            "Train Epoch: 72 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.1348, Accuracy: 6145/10000 (61%)\n",
            "\n",
            "Train Epoch: 73 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.1393, Accuracy: 6145/10000 (61%)\n",
            "\n",
            "Train Epoch: 74 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.1436, Accuracy: 6145/10000 (61%)\n",
            "\n",
            "Train Epoch: 75 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.1478, Accuracy: 6145/10000 (61%)\n",
            "\n",
            "Train Epoch: 76 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.1520, Accuracy: 6146/10000 (61%)\n",
            "\n",
            "Train Epoch: 77 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.1562, Accuracy: 6147/10000 (61%)\n",
            "\n",
            "Train Epoch: 78 [50000/50000 (100%)]\tLoss: 0.000005\n",
            "\n",
            "Validation set: Average loss: 4.1602, Accuracy: 6148/10000 (61%)\n",
            "\n",
            "Train Epoch: 79 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 4.1643, Accuracy: 6148/10000 (61%)\n",
            "\n",
            "Train Epoch: 80 [50000/50000 (100%)]\tLoss: 0.000004\n",
            "\n",
            "Validation set: Average loss: 4.1683, Accuracy: 6150/10000 (62%)\n",
            "\n"
          ]
        }
      ]
    }
  ]
}